"Radio-frequency fingerprints~(RFFs) are promising solutions for realizing low-cost physical layer authentication. Machine learning-based methods have been proposed for RFF extraction and discrimination. However, most existing methods are designed for the closed-set scenario where the set of devices is remains unchanged. These methods can not be generalized to the RFF discrimination of unknown devices. To enable the discrimination of RFF from both known and unknown devices, we propose a new end-to-end deep learning framework for extracting RFFs from raw received signals. The proposed framework comprises a novel preprocessing module, called neural synchronization~(NS), which incorporates the data-driven learning with signal processing priors as an inductive bias from communication-model based processing. Compared to traditional carrier synchronization techniques, which are static, this module estimates offsets by two learnable deep neural networks jointly trained by the RFF extractor. Additionally, a hypersphere representation is proposed to further improve the discrimination of RFF. Theoretical analysis shows that such a data-and-model framework can better optimize the mutual information between device identity and the RFF, which naturally leads to better performance. Experimental results verify that the proposed RFF significantly outperforms purely data-driven DNN-design and existing handcrafted RFF methods in terms of both discrimination and network generalizability.",0
"Radio-frequency fingerprints (RFFs) show potential in achieving low-cost physical layer authentication. To extract and differentiate RFFs, machine learning-based methods have been proposed, but most of them are only applicable in a closed-set scenario where the set of devices remains the same. These methods cannot be generalized for identifying RFFs from unknown devices. To address this issue, we introduce an end-to-end deep learning framework for extracting RFFs from unprocessed received signals. The framework includes a novel preprocessing module, called neural synchronization (NS), that combines data-driven learning with communication-model based processing. Unlike traditional carrier synchronization techniques, which are static, NS uses two learnable deep neural networks to estimate offsets. Additionally, we propose a hypersphere representation to further improve RFF differentiation. Theoretical analysis shows that this data-and-model framework optimizes mutual information between device identity and RFF, leading to better performance. Experimental results demonstrate that our RFF outperforms purely data-driven DNN-designed and existing handcrafted RFF methods in terms of discrimination and network generalizability.",1
"Simulating physical systems is a core component of scientific computing, encompassing a wide range of physical domains and applications. Recently, there has been a surge in data-driven methods to complement traditional numerical simulations methods, motivated by the opportunity to reduce computational costs and/or learn new physical models leveraging access to large collections of data. However, the diversity of problem settings and applications has led to a plethora of approaches, each one evaluated on a different setup and with different evaluation metrics. We introduce a set of benchmark problems to take a step towards unified benchmarks and evaluation protocols. We propose four representative physical systems, as well as a collection of both widely used classical time integrators and representative data-driven methods (kernel-based, MLP, CNN, nearest neighbors). Our framework allows evaluating objectively and systematically the stability, accuracy, and computational efficiency of data-driven methods. Additionally, it is configurable to permit adjustments for accommodating other learning tasks and for establishing a foundation for future developments in machine learning for scientific computing.",0
"In scientific computing, simulating physical systems is a crucial aspect that covers a broad spectrum of physical domains and applications. In recent times, data-driven approaches have gained momentum to supplement conventional numerical simulation methods, with the aim of reducing computational costs and discovering new physical models by utilizing vast data collections. However, due to the varied problem settings and applications, there are numerous approaches, each evaluated on different criteria and in distinct settings. To address this issue, we have created a set of benchmark problems to establish a standardized evaluation protocol. Our proposal includes four representative physical systems and a comprehensive collection of classical time integrators and data-driven methods, such as kernel-based, MLP, CNN, and nearest neighbors. Our framework allows for objective and systematic evaluations of stability, accuracy, and computational efficiency of data-driven methods. Furthermore, it is adaptable to accommodate other learning tasks and to serve as a foundation for future developments in machine learning for scientific computing.",1
"We present a novel and flexible architecture for point cloud segmentation with dual-representation iterative learning. In point cloud processing, different representations have their own pros and cons. Thus, finding suitable ways to represent point cloud data structure while keeping its own internal physical property such as permutation and scale-invariant is a fundamental problem. Therefore, we propose our work, DRINet, which serves as the basic network structure for dual-representation learning with great flexibility at feature transferring and less computation cost, especially for large-scale point clouds. DRINet mainly consists of two modules called Sparse Point-Voxel Feature Extraction and Sparse Voxel-Point Feature Extraction. By utilizing these two modules iteratively, features can be propagated between two different representations. We further propose a novel multi-scale pooling layer for pointwise locality learning to improve context information propagation. Our network achieves state-of-the-art results for point cloud classification and segmentation tasks on several datasets while maintaining high runtime efficiency. For large-scale outdoor scenarios, our method outperforms state-of-the-art methods with a real-time inference speed of 62ms per frame.",0
"Introducing our latest development in point cloud segmentation using dual-representation iterative learning, we address the challenge of finding appropriate methods for representing point cloud data structure that preserves its internal physical properties, such as permutation and scale invariance. Our solution, DRINet, is a flexible network architecture that provides efficient feature transfer and low computation cost for larger point clouds. The DRINet is composed of two modules: Sparse Point-Voxel Feature Extraction and Sparse Voxel-Point Feature Extraction, which enable the iterative propagation of features between different representations. We have also introduced a new multi-scale pooling layer that enhances the context information propagation for pointwise locality learning. Our network has achieved remarkable results for point cloud classification and segmentation tasks on various datasets, with high runtime efficiency. Notably, our method has outperformed state-of-the-art techniques for large-scale outdoor scenarios with a real-time inference speed of 62ms per frame.",1
"The first known case of Coronavirus disease 2019 (COVID-19) was identified in December 2019. It has spread worldwide, leading to an ongoing pandemic, imposed restrictions and costs to many countries. Predicting the number of new cases and deaths during this period can be a useful step in predicting the costs and facilities required in the future. The purpose of this study is to predict new cases and deaths rate one, three and seven-day ahead during the next 100 days. The motivation for predicting every n days (instead of just every day) is the investigation of the possibility of computational cost reduction and still achieving reasonable performance. Such a scenario may be encountered real-time forecasting of time series. Six different deep learning methods are examined on the data adopted from the WHO website. Three methods are LSTM, Convolutional LSTM, and GRU. The bidirectional extension is then considered for each method to forecast the rate of new cases and new deaths in Australia and Iran countries.",0
"The COVID-19 outbreak was first discovered in December 2019 and has since spread globally, resulting in a pandemic that has impacted many countries with restrictions and expenses. In order to anticipate future costs and resources needed, it is helpful to forecast the number of new cases and deaths. This study aims to predict the rates of new cases and deaths for the next 100 days, at intervals of one, three, and seven days. By predicting at intervals, the study seeks to reduce computational costs while maintaining reasonable accuracy. The data used for the study is taken from the WHO website, and six deep learning methods are examined including LSTM, Convolutional LSTM, and GRU. The study also incorporates bidirectional extensions to forecast the rates of new cases and deaths in Australia and Iran.",1
"Forecasting the trajectory of pedestrians in shared urban traffic environments is still considered one of the challenging problems facing the development of autonomous vehicles (AVs). In the literature, this problem is often tackled using recurrent neural networks (RNNs). Despite the powerful capabilities of RNNs in capturing the temporal dependency in the pedestrians' motion trajectories, they were argued to be challenged when dealing with longer sequential data. Thus, in this work, we are introducing a framework based on the transformer networks that were shown recently to be more efficient and outperformed RNNs in many sequential-based tasks. We relied on a fusion of the past positional information, agent interactions information and scene physical semantics information as an input to our framework in order to provide a robust trajectory prediction of pedestrians. We have evaluated our framework on two real-life datasets of pedestrians in shared urban traffic environments and it has outperformed the compared baseline approaches in both short-term and long-term prediction horizons.",0
"One of the most difficult challenges facing the development of autonomous vehicles (AVs) is predicting the movement of pedestrians in shared urban traffic environments. To address this issue, recurrent neural networks (RNNs) are often used in the literature. However, RNNs struggle with longer sequences of data despite their ability to capture temporal dependencies in pedestrian motion. In this study, we present a framework based on transformer networks, which have recently been shown to outperform RNNs in many sequential-based tasks. Our framework uses a combination of past positional information, agent interactions information, and scene physical semantics information to predict pedestrian trajectories accurately. We evaluated our framework on two real-life pedestrian datasets in shared urban traffic environments and found that it outperformed other baseline approaches in both short-term and long-term prediction horizons.",1
"Gradient-based algorithms are crucial to modern computer-vision and graphics applications, enabling learning-based optimization and inverse problems. For example, photorealistic differentiable rendering pipelines for color images have been proven highly valuable to applications aiming to map 2D and 3D domains. However, to the best of our knowledge, no effort has been made so far towards extending these gradient-based methods to the generation of depth (2.5D) images, as simulating structured-light depth sensors implies solving complex light transport and stereo-matching problems. In this paper, we introduce a novel end-to-end differentiable simulation pipeline for the generation of realistic 2.5D scans, built on physics-based 3D rendering and custom block-matching algorithms. Each module can be differentiated w.r.t sensor and scene parameters; e.g., to automatically tune the simulation for new devices over some provided scans or to leverage the pipeline as a 3D-to-2.5D transformer within larger computer-vision applications. Applied to the training of deep-learning methods for various depth-based recognition tasks (classification, pose estimation, semantic segmentation), our simulation greatly improves the performance of the resulting models on real scans, thereby demonstrating the fidelity and value of its synthetic depth data compared to previous static simulations and learning-based domain adaptation schemes.",0
"Modern computer-vision and graphics applications rely heavily on gradient-based algorithms for learning-based optimization and solving inverse problems. These algorithms have proved highly valuable in creating photorealistic differentiable rendering pipelines for color images and mapping 2D and 3D domains. However, generating depth images has been challenging due to the complex light transport and stereo-matching problems involved when simulating structured-light depth sensors. In this paper, we present a novel end-to-end differentiable simulation pipeline that uses physics-based 3D rendering and custom block-matching algorithms to generate realistic 2.5D scans. Each module of the pipeline can be differentiated with respect to sensor and scene parameters, allowing for automatic tuning for new devices and use as a 3D-to-2.5D transformer within larger computer-vision applications. Our simulation greatly improves the performance of deep-learning methods for various depth-based recognition tasks, demonstrating the fidelity and value of its synthetic depth data compared to previous static simulations and learning-based domain adaptation schemes.",1
"Time-series data are one of the fundamental types of raw data representation used in data-driven techniques. In machine condition monitoring, time-series vibration data are overly used in data mining for deep neural networks. Typically, vibration data is converted into images for classification using Deep Neural Networks (DNNs), and scalograms are the most effective form of image representation. However, the DNN classifiers require huge labeled training samples to reach their optimum performance. So, many forms of data augmentation techniques are applied to the classifiers to compensate for the lack of training samples. However, the scalograms are graphical representations where the existing augmentation techniques suffer because they either change the graphical meaning or have too much noise in the samples that change the physical meaning. In this study, a data augmentation technique named ensemble augmentation is proposed to overcome this limitation. This augmentation method uses the power of white noise added in ensembles to the original samples to generate real-like samples. After averaging the signal with ensembles, a new signal is obtained that contains the characteristics of the original signal. The parameters for the ensemble augmentation are validated using a simulated signal. The proposed method is evaluated using 10 class bearing vibration data using three state-of-the-art Transfer Learning (TL) models, namely, Inception-V3, MobileNet-V2, and ResNet50. Augmented samples are generated in two increments: the first increment generates the same number of fake samples as the training samples, and in the second increment, the number of samples is increased gradually. The outputs from the proposed method are compared with no augmentation, augmentations using deep convolution generative adversarial network (DCGAN), and several geometric transformation-based augmentations...",0
"Data-driven techniques rely on various types of raw data representation, and time-series data are considered fundamental. In machine condition monitoring, time-series vibration data are commonly used for data mining through deep neural networks, which typically require vibration data to be converted into images for classification. Scalograms are the most effective form of image representation, but DNN classifiers need a large number of labeled training samples to achieve optimal performance. To compensate for the lack of training samples, various data augmentation techniques are applied; however, scalograms present challenges for existing augmentation techniques due to changes in graphical or physical meaning. This study proposes an ensemble augmentation technique that adds white noise in ensembles to original samples to generate real-like samples. The proposed method is evaluated using 10 class bearing vibration data with three Transfer Learning models, and the outputs are compared with other augmentation methods, including DCGAN and geometric transformation-based augmentations.",1
"Single image dehazing is a challenging task, for which the domain shift between synthetic training data and real-world testing images usually leads to degradation of existing methods. To address this issue, we propose a novel image dehazing framework collaborating with unlabeled real data. First, we develop a disentangled image dehazing network (DID-Net), which disentangles the feature representations into three component maps, i.e. the latent haze-free image, the transmission map, and the global atmospheric light estimate, respecting the physical model of a haze process. Our DID-Net predicts the three component maps by progressively integrating features across scales, and refines each map by passing an independent refinement network. Then a disentangled-consistency mean-teacher network (DMT-Net) is employed to collaborate unlabeled real data for boosting single image dehazing. Specifically, we encourage the coarse predictions and refinements of each disentangled component to be consistent between the student and teacher networks by using a consistency loss on unlabeled real data. We make comparison with 13 state-of-the-art dehazing methods on a new collected dataset (Haze4K) and two widely-used dehazing datasets (i.e., SOTS and HazeRD), as well as on real-world hazy images. Experimental results demonstrate that our method has obvious quantitative and qualitative improvements over the existing methods.",0
"Single image dehazing is a difficult task as existing methods often deteriorate due to the domain shift between synthetic training data and real-world testing images. To overcome this challenge, we present a new approach to image dehazing that employs unlabeled real data. Our framework involves developing a disentangled image dehazing network (DID-Net) that separates feature representations into three component maps, including the latent haze-free image, the transmission map, and the global atmospheric light estimate. Our method progressively integrates features across scales and refines each map using an independent refinement network. Additionally, we use a disentangled-consistency mean-teacher network (DMT-Net) to collaborate with unlabeled real data for boosting single image dehazing. By using a consistency loss on unlabeled real data, we ensure that the coarse predictions and refinements of each disentangled component are consistent between the student and teacher networks. We compare our approach with 13 state-of-the-art dehazing methods on various datasets and real-world hazy images. Our experimental results demonstrate that our method significantly improves upon existing methods both quantitatively and qualitatively.",1
"Catastrophic forgetting describes the fact that machine learning models will likely forget the knowledge of previously learned tasks after the learning process of a new one. It is a vital problem in the continual learning scenario and recently has attracted tremendous concern across different communities. In this paper, we explore the catastrophic forgetting phenomena in the context of quantum machine learning. We find that, similar to those classical learning models based on neural networks, quantum learning systems likewise suffer from such forgetting problem in classification tasks emerging from various application scenes. We show that based on the local geometrical information in the loss function landscape of the trained model, a uniform strategy can be adapted to overcome the forgetting problem in the incremental learning setting. Our results uncover the catastrophic forgetting phenomena in quantum machine learning and offer a practical method to overcome this problem, which opens a new avenue for exploring potential quantum advantages towards continual learning.",0
"The phenomenon of catastrophic forgetting occurs when a machine learning model loses the knowledge of previously learned tasks after acquiring new ones. This problem is particularly concerning in continual learning and has gained significant attention from various communities. In this study, we investigate the occurrence of catastrophic forgetting in quantum machine learning. Our findings indicate that similar to classical learning models based on neural networks, quantum learning systems also face this issue in classification tasks across different application scenarios. We demonstrate that by utilizing the local geometric information in the loss function landscape of the trained model, a uniform approach can be employed to address the forgetting problem in the incremental learning setting. Our results highlight the occurrence of catastrophic forgetting in quantum machine learning and provide a practical solution to overcome this challenge, which opens up new avenues for exploring the potential benefits of quantum technology in continual learning.",1
"In this paper, we propose neural networks that tackle the problems of stability and field-of-view of a Convolutional Neural Network (CNN). As an alternative to increasing the network's depth or width to improve performance, we propose integral-based spatially nonlocal operators which are related to global weighted Laplacian, fractional Laplacian and inverse fractional Laplacian operators that arise in several problems in the physical sciences. The forward propagation of such networks is inspired by partial integro-differential equations (PIDEs). We test the effectiveness of the proposed neural architectures on benchmark image classification datasets and semantic segmentation tasks in autonomous driving. Moreover, we investigate the extra computational costs of these dense operators and the stability of forward propagation of the proposed neural networks.",0
"The aim of this paper is to introduce neural networks that address issues related to stability and field-of-view in Convolutional Neural Networks (CNNs). Instead of relying on increasing the depth or width of the network to improve performance, we propose using spatially nonlocal operators that are integral-based and linked to various global weighted Laplacian, fractional Laplacian, and inverse fractional Laplacian operators commonly used in physical sciences. The forward propagation of these networks is inspired by partial integro-differential equations (PIDEs). To evaluate the effectiveness of these neural architectures, we conduct experiments on standard image classification datasets and semantic segmentation tasks in autonomous driving. Additionally, we analyze the extra computational costs incurred by these dense operators and examine the stability of forward propagation in our proposed neural networks.",1
"Image-based navigation is widely considered the next frontier of minimally invasive surgery. It is believed that image-based navigation will increase the access to reproducible, safe, and high-precision surgery as it may then be performed at acceptable costs and effort. This is because image-based techniques avoid the need of specialized equipment and seamlessly integrate with contemporary workflows. Further, it is expected that image-based navigation will play a major role in enabling mixed reality environments and autonomous, robotic workflows. A critical component of image guidance is 2D/3D registration, a technique to estimate the spatial relationships between 3D structures, e.g., volumetric imagery or tool models, and 2D images thereof, such as fluoroscopy or endoscopy. While image-based 2D/3D registration is a mature technique, its transition from the bench to the bedside has been restrained by well-known challenges, including brittleness of the optimization objective, hyperparameter selection, and initialization, difficulties around inconsistencies or multiple objects, and limited single-view performance. One reason these challenges persist today is that analytical solutions are likely inadequate considering the complexity, variability, and high-dimensionality of generic 2D/3D registration problems. The recent advent of machine learning-based approaches to imaging problems that, rather than specifying the desired functional mapping, approximate it using highly expressive parametric models holds promise for solving some of the notorious challenges in 2D/3D registration. In this manuscript, we review the impact of machine learning on 2D/3D registration to systematically summarize the recent advances made by introduction of this novel technology. Grounded in these insights, we then offer our perspective on the most pressing needs, significant open problems, and possible next steps.",0
"The next frontier of minimally invasive surgery is believed to be image-based navigation, which is expected to increase the accessibility of safe and precise surgery at reasonable costs and effort. Image-based techniques seamlessly integrate with current workflows and eliminate the need for specialized equipment. Moreover, image-based navigation is expected to facilitate mixed reality environments and autonomous, robotic workflows. However, the transition of image-based 2D/3D registration from the laboratory to the clinical setting has been impeded by various challenges, including optimization objectives, hyperparameter selection, initialization, inconsistencies or multiple objects, and limited single-view performance. Analytical solutions are insufficient for these issues due to the complexity, variability, and high-dimensionality of generic 2D/3D registration problems. Nevertheless, the recent emergence of machine learning-based approaches that use highly expressive parametric models to approximate the desired functional mapping holds promise for addressing some of these challenges. This paper reviews the impact of machine learning on 2D/3D registration, summarizes the recent advances, and provides insights into the most pressing needs, significant open problems, and potential next steps.",1
"The performance of machine learning algorithms used for the segmentation of 3D biomedical images lags behind that of the algorithms employed in the classification of 2D photos. This may be explained by the comparative lack of high-volume, high-quality training datasets, which require state-of-the art imaging facilities, domain experts for annotation and large computational and personal resources to create. The HR-Kidney dataset presented in this work bridges this gap by providing 1.7 TB of artefact-corrected synchrotron radiation-based X-ray phase-contrast microtomography images of whole mouse kidneys and validated segmentations of 33 729 glomeruli, which represents a 1-2 orders of magnitude increase over currently available biomedical datasets. The dataset further contains the underlying raw data, classical segmentations of renal vasculature and uriniferous tubules, as well as true 3D manual annotations. By removing limits currently imposed by small training datasets, the provided data open up the possibility for disruptions in machine learning for biomedical image analysis.",0
"The performance of machine learning algorithms in segmenting 3D biomedical images is not as advanced as those used for classifying 2D photos. This could be attributed to the scarcity of high-quality training datasets that require modern imaging equipment, expert annotators, and significant computational and personal resources to create. However, the HR-Kidney dataset presented in this study overcomes this issue by providing 1.7 TB of synchrotron radiation-based X-ray phase-contrast microtomography images of whole mouse kidneys and verified segmentations of 33,729 glomeruli, which is a significant increase compared to the current biomedical datasets. The dataset also includes raw data, conventional segmentations of renal vasculature and uriniferous tubules, and true 3D manual annotations. By eliminating the limitations of small training datasets, this data can revolutionize machine learning in biomedical image analysis.",1
"So far, numerous learned models have been pressed to use in microwave imaging problems. These models however, are oblivious to the imaging geometry. It has always been hard to bake the physical setup of the imaging array into the structure of the network, resulting in a data-intensive models that are not practical. This work put forward a graph formulation of the microwave imaging array. The architectures proposed is made cognizant of the physical setup, allowing it to incorporate the symmetries, resulting in a less data requirements. Graph convolution and attention mechanism is deployed to handle the cases of fully-connected graphs corresponding to multi-static arrays. The graph-treatment of the problem is evaluated on experimental setup in context of brain anomaly localization with microwave imaging.",0
"Several sophisticated models have been employed for microwave imaging problems, but they lack awareness of the imaging geometry, making them impractical due to their data-intensive nature. To address this, a graph formulation of the microwave imaging array was proposed, which considers the physical setup and incorporates symmetries, resulting in reduced data requirements. Graph convolution and attention mechanism were used to handle fully-connected graphs associated with multi-static arrays. The effectiveness of the graph approach was evaluated in a brain anomaly localization experiment using microwave imaging.",1
"Slice Sampling has emerged as a powerful Markov Chain Monte Carlo algorithm that adapts to the characteristics of the target distribution with minimal hand-tuning. However, Slice Sampling's performance is highly sensitive to the user-specified initial length scale hyperparameter and the method generally struggles with poorly scaled or strongly correlated distributions. This paper introduces Ensemble Slice Sampling (ESS), a new class of algorithms that bypasses such difficulties by adaptively tuning the initial length scale and utilising an ensemble of parallel walkers in order to efficiently handle strong correlations between parameters. These affine-invariant algorithms are trivial to construct, require no hand-tuning, and can easily be implemented in parallel computing environments. Empirical tests show that Ensemble Slice Sampling can improve efficiency by more than an order of magnitude compared to conventional MCMC methods on a broad range of highly correlated target distributions. In cases of strongly multimodal target distributions, Ensemble Slice Sampling can sample efficiently even in high dimensions. We argue that the parallel, black-box and gradient-free nature of the method renders it ideal for use in scientific fields such as physics, astrophysics and cosmology which are dominated by a wide variety of computationally expensive and non-differentiable models.",0
"Slice Sampling is a notable Markov Chain Monte Carlo algorithm that can easily adapt to the characteristics of the target distribution with minimal adjustments. However, it is susceptible to issues such as the specified initial length scale hyperparameter and struggles with poorly scaled or strongly correlated distributions. To address these challenges, Ensemble Slice Sampling (ESS) has been introduced as a new class of algorithms. ESS can dynamically adjust the initial length scale and employ a group of parallel walkers to handle strong correlations between parameters. The affine-invariant algorithms are simple to develop, require no manual adjustments, and can be implemented in parallel computing environments. Empirical tests indicate that ESS can improve efficiency by over 10 times compared to conventional MCMC methods on a wide range of highly correlated target distributions. Furthermore, ESS can efficiently sample even in high dimensions when the target distribution is strongly multimodal. The method's parallel, black-box, and gradient-free nature makes it an excellent candidate for use in scientific fields such as physics, astrophysics, and cosmology, which have various computationally expensive and non-differentiable models.",1
"Physical reservoir computing is a computational paradigm that enables temporal pattern recognition to be performed directly in physical matter. By exciting non-linear dynamical systems and linearly classifying their changes in state, we can create highly energy-efficient devices capable of solving machine learning tasks without the need to build a modular system consisting of millions of neurons interconnected by synapses. The chosen dynamical system must have three desirable properties: non-linearity, complexity, and fading memory to act as an effective reservoir. We present task agnostic quantitative measures for each of these three requirements and exemplify them for two reservoirs: an echo state network and a simulated magnetic skyrmion-based reservoir. We show that, in general, systems with lower damping reach higher values in all three performance metrics. Whilst for input signal strength, there is a natural trade-off between memory capacity and non-linearity of the reservoir's behaviour. In contrast to typical task-dependent reservoir computing benchmarks, these metrics can be evaluated in parallel from a single input signal, drastically speeding up the parameter search to design efficient and high-performance reservoirs.",0
"Physical reservoir computing is a computational approach that enables direct temporal pattern recognition in physical matter. By exciting non-linear dynamical systems and linearly classifying their state changes, energy-efficient devices can be developed for machine learning tasks, without the need for a modular system with millions of interconnected neurons. To be an effective reservoir, the chosen dynamical system must possess non-linearity, complexity, and fading memory, which can be measured quantitatively. Two reservoirs, an echo state network and a simulated magnetic skyrmion-based reservoir, are used as examples. Lower damping systems generally perform better in all three metrics, while a trade-off exists between memory capacity and non-linearity for input signal strength. These metrics can be evaluated in parallel from a single input signal, speeding up the parameter search for efficient and high-performance reservoirs compared to task-specific benchmarks.",1
"The method recently introduced in arXiv:2011.10115 realizes a deep neural network with just a single nonlinear element and delayed feedback. It is applicable for the description of physically implemented neural networks. In this work, we present an infinite-dimensional generalization, which allows for a more rigorous mathematical analysis and a higher flexibility in choosing the weight functions. Precisely speaking, the weights are described by Lebesgue integrable functions instead of step functions. We also provide a functional back-propagation algorithm, which enables gradient descent training of the weights. In addition, with a slight modification, our concept realizes recurrent neural networks.",0
"A recent arXiv publication, identified as arXiv:2011.10115, has introduced a novel technique for constructing a deep neural network that utilizes only a single nonlinear element and delayed feedback. This methodology is useful for modeling physically implemented neural networks. In our research, we propose an infinite-dimensional extension, which facilitates a more rigorous mathematical analysis and greater flexibility in selecting weight functions. Specifically, we adopt Lebesgue integrable functions instead of step functions to describe the weights. We also provide a functional back-propagation algorithm that allows for gradient descent training of the weights. Furthermore, our approach can be adapted to construct recurrent neural networks.",1
"Reinforcement learning from large-scale offline datasets provides us with the ability to learn policies without potentially unsafe or impractical exploration. Significant progress has been made in the past few years in dealing with the challenge of correcting for differing behavior between the data collection and learned policies. However, little attention has been paid to potentially changing dynamics when transferring a policy to the online setting, where performance can be up to 90% reduced for existing methods. In this paper we address this problem with Augmented World Models (AugWM). We augment a learned dynamics model with simple transformations that seek to capture potential changes in physical properties of the robot, leading to more robust policies. We not only train our policy in this new setting, but also provide it with the sampled augmentation as a context, allowing it to adapt to changes in the environment. At test time we learn the context in a self-supervised fashion by approximating the augmentation which corresponds to the new environment. We rigorously evaluate our approach on over 100 different changed dynamics settings, and show that this simple approach can significantly improve the zero-shot generalization of a recent state-of-the-art baseline, often achieving successful policies where the baseline fails.",0
"Learning policies from large-scale offline datasets through reinforcement is a safer and more practical alternative to exploration. While progress has been made in adjusting for discrepancies between data collection and learned policies, little attention has been given to the potential changes in dynamics when transferring policies to an online setting. Existing methods can result in up to 90% performance reduction. Our paper introduces Augmented World Models (AugWM) to address this issue. We enhance a learned dynamics model with basic transformations to account for potential changes in the robot's physical properties, leading to more robust policies. Our approach not only trains policies in this new setting but also provides them with the sampled augmentation as context to adapt to environmental changes. At test time, we learn the context in a self-supervised manner by approximating the corresponding augmentation in the new environment. We evaluate our method on over 100 different dynamics settings and show that AugWM significantly improves zero-shot generalization compared to a recent state-of-the-art baseline, often resulting in successful policies where the baseline fails.",1
"The work in this paper focuses on the role of machine learning in assessing the correctness of a human motion or action. This task proves to be more challenging than the gesture and action recognition ones. We will demonstrate, through a set of experiments on a recent dataset, that machine learning algorithms can produce good results for certain actions, but can also fall into the trap of classifying an incorrect execution of an action as a correct execution of another action.",0
"This paper emphasizes the significance of machine learning in evaluating the accuracy of human motion or action, which is a more difficult task compared to recognizing gestures and actions. By conducting experiments on a recent dataset, we will present that while certain actions can be accurately classified by machine learning algorithms, there is a possibility of misclassifying an inaccurate execution of an action as an accurate execution of a distinct action.",1
"Photoelastic techniques have a long tradition in both qualitative and quantitative analysis of the stresses in granular materials. Over the last two decades, computational methods for reconstructing forces between particles from their photoelastic response have been developed by many different experimental teams. Unfortunately, all of these methods are computationally expensive. This limits their use for processing extensive data sets that capture the time evolution of granular ensembles consisting of a large number of particles. In this paper, we present a novel approach to this problem which leverages the power of convolutional neural networks to recognize complex spatial patterns. The main drawback of using neural networks is that training them usually requires a large labeled data set which is hard to obtain experimentally. We show that this problem can be successfully circumvented by pretraining the networks on a large synthetic data set and then fine-tuning them on much smaller experimental data sets. Due to our current lack of experimental data, we demonstrate the potential of our method by changing the size of the considered particles which alters the exhibited photoelastic patterns more than typical experimental errors.",0
"For many years, photoelastic methods have been used to analyze stresses in granular materials both qualitatively and quantitatively. However, the development of computational techniques for reconstructing forces between particles from their photoelastic response has been limited due to their high computational cost. This has made it difficult to process large data sets capturing the time evolution of granular ensembles with many particles. To address this issue, we propose a new method that uses convolutional neural networks to recognize complex spatial patterns. While training neural networks requires a large labeled data set, we show that pretraining them on synthetic data sets and fine-tuning them on smaller experimental data sets can successfully overcome this problem. Although we currently lack experimental data, we demonstrate the potential of our approach by altering the size of the particles to generate different photoelastic patterns.",1
"The efficiency and reliability of real-time incident detection models directly impact the affected corridors' traffic safety and operational conditions. The recent emergence of cloud-based quantum computing infrastructure and innovations in noisy intermediate-scale quantum devices have revealed a new era of quantum-enhanced algorithms that can be leveraged to improve real-time incident detection accuracy. In this research, a hybrid machine learning model, which includes classical and quantum machine learning (ML) models, is developed to identify incidents using the connected vehicle (CV) data. The incident detection performance of the hybrid model is evaluated against baseline classical ML models. The framework is evaluated using data from a microsimulation tool for different incident scenarios. The results indicate that a hybrid neural network containing a 4-qubit quantum layer outperforms all other baseline models when there is a lack of training data. We have created three datasets; DS-1 with sufficient training data, and DS-2 and DS-3 with insufficient training data. The hybrid model achieves a recall of 98.9%, 98.3%, and 96.6% for DS-1, DS-2, and DS-3, respectively. For DS-2 and DS-3, the average improvement in F2-score (measures model's performance to correctly identify incidents) achieved by the hybrid model is 1.9% and 7.8%, respectively, compared to the classical models. It shows that with insufficient data, which may be common for CVs, the hybrid ML model will perform better than the classical models. With the continuing improvements of quantum computing infrastructure, the quantum ML models could be a promising alternative for CV-related applications when the available data is insufficient.",0
"Real-time incident detection models have a direct impact on traffic safety and operational conditions in affected corridors. The emergence of cloud-based quantum computing infrastructure and advancements in noisy intermediate-scale quantum devices have introduced a new era of quantum-enhanced algorithms that can improve the accuracy of incident detection. This research develops a hybrid machine learning model, incorporating both classical and quantum machine learning, to identify incidents using connected vehicle data. The hybrid model's incident detection performance is compared to baseline classical machine learning models using data from a microsimulation tool for various incident scenarios. Results show that the hybrid model outperforms all baseline models, especially with a lack of training data. The hybrid model achieves high recall percentages for datasets with sufficient and insufficient training data and improves the F2-score compared to classical models for datasets with insufficient training data. With the ongoing advancements of quantum computing infrastructure, quantum machine learning models may be a promising alternative for connected vehicle-related applications with insufficient data.",1
"A synergistic approach for optimizing devices, circuits, and neural network architectures was used to abate junction-temperature-change-induced performance degradation of a Fe-FinFET-based artificial neural network. We demonstrated that the digital nature of the binarized neural network, with the ""0"" state programmed deep in the subthreshold and the ""1"" state in strong inversion, is crucial for robust DNN inference. The performance of a purely software-based binary neural network (BNN), with 96.1% accuracy for Modified National Institute of Standards and Technology (MNIST) handwritten digit recognition, was used as a baseline. The Fe-FinFET-based BNN (including device-to-device variation at 300 K) achieved 95.7% inference accuracy on the MNIST dataset. Although substantial inference accuracy degradation with temperature change was observed in a nonbinary neural network, the BNN with optimized Fe-FinFETs as synaptic devices had excellent resistance to temperature change effects and maintained a minimum inference accuracy of 95.2% within a temperature range of -233K to 398K after gate stack and bias optimization. However, reprogramming to adjust device conductance was necessary for temperatures higher than 398K.",0
"To prevent the decline in performance caused by changes in junction temperature in a Fe-FinFET-based artificial neural network, a synergistic approach was employed to optimize devices, circuits, and neural network architectures. It was found that the digital nature of the binarized neural network, with ""0"" state programmed deep in the subthreshold and ""1"" state in strong inversion, was crucial for robust DNN inference. A software-based binary neural network (BNN) with 96.1% accuracy for Modified National Institute of Standards and Technology (MNIST) handwritten digit recognition was used as a baseline. The Fe-FinFET-based BNN achieved an accuracy of 95.7% on the MNIST dataset, including device-to-device variation at 300 K. The nonbinary neural network showed significant inference accuracy degradation with temperature change, but the BNN with optimized Fe-FinFETs as synaptic devices had excellent resistance to temperature change effects and maintained a minimum inference accuracy of 95.2% in a temperature range of -233K to 398K after gate stack and bias optimization. However, device conductance reprogramming was necessary for temperatures higher than 398K.",1
"Application of underwater robots are on the rise, most of them are dependent on sonar for underwater vision, but the lack of strong perception capabilities limits them in this task. An important issue in sonar perception is matching image patches, which can enable other techniques like localization, change detection, and mapping. There is a rich literature for this problem in color images, but for acoustic images, it is lacking, due to the physics that produce these images. In this paper we improve on our previous results for this problem (Valdenegro-Toro et al, 2017), instead of modeling features manually, a Convolutional Neural Network (CNN) learns a similarity function and predicts if two input sonar images are similar or not. With the objective of improving the sonar image matching problem further, three state of the art CNN architectures are evaluated on the Marine Debris dataset, namely DenseNet, and VGG, with a siamese or two-channel architecture, and contrastive loss. To ensure a fair evaluation of each network, thorough hyper-parameter optimization is executed. We find that the best performing models are DenseNet Two-Channel network with 0.955 AUC, VGG-Siamese with contrastive loss at 0.949 AUC and DenseNet Siamese with 0.921 AUC. By ensembling the top performing DenseNet two-channel and DenseNet-Siamese models overall highest prediction accuracy obtained is 0.978 AUC, showing a large improvement over the 0.91 AUC in the state of the art.",0
"The use of underwater robots is increasing, but their ability to perceive underwater environments is limited by their reliance on sonar technology. One key challenge with sonar perception is accurately matching image patches, which is crucial for tasks such as localization, change detection, and mapping. While there is extensive literature on this problem for color images, the same cannot be said for acoustic images due to their unique physical characteristics. In this study, we build upon our previous work (Valdenegro-Toro et al, 2017) by utilizing a Convolutional Neural Network (CNN) to learn a similarity function for sonar images, rather than manually modeling features. We evaluate three advanced CNN architectures (DenseNet, VGG with a siamese or two-channel structure, and contrastive loss) on the Marine Debris dataset, conducting thorough hyper-parameter optimization to ensure a fair comparison. The DenseNet Two-Channel network performs the best, achieving an AUC of 0.955, followed by VGG-Siamese with contrastive loss at 0.949 AUC, and DenseNet Siamese with 0.921 AUC. By combining the top performing models (DenseNet two-channel and DenseNet-Siamese), we achieve an overall highest prediction accuracy of 0.978 AUC, representing a significant improvement over the current state of the art (0.91 AUC).",1
"Much environmental enforcement in the United States has historically relied on either self-reported data or physical, resource-intensive, infrequent inspections. Advances in remote sensing and computer vision, however, have the potential to augment compliance monitoring by detecting early warning signs of noncompliance. We demonstrate a process for rapid identification of significant structural expansion using Planet's 3m/pixel satellite imagery products and focusing on Concentrated Animal Feeding Operations (CAFOs) in the US as a test case. Unpermitted building expansion has been a particular challenge with CAFOs, which pose significant health and environmental risks. Using new hand-labeled dataset of 145,053 images of 1,513 CAFOs, we combine state-of-the-art building segmentation with a likelihood-based change-point detection model to provide a robust signal of building expansion (AUC = 0.86). A major advantage of this approach is that it can work with higher cadence (daily to weekly), but lower resolution (3m/pixel), satellite imagery than previously used in similar environmental settings. It is also highly generalizable and thus provides a near real-time monitoring tool to prioritize enforcement resources in other settings where unpermitted construction poses environmental risk, e.g. zoning, habitat modification, or wetland protection.",0
"Environmental enforcement in the United States has traditionally relied on self-reported data or infrequent inspections, which can be resource-intensive. However, advances in remote sensing and computer vision offer a promising solution for detecting early warning signs of noncompliance. In this study, we use Planet's 3m/pixel satellite imagery products to identify structural expansion in Concentrated Animal Feeding Operations (CAFOs) as a test case. Unpermitted building expansion is a significant challenge for CAFOs as it poses health and environmental risks. By creating a new dataset of 145,053 images of 1,513 CAFOs, we apply building segmentation and change-point detection models to detect building expansion with high accuracy (AUC = 0.86). This approach is advantageous because it can work with daily to weekly satellite imagery at a lower resolution than previously used, making it highly generalizable and a valuable tool for monitoring unpermitted construction in other settings such as zoning, habitat modification, or wetland protection.",1
"For a global breeding organization, identifying the next generation of superior crops is vital for its success. Recognizing new genetic varieties requires years of in-field testing to gather data about the crop's yield, pest resistance, heat resistance, etc. At the conclusion of the growing season, organizations need to determine which varieties will be advanced to the next growing season (or sold to farmers) and which ones will be discarded from the candidate pool. Specifically for soybeans, identifying their relative maturity is a vital piece of information used for advancement decisions. However, this trait needs to be physically observed, and there are resource limitations (time, money, etc.) that bottleneck the data collection process. To combat this, breeding organizations are moving toward advanced image capturing devices. In this paper, we develop a robust and automatic approach for estimating the relative maturity of soybeans using a time series of UAV images. An end-to-end hybrid model combining Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) is proposed to extract features and capture the sequential behavior of time series data. The proposed deep learning model was tested on six different environments across the United States. Results suggest the effectiveness of our proposed CNN-LSTM model compared to the local regression method. Furthermore, we demonstrate how this newfound information can be used to aid in plant breeding advancement decisions.",0
"The success of a global breeding organization hinges on its ability to identify superior crop generations. This task involves years of field testing to collect data on factors such as yield, pest and heat resistance. At the end of each growing season, the organization must decide which crops to advance for the next season or sell to farmers, and which ones to discard. The identification of relative maturity is particularly crucial for soybeans, but this requires physical observation and can be limited by resources. To address this issue, breeding organizations are turning to advanced image capturing devices. This study presents an automatic and robust approach for estimating the relative maturity of soybeans using a time series of UAV images. The proposed method combines Convolutional Neural Networks and Long Short-Term Memory to extract features and capture the sequential behavior of time series data. Our deep learning model was tested in six different environments across the United States and showed superior performance to the local regression method. Additionally, we demonstrate the utility of this newfound information in aiding plant breeding advancement decisions.",1
"Modeling of large-scale research facilities is extremely challenging due to complex physical processes and engineering problems. Here, we adopt a data-driven approach to model the longitudinal phase-space diagnostic beamline at the photoinector of the European XFEL with an encoder-decoder neural network model. A deep convolutional neural network (decoder) is used to build images measured on the screen from a small feature map generated by another neural network (encoder). We demonstrate that the model trained only with experimental data can make high-fidelity predictions of megapixel images for the longitudinal phase-space measurement without any prior knowledge of photoinjectors and electron beams. The prediction significantly outperforms existing methods. We also show the scalability and interpretability of the model by sharing the same decoder with more than one encoder used for different setups of the photoinjector, and propose a pragmatic way to model a facility with various diagnostics and working points. This opens the door to a new way of accurately modeling a photoinjector using neural networks and experimental data. The approach can possibly be extended to the whole accelerator and even other types of scientific facilities.",0
"Creating models for large-scale research facilities is a difficult task due to the complex physical processes and engineering problems involved. In this study, we utilized a data-driven approach to model the longitudinal phase-space diagnostic beamline at the photoinector of the European XFEL using an encoder-decoder neural network model. The decoder, which is a deep convolutional neural network, was used to construct images from a small feature map generated by another neural network, the encoder. We demonstrated that our model, trained solely with experimental data, can accurately predict megapixel images for the longitudinal phase-space measurement without any prior knowledge of photoinjectors or electron beams. Our approach outperformed existing methods and showed scalability and interpretability by sharing the same decoder with multiple encoders used for different photoinjector setups. We propose a practical way to model facilities with various diagnostics and working points. Our study presents a new and accurate way of modeling photoinjectors using neural networks and experimental data, which can potentially be extended to other scientific facilities beyond accelerators.",1
"Tensor models play an increasingly prominent role in many fields, notably in machine learning. In several applications of such models, such as community detection, topic modeling and Gaussian mixture learning, one must estimate a low-rank signal from a noisy tensor. Hence, understanding the fundamental limits and the attainable performance of estimators of that signal inevitably calls for the study of random tensors. Substantial progress has been achieved on this subject thanks to recent efforts, under the assumption that the tensor dimensions grow large. Yet, some of the most significant among these results--in particular, a precise characterization of the abrupt phase transition (in terms of signal-to-noise ratio) that governs the performance of the maximum likelihood (ML) estimator of a symmetric rank-one model with Gaussian noise--were derived on the basis of statistical physics ideas, which are not easily accessible to non-experts.   In this work, we develop a sharply distinct approach, relying instead on standard but powerful tools brought by years of advances in random matrix theory. The key idea is to study the spectra of random matrices arising from contractions of a given random tensor. We show how this gives access to spectral properties of the random tensor itself. In the specific case of a symmetric rank-one model with Gaussian noise, our technique yields a hitherto unknown characterization of the local maximum of the ML problem that is global above the phase transition threshold. This characterization is in terms of a fixed-point equation satisfied by a formula that had only been previously obtained via statistical physics methods. Moreover, our analysis sheds light on certain properties of the landscape of the ML problem in the large-dimensional setting. Our approach is versatile and can be extended to other models, such as asymmetric, non-Gaussian and higher-order ones.",0
"Tensor models are becoming increasingly important in various fields, particularly in machine learning. In certain applications, including community detection, topic modeling, and Gaussian mixture learning, it is necessary to estimate a low-rank signal from a noisy tensor. Therefore, studying random tensors is essential to comprehend the fundamental limits and achievable performance of such estimators. Although significant progress has been made in this area, some of the most notable results were obtained using statistical physics ideas which are not easily understood by non-experts. In contrast, our work proposes a new approach that employs standard yet powerful tools from random matrix theory. By studying the spectra of random matrices resulting from contractions of a given random tensor, we can access the spectral properties of the tensor itself. Specifically, our technique provides a novel characterization of the local maximum of the maximum likelihood estimator for a symmetric rank-one model with Gaussian noise. This characterization is expressed as a fixed-point equation satisfied by a formula previously obtained via statistical physics methods. Additionally, our analysis offers insights into the landscape of the maximum likelihood problem in the large-dimensional setting. Our approach is flexible and can be extended to other models, such as asymmetric, non-Gaussian, and higher-order models.",1
"We describe a stacked model for predicting the cumulative fluid production for an oil well with a multistage-fracture completion based on a combination of Ridge Regression and CatBoost algorithms. The model is developed based on an extended digital field data base of reservoir, well and fracturing design parameters. The database now includes more than 5000 wells from 23 oilfields of Western Siberia (Russia), with 6687 fracturing operations in total. Starting with 387 parameters characterizing each well, including construction, reservoir properties, fracturing design features and production, we end up with 38 key parameters used as input features for each well in the model training process. The model demonstrates physically explainable dependencies plots of the target on the design parameters (number of stages, proppant mass, average and final proppant concentrations and fluid rate). We developed a set of methods including those based on the use of Euclidean distance and clustering techniques to perform similar (offset) wells search, which is useful for a field engineer to analyze earlier fracturing treatments on similar wells. These approaches are also adapted for obtaining the optimization parameters boundaries for the particular pilot well, as part of the field testing campaign of the methodology. An inverse problem (selecting an optimum set of fracturing design parameters to maximize production) is formulated as optimizing a high dimensional black box approximation function constrained by boundaries and solved with four different optimization methods: surrogate-based optimization, sequential least squares programming, particle swarm optimization and differential evolution. A recommendation system containing all the above methods is designed to advise a production stimulation engineer on an optimized fracturing design.",0
"A combination of Ridge Regression and CatBoost algorithms were utilized to create a stacked model for predicting cumulative fluid production from multistage-fracture completion oil wells. The model was developed using an extensive digital field data base, comprising of over 5000 wells from 23 oilfields in Western Siberia, Russia, and 6687 fracturing operations. Initially, 387 parameters were used to characterize each well, including construction, reservoir properties, fracturing design features, and production. However, 38 key parameters were selected as input features for each well during the model training process. The model was able to physically explain the dependencies between the target and design parameters such as the number of stages, proppant mass, average and final proppant concentrations, and fluid rate. Additionally, a set of methods based on Euclidean distance and clustering techniques were developed to perform offset well searches and identify earlier fracturing treatments on similar wells. These methods were also adapted to obtain optimization parameters boundaries for the pilot well during field testing. To maximize production, an inverse problem was formulated as optimizing a high dimensional black box approximation function constrained by boundaries and solved using four optimization methods: surrogate-based optimization, sequential least squares programming, particle swarm optimization, and differential evolution. Finally, a recommendation system was designed to advise production stimulation engineers on an optimized fracturing design using all the above methods.",1
"Low-light images captured in the real world are inevitably corrupted by sensor noise. Such noise is spatially variant and highly dependent on the underlying pixel intensity, deviating from the oversimplified assumptions in conventional denoising. Existing light enhancement methods either overlook the important impact of real-world noise during enhancement, or treat noise removal as a separate pre- or post-processing step. We present Coordinated Enhancement for Real-world Low-light Noisy Images (CERL), that seamlessly integrates light enhancement and noise suppression parts into a unified and physics-grounded optimization framework. For the real low-light noise removal part, we customize a self-supervised denoising model that can easily be adapted without referring to clean ground-truth images. For the light enhancement part, we also improve the design of a state-of-the-art backbone. The two parts are then joint formulated into one principled plug-and-play optimization. Our approach is compared against state-of-the-art low-light enhancement methods both qualitatively and quantitatively. Besides standard benchmarks, we further collect and test on a new realistic low-light mobile photography dataset (RLMP), whose mobile-captured photos display heavier realistic noise than those taken by high-quality cameras. CERL consistently produces the most visually pleasing and artifact-free results across all experiments. Our RLMP dataset and codes are available at: https://github.com/VITA-Group/CERL.",0
"Images taken in low-light conditions in the real world are subject to sensor noise, which is not uniform and depends on the pixel intensity, contrary to common denoising assumptions. Existing methods for improving image quality either do not consider the impact of real-world noise or treat noise removal as a separate step. Our solution, Coordinated Enhancement for Real-world Low-light Noisy Images (CERL), integrates noise suppression and light enhancement into a single, physics-grounded optimization framework. For noise removal, we use a self-supervised denoising model that adapts to real-world noise without a clean ground-truth image. For light enhancement, we improve on existing methods. Our approach outperforms other methods on standard benchmarks and a new realistic low-light mobile photography dataset. We provide the dataset and code at https://github.com/VITA-Group/CERL.",1
"This paper presents a scalable deep learning model called Agile Temporal Convolutional Network (ATCN) for high-accurate fast classification and time series prediction in resource-constrained embedded systems. ATCN is a family of compact networks with formalized hyperparameters that enable application-specific adjustments to be made to the model architecture. It is primarily designed for embedded edge devices with very limited performance and memory, such as wearable biomedical devices and real-time reliability monitoring systems. ATCN makes fundamental improvements over the mainstream temporal convolutional neural networks, including residual connections as time attention machines to increase the network depth and accuracy and the incorporation of separable depth-wise convolution to reduce the computational complexity of the model. As part of the present work, three ATCN families, namely T0, T1, and T2, are also presented and evaluated on different ranges of embedded processors - Cortex-M7 and Cortex-A57 processor. An evaluation of the ATCN models against the best-in-class InceptionTime shows that ATCN improves both accuracy and execution time on a broad range of embedded and cyber-physical applications with demand for real-time processing on the embedded edge. At the same time, in contrast to existing solutions, ATCN is the first deep learning-based approach that can be run on embedded microcontrollers (Cortex-M7) with limited computational performance and memory capacity while delivering state-of-the-art accuracy.",0
"The paper introduces the Agile Temporal Convolutional Network (ATCN), a deep learning model suitable for accurate and fast classification and time series prediction in resource-limited embedded systems. ATCN is a group of compact networks that can be customized for specific applications using formalized hyperparameters. It is designed to work on embedded edge devices with limited memory and performance, such as biomedical wearables and real-time reliability monitoring systems. ATCN offers several enhancements over mainstream temporal convolutional neural networks, such as the use of residual connections as time attention machines to improve network depth and accuracy, and the inclusion of separable depth-wise convolution to reduce computational complexity. The paper evaluates three ATCN families (T0, T1, and T2) on different embedded processors, including Cortex-M7 and Cortex-A57. The results show that ATCN outperforms the best-in-class InceptionTime in both accuracy and execution time for various embedded and cyber-physical applications that require real-time processing on the embedded edge. Moreover, ATCN is the first deep learning-based solution that can operate on embedded microcontrollers with limited computational performance and memory capacity while maintaining state-of-the-art accuracy.",1
"In this work we create agents that can perform well beyond a single, individual task, that exhibit much wider generalisation of behaviour to a massive, rich space of challenges. We define a universe of tasks within an environment domain and demonstrate the ability to train agents that are generally capable across this vast space and beyond. The environment is natively multi-agent, spanning the continuum of competitive, cooperative, and independent games, which are situated within procedurally generated physical 3D worlds. The resulting space is exceptionally diverse in terms of the challenges posed to agents, and as such, even measuring the learning progress of an agent is an open research problem. We propose an iterative notion of improvement between successive generations of agents, rather than seeking to maximise a singular objective, allowing us to quantify progress despite tasks being incomparable in terms of achievable rewards. We show that through constructing an open-ended learning process, which dynamically changes the training task distributions and training objectives such that the agent never stops learning, we achieve consistent learning of new behaviours. The resulting agent is able to score reward in every one of our humanly solvable evaluation levels, with behaviour generalising to many held-out points in the universe of tasks. Examples of this zero-shot generalisation include good performance on Hide and Seek, Capture the Flag, and Tag. Through analysis and hand-authored probe tasks we characterise the behaviour of our agent, and find interesting emergent heuristic behaviours such as trial-and-error experimentation, simple tool use, option switching, and cooperation. Finally, we demonstrate that the general capabilities of this agent could unlock larger scale transfer of behaviour through cheap finetuning.",0
"The objective of our work is to create agents that possess a broad range of skills and can perform well in various tasks. To achieve this, we have defined a universe of tasks within an environment domain that includes competitive, cooperative, and independent games. These tasks are situated within procedurally generated 3D worlds, which pose unique challenges to the agents. We have proposed an iterative approach to improve the agents' performance across this diverse space, rather than focusing on a single objective. Our open-ended learning process ensures that the agents can consistently learn new behaviours. We have observed that the resulting agents can perform well in tasks beyond those they were explicitly trained on, such as Hide and Seek, Capture the Flag, and Tag. Our analysis has revealed interesting emergent heuristic behaviours, including trial-and-error experimentation, simple tool use, option switching, and cooperation. Additionally, we have demonstrated that the general capabilities of these agents can be transferred to larger scale tasks through cheap finetuning.",1
"Stroke is the top leading causes of death in China (Zhou et al. The Lancet 2019). A dataset from Shanxi Province is used to identify the risk of each patient's at four states low/medium/high/attack and provide the state transition tendency through a SHAP DeepExplainer. To improve the accuracy on an imbalance sample set, the Quadratic Interactive Deep Neural Network (QIDNN) model is first proposed by flexible selecting and appending of quadratic interactive features. The experimental results showed that the QIDNN model with 7 interactive features achieve the state-of-art accuracy $83.25\%$. Blood pressure, physical inactivity, smoking, weight and total cholesterol are the top five important features. Then, for the sake of high recall on the most urgent state, attack state, the stroke occurrence prediction is taken as an auxiliary objective to benefit from multi-objective optimization. The prediction accuracy was promoted, meanwhile the recall of the attack state was improved by $24.9\%$ (to $84.83\%$) compared to QIDNN (from $67.93\%$) with same features. The prediction model and analysis tool in this paper not only gave the theoretical optimized prediction method, but also provided the attribution explanation of risk states and transition direction of each patient, which provided a favorable tool for doctors to analyze and diagnose the disease.",0
"According to Zhou et al. in The Lancet 2019, stroke is among the leading causes of death in China. Researchers analyzed a dataset from Shanxi Province to determine the risk of stroke for each patient in four states: low, medium, high, and attack. They used a SHAP DeepExplainer to identify state transition tendencies, and proposed the Quadratic Interactive Deep Neural Network (QIDNN) model to improve accuracy on an imbalanced sample set. The QIDNN model achieved 83.25% accuracy, with blood pressure, physical inactivity, smoking, weight, and total cholesterol as the top five important features. To increase recall for the most urgent state, the attack state, stroke occurrence prediction was used as an auxiliary objective. This improved prediction accuracy and attack state recall by 24.9% (to 84.83%) compared to QIDNN with the same features. The prediction model and analysis tool provide an optimized prediction method and attribution explanation of risk states and transition direction for each patient, which can assist doctors in analyzing and diagnosing the disease.",1
"The seamless illumination integration between a foreground object and a background scene is an important but challenging task in computer vision and augmented reality community. However, to our knowledge, there is no publicly available high-quality dataset that meets the illumination seamless integration task, which greatly hinders the development of this research direction. To this end, we apply a physically-based rendering method to create a large-scale, high-quality dataset, named IH dataset, which provides rich illumination information for seamless illumination integration task. In addition, we propose a deep learning-based SI-GAN method, a multi-task collaborative network, which makes full use of the multi-scale attention mechanism and adversarial learning strategy to directly infer mapping relationship between the inserted foreground object and corresponding background environment, and edit object illumination according to the proposed illumination exchange mechanism in parallel network. By this means, we can achieve the seamless illumination integration without explicit estimation of 3D geometric information. Comprehensive experiments on both our dataset and real-world images collected from the Internet show that our proposed SI-GAN provides a practical and effective solution for image-based object illumination editing, and validate the superiority of our method against state-of-the-art methods.",0
"Achieving seamless illumination integration between a foreground object and a background scene is a difficult but crucial task in the fields of computer vision and augmented reality. Unfortunately, the lack of a publicly available, high-quality dataset that can be used for this task has greatly impeded research in this area. To address this issue, we have developed a physically-based rendering method to create the IH dataset, which is a large-scale, high-quality dataset that provides rich illumination information for seamless illumination integration. We have also proposed a deep learning-based method called SI-GAN, which is a multi-task collaborative network that utilizes a multi-scale attention mechanism and an adversarial learning strategy to directly infer the mapping relationship between the inserted foreground object and the corresponding background environment. This method also includes an illumination exchange mechanism that allows for editing of object illumination in parallel network without explicit estimation of 3D geometric information. Our comprehensive experiments on both our dataset and real-world images from the Internet demonstrate that our proposed SI-GAN method is a practical and effective solution for image-based object illumination editing, and outperforms state-of-the-art methods.",1
"Since stress contributes to a broad range of mental and physical health problems, the objective assessment of stress is essential for behavioral and physiological studies. Although several studies have evaluated stress levels in controlled settings, objective stress assessment in everyday settings is still largely under-explored due to challenges arising from confounding contextual factors and limited adherence for self-reports. In this paper, we explore the objective prediction of stress levels in everyday settings based on heart rate (HR) and heart rate variability (HRV) captured via low-cost and easy-to-wear photoplethysmography (PPG) sensors that are widely available on newer smart wearable devices. We present a layered system architecture for personalized stress monitoring that supports a tunable collection of data samples for labeling, and present a method for selecting informative samples from the stream of real-time data for labeling. We captured the stress levels of fourteen volunteers through self-reported questionnaires over periods of between 1-3 months, and explored binary stress detection based on HR and HRV using Machine Learning Methods. We observe promising preliminary results given that the dataset is collected in the challenging environments of everyday settings. The binary stress detector is fairly accurate and can detect stressful vs non-stressful samples with a macro-F1 score of up to \%76. Our study lays the groundwork for more sophisticated labeling strategies that generate context-aware, personalized models that will empower health professionals to provide personalized interventions.",0
"The assessment of stress is crucial for behavioral and physiological research as it contributes to various mental and physical health problems. Although stress levels have been evaluated in controlled settings, it remains under-explored in everyday settings due to contextual factors and limited adherence to self-reports. This paper presents a layered system architecture for monitoring stress levels using photoplethysmography sensors, which are widely available on smart wearable devices. We captured stress levels of fourteen volunteers through self-reported questionnaires and explored binary stress detection using Machine Learning Methods. Despite the challenging environments of everyday settings, our study obtained promising results with a macro-F1 score of up to \%76. This study sets the foundation for personalized models that will empower health professionals to provide personalized interventions.",1
"Model-based reinforcement learning (MBRL) is believed to have much higher sample efficiency compared to model-free algorithms by learning a predictive model of the environment. However, the performance of MBRL highly relies on the quality of the learned model, which is usually built in a black-box manner and may have poor predictive accuracy outside of the data distribution. The deficiencies of the learned model may prevent the policy from being fully optimized. Although some uncertainty analysis-based remedies have been proposed to alleviate this issue, model bias still poses a great challenge for MBRL. In this work, we propose to leverage the prior knowledge of underlying physics of the environment, where the governing laws are (partially) known. In particular, we developed a physics-informed MBRL framework, where governing equations and physical constraints are utilized to inform the model learning and policy search. By incorporating the prior information of the environment, the quality of the learned model can be notably improved, while the required interactions with the environment are significantly reduced, leading to better sample efficiency and learning performance. The effectiveness and merit have been demonstrated over a handful of classic control problems, where the environments are governed by canonical ordinary/partial differential equations.",0
"It is commonly believed that Model-based reinforcement learning (MBRL) is more efficient in terms of sample usage than model-free algorithms due to its ability to learn a predictive model of the environment. However, the success of MBRL is highly dependent on the quality of the model that is learned, which is often developed in a black-box manner and may have low predictive accuracy outside of the data distribution. This deficiency can hinder the optimization of the policy. Although some remedies based on uncertainty analysis have been proposed to address this issue, model bias remains a significant challenge for MBRL. In this study, we propose using prior knowledge of the underlying physics of the environment, where the governing laws are partially known. We created a physics-informed MBRL framework that uses governing equations and physical constraints to inform the model learning and policy search. By incorporating prior information about the environment, the quality of the learned model can be significantly improved, leading to better sample efficiency and learning performance while reducing the required interactions with the environment. We demonstrated the effectiveness and value of this approach on several classic control problems, where the environments are governed by typical ordinary/partial differential equations.",1
"We develop a physics-informed machine learning approach for large-scale data assimilation and parameter estimation and apply it for estimating transmissivity and hydraulic head in the two-dimensional steady-state subsurface flow model of the Hanford Site given synthetic measurements of said variables. In our approach, we extend the physics-informed conditional Karhunen-Lo\'{e}ve expansion (PICKLE) method for modeling subsurface flow with unknown flux (Neumann) and varying head (Dirichlet) boundary conditions. We demonstrate that the PICKLE method is comparable in accuracy with the standard maximum a posteriori (MAP) method, but is significantly faster than MAP for large-scale problems. Both methods use a mesh to discretize the computational domain. In MAP, the parameters and states are discretized on the mesh; therefore, the size of the MAP parameter estimation problem directly depends on the mesh size. In PICKLE, the mesh is used to evaluate the residuals of the governing equation, while the parameters and states are approximated by the truncated conditional Karhunen-Lo\'{e}ve expansions with the number of parameters controlled by the smoothness of the parameter and state fields, and not by the mesh size. For a considered example, we demonstrate that the computational cost of PICKLE increases near linearly (as $N_{FV}^{1.15}$) with the number of grid points $N_{FV}$, while that of MAP increases much faster as $N_{FV}^{3.28}$. We demonstrated that once trained for one set of Dirichlet boundary conditions (i.e., one river stage), the PICKLE method provides accurate estimates of the hydraulic head for any value of the Dirichlet boundary conditions (i.e., for any river stage).",0
"Our study presents a novel machine learning approach that incorporates physics to estimate transmissivity and hydraulic head in a two-dimensional steady-state subsurface flow model. We employ the physics-informed conditional Karhunen-Lo\'{e}ve expansion (PICKLE) method to model subsurface flow, which can handle unknown flux (Neumann) and varying head (Dirichlet) boundary conditions. We compare PICKLE with the standard maximum a posteriori (MAP) method and demonstrate that PICKLE is more efficient for large-scale problems. In MAP, the parameters and states are discretized on a mesh, which directly affects the size of the parameter estimation problem. In contrast, PICKLE uses the mesh to evaluate the governing equation's residuals and approximates the parameters and states by the truncated conditional Karhunen-Lo\'{e}ve expansions. The smoothness of the parameter and state fields, rather than the mesh size, controls the number of parameters. We show that PICKLE's computational cost increases linearly with the number of grid points, while MAP's cost increases significantly faster. We also demonstrate that PICKLE accurately estimates hydraulic head for any value of the Dirichlet boundary conditions once trained for one set of conditions.",1
"We investigate active learning in Gaussian Process state-space models (GPSSM). Our problem is to actively steer the system through latent states by determining its inputs such that the underlying dynamics can be optimally learned by a GPSSM. In order that the most informative inputs are selected, we employ mutual information as our active learning criterion. In particular, we present two approaches for the approximation of mutual information for the GPSSM given latent states. The proposed approaches are evaluated in several physical systems where we actively learn the underlying non-linear dynamics represented by the state-space model.",0
"Our research focuses on the exploration of active learning in Gaussian Process state-space models (GPSSM) to effectively navigate a system through latent states by selecting inputs that optimize the learning of its underlying dynamics. To ensure the selection of the most informative inputs, we utilize mutual information as our active learning criterion, and present two methods for approximating mutual information for the GPSSM based on latent states. We evaluate these approaches in various physical systems to actively learn the non-linear dynamics represented by the state-space model.",1
"Mobile AR applications benefit from fast initialization to display world-locked effects instantly. However, standard visual odometry or SLAM algorithms require motion parallax to initialize (see Figure 1) and, therefore, suffer from delayed initialization. In this paper, we present a 6-DoF monocular visual odometry that initializes instantly and without motion parallax. Our main contribution is a pose estimator that decouples estimating the 5-DoF relative rotation and translation direction from the 1-DoF translation magnitude. While scale is not observable in a monocular vision-only setting, it is still paramount to estimate a consistent scale over the whole trajectory (even if not physically accurate) to avoid AR effects moving erroneously along depth. In our approach, we leverage the fact that depth errors are not perceivable to the user during rotation-only motion. However, as the user starts translating the device, depth becomes perceivable and so does the capability to estimate consistent scale. Our proposed algorithm naturally transitions between these two modes. We perform extensive validations of our contributions with both a publicly available dataset and synthetic data. We show that the proposed pose estimator outperforms the classical approaches for 6-DoF pose estimation used in the literature in low-parallax configurations. We release a dataset for the relative pose problem using real data to facilitate the comparison with future solutions for the relative pose problem. Our solution is either used as a full odometry or as a preSLAM component of any supported SLAM system (ARKit, ARCore) in world-locked AR effects on platforms such as Instagram and Facebook.",0
"Fast initialization is crucial for Mobile AR applications to display world-locked effects immediately. However, conventional visual odometry or SLAM algorithms experience delayed initialization as they require motion parallax to initialize. In this study, we introduce a 6-DoF monocular visual odometry that eliminates the need for motion parallax and initializes instantly. Our approach decouples the estimation of the 5-DoF relative rotation and translation direction from the 1-DoF translation magnitude. Even though scale is not observable in a monocular vision-only setting, it is essential to estimate a consistent scale to prevent AR effects from moving erroneously along depth. Our algorithm naturally transitions between two modes, taking advantage of the fact that depth errors are not perceivable during rotation-only motion. We validate our approach using both a publicly available dataset and synthetic data, showing that it outperforms classical approaches for 6-DoF pose estimation in low-parallax configurations. Our solution can be used as a full odometry or as a preSLAM component of any supported SLAM system, such as ARKit and ARCore, for world-locked AR effects on platforms like Instagram and Facebook. Additionally, we provide a dataset for the relative pose problem using real data to facilitate future comparisons with other solutions.",1
"As technology scaling is approaching the physical limit, lithography hotspot detection has become an essential task in design for manufacturability. While the deployment of pattern matching or machine learning in hotspot detection can help save significant simulation time, such methods typically demand for non-trivial quality data to build the model, which most design houses are short of. Moreover, the design houses are also unwilling to directly share such data with the other houses to build a unified model, which can be ineffective for the design house with unique design patterns due to data insufficiency. On the other hand, with data homogeneity in each design house, the locally trained models can be easily over-fitted, losing generalization ability and robustness. In this paper, we propose a heterogeneous federated learning framework for lithography hotspot detection that can address the aforementioned issues. On one hand, the framework can build a more robust centralized global sub-model through heterogeneous knowledge sharing while keeping local data private. On the other hand, the global sub-model can be combined with a local sub-model to better adapt to local data heterogeneity. The experimental results show that the proposed framework can overcome the challenge of non-independent and identically distributed (non-IID) data and heterogeneous communication to achieve very high performance in comparison to other state-of-the-art methods while guaranteeing a good convergence rate in various scenarios.",0
"Due to the physical limitations of technology scaling, detecting lithography hotspots has become a crucial task in ensuring design for manufacturability. While utilizing pattern matching or machine learning can significantly reduce simulation time, these methods require high-quality data to construct models, which is often lacking in design houses. Additionally, design houses are hesitant to share their data to build a unified model, as their unique design patterns may lead to data insufficiency. Local models trained with homogeneous data can also lead to over-fitting, resulting in a loss of generalization ability and robustness. To address these issues, we propose a heterogeneous federated learning framework for lithography hotspot detection. This framework allows for the sharing of heterogeneous knowledge to build a centralized global sub-model while maintaining local data privacy. The global sub-model can then be combined with a local sub-model to better adapt to local data heterogeneity. Our experimental results demonstrate that our proposed framework outperforms other state-of-the-art methods while achieving a good convergence rate in various scenarios, despite the challenge of non-independent and identically distributed data and heterogeneous communication.",1
"Uncertainties in machine learning are a significant roadblock for its application in safety-critical cyber-physical systems (CPS). One source of uncertainty arises from distribution shifts in the input data between training and test scenarios. Detecting such distribution shifts in real-time is an emerging approach to address the challenge. The high dimensional input space in CPS applications involving imaging adds extra difficulty to the task. Generative learning models are widely adopted for the task, namely out-of-distribution (OoD) detection. To improve the state-of-the-art, we studied existing proposals from both machine learning and CPS fields. In the latter, safety monitoring in real-time for autonomous driving agents has been a focus. Exploiting the spatiotemporal correlation of motion in videos, we can robustly detect hazardous motion around autonomous driving agents. Inspired by the latest advances in the Variational Autoencoder (VAE) theory and practice, we tapped into the prior knowledge in data to further boost OoD detection's robustness. Comparison studies over nuScenes and Synthia data sets show our methods significantly improve detection capabilities of OoD factors unique to driving scenarios, 42% better than state-of-the-art approaches. Our model also generalized near-perfectly, 97% better than the state-of-the-art across the real-world and simulation driving data sets experimented. Finally, we customized one proposed method into a twin-encoder model that can be deployed to resource limited embedded devices for real-time OoD detection. Its execution time was reduced over four times in low-precision 8-bit integer inference, while detection capability is comparable to its corresponding floating-point model.",0
"The application of machine learning in safety-critical cyber-physical systems encounters significant roadblocks due to uncertainties. One such uncertainty arises from distribution shifts in input data between training and test scenarios. Detecting these shifts in real-time is an emerging approach to address the challenge, but the high dimensional input space in CPS applications involving imaging makes the task even more difficult. To improve the state-of-the-art in out-of-distribution (OoD) detection using generative learning models, we studied existing proposals from both machine learning and CPS fields. Our focus was on safety monitoring in real-time for autonomous driving agents, exploiting the spatiotemporal correlation of motion in videos to detect hazardous motion around them. We also tapped into the prior knowledge in data to further boost OoD detection's robustness, inspired by the latest advances in Variational Autoencoder (VAE) theory and practice. Comparison studies over nuScenes and Synthia data sets show that our methods significantly improve detection capabilities of OoD factors unique to driving scenarios, outperforming state-of-the-art approaches by 42%. Our model also generalized near-perfectly, surpassing state-of-the-art performance by 97% across the real-world and simulation driving data sets experimented. Finally, we customized one proposed method into a twin-encoder model that can be deployed to resource-limited embedded devices for real-time OoD detection, reducing its execution time by over four times in low-precision 8-bit integer inference while maintaining comparable detection capability to its corresponding floating-point model.",1
"Information-based Bayesian optimization (BO) algorithms have achieved state-of-the-art performance in optimizing a black-box objective function. However, they usually require several approximations or simplifying assumptions (without clearly understanding their effects on the BO performance) and/or their generalization to batch BO is computationally unwieldy, especially with an increasing batch size. To alleviate these issues, this paper presents a novel trusted-maximizers entropy search (TES) acquisition function: It measures how much an input query contributes to the information gain on the maximizer over a finite set of trusted maximizers, i.e., inputs optimizing functions that are sampled from the Gaussian process posterior belief of the objective function. Evaluating TES requires either only a stochastic approximation with sampling or a deterministic approximation with expectation propagation, both of which are investigated and empirically evaluated using synthetic benchmark objective functions and real-world optimization problems, e.g., hyperparameter tuning of a convolutional neural network and synthesizing 'physically realizable' faces to fool a black-box face recognition system. Though TES can naturally be generalized to a batch variant with either approximation, the latter is amenable to be scaled to a much larger batch size in our experiments.",0
"State-of-the-art performance in optimizing a black-box objective function has been achieved by information-based Bayesian optimization (BO) algorithms. However, such algorithms typically rely on approximations or assumptions that may not be fully understood with respect to their impact on BO performance. Additionally, extending such algorithms to batch BO is computationally challenging, especially with increasing batch size. To address these issues, this paper introduces a novel acquisition function called trusted-maximizers entropy search (TES). TES measures how much an input query contributes to the information gain on the maximizer over a finite set of trusted maximizers. Evaluating TES requires either a stochastic approximation with sampling or a deterministic approximation with expectation propagation. Both methods are evaluated empirically using synthetic benchmark objective functions and real-world optimization problems, including hyperparameter tuning of a convolutional neural network and synthesizing 'physically realizable' faces to fool a black-box face recognition system. Although TES can be extended to a batch variant, the latter is more scalable to larger batch sizes in our experiments.",1
"Effective molecular representation learning is of great importance to facilitate molecular property prediction, which is a fundamental task for the drug and material industry. Recent advances in graph neural networks (GNNs) have shown great promise in applying GNNs for molecular representation learning. Moreover, a few recent studies have also demonstrated successful applications of self-supervised learning methods to pre-train the GNNs to overcome the problem of insufficient labeled molecules. However, existing GNNs and pre-training strategies usually treat molecules as topological graph data without fully utilizing the molecular geometry information. Whereas, the three-dimensional (3D) spatial structure of a molecule, a.k.a molecular geometry, is one of the most critical factors for determining molecular physical, chemical, and biological properties. To this end, we propose a novel Geometry Enhanced Molecular representation learning method (GEM) for Chemical Representation Learning (ChemRL). At first, we design a geometry-based GNN architecture that simultaneously models atoms, bonds, and bond angles in a molecule. To be specific, we devised double graphs for a molecule: The first one encodes the atom-bond relations; The second one encodes bond-angle relations. Moreover, on top of the devised GNN architecture, we propose several novel geometry-level self-supervised learning strategies to learn spatial knowledge by utilizing the local and global molecular 3D structures. We compare ChemRL-GEM with various state-of-the-art (SOTA) baselines on different molecular benchmarks and exhibit that ChemRL-GEM can significantly outperform all baselines in both regression and classification tasks. For example, the experimental results show an overall improvement of 8.8% on average compared to SOTA baselines on the regression tasks, demonstrating the superiority of the proposed method.",0
"Molecular property prediction is a crucial task for the drug and material industry, and effective molecular representation learning is essential for achieving this goal. Recent advances in graph neural networks (GNNs) have shown great potential for molecular representation learning, with some studies successfully applying self-supervised learning methods to pre-train GNNs for insufficient labeled molecules. However, existing GNNs and pre-training strategies often neglect the critical role of a molecule's 3D spatial structure in determining its physical, chemical, and biological properties. To address this gap, we propose a novel Geometry Enhanced Molecular representation learning method (GEM) for Chemical Representation Learning (ChemRL). Our approach uses a geometry-based GNN architecture that models atoms, bonds, and bond angles in a molecule using double graphs. In addition, we introduce several geometry-level self-supervised learning strategies to learn spatial knowledge by leveraging the local and global molecular 3D structures. Our experiments show that ChemRL-GEM outperforms various state-of-the-art baselines on different molecular benchmarks in both regression and classification tasks, demonstrating the superiority of our proposed method. Specifically, our results show an overall improvement of 8.8% on average compared to state-of-the-art baselines on the regression tasks.",1
"We discuss a software package for incorporating into simulations data-driven models trained using machine learning methods. These can be used for (i) modeling dynamics and time-step integration, (ii) modeling interactions between system components, and (iii) computing quantities of interest characterizing system state. The package allows for use of machine learning methods with general model classes including Neural Networks, Gaussian Process Regression, Kernel Models, and other approaches. We discuss in this whitepaper our prototype C++ package, aims, and example usage.",0
"In this whitepaper, we present a prototype C++ package that enables the integration of data-driven models trained with machine learning techniques into simulations. These models are useful for modeling system dynamics and time-step integration, interactions between system components, and computation of system state-related quantities of interest. The package supports the use of various machine learning methods, which cover general model classes like Neural Networks, Gaussian Process Regression, Kernel Models, and other approaches. Our discussion covers the package's objectives and example usage.",1
"Image-to-image translation (i2i) networks suffer from entanglement effects in presence of physics-related phenomena in target domain (such as occlusions, fog, etc), thus lowering the translation quality and variability. In this paper, we present a comprehensive method for disentangling physics-based traits in the translation, guiding the learning process with neural or physical models. For the latter, we integrate adversarial estimation and genetic algorithms to correctly achieve disentanglement. The results show our approach dramatically increase performances in many challenging scenarios for image translation.",0
"The quality and variability of image-to-image (i2i) translation networks are hindered by entanglement effects caused by physics-related phenomena, such as occlusions and fog, in the target domain. To address this issue, we propose a comprehensive method that disentangles physics-based traits during the translation process by utilizing either neural or physical models. Our approach employs adversarial estimation and genetic algorithms to achieve accurate disentanglement. The results demonstrate significant improvements in the performance of image translation in various challenging scenarios.",1
"Manifold embedding algorithms map high-dimensional data down to coordinates in a much lower-dimensional space. One of the aims of dimension reduction is to find intrinsic coordinates that describe the data manifold. The coordinates returned by the embedding algorithm are abstract, and finding their physical or domain-related meaning is not formalized and often left to domain experts. This paper studies the problem of recovering the meaning of the new low-dimensional representation in an automatic, principled fashion. We propose a method to explain embedding coordinates of a manifold as non-linear compositions of functions from a user-defined dictionary. We show that this problem can be set up as a sparse linear Group Lasso recovery problem, find sufficient recovery conditions, and demonstrate its effectiveness on data.",0
"Algorithms that perform manifold embedding transform high-dimensional data into coordinates that exist in a lower-dimensional space. The goal of dimension reduction is to discover intrinsic coordinates that accurately describe the data manifold. However, the coordinates produced by the embedding algorithm are abstract and do not hold a formalized physical or domain-related meaning. Typically, domain experts are left to interpret their significance. This research investigates the issue of automatically and systematically understanding the meaning of the low-dimensional representation. Our approach involves explaining the embedding coordinates of a manifold as non-linear functions derived from a user-defined dictionary. Through the use of a sparse linear Group Lasso recovery problem, we establish sufficient recovery conditions and demonstrate its efficacy on data.",1
"Understanding the behavior of Artificial Neural Networks is one of the main topics in the field recently, as black-box approaches have become usual since the widespread of deep learning. Such high-dimensional models may manifest instabilities and weird properties that resemble complex systems. Therefore, we propose Complex Network (CN) techniques to analyze the structure and performance of fully connected neural networks. For that, we build a dataset with 4 thousand models and their respective CN properties. They are employed in a supervised classification setup considering four vision benchmarks. Each neural network is approached as a weighted and undirected graph of neurons and synapses, and centrality measures are computed after training. Results show that these measures are highly related to the network classification performance. We also propose the concept of Bag-Of-Neurons (BoN), a CN-based approach for finding topological signatures linking similar neurons. Results suggest that six neuronal types emerge in such networks, independently of the target domain, and are distributed differently according to classification accuracy. We also tackle specific CN properties related to performance, such as higher subgraph centrality on lower-performing models. Our findings suggest that CN properties play a critical role in the performance of fully connected neural networks, with topological patterns emerging independently on a wide range of models.",0
"Recently, the study of Artificial Neural Networks has focused on understanding their behavior due to the increased use of black-box methods in deep learning. These models are often high-dimensional and exhibit complex properties and instabilities. To address this issue, we propose the use of Complex Network (CN) techniques to analyze the structure and performance of fully connected neural networks. We collected a dataset of 4,000 models and their respective CN properties and used them in a supervised classification setup for four vision benchmarks. Each neural network was treated as an undirected graph of neurons and synapses, and centrality measures were calculated after training. Our results demonstrate a strong correlation between these measures and network performance. We also introduce the concept of Bag-Of-Neurons (BoN), a CN-based approach that identifies topological signatures linking similar neurons. Our findings reveal the emergence of six neuronal types in these networks, regardless of the target domain, and their distribution varies depending on classification accuracy. Additionally, we examine specific CN properties related to performance, such as higher subgraph centrality in lower-performing models. Our study highlights the critical role of CN properties in the performance of fully connected neural networks, with topological patterns emerging consistently across a wide range of models.",1
"Continuous and multimodal stress detection has been performed recently through wearable devices and machine learning algorithms. However, a well-known and important challenge of working on physiological signals recorded by conventional monitoring devices is missing data due to sensors insufficient contact and interference by other equipment. This challenge becomes more problematic when the user/patient is mentally or physically active or stressed because of more frequent conscious or subconscious movements. In this paper, we propose ReLearn, a robust machine learning framework for stress detection from biomarkers extracted from multimodal physiological signals. ReLearn effectively copes with missing data and outliers both at training and inference phases. ReLearn, composed of machine learning models for feature selection, outlier detection, data imputation, and classification, allows us to classify all samples, including those with missing values at inference. In particular, according to our experiments and stress database, while by discarding all missing data, as a simplistic yet common approach, no prediction can be made for 34% of the data at inference, our approach can achieve accurate predictions, as high as 78%, for missing samples. Also, our experiments show that the proposed framework obtains a cross-validation accuracy of 86.8% even if more than 50% of samples within the features are missing.",0
"Recently, wearable devices and machine learning algorithms have enabled the continuous and multimodal detection of stress. However, conventional monitoring devices often suffer from missing data due to insufficient sensor contact and interference from other equipment, posing a significant challenge. This problem is exacerbated when the user/patient is active or stressed, leading to more movements that can interfere with signal recording. In this paper, we introduce ReLearn, a robust machine learning framework for stress detection using biomarkers extracted from multimodal physiological signals. ReLearn addresses missing data and outlier challenges in both training and inference phases. Our framework includes machine learning models for feature selection, outlier detection, data imputation, and classification, enabling accurate classification of all samples, including those with missing values. Our experiments demonstrate that our approach achieves up to 78% accurate predictions for missing samples, while a simplistic approach of discarding missing data results in no prediction for 34% of the data at inference. Moreover, our framework achieves a cross-validation accuracy of 86.8%, even when more than 50% of the samples within the features are missing.",1
"In this article we address the question whether it is possible to learn the differential equations describing the physical properties of a dynamical system, subject to non-conservative forces, from observations of its realspace trajectory(ies) only. We introduce a network that incorporates a difference approximation for the second order derivative in terms of residual connections between convolutional blocks, whose shared weights represent the coefficients of a second order ordinary differential equation. We further combine this solver-like architecture with a convolutional network, capable of learning the relation between trajectories of coupled oscillators and therefore allows us to make a stable forecast even if the system is only partially observed. We optimize this map together with the solver network, while sharing their weights, to form a powerful framework capable of learning the complex physical properties of a dissipative dynamical system.",0
"The aim of this article is to investigate whether the differential equations that describe the physical characteristics of a non-conservative dynamical system can be learned solely from observing its real-space trajectory. To achieve this, we propose a network that incorporates a difference approximation for the second-order derivative using residual connections between convolutional blocks. The shared weights of this network represent the coefficients of a second-order ordinary differential equation. Additionally, we combine this architecture with a convolutional network that can learn the relationship between coupled oscillators' trajectories, enabling us to make a stable prediction even when the system is only partially observed. We jointly optimize this map and the solver network by sharing their weights to create a potent framework that can learn the intricate physical properties of a dissipative dynamical system.",1
"Counting the repetition of human exercise and physical rehabilitation is a common task in rehabilitation and exercise training. The existing vision-based repetition counting methods less emphasize the concurrent motions in the same video. This work presents a vision-based human motion repetition counting applicable to counting concurrent motions through the skeleton location extracted from various pose estimation methods. The presented method was validated on the University of Idaho Physical Rehabilitation Movements Data Set (UI-PRMD), and MM-fit dataset. The overall mean absolute error (MAE) for mm-fit was 0.06 with off-by-one Accuracy (OBOA) 0.94. Overall MAE for UI-PRMD dataset was 0.06 with OBOA 0.95. We have also tested the performance in a variety of camera locations and concurrent motions with conveniently collected video with overall MAE 0.06 and OBOA 0.88. The proposed method provides a view-angle and motion agnostic concurrent motion counting. This method can potentially use in large-scale remote rehabilitation and exercise training with only one camera.",0
"Repetitive human exercise and physical rehabilitation are often counted in rehabilitation and exercise training. The current repetition counting methods that are based on vision place less emphasis on concurrent motions in the same video. This study introduces a vision-based method for counting the repetition of human motion that is applicable to counting concurrent motions, by using skeleton location extracted from various pose estimation methods. The proposed method was tested on the University of Idaho Physical Rehabilitation Movements Data Set (UI-PRMD), and MM-fit dataset, and achieved an overall mean absolute error (MAE) of 0.06 with an off-by-one accuracy (OBOA) of 0.94 for mm-fit and an overall MAE of 0.06 with an OBOA of 0.95 for the UI-PRMD dataset. The method was also tested in different camera locations and concurrent motions with conveniently collected video, achieving an overall MAE of 0.06 and an OBOA of 0.88. This method allows concurrent motion counting regardless of view-angle and motion, making it potentially useful for large-scale remote rehabilitation and exercise training using only one camera.",1
"Densely connected convolutional networks (DenseNet) behave well in image processing. However, for regression tasks, convolutional DenseNet may lose essential information from independent input features. To tackle this issue, we propose a novel DenseNet regression model where convolution and pooling layers are replaced by fully connected layers and the original concatenation shortcuts are maintained to reuse the feature. To investigate the effects of depth and input dimension of proposed model, careful validations are performed by extensive numerical simulation. The results give an optimal depth (19) and recommend a limited input dimension (under 200). Furthermore, compared with the baseline models including support vector regression, decision tree regression, and residual regression, our proposed model with the optimal depth performs best. Ultimately, DenseNet regression is applied to predict relative humidity, and the outcome shows a high correlation (0.91) with observations, which indicates that our model could advance environmental data analysis.",0
"Although DenseNet is effective in image processing, it may not retain important information from independent input features when used for regression tasks. To address this issue, we suggest a new DenseNet regression model that replaces convolution and pooling layers with fully connected layers while preserving the original concatenation shortcuts for feature reuse. We conduct extensive numerical simulations to investigate the impact of depth and input dimension on the proposed model, and we find that a depth of 19 and an input dimension of less than 200 are optimal. Our proposed model outperforms baseline models such as support vector regression, decision tree regression, and residual regression, particularly at the optimal depth. Finally, we apply DenseNet regression to predict relative humidity, and our model is highly correlated (0.91) with observations, indicating its potential to enhance environmental data analysis.",1
"We present the Regensburg Breast Shape Model (RBSM) - a 3D statistical shape model of the female breast built from 110 breast scans, and the first ever publicly available. Together with the model, a fully automated, pairwise surface registration pipeline used to establish correspondence among 3D breast scans is introduced. Our method is computationally efficient and requires only four landmarks to guide the registration process. In order to weaken the strong coupling between breast and thorax, we propose to minimize the variance outside the breast region as much as possible. To achieve this goal, a novel concept called breast probability masks (BPMs) is introduced. A BPM assigns probabilities to each point of a 3D breast scan, telling how likely it is that a particular point belongs to the breast area. During registration, we use BPMs to align the template to the target as accurately as possible inside the breast region and only roughly outside. This simple yet effective strategy significantly reduces the unwanted variance outside the breast region, leading to better statistical shape models in which breast shapes are quite well decoupled from the thorax. The RBSM is thus able to produce a variety of different breast shapes as independently as possible from the shape of the thorax. Our systematic experimental evaluation reveals a generalization ability of 0.17 mm and a specificity of 2.8 mm for the RBSM. Ultimately, our model is seen as a first step towards combining physically motivated deformable models of the breast and statistical approaches in order to enable more realistic surgical outcome simulation.",0
"We are introducing the Regensburg Breast Shape Model (RBSM), which is a 3D statistical shape model of the female breast. This model is the first publicly available one and was built from 110 breast scans. Additionally, we are introducing a fully automated, pairwise surface registration pipeline that is used to establish correspondence among 3D breast scans. Our method is efficient and only requires four landmarks to guide the registration process. To reduce the coupling between the breast and thorax, we propose minimizing the variance outside of the breast region by introducing a novel concept called breast probability masks (BPMs). BPMs assign probabilities to each point of the 3D breast scan, indicating the likelihood that a particular point belongs to the breast area. During registration, we use BPMs to align the template to the target as accurately as possible inside the breast region and only roughly outside. This strategy reduces unwanted variance outside the breast region, leading to better statistical shape models where breast shapes are well decoupled from the thorax. The RBSM is capable of producing various breast shapes independently from the shape of the thorax. Our systematic experimental evaluation shows that the RBSM has a generalization ability of 0.17 mm and a specificity of 2.8 mm. Ultimately, this model is a first step towards combining physically motivated deformable models of the breast and statistical approaches to enable more realistic surgical outcome simulation.",1
"We introduce a class of Sparse, Physics-based, and partially Interpretable Neural Networks (SPINN) for solving ordinary and partial differential equations (PDEs). By reinterpreting a traditional meshless representation of solutions of PDEs we develop a class of sparse neural network architectures that are partially interpretable. The SPINN model we propose here serves as a seamless bridge between two extreme modeling tools for PDEs, namely dense neural network based methods like Physics Informed Neural Networks (PINNs) and traditional mesh-free numerical methods, thereby providing a novel means to develop a new class of hybrid algorithms that build on the best of both these viewpoints. A unique feature of the SPINN model that distinguishes it from other neural network based approximations proposed earlier is that it is (i) interpretable, in a particular sense made precise in the work, and (ii) sparse in the sense that it has much fewer connections than typical dense neural networks used for PDEs. Further, the SPINN algorithm implicitly encodes mesh adaptivity and is able to handle discontinuities in the solutions. In addition, we demonstrate that Fourier series representations can also be expressed as a special class of SPINN and propose generalized neural network analogues of Fourier representations. We illustrate the utility of the proposed method with a variety of examples involving ordinary differential equations, elliptic, parabolic, hyperbolic and nonlinear partial differential equations, and an example in fluid dynamics.",0
"Our paper presents a new type of neural network, called Sparse, Physics-based, and partially Interpretable Neural Networks (SPINN), which can solve both ordinary and partial differential equations (PDEs). We take a different approach to traditional meshless methods for solving PDEs, resulting in a sparse neural network architecture that offers partial interpretability. Our proposed SPINN model acts as a bridge between two opposing PDE modeling tools: dense neural network approaches such as Physics Informed Neural Networks (PINNs) and conventional mesh-free numerical methods, allowing for a novel hybrid algorithm that combines the strengths of each approach. Unlike other neural network approximations for PDEs, our model is both interpretable and sparse, with fewer connections than typical dense neural networks. Additionally, the SPINN algorithm incorporates mesh adaptivity and can handle solution discontinuities. We also show how Fourier series representations can be expressed as a special SPINN class and propose generalized neural network analogues for Fourier representations. Our proposed method is demonstrated through various examples of differential equations, including ordinary, elliptic, parabolic, hyperbolic, and nonlinear PDEs, as well as an example in fluid dynamics.",1
"We perform approximate inference in state-space models that allow for nonlinear higher-order Markov chains in latent space. The conditional independencies of the generative model enable us to parameterize only an inference model, which learns to estimate clean states in a self-supervised manner using maximum likelihood. First, we propose a recurrent method that is trained directly on noisy observations. Afterward, we cast the model such that the optimization problem leads to an update scheme that backpropagates through a recursion similar to the classical Kalman filter and smoother. In scientific applications, domain knowledge can give a linear approximation of the latent transition maps. We can easily incorporate this knowledge into our model, leading to a hybrid inference approach. In contrast to other methods, experiments show that the hybrid method makes the inferred latent states physically more interpretable and accurate, especially in low-data regimes. Furthermore, we do not rely on an additional parameterization of the generative model or supervision via uncorrupted observations or ground truth latent states. Despite our model's simplicity, we obtain competitive results on the chaotic Lorenz system compared to a fully supervised approach and outperform a method based on variational inference.",0
"Our approach involves approximate inference in state-space models that permit nonlinear higher-order Markov chains in the latent space. By utilizing the conditional independencies of the generative model, we can parameterize only an inference model that learns to estimate clean states via maximum likelihood in a self-supervised manner. We first propose a recurrent technique that directly trains on noisy observations. Then, we modify the model to create an optimization problem that backpropagates through a recursion similar to the classical Kalman filter and smoother. In scientific applications, domain knowledge can provide a linear approximation of the latent transition maps, which we can easily incorporate into our hybrid inference approach. Compared to other methods, experiments indicate that our hybrid method generates latent states that are physically more interpretable and accurate, particularly in low-data regimes. Moreover, we do not require an additional parameterization of the generative model or supervision via uncorrupted observations or ground truth latent states. Despite its simplicity, our model produces competitive results on the chaotic Lorenz system, surpassing a fully supervised approach and a method based on variational inference.",1
"In recent years, the growth of Machine Learning (ML) algorithms has raised the number of studies including their applicability in a variety of different scenarios. Among all, one of the hardest ones is the aerospace, due to its peculiar physical requirements. In this context, a feasibility study and a first prototype for an Artificial Intelligence (AI) model to be deployed on board satellites are presented in this work. As a case study, the detection of volcanic eruptions has been investigated as a method to swiftly produce alerts and allow immediate interventions. Two Convolutional Neural Networks (CNNs) have been proposed and designed, showing how to efficiently implement them for identifying the eruptions and at the same time adapting their complexity in order to fit on board requirements.",0
"The number of studies examining the applicability of Machine Learning (ML) algorithms in various scenarios has increased in recent years. However, one of the most challenging scenarios is aerospace due to its unique physical requirements. This work presents a feasibility study and the first prototype of an Artificial Intelligence (AI) model that can be deployed on satellites. The detection of volcanic eruptions has been examined as a case study, as it can produce quick alerts and enable immediate interventions. Two Convolutional Neural Networks (CNNs) have been proposed and designed to identify eruptions efficiently while adapting their complexity to meet onboard requirements.",1
"Remote photoplethysmography (rPPG) monitors heart rate without requiring physical contact, which allows for a wide variety of applications. Deep learning-based rPPG have demonstrated superior performance over the traditional approaches in controlled context. However, the lighting situation in indoor space is typically complex, with uneven light distribution and frequent variations in illumination. It lacks a fair comparison of different methods under different illuminations using the same dataset. In this paper, we present a public dataset, namely the BH-rPPG dataset, which contains data from twelve subjects under three illuminations: low, medium, and high illumination. We also provide the ground truth heart rate measured by an oximeter. We evaluate the performance of three deep learning-based methods to that of four traditional methods using two public datasets: the UBFC-rPPG dataset and the BH-rPPG dataset. The experimental results demonstrate that traditional methods are generally more resistant to fluctuating illuminations. We found that the rPPGNet achieves lowest MAE among deep learning-based method under medium illumination, whereas the CHROM achieves 1.5 beats per minute (BPM), outperforming the rPPGNet by 60%. These findings suggest that while developing deep learning-based heart rate estimation algorithms, illumination variation should be taken into account. This work serves as a benchmark for rPPG performance evaluation and it opens a pathway for future investigation into deep learning-based rPPG under illumination variations.",0
"The monitoring of heart rate without physical contact is possible through Remote photoplethysmography (rPPG). This allows for a wide range of applications. In controlled environments, deep learning-based rPPG has shown better results than traditional methods. However, in indoor spaces, the lighting situation is complex, with uneven light distribution and frequent illumination variations. There is a lack of fair comparison of different methods using the same dataset under different illuminations. In this study, the authors present the BH-rPPG dataset, which includes data from twelve subjects under low, medium, and high illuminations. The ground truth heart rate measured by an oximeter is also provided. The authors evaluate the performance of three deep learning-based methods and four traditional methods using two public datasets. The results show that traditional methods are more resistant to fluctuating illuminations. rPPGNet performs best under medium illumination, while CHROM outperforms rPPGNet by 60% with a heart rate estimation of 1.5 beats per minute (BPM). The study highlights the importance of considering illumination variation while developing deep learning-based heart rate estimation algorithms. The authors provide a benchmark for rPPG performance evaluation and open a pathway for future research into deep learning-based rPPG under illumination variations.",1
"A cross-benchmark has been done on three critical aspects, data imputing, feature selection and regression algorithms, for machine learning based chemical vapor deposition (CVD) virtual metrology (VM). The result reveals that linear feature selection regression algorithm would extensively under-fit the VM data. Data imputing is also necessary to achieve a higher prediction accuracy as the data availability is only ~70% when optimal accuracy is obtained. This work suggests a nonlinear feature selection and regression algorithm combined with nearest data imputing algorithm would provide a prediction accuracy as high as 0.7. This would lead to 70% reduced CVD processing variation, which is believed to will lead to reduced frequency of physical metrology as well as more reliable mass-produced wafer with improved quality.",0
"A comparison was made on three key factors - data imputing, feature selection, and regression algorithms - for machine learning-based virtual metrology in chemical vapor deposition (CVD). The outcome indicated that the linear feature selection regression algorithm was inadequate for the VM data, resulting in extensive under-fitting. To achieve optimal prediction accuracy, data imputing was also necessary since the data availability was only around 70%. This study suggests that a combination of nonlinear feature selection and regression algorithms with the nearest data imputing algorithm would result in a prediction accuracy of up to 0.7. This would lead to a 70% reduction in CVD processing variation, which is expected to lower the frequency of physical metrology and produce more reliable, high-quality wafers on a large scale.",1
"Crowd counting has drawn much attention due to its importance in safety-critical surveillance systems. Especially, deep neural network (DNN) methods have significantly reduced estimation errors for crowd counting missions. Recent studies have demonstrated that DNNs are vulnerable to adversarial attacks, i.e., normal images with human-imperceptible perturbations could mislead DNNs to make false predictions. In this work, we propose a robust attack strategy called Adversarial Patch Attack with Momentum (APAM) to systematically evaluate the robustness of crowd counting models, where the attacker's goal is to create an adversarial perturbation that severely degrades their performances, thus leading to public safety accidents (e.g., stampede accidents). Especially, the proposed attack leverages the extreme-density background information of input images to generate robust adversarial patches via a series of transformations (e.g., interpolation, rotation, etc.). We observe that by perturbing less than 6\% of image pixels, our attacks severely degrade the performance of crowd counting systems, both digitally and physically. To better enhance the adversarial robustness of crowd counting models, we propose the first regression model-based Randomized Ablation (RA), which is more sufficient than Adversarial Training (ADT) (Mean Absolute Error of RA is 5 lower than ADT on clean samples and 30 lower than ADT on adversarial examples). Extensive experiments on five crowd counting models demonstrate the effectiveness and generality of the proposed method. The supplementary materials and certificate retrained models are available at \url{https://www.dropbox.com/s/hc4fdx133vht0qb/ACM_MM2021_Supp.pdf?dl=0}",0
"The significance of crowd counting in safety-critical surveillance systems has led to a focus on its accuracy. Deep neural network (DNN) methods have shown progress in reducing estimation errors for crowd counting missions. However, recent studies have highlighted the vulnerability of DNNs to adversarial attacks, where slight alterations to normal images can mislead DNNs into making false predictions. To assess the robustness of crowd counting models, we propose a strategy called Adversarial Patch Attack with Momentum (APAM), which aims to create an adversarial perturbation that drastically reduces their performance and leads to public safety accidents. Our attack method generates robust adversarial patches by utilizing the extreme-density background information of input images and applying various transformations. We observe that our attacks, which perturb under 6% of image pixels, significantly degrade the performance of crowd counting systems both digitally and physically. To improve adversarial robustness, we propose Randomized Ablation (RA), which is more effective than Adversarial Training (ADT) in reducing errors on both clean and adversarial examples. We demonstrate the effectiveness and generality of our proposed method through experiments on five crowd counting models. Supplementary materials and certificate retrained models are available at \url{https://www.dropbox.com/s/hc4fdx133vht0qb/ACM_MM2021_Supp.pdf?dl=0}.",1
"We present a method to estimate an HDR environment map from a narrow field-of-view LDR camera image in real-time. This enables perceptually appealing reflections and shading on virtual objects of any material finish, from mirror to diffuse, rendered into a real physical environment using augmented reality. Our method is based on our efficient convolutional neural network architecture, EnvMapNet, trained end-to-end with two novel losses, ProjectionLoss for the generated image, and ClusterLoss for adversarial training. Through qualitative and quantitative comparison to state-of-the-art methods, we demonstrate that our algorithm reduces the directional error of estimated light sources by more than 50%, and achieves 3.7 times lower Frechet Inception Distance (FID). We further showcase a mobile application that is able to run our neural network model in under 9 ms on an iPhone XS, and render in real-time, visually coherent virtual objects in previously unseen real-world environments.",0
"Our technique enables the real-time estimation of an HDR environment map from a LDR camera image with a narrow field-of-view. This results in visually appealing reflections and shading on virtual objects, regardless of their material finish, when rendered into a physical environment using augmented reality. Our approach utilizes the EnvMapNet convolutional neural network architecture, which is trained end-to-end with two unique losses, ProjectionLoss and ClusterLoss for adversarial training. Our method outperforms state-of-the-art techniques, reducing directional error of estimated light sources by over 50% and achieving a 3.7 times lower Frechet Inception Distance (FID). We also present a mobile application that can run our neural network model on an iPhone XS in under 9 ms, rendering visually coherent virtual objects in previously unseen real-world environments in real-time.",1
"In this paper we study a multi-arm bandit problem in which the quality of each arm is measured by the Conditional Value at Risk (CVaR) at some level alpha of the reward distribution. While existing works in this setting mainly focus on Upper Confidence Bound algorithms, we introduce a new Thompson Sampling approach for CVaR bandits on bounded rewards that is flexible enough to solve a variety of problems grounded on physical resources. Building on a recent work by Riou & Honda (2020), we introduce B-CVTS for continuous bounded rewards and M-CVTS for multinomial distributions. On the theoretical side, we provide a non-trivial extension of their analysis that enables to theoretically bound their CVaR regret minimization performance. Strikingly, our results show that these strategies are the first to provably achieve asymptotic optimality in CVaR bandits, matching the corresponding asymptotic lower bounds for this setting. Further, we illustrate empirically the benefit of Thompson Sampling approaches both in a realistic environment simulating a use-case in agriculture and on various synthetic examples.",0
"The Conditional Value at Risk (CVaR) is utilized as a measure of arm quality in our research on multi-arm bandit problems. While previous studies focused on Upper Confidence Bound algorithms, we introduce a new Thompson Sampling approach suitable for solving problems based on physical resources with bounded rewards. We present B-CVTS for continuous bounded rewards and M-CVTS for multinomial distributions, based on a recent work by Riou & Honda (2020). Our analysis extends their work and provides theoretical bounds for CVaR regret minimization performance. Our results demonstrate that these strategies are the first to achieve asymptotic optimality in CVaR bandits, matching the corresponding asymptotic lower bounds. We also show the benefits of Thompson Sampling through empirical evidence from a realistic environment simulating agriculture and various synthetic examples.",1
"In this paper, we investigate data-driven parameterized modeling of insertion loss for transmission lines with respect to design parameters. We first show that direct application of neural networks can lead to non-physics models with negative insertion loss. To mitigate this problem, we propose two deep learning solutions. One solution is to add a regulation term, which represents the passive condition, to the final loss function to enforce the negative quantity of insertion loss. In the second method, a third-order polynomial expression is defined first, which ensures positiveness, to approximate the insertion loss, then DeepONet neural network structure, which was proposed recently for function and system modeling, was employed to model the coefficients of polynomials. The resulting neural network is applied to predict the coefficients of the polynomial expression. The experimental results on an open-sourced SI/PI database of a PCB design show that both methods can ensure the positiveness for the insertion loss. Furthermore, both methods can achieve similar prediction results, while the polynomial-based DeepONet method is faster than DeepONet based method in training time.",0
"The aim of this paper is to explore the use of data-driven parameterized modeling to analyze insertion loss for transmission lines in relation to design parameters. However, it is observed that a direct application of neural networks could generate models that did not conform to physical laws, resulting in negative insertion loss. To address this issue, two deep learning techniques were proposed. The first approach involves adding a regulation term to the final loss function that enforces the negative value of insertion loss. The second method entails defining a third-order polynomial expression that guarantees positivity to approximate the insertion loss, followed by utilizing the DeepONet neural network structure to model the coefficients of polynomials. The resulting neural network was then employed to predict the coefficients of the polynomial expression. The study utilized an open-sourced SI/PI database of a PCB design, and results showed that both methods ensured the positivity of the insertion loss and achieved comparable predictive outcomes. However, the polynomial-based DeepONet method was faster than the DeepONet based method during training.",1
"This is a tutorial and survey paper on Boltzmann Machine (BM), Restricted Boltzmann Machine (RBM), and Deep Belief Network (DBN). We start with the required background on probabilistic graphical models, Markov random field, Gibbs sampling, statistical physics, Ising model, and the Hopfield network. Then, we introduce the structures of BM and RBM. The conditional distributions of visible and hidden variables, Gibbs sampling in RBM for generating variables, training BM and RBM by maximum likelihood estimation, and contrastive divergence are explained. Then, we discuss different possible discrete and continuous distributions for the variables. We introduce conditional RBM and how it is trained. Finally, we explain deep belief network as a stack of RBM models. This paper on Boltzmann machines can be useful in various fields including data science, statistics, neural computation, and statistical physics.",0
"The aim of this paper is to provide a tutorial and survey of Boltzmann Machine (BM), Restricted Boltzmann Machine (RBM), and Deep Belief Network (DBN). To begin, we offer an overview of probabilistic graphical models, Markov random field, Gibbs sampling, statistical physics, Ising model, and the Hopfield network. Next, we delve into the structures of BM and RBM and explore the conditional distributions of visible and hidden variables. Additionally, we explain Gibbs sampling in RBM for generating variables and training BM and RBM through maximum likelihood estimation and contrastive divergence. We also examine discrete and continuous distribution options for the variables and introduce conditional RBM and its training. Finally, we introduce deep belief network as a stack of RBM models. This paper on Boltzmann machines has broad applications in data science, statistics, neural computation, and statistical physics.",1
"Deep Learning (DL), in particular deep neural networks (DNN), by design is purely data-driven and in general does not require physics. This is the strength of DL but also one of its key limitations when applied to science and engineering problems in which underlying physical properties (such as stability, conservation, and positivity) and desired accuracy need to be achieved. DL methods in their original forms are not capable of respecting the underlying mathematical models or achieving desired accuracy even in big-data regimes. On the other hand, many data-driven science and engineering problems, such as inverse problems, typically have limited experimental or observational data, and DL would overfit the data in this case. Leveraging information encoded in the underlying mathematical models, we argue, not only compensates missing information in low data regimes but also provides opportunities to equip DL methods with the underlying physics and hence obtaining higher accuracy. This short communication introduces several model-constrained DL approaches (including both feed-forward DNN and autoencoders) that are capable of learning not only information hidden in the training data but also in the underlying mathematical models to solve inverse problems. We present and provide intuitions for our formulations for general nonlinear problems. For linear inverse problems and linear networks, the first order optimality conditions show that our model-constrained DL approaches can learn information encoded in the underlying mathematical models, and thus can produce consistent or equivalent inverse solutions, while naive purely data-based counterparts cannot.",0
"Deep Learning, particularly deep neural networks, relies solely on data and does not necessarily require an understanding of physics. While this is advantageous, it also poses a significant limitation when applied to scientific and engineering problems that require achieving specific levels of accuracy and respecting physical properties such as stability and conservation. DL methods, in their original form, cannot adhere to mathematical models and achieve desired accuracy, especially in low-data regimes. Conversely, data-driven problems in science and engineering, such as inverse problems, often have a limited amount of data, making DL prone to overfitting. We believe that incorporating information from mathematical models can compensate for missing data in low-data regimes and improve the accuracy of DL methods. In this communication, we introduce several model-constrained DL approaches that can learn both from underlying mathematical models and training data to solve inverse problems. Our formulations are suitable for general nonlinear problems, and we provide intuitions for each. Our model-constrained DL approaches can learn information encoded in the underlying mathematical models for linear inverse problems and linear networks, thereby producing consistent or equivalent inverse solutions, which naive purely data-based counterparts cannot achieve.",1
"In a recent methodological paper, we have shown how to learn chaotic dynamics along with the state trajectory from sequentially acquired observations, using local ensemble Kalman filters. Here, we more systematically investigate the possibilty to use a local ensemble Kalman filter with either covariance localization or local domains, in order to retrieve the state and a mix of key global and local parameters. Global parameters are meant to represent the surrogate dynamics, for instance through a neural network, which is reminiscent of data-driven machine learning of dynamics, while the local parameters typically stand for the forcings of the model. A family of algorithms for covariance and local domain localization is proposed in this joint state and parameter filter context. In particular, we show how to rigorously update global parameters using a local domain EnKF such as the LETKF, an inherently local method. The approach is tested with success on the 40-variable Lorenz model using several of the local EnKF flavors. A two-dimensional illustration based on a multi-layer Lorenz model is finally provided. It uses radiance-like non-local observations, and both local domains and covariance localization in order to learn the chaotic dynamics, the local forcings, and the couplings between layers. This paper more generally addresses the key question of online estimation of both global and local model parameters.",0
"Recently, we presented a methodology that demonstrates the ability to acquire chaotic dynamics and state trajectories from sequentially collected observations using local ensemble Kalman filters. In this study, we explore the potential of using a local ensemble Kalman filter with either covariance localization or local domains to retrieve the state and a combination of important global and local parameters. Global parameters are utilized to represent surrogate dynamics, such as a neural network, which is similar to data-driven machine learning of dynamics, while local parameters typically represent the model's forcings. We introduce a family of algorithms for covariance and local domain localization in the context of this joint state and parameter filter. Specifically, we demonstrate how to accurately update global parameters using a local domain EnKF, such as LETKF, which is inherently a local method. Through testing on the 40-variable Lorenz model using various local EnKF methods, we show the effectiveness of our approach. Finally, we provide a two-dimensional illustration based on a multi-layer Lorenz model that uses radiance-like non-local observations, and both local domains and covariance localization to learn the chaotic dynamics, local forcings, and the connections between layers. This paper addresses the crucial question of online estimation of both global and local model parameters.",1
"The rapid developments in advanced sensing and imaging bring about a data-rich environment, facilitating the effective modeling, monitoring, and control of complex systems. For example, the body-sensor network captures multi-channel information pertinent to the electrical activity of the heart (i.e., electrocardiograms (ECG)), which enables medical scientists to monitor and detect abnormal cardiac conditions. However, the high-dimensional sensing data are generally complexly structured and realizing the full data potential depends to a great extent on advanced analytical and predictive methods. This paper presents a physics-constrained deep learning (P-DL) framework for high-dimensional inverse ECG modeling. This method integrates the physical laws of the complex system with the advanced deep learning infrastructure for effective prediction of the system dynamics. The proposed P-DL approach is implemented to solve the inverse ECG model and predict the time-varying distribution of electric potentials in the heart from the ECG data measured by the body-surface sensor network. Experimental results show that the proposed P-DL method significantly outperforms existing methods that are commonly used in current practice.",0
"The advancements in sensing and imaging technology have led to an environment rich in data, which can be utilized for modeling, monitoring, and controlling complex systems. For instance, the body-sensor network captures multi-channel information related to the electrical activity of the heart, allowing medical professionals to detect abnormal cardiac conditions. However, due to the complex structure of high-dimensional sensing data, advanced analytical and predictive methods are necessary to fully exploit its potential. This study introduces a physics-constrained deep learning (P-DL) framework that integrates physical laws with deep learning infrastructure to effectively predict system dynamics. The proposed approach is used to solve the inverse ECG model and predict the time-varying distribution of electric potentials in the heart. Experimental results show that P-DL significantly outperforms existing methods.",1
"Learning in deep neural networks (DNNs) is implemented through minimizing a highly non-convex loss function, typically by a stochastic gradient descent (SGD) method. This learning process can effectively find good wide minima without being trapped in poor local ones. We present a novel account of how such effective deep learning emerges through the interactions of the SGD and the geometrical structure of the loss landscape. Rather than being a normal diffusion process (i.e. Brownian motion) as often assumed, we find that the SGD exhibits rich, complex dynamics when navigating through the loss landscape; initially, the SGD exhibits anomalous superdiffusion, which attenuates gradually and changes to subdiffusion at long times when the solution is reached. Such learning dynamics happen ubiquitously in different DNNs such as ResNet and VGG-like networks and are insensitive to batch size and learning rate. The anomalous superdiffusion process during the initial learning phase indicates that the motion of SGD along the loss landscape possesses intermittent, big jumps; this non-equilibrium property enables the SGD to escape from sharp local minima. By adapting the methods developed for studying energy landscapes in complex physical systems, we find that such superdiffusive learning dynamics are due to the interactions of the SGD and the fractal-like structure of the loss landscape. We further develop a simple model to demonstrate the mechanistic role of the fractal loss landscape in enabling the SGD to effectively find global minima. Our results thus reveal the effectiveness of deep learning from a novel perspective and have implications for designing efficient deep neural networks.",0
"The process of learning in deep neural networks (DNNs) involves minimizing a non-convex loss function using stochastic gradient descent (SGD). This approach is effective in finding good wide minima while avoiding poor local ones. Our research offers a new perspective on how this successful deep learning occurs through the interaction between SGD and the geometrical structure of the loss landscape. Contrary to previous assumptions, we found that the SGD displays intricate dynamics when navigating through the loss landscape. Initially, the SGD exhibits anomalous superdiffusion, which gradually attenuates and changes to subdiffusion when the optimal solution is reached. These dynamics are common in different DNNs and are not dependent on batch size or learning rate. During the initial learning phase, the anomalous superdiffusion process indicates that SGD's motion along the loss landscape involves intermittent, large jumps that allow it to avoid sharp local minima. We use methods developed for studying energy landscapes in complex physical systems to demonstrate that the fractal-like structure of the loss landscape plays a crucial role in enabling SGD to find global minima effectively. Our findings offer a new understanding of deep learning and have important implications for the design of efficient DNNs.",1
"Highly complex deep learning models are increasingly integrated into modern cyber-physical systems (CPS), many of which have strict safety requirements. One problem arising from this is that deep learning lacks interpretability, operating as a black box. The reliability of deep learning is heavily impacted by how well the model training data represents runtime test data, especially when the input space dimension is high as natural images. In response, we propose a robust out-of-distribution (OOD) detection framework. Our approach detects unusual movements from driving video in real-time by combining classical optic flow operation with representation learning via variational autoencoder (VAE). We also design a method to locate OOD factors in images. Evaluation on a driving simulation data set shows that our approach is statistically more robust than related works.",0
"Modern cyber-physical systems (CPS) often require the integration of highly complex deep learning models, which can pose a challenge due to their lack of interpretability. This is particularly concerning for systems with strict safety requirements. The reliability of deep learning models is heavily influenced by the representativeness of the training data, particularly in high-dimensional input spaces like natural images. To address this issue, we propose a robust out-of-distribution (OOD) detection framework that combines classical optic flow operation with representation learning via variational autoencoder (VAE). Our approach can detect unusual movements from driving video in real-time and identify OOD factors in images. Evaluation on a driving simulation data set demonstrates that our approach is more statistically robust than related works.",1
"Predictive monitoring -- making predictions about future states and monitoring if the predicted states satisfy requirements -- offers a promising paradigm in supporting the decision making of Cyber-Physical Systems (CPS). Existing works of predictive monitoring mostly focus on monitoring individual predictions rather than sequential predictions. We develop a novel approach for monitoring sequential predictions generated from Bayesian Recurrent Neural Networks (RNNs) that can capture the inherent uncertainty in CPS, drawing on insights from our study of real-world CPS datasets. We propose a new logic named \emph{Signal Temporal Logic with Uncertainty} (STL-U) to monitor a flowpipe containing an infinite set of uncertain sequences predicted by Bayesian RNNs. We define STL-U strong and weak satisfaction semantics based on if all or some sequences contained in a flowpipe satisfy the requirement. We also develop methods to compute the range of confidence levels under which a flowpipe is guaranteed to strongly (weakly) satisfy an STL-U formula. Furthermore, we develop novel criteria that leverage STL-U monitoring results to calibrate the uncertainty estimation in Bayesian RNNs. Finally, we evaluate the proposed approach via experiments with real-world datasets and a simulated smart city case study, which show very encouraging results of STL-U based predictive monitoring approach outperforming baselines.",0
"The use of predictive monitoring in Cyber-Physical Systems (CPS) has the potential to greatly aid decision making by predicting future states and monitoring them for compliance with requirements. However, current predictive monitoring approaches mainly focus on monitoring individual predictions rather than sequential ones. Our study of real-world CPS datasets led us to develop a unique method for monitoring sequential predictions generated from Bayesian Recurrent Neural Networks (RNNs) that can account for the inherent uncertainty in CPS. We introduce a new logic, called Signal Temporal Logic with Uncertainty (STL-U), to monitor a flowpipe containing an infinite number of uncertain sequences predicted by Bayesian RNNs. Our approach includes both strong and weak satisfaction semantics for STL-U, depending on whether all or some sequences in a flowpipe meet the requirements. We also provide methods for computing the confidence level range within which a flowpipe will strongly or weakly satisfy an STL-U formula. Additionally, we propose criteria that use STL-U monitoring results to adjust the uncertainty estimation in Bayesian RNNs. Finally, we demonstrate the effectiveness of our approach through experiments with real-world datasets and a simulated smart city case study, which indicate that STL-U based predictive monitoring outperforms existing methods.",1
"The quantification of positively buoyant marine plastic debris is critical to understanding how concentrations of trash from across the world's ocean and identifying high concentration garbage hotspots in dire need of trash removal. Currently, the most common monitoring method to quantify floating plastic requires the use of a manta trawl. Techniques requiring manta trawls (or similar surface collection devices) utilize physical removal of marine plastic debris as the first step and then analyze collected samples as a second step. The need for physical removal before analysis incurs high costs and requires intensive labor preventing scalable deployment of a real-time marine plastic monitoring service across the entirety of Earth's ocean bodies. Without better monitoring and sampling methods, the total impact of plastic pollution on the environment as a whole, and details of impact within specific oceanic regions, will remain unknown. This study presents a highly scalable workflow that utilizes images captured within the epipelagic layer of the ocean as an input. It produces real-time quantification of marine plastic debris for accurate quantification and physical removal. The workflow includes creating and preprocessing a domain-specific dataset, building an object detection model utilizing a deep neural network, and evaluating the model's performance. YOLOv5-S was the best performing model, which operates at a Mean Average Precision (mAP) of 0.851 and an F1-Score of 0.89 while maintaining near-real-time speed.",0
"Understanding the concentration of buoyant marine plastic debris is crucial in identifying areas with high levels of trash in need of removal. The common method for monitoring floating plastic involves using a manta trawl to physically remove debris before analyzing samples, which is costly and labor-intensive. Without better monitoring and sampling techniques, the impact of plastic pollution on the environment and specific oceanic regions will remain unknown. This study presents a scalable workflow using images from the epipelagic layer to quantify debris in real-time, eliminating the need for physical removal. The workflow involves creating a domain-specific dataset, building an object detection model with YOLOv5-S, and evaluating its performance, which has a high Mean Average Precision and F1-Score while maintaining near-real-time speed.",1
"This paper presents a PINN training framework that employs (1) pre-training steps that accelerates and improve the robustness of the training of physics-informed neural network with auxiliary data stored in point clouds, (2) a net-to-net knowledge transfer algorithm that improves the weight initialization of the neural network and (3) a multi-objective optimization algorithm that may improve the performance of a physical-informed neural network with competing constraints. We consider the training and transfer and multi-task learning of physics-informed neural network (PINN) as multi-objective problems where the physics constraints such as the governing equation, boundary conditions, thermodynamic inequality, symmetry, and invariant properties, as well as point cloud used for pre-training can sometimes lead to conflicts and necessitating the seek of the Pareto optimal solution. In these situations, weighted norms commonly used to handle multiple constraints may lead to poor performance, while other multi-objective algorithms may scale poorly with increasing dimensionality. To overcome this technical barrier, we adopt the concept of vectorized objective function and modify a gradient descent approach to handle the issue of conflicting gradients. Numerical experiments are compared the benchmark boundary value problems solved via PINN. The performance of the proposed paradigm is compared against the classical equal-weighted norm approach. Our numerical experiments indicate that the brittleness and lack of robustness demonstrated in some PINN implementations can be overcome with the proposed strategy.",0
"In this paper, we introduce a framework for training physics-informed neural networks (PINNs) using a multi-objective approach. To improve the robustness and efficiency of the training process, we employ pre-training steps that utilize auxiliary data stored in point clouds, a net-to-net knowledge transfer algorithm for weight initialization, and a multi-objective optimization algorithm to handle competing constraints. We recognize that the training and transfer of PINNs can present conflicts between physics constraints and pre-training data, requiring the search for a Pareto optimal solution. To address this, we propose a vectorized objective function and modify a gradient descent approach to handle conflicting gradients. Numerical experiments demonstrate that our approach outperforms the traditional equal-weighted norm approach, overcoming the brittleness and lack of robustness seen in some PINN implementations.",1
"Deep learning has an increasing impact to assist research, allowing, for example, the discovery of novel materials. Until now, however, these artificial intelligence techniques have fallen short of discovering the full differential equation of an experimental physical system. Here we show that a dynamical neural network, trained on a minimal amount of data, can predict the behavior of spintronic devices with high accuracy and an extremely efficient simulation time, compared to the micromagnetic simulations that are usually employed to model them. For this purpose, we re-frame the formalism of Neural Ordinary Differential Equations (ODEs) to the constraints of spintronics: few measured outputs, multiple inputs and internal parameters. We demonstrate with Spin-Neural ODEs an acceleration factor over 200 compared to micromagnetic simulations for a complex problem -- the simulation of a reservoir computer made of magnetic skyrmions (20 minutes compared to three days). In a second realization, we show that we can predict the noisy response of experimental spintronic nano-oscillators to varying inputs after training Spin-Neural ODEs on five milliseconds of their measured response to different excitations. Spin-Neural ODE is a disruptive tool for developing spintronic applications in complement to micromagnetic simulations, which are time-consuming and cannot fit experiments when noise or imperfections are present. Spin-Neural ODE can also be generalized to other electronic devices involving dynamics.",0
"Although deep learning has been useful for assisting research and discovering new materials, it has previously been insufficient in discovering the complete differential equation of an experimental physical system. However, through the use of a dynamical neural network, we show that spintronic device behavior can be accurately predicted with minimal data and an efficient simulation time compared to traditional micromagnetic simulations. This is accomplished by using the formalism of Neural Ordinary Differential Equations (ODEs) and adapting it to the constraints of spintronics. Our Spin-Neural ODEs allow for an acceleration factor of over 200 compared to micromagnetic simulations, as demonstrated in the simulation of a magnetic skyrmion reservoir computer. Additionally, we can predict the noisy response of experimental spintronic nano-oscillators to varying inputs after training Spin-Neural ODEs on just five milliseconds of their measured response. This tool is disruptive in the development of spintronic applications as it complements micromagnetic simulations and can account for noise and imperfections. Furthermore, Spin-Neural ODE can be applied to other electronic devices that involve dynamics.",1
"We propose a novel method for exploring the dynamics of physically based animated characters, and learning a task-agnostic action space that makes movement optimization easier. Like several previous papers, we parameterize actions as target states, and learn a short-horizon goal-conditioned low-level control policy that drives the agent's state towards the targets. Our novel contribution is that with our exploration data, we are able to learn the low-level policy in a generic manner and without any reference movement data. Trained once for each agent or simulation environment, the policy improves the efficiency of optimizing both trajectories and high-level policies across multiple tasks and optimization algorithms. We also contribute novel visualizations that show how using target states as actions makes optimized trajectories more robust to disturbances; this manifests as wider optima that are easy to find. Due to its simplicity and generality, our proposed approach should provide a building block that can improve a large variety of movement optimization methods and applications.",0
"Our method proposes a new way to study the movements of physically based animated characters and learn an action space that simplifies movement optimization for various tasks. Similar to past studies, we represent actions as target states and develop a low-level control policy that guides the agent's state towards the targets. However, our innovation lies in the ability to learn the low-level policy in a universal manner without relying on any reference movement data, using only exploration data. Once trained for each agent or simulation environment, the policy enhances the efficiency of optimizing trajectories and high-level policies across multiple tasks and optimization algorithms. We also introduce novel visualizations that demonstrate how using target states as actions creates wider optima that are more resistant to disturbances. Our approach's simplicity and adaptability make it a valuable building block that can enhance a wide range of movement optimization methods and applications.",1
"We present a new four-pronged approach to build firefighter's situational awareness for the first time in the literature. We construct a series of deep learning frameworks built on top of one another to enhance the safety, efficiency, and successful completion of rescue missions conducted by firefighters in emergency first response settings. First, we used a deep Convolutional Neural Network (CNN) system to classify and identify objects of interest from thermal imagery in real-time. Next, we extended this CNN framework for object detection, tracking, segmentation with a Mask RCNN framework, and scene description with a multimodal natural language processing(NLP) framework. Third, we built a deep Q-learning-based agent, immune to stress-induced disorientation and anxiety, capable of making clear navigation decisions based on the observed and stored facts in live-fire environments. Finally, we used a low computational unsupervised learning technique called tensor decomposition to perform meaningful feature extraction for anomaly detection in real-time. With these ad-hoc deep learning structures, we built the artificial intelligence system's backbone for firefighters' situational awareness. To bring the designed system into usage by firefighters, we designed a physical structure where the processed results are used as inputs in the creation of an augmented reality capable of advising firefighters of their location and key features around them, which are vital to the rescue operation at hand, as well as a path planning feature that acts as a virtual guide to assist disoriented first responders in getting back to safety. When combined, these four approaches present a novel approach to information understanding, transfer, and synthesis that could dramatically improve firefighter response and efficacy and reduce life loss.",0
"In this literature, we introduce a new approach to enhance firefighter's situational awareness, which comprises four different methods. Firstly, we applied a deep Convolutional Neural Network (CNN) system to categorize and recognize objects of interest from thermal imagery in real-time. Then, we expanded this CNN framework to include object detection, tracking, segmentation using a Mask RCNN framework, and scene description with a multimodal natural language processing (NLP) framework. Thirdly, we developed a deep Q-learning-based agent that can make clear navigation decisions based on observed and stored facts in live-fire environments, immune to stress-induced disorientation and anxiety. Finally, we used a low computational unsupervised learning technique called tensor decomposition to perform meaningful feature extraction for anomaly detection in real-time. By implementing these ad-hoc deep learning structures, we established the foundation of an artificial intelligence system to enhance firefighter's situational awareness. Furthermore, we designed a physical structure to bring this system into usage, which incorporates an augmented reality feature, advising firefighters of their location and key features around them, along with a path planning feature to assist disoriented first responders in getting back to safety. The combination of these four approaches presents a unique approach to information understanding, transfer, and synthesis that could significantly improve firefighter response and efficacy while minimizing loss of life.",1
"Physics-informed neural networks (PINNs) have been widely used to solve various scientific computing problems. However, large training costs limit PINNs for some real-time applications. Although some works have been proposed to improve the training efficiency of PINNs, few consider the influence of initialization. To this end, we propose a New Reptile initialization based Physics-Informed Neural Network (NRPINN). The original Reptile algorithm is a meta-learning initialization method based on labeled data. PINNs can be trained with less labeled data or even without any labeled data by adding partial differential equations (PDEs) as a penalty term into the loss function. Inspired by this idea, we propose the new Reptile initialization to sample more tasks from the parameterized PDEs and adapt the penalty term of the loss. The new Reptile initialization can acquire initialization parameters from related tasks by supervised, unsupervised, and semi-supervised learning. Then, PINNs with initialization parameters can efficiently solve PDEs. Besides, the new Reptile initialization can also be used for the variants of PINNs. Finally, we demonstrate and verify the NRPINN considering both forward problems, including solving Poisson, Burgers, and Schr\""odinger equations, as well as inverse problems, where unknown parameters in the PDEs are estimated. Experimental results show that the NRPINN training is much faster and achieves higher accuracy than PINNs with other initialization methods.",0
"Physics-informed neural networks (PINNs) have gained widespread application in tackling diverse scientific computing problems. However, their large training costs limit their use in some real-time applications. Existing works have attempted to address this issue but have overlooked the impact of initialization. To address this, we propose a New Reptile initialization-based Physics-Informed Neural Network (NRPINN). The Reptile algorithm is a meta-learning initialization technique based on labeled data. PINNs can be trained with less labeled data or none at all by incorporating partial differential equations (PDEs) as a penalty term in the loss function. Drawing inspiration from this idea, our new Reptile initialization samples more tasks from parameterized PDEs and adjusts the penalty term of the loss function. Supervised, unsupervised, and semi-supervised learning help the new Reptile initialization acquire initialization parameters from related tasks, allowing PINNs to solve PDEs more efficiently. Moreover, the new Reptile initialization can be used for various PINN variants. We demonstrate and verify the NRPINN's effectiveness in solving both forward and inverse problems, such as Poisson, Burgers, and Schr\""odinger equations. Experimental results show that the NRPINN's training is significantly faster and more accurate than PINNs with other initialization methods.",1
"Identifying the governing equations of a nonlinear dynamical system is key to both understanding the physical features of the system and constructing an accurate model of the dynamics that generalizes well beyond the available data. We propose a machine learning framework for discovering these governing equations using only partial observations, combining an encoder for state reconstruction with a sparse symbolic model. Our tests show that this method can successfully reconstruct the full system state and identify the underlying dynamics for a variety of ODE and PDE systems.",0
"To comprehend the physical characteristics of a nonlinear dynamic system and develop a precise model of its dynamics that extends beyond the given data, it is essential to determine the governing equations. Our approach employs a machine learning system that detects these equations using only limited observations. This method involves a state reconstruction encoder combined with a sparse symbolic model. Our experiments demonstrate that this technique can effectively reconstruct the complete system state and recognize the fundamental dynamics of different ODE and PDE systems.",1
"In this paper, we inaugurate the field of quantum fair machine learning. We undertake a comparative analysis of differences and similarities between classical and quantum fair machine learning algorithms, specifying how the unique features of quantum computation alter measures, metrics and remediation strategies when quantum algorithms are subject to fairness constraints. We present the first results in quantum fair machine learning by demonstrating the use of Grover's search algorithm to satisfy statistical parity constraints imposed on quantum algorithms. We provide lower-bounds on iterations needed to achieve such statistical parity within $\epsilon$-tolerance. We extend canonical Lipschitz-conditioned individual fairness criteria to the quantum setting using quantum metrics. We examine the consequences for typical measures of fairness in machine learning context when quantum information processing and quantum data are involved. Finally, we propose open questions and research programmes for this new field of interest to researchers in computer science, ethics and quantum computation.",0
"This article introduces the concept of quantum fair machine learning and compares classical and quantum fair machine learning algorithms. The paper explains how quantum computation affects measures, metrics, and remediation strategies when quantum algorithms are subject to fairness constraints. The authors demonstrate the use of Grover's search algorithm to achieve statistical parity constraints imposed on quantum algorithms and provide lower-bounds on iterations needed to achieve statistical parity within $\epsilon$-tolerance. They also extend canonical Lipschitz-conditioned individual fairness criteria to the quantum setting using quantum metrics. The article discusses the implications for measures of fairness in machine learning when quantum information processing and quantum data are involved. Finally, the authors propose open questions and research programs for this new field, which will be of interest to researchers in computer science, ethics, and quantum computation.",1
"The reliability of deep learning algorithms is fundamentally challenged by the existence of adversarial examples, which are incorrectly classified inputs that are extremely close to a correctly classified input. We explore the properties of adversarial examples for deep neural networks with random weights and biases, and prove that for any $p\ge1$, the $\ell^p$ distance of any given input from the classification boundary scales as one over the square root of the dimension of the input times the $\ell^p$ norm of the input. The results are based on the recently proved equivalence between Gaussian processes and deep neural networks in the limit of infinite width of the hidden layers, and are validated with experiments on both random deep neural networks and deep neural networks trained on the MNIST and CIFAR10 datasets. The results constitute a fundamental advance in the theoretical understanding of adversarial examples, and open the way to a thorough theoretical characterization of the relation between network architecture and robustness to adversarial perturbations.",0
"The presence of adversarial examples, which are inputs that are similar to correctly classified inputs but are classified incorrectly, poses a significant challenge to the dependability of deep learning algorithms. We investigated the features of adversarial examples in deep neural networks with arbitrary weights and biases. Our research demonstrates that the $\ell^p$ distance of an input from the classification boundary is proportional to the reciprocal of the square root of the input dimension and the $\ell^p$ norm of the input for any $p\ge1$. These findings are rooted in the newly established connection between Gaussian processes and deep neural networks in the context of infinite-width hidden layers, and are supported by experiments using random deep neural networks as well as those trained on the MNIST and CIFAR10 datasets. These results mark a significant development in the comprehension of adversarial examples and pave the way for a comprehensive theoretical analysis of the relationship between network architecture and resilience to adversarial perturbations.",1
"Compared to the conventional metasurface design, machine learning-based methods have recently created an inspiring platform for an inverse realization of the metasurfaces. Here, we have used the Deep Neural Network (DNN) for the generation of desired output unit cell structures in an ultra-wide working frequency band for both TE and TM polarized waves. To automatically generate metasurfaces in a wide range of working frequencies from 4 to 45 GHz, we deliberately design an 8 ring-shaped pattern in such a way that the unit-cells generated in the dataset can produce single or multiple notches in the desired working frequency band. Compared to the general approach, whereby the final metasurface structure may be formed by any randomly distributed ""0"" and ""1"", we propose here a restricted output structure. By restricting the output, the number of calculations will be reduced and the learning speed will be increased. Moreover, we have shown that the accuracy of the network reaches 91\%. Obtaining the final unit cell directly without any time-consuming optimization algorithms for both TE and TM polarized waves, and high average accuracy, promises an effective strategy for the metasurface design; thus, the designer is required only to focus on the design goal.",0
"Machine learning-based methods have created a promising platform for inverse realization of metasurfaces when compared to conventional designs. In this study, we utilized a Deep Neural Network (DNN) to generate desired output unit cell structures for both TE and TM polarized waves in an ultra-wide working frequency band. To create metasurfaces across a wide range of frequencies from 4 to 45 GHz, we designed an 8 ring-shaped pattern that would produce single or multiple notches in the desired frequency band. Rather than using a general approach of randomly distributed ""0"" and ""1"" to form the final metasurface structure, we proposed a restricted output structure to reduce calculations and increase learning speed. Our approach achieved a 91% accuracy rate, and we obtained the final unit cell directly without the need for time-consuming optimization algorithms for both polarized waves. This effective strategy for metasurface design allows designers to focus solely on the design goal.",1
"We study how an offline dataset of prior (possibly random) experience can be used to address two challenges that autonomous systems face when they endeavor to learn from, adapt to, and collaborate with humans : (1) identifying the human's intent and (2) safely optimizing the autonomous system's behavior to achieve this inferred intent. First, we use the offline dataset to efficiently infer the human's reward function via pool-based active preference learning. Second, given this learned reward function, we perform offline reinforcement learning to optimize a policy based on the inferred human intent. Crucially, our proposed approach does not require actual physical rollouts or an accurate simulator for either the reward learning or policy optimization steps, enabling both safe and efficient apprenticeship learning. We identify and evaluate our approach on a subset of existing offline RL benchmarks that are well suited for offline reward learning and also evaluate extensions of these benchmarks which allow more open-ended behaviors. Our experiments show that offline preference-based reward learning followed by offline reinforcement learning enables efficient and high-performing policies, while only requiring small numbers of preference queries. Videos available at https://sites.google.com/view/offline-prefs.",0
"Our focus is on how autonomous systems can overcome two key challenges when collaborating with humans, namely identifying human intent and optimizing behavior to achieve this intent. To achieve this, we utilize an offline dataset of previous experiences and employ pool-based active preference learning to efficiently infer human reward functions. From this, we can perform offline reinforcement learning to optimize policies based on the inferred human intent. Crucially, our approach does not require physical rollouts or an accurate simulator, making it both safe and efficient for apprenticeship learning. We evaluate our approach on a subset of existing offline RL benchmarks and demonstrate its effectiveness in enabling efficient and high-performing policies with minimal preference queries. Further details and videos can be found at https://sites.google.com/view/offline-prefs.",1
"In a physical neural system, backpropagation is faced with a number of obstacles including: the need for labeled data, the violation of the locality learning principle, the need for symmetric connections, and the lack of modularity. Tourbillon is a new architecture that addresses all these limitations. At its core, it consists of a stack of circular autoencoders followed by an output layer. The circular autoencoders are trained in self-supervised mode by recirculation algorithms and the top layer in supervised mode by stochastic gradient descent, with the option of propagating error information through the entire stack using non-symmetric connections. While the Tourbillon architecture is meant primarily to address physical constraints, and not to improve current engineering applications of deep learning, we demonstrate its viability on standard benchmark datasets including MNIST, Fashion MNIST, and CIFAR10. We show that Tourbillon can achieve comparable performance to models trained with backpropagation and outperform models that are trained with other physically plausible algorithms, such as feedback alignment.",0
"Backpropagation encounters several challenges when operated in a physical neural system, such as the requirement for labeled data, non-compliance with the locality learning principle, the need for symmetrical connections, and a lack of modularity. To overcome these obstacles, Tourbillon has been developed as a new architecture that comprises a stack of circular autoencoders followed by an output layer. The circular autoencoders are trained using self-supervised mode through recirculation algorithms, while the top layer is trained using supervised mode with stochastic gradient descent. Error information can be propagated through the entire stack using non-symmetric connections. Although the Tourbillon architecture is primarily intended to address physical constraints rather than improve current engineering applications of deep learning, we demonstrate its effectiveness on standard benchmark datasets, including MNIST, Fashion MNIST, and CIFAR10. Our results show that Tourbillon can achieve comparable performance to models trained using backpropagation and outperform models trained using other physically plausible algorithms, such as feedback alignment.",1
"Localization and tracking of objects using data-driven methods is a popular topic due to the complexity in characterizing the physics of wireless channel propagation models. In these modeling approaches, data needs to be gathered to accurately train models, at the same time that user's privacy is maintained. An appealing scheme to cooperatively achieve these goals is known as Federated Learning (FL). A challenge in FL schemes is the presence of non-independent and identically distributed (non-IID) data, caused by unevenly exploration of different areas. In this paper, we consider the use of recent FL schemes to train a set of personalized models that are then optimally fused through Bayesian rules, which makes it appropriate in the context of indoor localization.",0
"The complexity of wireless channel propagation models makes object localization and tracking using data-driven methods a popular topic. However, accurate model training requires data gathering while maintaining user privacy. One solution that addresses these concerns is Federated Learning (FL), which cooperatively achieves these goals. However, FL schemes can face challenges due to non-independent and identically distributed (non-IID) data caused by uneven exploration of different areas. In this paper, we explore the use of recent FL schemes to train personalized models that are optimally fused using Bayesian rules, making it a suitable approach for indoor localization.",1
"We consider the task of feature selection for reconstruction which consists in choosing a small subset of features from which whole data instances can be reconstructed. This is of particular importance in several contexts involving for example costly physical measurements, sensor placement or information compression. To break the intrinsic combinatorial nature of this problem, we formulate the task as optimizing a binary mask distribution enabling an accurate reconstruction. We then face two main challenges. One concerns differentiability issues due to the binary distribution. The second one corresponds to the elimination of redundant information by selecting variables in a correlated fashion which requires modeling the covariance of the binary distribution. We address both issues by introducing a relaxation of the problem via a novel reparameterization of the logitNormal distribution. We demonstrate that the proposed method provides an effective exploration scheme and leads to efficient feature selection for reconstruction through evaluation on several high dimensional image benchmarks. We show that the method leverages the intrinsic geometry of the data, facilitating reconstruction.",0
"The objective is to select a small number of features that can be used to reconstruct entire data instances, which is crucial in various scenarios such as expensive physical measurements, sensor placement, and information compression. To overcome the combinatorial nature of the task, we propose optimizing a binary mask distribution to achieve accurate reconstruction. However, two primary challenges arise: differentiability issues due to the binary distribution and the elimination of redundant information by selecting correlated variables, requiring modeling of the binary distribution's covariance. We resolve both challenges by introducing a novel reparameterization of the logitNormal distribution. Our method demonstrates effective exploration and efficient feature selection for reconstruction, as demonstrated by evaluation on high dimensional image benchmarks. Additionally, we demonstrate that our approach leverages the intrinsic geometry of the data, facilitating reconstruction.",1
"We propose a novel method to generate fabrication blueprints from images of carpentered items. While 3D reconstruction from images is a well-studied problem, typical approaches produce representations that are ill-suited for computer-aided design and fabrication applications. Our key insight is that fabrication processes define and constrain the design space for carpentered objects, and can be leveraged to develop novel reconstruction methods. Our method makes use of domain-specific constraints to recover not just valid geometry, but a semantically valid assembly of parts, using a combination of image-based and geometric optimization techniques.   We demonstrate our method on a variety of wooden objects and furniture, and show that we can automatically obtain designs that are both easy to edit and accurate recreations of the ground truth. We further illustrate how our method can be used to fabricate a physical replica of the captured object as well as a customized version, which can be produced by directly editing the reconstructed model in CAD software.",0
"Our proposal presents a new approach for generating fabrication blueprints by using images of carpentered items. While 3D reconstruction from images is a well-known problem, the typical methods are not suitable for computer-aided design and fabrication applications. Our approach aims to leverage fabrication processes, which define and restrict the design space for carpentered objects, to develop innovative reconstruction techniques. By using domain-specific constraints, our method recovers not only valid geometry but also a semantically valid assembly of parts, through a combination of image-based and geometric optimization techniques. We showcase the effectiveness of our method by demonstrating its application on various wooden objects and furniture. Furthermore, we show that our method automatically produces designs that are both editable and accurate recreations of the ground truth. Lastly, we illustrate how our approach can be used to create physical replicas of the captured object, as well as customized versions that can be produced by directly editing the reconstructed model in CAD software.",1
"The concept of Hybrid Twin (HT) has recently received a growing interest thanks to the availability of powerful machine learning techniques. This twin concept combines physics-based models within a model-order reduction framework-to obtain real-time feedback rates-and data science. Thus, the main idea of the HT is to develop on-the-fly data-driven models to correct possible deviations between measurements and physics-based model predictions. This paper is focused on the computation of stable, fast and accurate corrections in the Hybrid Twin framework. Furthermore, regarding the delicate and important problem of stability, a new approach is proposed, introducing several sub-variants and guaranteeing a low computational cost as well as the achievement of a stable time-integration.",0
"The Hybrid Twin (HT) has gained attention recently due to the availability of advanced machine learning techniques. It combines physics-based models and model-order reduction to achieve real-time feedback rates, as well as data science. The primary objective of the HT is to create data-driven models in real-time to correct any discrepancies between measurements and physics-based model predictions. This research focuses on generating stable, fast, and precise corrections within the Hybrid Twin framework. Additionally, a new approach is suggested for ensuring stability, consisting of various sub-variants that ensure low computational costs and stable time-integration.",1
"We present Megaverse, a new 3D simulation platform for reinforcement learning and embodied AI research. The efficient design of our engine enables physics-based simulation with high-dimensional egocentric observations at more than 1,000,000 actions per second on a single 8-GPU node. Megaverse is up to 70x faster than DeepMind Lab in fully-shaded 3D scenes with interactive objects. We achieve this high simulation performance by leveraging batched simulation, thereby taking full advantage of the massive parallelism of modern GPUs. We use Megaverse to build a new benchmark that consists of several single-agent and multi-agent tasks covering a variety of cognitive challenges. We evaluate model-free RL on this benchmark to provide baselines and facilitate future research. The source code is available at https://www.megaverse.info",0
"Megaverse is a novel 3D simulation platform designed for reinforcement learning and embodied AI research. With an efficient engine design, our platform can perform physics-based simulation with high-dimensional egocentric observations at over 1,000,000 actions per second on a single 8-GPU node. In fact, Megaverse is up to 70 times faster than DeepMind Lab when working with fully-shaded 3D scenes that include interactive objects. We achieve such high simulation performance through batched simulation, which fully utilizes the massive parallelism of modern GPUs. By using Megaverse, we created a new benchmark that includes various single-agent and multi-agent tasks that pose different cognitive challenges. We evaluated model-free RL on this benchmark to establish baselines and support future research. The source code for Megaverse is available at https://www.megaverse.info.",1
"Developing video understanding intelligence is quite challenging because it requires holistic integration of images, scripts, and sounds based on natural language processing, temporal dependency, and reasoning. Recently, substantial attempts have been made on several video datasets with associated question answering (QA) on a large scale. However, existing evaluation metrics for video question answering (VideoQA) do not provide meaningful analysis. To make progress, we argue that a well-made framework, established on the way humans understand, is required to explain and evaluate the performance of understanding in detail. Then we propose a top-down evaluation system for VideoQA, based on the cognitive process of humans and story elements: Cognitive Modules for Evaluation (CogME). CogME is composed of three cognitive modules: targets, contents, and thinking. The interaction among the modules in the understanding procedure can be expressed in one sentence as follows: ""I understand the CONTENT of the TARGET through a way of THINKING."" Each module has sub-components derived from the story elements. We can specify the required aspects of understanding by annotating the sub-components to individual questions. CogME thus provides a framework for an elaborated specification of VideoQA datasets. To examine the suitability of a VideoQA dataset for validating video understanding intelligence, we evaluated the baseline model of the DramaQA dataset by applying CogME. The evaluation reveals that story elements are unevenly reflected in the existing dataset, and the model based on the dataset may cause biased predictions. Although this study has only been able to grasp a narrow range of stories, we expect that it offers the first step in considering the cognitive process of humans on the video understanding intelligence of humans and AI.",0
"It is quite difficult to develop intelligence for video understanding as it requires a comprehensive integration of images, scripts, and sounds based on natural language processing, temporal dependency, and reasoning. Though there have been substantial efforts to perform question answering on various video datasets, existing evaluation metrics for VideoQA are not meaningful. To make progress, a framework based on human understanding is necessary to explain and evaluate the performance of understanding in detail. Therefore, we propose a top-down evaluation system, CogME, for VideoQA based on the cognitive process of humans and story elements. CogME consists of three cognitive modules: targets, contents, and thinking, and the interaction among them can be expressed as ""I understand the content of the target through a way of thinking."" We can specify the required aspects of understanding by annotating the sub-components to individual questions. CogME provides a framework for an elaborated specification of VideoQA datasets. We evaluated the baseline model of the DramaQA dataset by applying CogME to examine its suitability for validating video understanding intelligence. The evaluation shows that story elements are unevenly reflected in the existing dataset and the model may cause biased predictions. Although our study has a narrow focus, we believe that it represents the first step towards considering the cognitive process of humans and AI in video understanding intelligence.",1
"Efficient machine learning implementations optimized for inference in hardware have wide-ranging benefits, depending on the application, from lower inference latency to higher data throughput and reduced energy consumption. Two popular techniques for reducing computation in neural networks are pruning, removing insignificant synapses, and quantization, reducing the precision of the calculations. In this work, we explore the interplay between pruning and quantization during the training of neural networks for ultra low latency applications targeting high energy physics use cases. Techniques developed for this study have potential applications across many other domains. We study various configurations of pruning during quantization-aware training, which we term quantization-aware pruning, and the effect of techniques like regularization, batch normalization, and different pruning schemes on performance, computational complexity, and information content metrics. We find that quantization-aware pruning yields more computationally efficient models than either pruning or quantization alone for our task. Further, quantization-aware pruning typically performs similar to or better in terms of computational efficiency compared to other neural architecture search techniques like Bayesian optimization. Surprisingly, while networks with different training configurations can have similar performance for the benchmark application, the information content in the network can vary significantly, affecting its generalizability.",0
"Implementing efficient machine learning in hardware for inference can lead to various benefits, such as reduced latency, increased data throughput, and lower energy consumption, depending on the application. To decrease computation in neural networks, two commonly used techniques are pruning, which eliminates insignificant synapses, and quantization, which reduces calculation precision. In this study, we investigate the interaction between pruning and quantization during neural network training for ultra-low latency applications in high energy physics. Our techniques have potential applications in various domains. We analyze different configurations of pruning during quantization-aware training, which we refer to as quantization-aware pruning, and assess the impact of regularization, batch normalization, and diverse pruning schemes on computational complexity, performance, and information content metrics. Our findings demonstrate that quantization-aware pruning generates more computationally efficient models for our task than either pruning or quantization alone. Additionally, compared to other neural architecture search techniques such as Bayesian optimization, quantization-aware pruning typically performs similarly or better in terms of computational efficiency. Surprisingly, although networks with different training settings can have comparable performance for the benchmark application, the information content in the network can differ significantly and influence its generalizability.",1
"In this work we explore the limiting dynamics of deep neural networks trained with stochastic gradient descent (SGD). We find empirically that long after performance has converged, networks continue to move through parameter space by a process of anomalous diffusion in which distance travelled grows as a power law in the number of gradient updates with a nontrivial exponent. We reveal an intricate interaction between the hyperparameters of optimization, the structure in the gradient noise, and the Hessian matrix at the end of training that explains this anomalous diffusion. To build this understanding, we first derive a continuous-time model for SGD with finite learning rates and batch sizes as an underdamped Langevin equation. We study this equation in the setting of linear regression, where we can derive exact, analytic expressions for the phase space dynamics of the parameters and their instantaneous velocities from initialization to stationarity. Using the Fokker-Planck equation, we show that the key ingredient driving these dynamics is not the original training loss, but rather the combination of a modified loss, which implicitly regularizes the velocity, and probability currents, which cause oscillations in phase space. We identify qualitative and quantitative predictions of this theory in the dynamics of a ResNet-18 model trained on ImageNet. Through the lens of statistical physics, we uncover a mechanistic origin for the anomalous limiting dynamics of deep neural networks trained with SGD.",0
"The focus of our study is on the dynamics of deep neural networks trained with stochastic gradient descent (SGD) and the limitations thereof. Our empirical findings indicate that networks continue to move through parameter space even after performance has converged. This movement is characterized by anomalous diffusion, whereby the distance covered increases proportionally to the number of gradient updates through a nontrivial exponent. Our research highlights the complex interplay between optimization hyperparameters, gradient noise structure, and the Hessian matrix at the end of training, which accounts for this anomalous diffusion. We developed a continuous-time model for SGD using underdamped Langevin equation, and studied this equation in the context of linear regression, where we derived exact analytic expressions for the phase space dynamics of parameters and their instantaneous velocities. We used the Fokker-Planck equation to demonstrate that the driving force behind these dynamics is not the original training loss but a combination of modified loss, which implicitly regularizes velocity, and probability currents that cause oscillations in phase space. We applied this theory to ResNet-18 model trained on ImageNet to identify qualitative and quantitative predictions. Our research provides a mechanistic explanation for the anomalous limiting dynamics of deep neural networks trained with SGD from the perspective of statistical physics.",1
"Automotive Cyber-Physical Systems (ACPS) have attracted a significant amount of interest in the past few decades, while one of the most critical operations in these systems is the perception of the environment. Deep learning and, especially, the use of Deep Neural Networks (DNNs) provides impressive results in analyzing and understanding complex and dynamic scenes from visual data. The prediction horizons for those perception systems are very short and inference must often be performed in real time, stressing the need of transforming the original large pre-trained networks into new smaller models, by utilizing Model Compression and Acceleration (MCA) techniques. Our goal in this work is to investigate best practices for appropriately applying novel weight sharing techniques, optimizing the available variables and the training procedures towards the significant acceleration of widely adopted DNNs. Extensive evaluation studies carried out using various state-of-the-art DNN models in object detection and tracking experiments, provide details about the type of errors that manifest after the application of weight sharing techniques, resulting in significant acceleration gains with negligible accuracy losses.",0
"In recent decades, there has been considerable interest in Automotive Cyber-Physical Systems (ACPS), which rely heavily on the perception of the environment. Deep Neural Networks (DNNs), particularly those that utilize deep learning, have proven to be effective in analyzing complex visual data. However, due to the short prediction horizons of perception systems, inference must be performed in real time, necessitating the use of Model Compression and Acceleration (MCA) techniques to transform large networks into smaller models. Our aim is to investigate optimal approaches for applying weight sharing techniques, optimizing variables and training procedures to accelerate widely-used DNNs. Through extensive evaluation studies, we have identified errors that occur after implementing weight sharing techniques, resulting in significant acceleration gains with minimal loss of accuracy in object detection and tracking experiments using state-of-the-art DNN models.",1
"Neural networks leverage robust internal representations in order to generalise. Learning them is difficult, and often requires a large training set that covers the data distribution densely. We study a common setting where our task is not purely opaque. Indeed, very often we may have access to information about the underlying system (e.g. that observations must obey certain laws of physics) that any ""tabula rasa"" neural network would need to re-learn from scratch, penalising data efficiency. We incorporate this information into a pre-trained reasoning module, and investigate its role in shaping the discovered representations in diverse self-supervised learning settings from pixels. Our approach paves the way for a new class of data-efficient representation learning.",0
"In order to generalize, neural networks rely on strong internal representations, which can be challenging to learn and often require a large training set that covers the data distribution extensively. In many scenarios, we have some knowledge about the underlying system, such as certain physical laws that observations must follow. This information is not readily available to a ""blank slate"" neural network, which would have to learn it from scratch, consuming more data. To address this issue, we integrate this knowledge into a pre-trained reasoning module and examine its impact on the representations discovered in various self-supervised learning settings from pixel data. Our approach opens up new possibilities for data-efficient representation learning.",1
"We present a bottom-up differentiable relaxation of the process of drawing points, lines and curves into a pixel raster. Our approach arises from the observation that rasterising a pixel in an image given parameters of a primitive can be reformulated in terms of the primitive's distance transform, and then relaxed to allow the primitive's parameters to be learned. This relaxation allows end-to-end differentiable programs and deep networks to be learned and optimised and provides several building blocks that allow control over how a compositional drawing process is modelled. We emphasise the bottom-up nature of our proposed approach, which allows for drawing operations to be composed in ways that can mimic the physical reality of drawing rather than being tied to, for example, approaches in modern computer graphics. With the proposed approach we demonstrate how sketches can be generated by directly optimising against photographs and how auto-encoders can be built to transform rasterised handwritten digits into vectors without supervision. Extensive experimental results highlight the power of this approach under different modelling assumptions for drawing tasks.",0
"Our method involves a differentiable, bottom-up approach to drawing points, lines, and curves onto a pixel raster. We noted that the process of rasterizing a pixel in an image based on a primitive's parameters can be redefined using the primitive's distance transform, and then modified to allow for the learning of the primitive's parameters. This modification enables the learning and optimization of end-to-end differentiable programs and deep networks, and offers various tools to control how a compositional drawing process is modeled. Our approach emphasizes a bottom-up perspective, allowing for drawing operations to mimic the physical reality of drawing, rather than being limited by contemporary computer graphics techniques. Our approach enables the direct optimization of sketches against photographs, as well as the creation of auto-encoders that transform handwritten digits into vectors without supervision. We have conducted extensive experiments under various modeling assumptions for drawing tasks, which demonstrate the efficacy of our approach.",1
"In this document, a neural network is employed in order to estimate the solution of the initial value problem in the context of non linear trajectories. Such trajectories can be subject to gravity, thrust, drag, centrifugal force, temperature, ambient air density and pressure. First, we generate a grid of trajectory points given a specified uniform density as a design parameter and then we investigate the performance of a neural network in a compression and inverse problem task: the network is trained to predict the initial conditions of the dynamics model we used in the simulation, given a target point in space. We investigate this as a regression task, with error propagation in consideration. For target points, up to a radius of 2 kilometers, the model is able to accurately predict the initial conditions of the trajectories, with sub-meter deviation. This simulation-based training process and novel real-world evaluation method is capable of computing trajectories of arbitrary dimensions.",0
"The aim of this document is to utilize a neural network to estimate the solution of the initial value problem in non-linear trajectories, which can be influenced by factors such as gravity, thrust, drag, centrifugal force, temperature, ambient air density, and pressure. Firstly, a trajectory point grid is generated with a specific uniform density, followed by an investigation into the performance of a neural network in a compression and inverse problem task. The network is trained to predict the initial conditions of the dynamics model in the simulation when given a target point in space. This is approached as a regression task with error propagation taken into account. The model is capable of accurately predicting initial conditions for target points within a 2-kilometer radius, with a sub-meter deviation. The simulation-based training process and novel real-world evaluation method can compute trajectories of any dimension.",1
"Motivated by objects such as electric fields or fluid streams, we study the problem of learning stochastic fields, i.e. stochastic processes whose samples are fields like those occurring in physics and engineering. Considering general transformations such as rotations and reflections, we show that spatial invariance of stochastic fields requires an inference model to be equivariant. Leveraging recent advances from the equivariance literature, we study equivariance in two classes of models. Firstly, we fully characterise equivariant Gaussian processes. Secondly, we introduce Steerable Conditional Neural Processes (SteerCNPs), a new, fully equivariant member of the Neural Process family. In experiments with Gaussian process vector fields, images, and real-world weather data, we observe that SteerCNPs significantly improve the performance of previous models and equivariance leads to improvements in transfer learning tasks.",0
"Our focus is on learning stochastic fields, which are stochastic processes that produce fields like those seen in physics and engineering, often influenced by electric fields or fluid streams. To account for spatial invariance, we examine general transformations like rotations and reflections and find that an inference model must be equivariant. To explore this concept, we investigate two types of models: equivariant Gaussian processes and Steerable Conditional Neural Processes (SteerCNPs), a new member of the Neural Process family. We fully characterize equivariant Gaussian processes and observe significant performance improvements in Gaussian process vector fields, images, and real-world weather data using SteerCNPs. Transfer learning tasks also benefit from the use of an equivariant model.",1
"We present an information-based uncertainty quantification method for general Markov Random Fields. Markov Random Fields (MRF) are structured, probabilistic graphical models over undirected graphs, and provide a fundamental unifying modeling tool for statistical mechanics, probabilistic machine learning, and artificial intelligence. Typically MRFs are complex and high-dimensional with nodes and edges (connections) built in a modular fashion from simpler, low-dimensional probabilistic models and their local connections; in turn, this modularity allows to incorporate available data to MRFs and efficiently simulate them by leveraging their graph-theoretic structure. Learning graphical models from data and/or constructing them from physical modeling and constraints necessarily involves uncertainties inherited from data, modeling choices, or numerical approximations. These uncertainties in the MRF can be manifested either in the graph structure or the probability distribution functions, and necessarily will propagate in predictions for quantities of interest. Here we quantify such uncertainties using tight, information based bounds on the predictions of quantities of interest; these bounds take advantage of the graphical structure of MRFs and are capable of handling the inherent high-dimensionality of such graphical models. We demonstrate our methods in MRFs for medical diagnostics and statistical mechanics models. In the latter, we develop uncertainty quantification bounds for finite size effects and phase diagrams, which constitute two of the typical predictions goals of statistical mechanics modeling.",0
"Our method provides a means of quantifying uncertainty in Markov Random Fields (MRFs) through the use of information-based bounds. MRFs are probabilistic graphical models that are commonly used in statistical mechanics, probabilistic machine learning, and artificial intelligence due to their modular structure and ability to incorporate available data. However, uncertainties in the MRF can arise from data, modeling choices, or numerical approximations, which can impact predictions of quantities of interest. Our approach utilizes the graph-theoretic structure of MRFs to handle their high-dimensionality and provides tight bounds on predictions of quantities of interest. We demonstrate the effectiveness of our method in medical diagnostics and statistical mechanics models, particularly in the context of finite size effects and phase diagrams.",1
"Probabilistic graphical models are a fundamental tool in probabilistic modeling, machine learning and artificial intelligence. They allow us to integrate in a natural way expert knowledge, physical modeling, heterogeneous and correlated data and quantities of interest. For exactly this reason, multiple sources of model uncertainty are inherent within the modular structure of the graphical model. In this paper we develop information-theoretic, robust uncertainty quantification methods and non-parametric stress tests for directed graphical models to assess the effect and the propagation through the graph of multi-sourced model uncertainties to quantities of interest. These methods allow us to rank the different sources of uncertainty and correct the graphical model by targeting its most impactful components with respect to the quantities of interest. Thus, from a machine learning perspective, we provide a mathematically rigorous approach to correctability that guarantees a systematic selection for improvement of components of a graphical model while controlling potential new errors created in the process in other parts of the model. We demonstrate our methods in two physico-chemical examples, namely quantum scale-informed chemical kinetics and materials screening to improve the efficiency of fuel cells.",0
"Probabilistic graphical models play a critical role in probabilistic modeling, artificial intelligence and machine learning. They enable the integration of diverse data sources, expert knowledge, physical modeling and quantities of interest in a seamless manner. As a result, the modular structure of graphical models inherently produces multiple sources of model uncertainty. This paper presents information-theoretic, robust uncertainty quantification techniques and non-parametric stress tests for directed graphical models. These techniques evaluate the impact of multi-sourced model uncertainties on quantities of interest and rank the different sources of uncertainty. By targeting the most significant components of the graphical model with respect to the quantities of interest, we correct it. Our approach guarantees a mathematically rigorous method to enhance the components of a graphical model while controlling new errors in other parts of the model. We illustrate our methods through two physico-chemical examples: quantum scale-informed chemical kinetics and materials screening to enhance fuel cell efficiency. From a machine learning perspective, this paper provides a systematic approach to correctability.",1
"Future climate change scenarios are usually hypothesized using simulations from weather generators. However, there only a few works comparing and evaluating promising deep learning models for weather generation against classical approaches. This study shows preliminary results making such evaluations for the multisite precipitation synthesis task. We compared two open-source weather generators: IBMWeathergen (an extension of the Weathergen library) and RGeneratePrec, and two deep generative models: GAN and VAE, on a variety of metrics. Our preliminary results can serve as a guide for improving the design of deep learning architectures and algorithms for the multisite precipitation synthesis task.",0
"Typically, predictions for future climate change are based on simulations generated by weather generators. However, there has been limited research comparing and assessing the effectiveness of advanced deep learning models for weather generation in comparison to traditional methods. This research examines initial findings from evaluating deep generative models, GAN and VAE, against two open-source weather generators, IBMWeathergen and RGeneratePrec, for the multisite precipitation synthesis task. Various metrics were analyzed and our preliminary results can provide insight for enhancing the development of deep learning algorithms and structures for the multisite precipitation synthesis task.",1
"Accurately learning the temporal behavior of dynamical systems requires models with well-chosen learning biases. Recent innovations embed the Hamiltonian and Lagrangian formalisms into neural networks and demonstrate a significant improvement over other approaches in predicting trajectories of physical systems. These methods generally tackle autonomous systems that depend implicitly on time or systems for which a control signal is known apriori. Despite this success, many real world dynamical systems are non-autonomous, driven by time-dependent forces and experience energy dissipation. In this study, we address the challenge of learning from such non-autonomous systems by embedding the port-Hamiltonian formalism into neural networks, a versatile framework that can capture energy dissipation and time-dependent control forces. We show that the proposed \emph{port-Hamiltonian neural network} can efficiently learn the dynamics of nonlinear physical systems of practical interest and accurately recover the underlying stationary Hamiltonian, time-dependent force, and dissipative coefficient. A promising outcome of our network is its ability to learn and predict chaotic systems such as the Duffing equation, for which the trajectories are typically hard to learn.",0
"To accurately understand the temporal behavior of dynamic systems, it is important to have models that have appropriate learning biases. Innovative techniques have integrated Hamiltonian and Lagrangian formalisms into neural networks, leading to significant improvements in predicting the trajectories of physical systems. However, these methods typically deal with autonomous systems that rely implicitly on time or systems that have a known control signal. The real world, however, comprises non-autonomous systems that are driven by time-dependent forces and experience energy dissipation. This study aims to address this challenge by incorporating the port-Hamiltonian formalism into neural networks, which is a versatile framework that can capture energy dissipation and time-dependent control forces. The proposed ""port-Hamiltonian neural network"" can efficiently learn the dynamics of nonlinear physical systems, including chaotic systems such as the Duffing equation, whose trajectories are typically difficult to learn. The network accurately recovers the underlying stationary Hamiltonian, time-dependent force, and dissipative coefficient, leading to promising outcomes.",1
"Uncertainty quantification in Artificial Intelligence (AI)-based predictions of material properties is of immense importance for the success and reliability of AI applications in material science. While confidence intervals are commonly reported for machine learning (ML) models, prediction intervals, i.e., the evaluation of the uncertainty on each prediction, are seldomly available. In this work we compare 3 different approaches to obtain such individual uncertainty, testing them on 12 ML-physical properties. Specifically, we investigated using the Quantile loss function, machine learning the prediction intervals directly and using Gaussian Processes. We identify each approachs advantages and disadvantages and end up slightly favoring the modeling of the individual uncertainties directly, as it is the easiest to fit and, in most cases, minimizes over-and under-estimation of the predicted errors. All data for training and testing were taken from the publicly available JARVIS-DFT database, and the codes developed for computing the prediction intervals are available through JARVIS-Tools.",0
"The importance of quantifying uncertainty in AI-based material property predictions cannot be overstated as it directly impacts the reliability and success of AI applications in material science. While machine learning models commonly report confidence intervals, evaluation of uncertainty on each prediction, or prediction intervals, is not often available. This study compares three methods for obtaining individual uncertainty in 12 ML-physical properties, namely, using the Quantile loss function, machine learning prediction intervals directly, and employing Gaussian Processes. Each approach is assessed for its advantages and disadvantages, with the modeling of individual uncertainties directly being slightly favored due to its ease of fitting and ability to minimize predicted errors. All data were sourced from the publicly available JARVIS-DFT database, and the codes for computing prediction intervals are available through JARVIS-Tools.",1
"Recent advances show that neural networks embedded with physics-informed priors significantly outperform vanilla neural networks in learning and predicting the long term dynamics of complex physical systems from noisy data. Despite this success, there has only been a limited study on how to optimally combine physics priors to improve predictive performance. To tackle this problem we unpack and generalize recent innovations into individual inductive bias segments. As such, we are able to systematically investigate all possible combinations of inductive biases of which existing methods are a natural subset. Using this framework we introduce Variational Integrator Graph Networks - a novel method that unifies the strengths of existing approaches by combining an energy constraint, high-order symplectic variational integrators, and graph neural networks. We demonstrate, across an extensive ablation, that the proposed unifying framework outperforms existing methods, for data-efficient learning and in predictive accuracy, across both single and many-body problems studied in recent literature. We empirically show that the improvements arise because high order variational integrators combined with a potential energy constraint induce coupled learning of generalized position and momentum updates which can be formalized via the Partitioned Runge-Kutta method.",0
"Recent progress has revealed that neural networks that integrate physics-based priors are more effective in learning and forecasting the long-term behavior of complicated physical systems from noisy data than standard neural networks. However, the optimal method of combining these priors to enhance predictive performance has not been thoroughly examined. To address this issue, we analyze recent advancements and generalize them into separate inductive bias components, allowing for systematic exploration of all feasible combinations of inductive biases, including those of existing techniques. To this end, we propose Variational Integrator Graph Networks, a new approach that combines an energy constraint, high-order symplectic variational integrators, and graph neural networks to unify existing strategies' strengths. Through an extensive ablation, we demonstrate that our comprehensive framework outperforms existing methods in both data-efficient learning and predictive precision, as demonstrated in recent studies of single and many-body problems. We show that the improvements stem from high-order variational integrators, which, when combined with a potential energy constraint, promote the linked learning of generalized position and momentum updates, which can be formalized using the Partitioned Runge-Kutta method.",1
"Deep neural networks (DNN) have an impressive ability to invert very complex models, i.e. to learn the generative parameters from a model's output. Once trained, the forward pass of a DNN is often much faster than traditional, optimization-based methods used to solve inverse problems. This is however done at the cost of lower interpretability, a fundamental limitation in most medical applications. We propose an approach for solving general inverse problems which combines the efficiency of DNN and the interpretability of traditional analytical methods. The measurements are first projected onto a dense dictionary of model-based responses. The resulting sparse representation is then fed to a DNN with an architecture driven by the problem's physics for fast parameter learning. Our method can handle generative forward models that are costly to evaluate and exhibits similar performance in accuracy and computation time as a fully-learned DNN, while maintaining high interpretability and being easier to train. Concrete results are shown on an example of model-based brain parameter estimation from magnetic resonance imaging (MRI).",0
"The ability of deep neural networks (DNN) to invert complex models and learn generative parameters from a model's output is impressive. However, while the forward pass of a DNN is faster than traditional optimization-based methods for solving inverse problems, it comes at the cost of lower interpretability, which is a significant limitation in medical applications. To address this, we propose an approach that combines the efficiency of DNN with the interpretability of traditional analytical methods to solve general inverse problems. Our approach involves projecting measurements onto a dense dictionary of model-based responses, resulting in a sparse representation that is fed into a DNN with an architecture driven by the problem's physics for fast parameter learning. Our method can handle generative forward models that are costly to evaluate and exhibits similar accuracy and computation time as a fully-learned DNN, while maintaining high interpretability and being easier to train. We demonstrate the effectiveness of our method on an example of model-based brain parameter estimation from magnetic resonance imaging (MRI).",1
"We focus on the task of future frame prediction in video governed by underlying physical dynamics. We work with models which are object-centric, i.e., explicitly work with object representations, and propagate a loss in the latent space. Specifically, our research builds on recent work by Kipf et al. \cite{kipf&al20}, which predicts the next state via contrastive learning of object interactions in a latent space using a Graph Neural Network. We argue that injecting explicit inductive bias in the model, in form of general physical laws, can help not only make the model more interpretable, but also improve the overall prediction of model. As a natural by-product, our model can learn feature maps which closely resemble actual object positions in the image, without having any explicit supervision about the object positions at the training time. In comparison with earlier works \cite{jaques&al20}, which assume a complete knowledge of the dynamics governing the motion in the form of a physics engine, we rely only on the knowledge of general physical laws, such as, world consists of objects, which have position and velocity. We propose an additional decoder based loss in the pixel space, imposed in a curriculum manner, to further refine the latent space predictions. Experiments in multiple different settings demonstrate that while Kipf et al. model is effective at capturing object interactions, our model can be significantly more effective at localising objects, resulting in improved performance in 3 out of 4 domains that we experiment with. Additionally, our model can learn highly intrepretable feature maps, resembling actual object positions.",0
"Our research centers on predicting future frames in video using underlying physical dynamics. We use object-centric models that work explicitly with object representations and propagate a loss in the latent space. Our work builds on Kipf et al.'s recent research, which predicts the next state by contrastive learning of object interactions in a latent space using a Graph Neural Network. We believe that introducing explicit inductive bias into the model, in the form of general physical laws, can not only improve the interpretability of the model but also enhance its overall prediction accuracy. Our model can also learn feature maps resembling actual object positions in the image without explicit supervision at training time. Unlike earlier works that assume complete knowledge of the dynamics governing motion, we rely only on general physical laws such as the world consisting of objects with position and velocity. We propose an additional decoder-based loss in the pixel space, imposed in a curriculum manner, to refine the latent space predictions further. Our experiments in multiple settings show that while Kipf et al.'s model is effective at capturing object interactions, our model is significantly more effective at localizing objects, resulting in improved performance in three out of four domains. Additionally, our model can learn highly interpretable feature maps resembling actual object positions.",1
"This paper contributes to the development and evaluation of a deep learning workflow that accurately and efficiently predicts the temporal-spatial evolution of pressure and CO2 plumes during injection and post-injection periods of geologic CO2 sequestration (GCS) operations. Based on a Fourier Neuron Operator, the deep learning workflow takes input variables or features including rock properties, well operational controls and time steps, and predicts the state variables of pressure and CO2 saturation. To further improve the predictive fidelity, separate deep learning models are trained for CO2 injection and post-injection periods due the difference in primary driving force of fluid flow and transport during these two phases. We also explore different combinations of features to predict the state variables. We use a realistic example of CO2 injection and storage in a 3D heterogeneous saline aquifer, and apply the deep learning workflow that is trained from physics-based simulation data and emulate the physics process. Through this numerical experiment, we demonstrate that using two separate deep learning models to distinguish post-injection from injection period generates the most accurate prediction of pressure, and a single deep learning model of the whole GCS process including the cumulative injection volume of CO2 as a deep learning feature, leads to the most accurate prediction of CO2 saturation. For the post-injection period, it is key to use cumulative CO2 injection volume to inform the deep learning models about the total carbon storage when predicting either pressure or saturation. The deep learning workflow not only provides high predictive fidelity across temporal and spatial scales, but also offers a speedup of 250 times compared to full physics reservoir simulation, and thus will be a significant predictive tool for engineers to manage the long term process of GCS.",0
"This study presents a deep learning workflow that can efficiently and accurately predict the temporal-spatial evolution of pressure and CO2 plumes during injection and post-injection periods of geologic CO2 sequestration (GCS) operations. The workflow, based on a Fourier Neuron Operator, uses input variables such as rock properties, well operational controls, and time steps to predict pressure and CO2 saturation. Separate deep learning models are trained for CO2 injection and post-injection periods to improve predictive fidelity, as the primary driving forces of fluid flow and transport differ during these phases. The study explores various feature combinations to predict state variables using a realistic example of CO2 injection and storage in a 3D heterogeneous saline aquifer. The results show that using two separate deep learning models generates the most accurate prediction of pressure during the post-injection period, while a single deep learning model that includes the cumulative injection volume of CO2 as a feature provides the most accurate prediction of CO2 saturation for the entire GCS process. Additionally, the study highlights the importance of using cumulative CO2 injection volume to inform the deep learning models during the post-injection period. The deep learning workflow offers high predictive fidelity across temporal and spatial scales and provides a 250 times faster speed compared to full physics reservoir simulation, making it a valuable tool for engineers managing the long-term process of GCS.",1
"Lidar-based object detectors are critical parts of the 3D perception pipeline in autonomous navigation systems such as self-driving cars. However, they are known to be sensitive to adverse weather conditions such as rain, snow and fog due to reduced signal-to-noise ratio (SNR) and signal-to-background ratio (SBR). As a result, lidar-based object detectors trained on data captured in normal weather tend to perform poorly in such scenarios. However, collecting and labelling sufficient training data in a diverse range of adverse weather conditions is laborious and prohibitively expensive. To address this issue, we propose a physics-based approach to simulate lidar point clouds of scenes in adverse weather conditions. These augmented datasets can then be used to train lidar-based detectors to improve their all-weather reliability. Specifically, we introduce a hybrid Monte-Carlo based approach that treats (i) the effects of large particles by placing them randomly and comparing their back reflected power against the target, and (ii) attenuation effects on average through calculation of scattering efficiencies from the Mie theory and particle size distributions. Retraining networks with this augmented data improves mean average precision evaluated on real world rainy scenes and we observe greater improvement in performance with our model relative to existing models from the literature. Furthermore, we evaluate recent state-of-the-art detectors on the simulated weather conditions and present an in-depth analysis of their performance.",0
"In autonomous navigation systems like self-driving cars, lidar-based object detectors are crucial components of the 3D perception pipeline. However, these detectors are vulnerable to harsh weather conditions such as snow, rain, and fog as they cause a reduction in the signal-to-noise ratio (SNR) and signal-to-background ratio (SBR). Thus, they tend to perform poorly when trained on data captured in normal weather. Nevertheless, gathering and labeling adequate training data in diverse adverse weather conditions is an arduous and unaffordable task. To tackle this problem, we suggest a physics-based method to simulate lidar point clouds depicting scenes in adverse weather conditions. These augmented datasets can then be utilized to train lidar-based detectors, improving their reliability in all weather conditions. Specifically, we introduce a hybrid Monte-Carlo approach that considers (i) the impact of large particles by randomly placing them and comparing their back reflected power against the target, and (ii) attenuation effects on average via the calculation of scattering efficiencies using the Mie theory and particle size distributions. By retraining networks with this augmented data, we witness an improvement in mean average precision evaluated on real-world rainy scenes, with more significant progress observed in our model compared to existing models from the literature. Additionally, we evaluate the performance of recent state-of-the-art detectors on simulated weather conditions and present an in-depth analysis of their performance.",1
"An impact of climate change is the increase in frequency and intensity of extreme precipitation events. However, confidently predicting the likelihood of extreme precipitation at seasonal scales remains an outstanding challenge. Here, we present an approach to forecasting the quantiles of the maximum daily precipitation in each week up to six months ahead using the temporal fusion transformer (TFT) model. Through experiments in two regions, we compare TFT predictions with those of two baselines: climatology and a calibrated ECMWF SEAS5 ensemble forecast (S5). Our results show that, in terms of quantile risk at six month lead time, the TFT predictions significantly outperform those from S5 and show an overall small improvement compared to climatology. The TFT also responds positively to departures from normal that climatology cannot.",0
"Climate change leads to more frequent and intense extreme precipitation events, but accurately predicting such events on a seasonal scale remains a challenge. In this study, we propose a method for forecasting the maximum daily precipitation quantiles for each week up to six months in advance using the temporal fusion transformer (TFT) model. We compare the TFT predictions to climatology and a calibrated ECMWF SEAS5 ensemble forecast (S5) in two regions and find that the TFT outperforms the S5 in terms of quantile risk at a six-month lead time. The TFT also shows a slight improvement over climatology and is able to respond positively to deviations from normal values, which climatology cannot.",1
"We predict the emergence of extreme events in a parametrically driven nonlinear dynamical system using three Deep Learning models, namely Multi-Layer Perceptron, Convolutional Neural Network and Long Short-Term Memory. The Deep Learning models are trained using the training set and are allowed to predict the test set data. After prediction, the time series of the actual and the predicted values are plotted one over the other in order to visualize the performance of the models. Upon evaluating the Root Mean Square Error value between predicted and the actual values of all three models, we find that the Long Short-Term Memory model can serve as the best model to forecast the chaotic time series and to predict the emergence of extreme events for the considered system.",0
"To anticipate extreme events in a parametrically driven nonlinear dynamical system, we employ three Deep Learning models: Multi-Layer Perceptron, Convolutional Neural Network and Long Short-Term Memory. These models are trained on a training set and used to forecast the test set data. We compare the predicted and actual values by plotting their time series together. The Root Mean Square Error is computed for all three models, and we determine that the Long Short-Term Memory model is the most effective in forecasting the chaotic time series and predicting the emergence of extreme events in the system.",1
"A significant amount of work has been done on adversarial attacks that inject imperceptible noise to images to deteriorate the image classification performance of deep models. However, most of the existing studies consider attacks in the digital (pixel) domain where an image acquired by an image sensor with sampling and quantization has been recorded. This paper, for the first time, introduces an optical adversarial attack, which physically alters the light field information arriving at the image sensor so that the classification model yields misclassification. More specifically, we modulate the phase of the light in the Fourier domain using a spatial light modulator placed in the photographic system. The operative parameters of the modulator are obtained by gradient-based optimization to maximize cross-entropy and minimize distortions. We present experiments based on both simulation and a real hardware optical system, from which the feasibility of the proposed optical attack is demonstrated. It is also verified that the proposed attack is completely different from common optical-domain distortions such as spherical aberration, defocus, and astigmatism in terms of both perturbation patterns and classification results.",0
"Numerous studies have focused on adversarial attacks that add imperceptible noise to images, causing deep models to perform poorly in image classification. However, these attacks are mainly conducted in the digital domain, where images are acquired by image sensors and recorded through sampling and quantization. This paper presents a novel optical adversarial attack that physically alters the light field information received by the image sensor, leading to misclassification by the classification model. By modulating the phase of the light in the Fourier domain using a spatial light modulator in the photographic system, we optimize the modulator's operative parameters through gradient-based optimization to maximize cross-entropy and minimize distortions. Both simulation and real optical systems are used to demonstrate the feasibility of the proposed attack, which differs from common optical-domain distortions such as defocus, astigmatism, and spherical aberration in both perturbation patterns and classification results.",1
"While predictive policing has become increasingly common in assisting with decisions in the criminal justice system, the use of these results is still controversial. Some software based on deep learning lacks accuracy (e.g., in F-1), and importantly many decision processes are not transparent, causing doubt about decision bias, such as perceived racial and age disparities. This paper addresses bias issues with post-hoc explanations to provide a trustable prediction of whether a person will receive future criminal charges given one's previous criminal records by learning temporal behavior patterns over twenty years. Bi-LSTM relieves the vanishing gradient problem, attentional mechanisms allow learning and interpretation of feature importance, and complex-valued networks inspired quantum physics to facilitate a certain level of transparency in modeling the decision process. Our approach shows a consistent and reliable prediction precision and recall on a real-life dataset. Our analysis of the importance of each input feature shows the critical causal impact on decision-making, suggesting that criminal histories are statistically significant factors, while identifiers, such as race and age, are not. Finally, our algorithm indicates that a suspect tends to rather than suddenly increase crime severity level over time gradually.",0
"The use of predictive policing has become more prevalent in the criminal justice system, but it remains a contentious issue. Some deep learning software lacks accuracy, which raises concerns about decision bias, including those based on race and age. This study aims to address these biases by providing post-hoc explanations. We use Bi-LSTM to avoid the vanishing gradient problem, attentional mechanisms to interpret feature importance, and complex-valued networks inspired by quantum physics to increase the transparency of the decision-making process. Our approach has proven to be reliable and consistent, with a high prediction precision and recall on a real-life dataset. We found that criminal histories are statistically significant factors, while race and age are not. Furthermore, our algorithm suggests that crime severity levels tend to increase gradually over time, rather than suddenly. We also analyzed the importance of each input feature, which highlights their critical causal impact on decision-making.",1
"Spectral approximation and variational inducing learning for the Gaussian process are two popular methods to reduce computational complexity. However, in previous research, those methods always tend to adopt the orthonormal basis functions, such as eigenvectors in the Hilbert space, in the spectrum method, or decoupled orthogonal components in the variational framework. In this paper, inspired by quantum physics, we introduce a novel basis function, which is tunable, local and bounded, to approximate the kernel function in the Gaussian process. There are two adjustable parameters in these functions, which control their orthogonality to each other and limit their boundedness. And we conduct extensive experiments on open-source datasets to testify its performance. Compared to several state-of-the-art methods, it turns out that the proposed method can obtain satisfactory or even better results, especially with poorly chosen kernel functions.",0
"Two widely used approaches to reduce computational complexity in Gaussian process modeling are spectral approximation and variational inducing learning. However, previous studies have typically utilized orthonormal basis functions, such as eigenvectors or decoupled orthogonal components. In this research, we propose a new basis function that is influenced by quantum physics and is tunable, local, and bounded. These functions have two adjustable parameters that control their orthogonality and boundedness. We conducted experiments on open-source datasets to evaluate their performance and found that our method outperforms several state-of-the-art methods, especially when poorly chosen kernel functions are used.",1
"Car-following behavior has been extensively studied using physics-based models, such as the Intelligent Driver Model. These models successfully interpret traffic phenomena observed in the real-world but may not fully capture the complex cognitive process of driving. Deep learning models, on the other hand, have demonstrated their power in capturing observed traffic phenomena but require a large amount of driving data to train. This paper aims to develop a family of neural network based car-following models that are informed by physics-based models, which leverage the advantage of both physics-based (being data-efficient and interpretable) and deep learning based (being generalizable) models. We design physics-informed deep learning car-following (PIDL-CF) architectures encoded with two popular physics-based models - IDM and OVM, on which acceleration is predicted for four traffic regimes: acceleration, deceleration, cruising, and emergency braking. Two types of PIDL-CFM problems are studied, one to predict acceleration only and the other to jointly predict acceleration and discover model parameters. We also demonstrate the superior performance of PIDL with the Next Generation SIMulation (NGSIM) dataset over baselines, especially when the training data is sparse. The results demonstrate the superior performance of neural networks informed by physics over those without. The developed PIDL-CF framework holds the potential for system identification of driving models and for the development of driving-based controls for automated vehicles.",0
"Extensive research has been conducted on car-following behavior using physics-based models like the Intelligent Driver Model. While these models can interpret real-world traffic phenomena, they may not fully capture the complex cognitive processes involved in driving. In contrast, deep learning models have shown their ability to capture observed traffic phenomena, but require a large amount of driving data to train. To address this, the authors of this paper aim to create neural network based car-following models that combine the strengths of both types of models. These physics-informed deep learning car-following (PIDL-CF) architectures are designed using two popular physics-based models, IDM and OVM, to predict acceleration in different traffic regimes. Two types of PIDL-CFM problems are studied, one to predict acceleration only, and the other to predict acceleration and discover model parameters. The authors demonstrate the superior performance of PIDL with the NGSIM dataset over baselines, particularly when the training data is sparse. The resulting PIDL-CF framework has the potential to identify driving models and develop driving-based controls for automated vehicles.",1
"Complex dynamical systems are used for predictions in many domains. Because of computational costs, models are truncated, coarsened, or aggregated. As the neglected and unresolved terms become important, the utility of model predictions diminishes. We develop a novel, versatile, and rigorous methodology to learn non-Markovian closure parameterizations for known-physics/low-fidelity models using data from high-fidelity simulations. The new ""neural closure models"" augment low-fidelity models with neural delay differential equations (nDDEs), motivated by the Mori-Zwanzig formulation and the inherent delays in complex dynamical systems. We demonstrate that neural closures efficiently account for truncated modes in reduced-order-models, capture the effects of subgrid-scale processes in coarse models, and augment the simplification of complex biological and physical-biogeochemical models. We find that using non-Markovian over Markovian closures improves long-term prediction accuracy and requires smaller networks. We derive adjoint equations and network architectures needed to efficiently implement the new discrete and distributed nDDEs, for any time-integration schemes and allowing nonuniformly-spaced temporal training data. The performance of discrete over distributed delays in closure models is explained using information theory, and we find an optimal amount of past information for a specified architecture. Finally, we analyze computational complexity and explain the limited additional cost due to neural closure models.",0
"In various fields, complex dynamical systems are utilized to make predictions. However, due to their high computational expenses, models are often simplified by truncation, coarsening, or aggregation. This results in the neglect of certain terms, causing the accuracy of the model's predictions to decrease. To address this issue, we have developed a new and versatile methodology that employs neural delay differential equations (nDDEs) to learn non-Markovian closure parameterizations for known-physics/low-fidelity models. This novel approach utilizes data from high-fidelity simulations to augment low-fidelity models with neural closures, which efficiently account for truncated modes in reduced-order-models and capture the effects of subgrid-scale processes in coarse models. Moreover, we find that using non-Markovian over Markovian closures improves long-term prediction accuracy and requires smaller networks. We have also derived adjoint equations and network architectures necessary for an efficient implementation of the new discrete and distributed nDDEs, which can accommodate nonuniformly-spaced temporal training data and any time-integration schemes. We have analyzed the computational complexity of the neural closure models and found that they incur limited additional costs. Additionally, we have explained the performance of discrete over distributed delays in closure models using information theory and determined an optimal amount of past information for a specified architecture. Finally, we have demonstrated how neural closures can augment the simplification of complex biological and physical-biogeochemical models.",1
"Machine learning (ML) tools such as encoder-decoder convolutional neural networks (CNN) can represent incredibly complex nonlinear functions which map between combinations of images and scalars. For example, CNNs can be used to map combinations of accelerator parameters and images which are 2D projections of the 6D phase space distributions of charged particle beams as they are transported between various particle accelerator locations. Despite their strengths, applying ML to time-varying systems, or systems with shifting distributions, is an open problem, especially for large systems for which collecting new data for re-training is impractical or interrupts operations. Particle accelerators are one example of large time-varying systems for which collecting detailed training data requires lengthy dedicated beam measurements which may no longer be available during regular operations. We present a recently developed method of adaptive ML for time-varying systems. Our approach is to map very high (N>100k) dimensional inputs (a combination of scalar parameters and images) into the low dimensional (N~2) latent space at the output of the encoder section of an encoder-decoder CNN. We then actively tune the low dimensional latent space-based representation of complex system dynamics by the addition of an adaptively tuned feedback vector directly before the decoder sections builds back up to our image-based high-dimensional phase space density representations. This method allows us to learn correlations within and to quickly tune the characteristics of incredibly high parameter systems and to track their evolution in real time based on feedback without massive new data sets for re-training.",0
"Encoder-decoder convolutional neural networks (CNN) are powerful machine learning (ML) tools that can handle complex nonlinear functions between image combinations and scalars. For instance, they can map accelerator parameters and 2D image projections of charged particle beams' 6D phase space distributions as they move between different locations. However, applying ML to time-varying or shifting systems, particularly large ones where collecting new data for retraining is not feasible, is a challenge. Particle accelerators are a prime example of such systems, where obtaining detailed training data requires lengthy beam measurements that may not be accessible during regular operations. To overcome this, we propose an adaptive ML approach for time-varying systems that maps high-dimensional inputs (scalar parameters and images) into a low-dimensional latent space at the encoder section's output. We then actively fine-tune the latent space-based representation of system dynamics using an adaptively tuned feedback vector before the decoder sections rebuild the image-based high-dimensional phase space density representations. This approach enables us to learn correlations and swiftly adjust the characteristics of high-parameter systems and track their evolution in real-time based on feedback, without requiring extensive new datasets for retraining.",1
"Deep image relighting allows photo enhancement by illumination-specific retouching without human effort and so it is getting much interest lately. Most of the existing popular methods available for relighting are run-time intensive and memory inefficient. Keeping these issues in mind, we propose the use of Stacked Deep Multi-Scale Hierarchical Network, which aggregates features from each image at different scales. Our solution is differentiable and robust for translating image illumination setting from input image to target image. Additionally, we have also shown that using a multi-step training approach to this problem with two different loss functions can significantly boost performance and can achieve a high quality reconstruction of a relighted image.",0
"Recently, there has been significant interest in deep image relighting as it offers effortless photo enhancement by illuminating specific retouching. However, most of the currently available popular relighting methods are time-consuming and inefficient in terms of memory usage. To address these issues, we propose a differentiable and robust solution using a Stacked Deep Multi-Scale Hierarchical Network that aggregates features from images at different scales. Furthermore, we demonstrate that a multi-step training approach, using two different loss functions, can considerably improve performance and achieve high-quality reconstruction of relighted images by translating the illumination setting from the input image to the target image.",1
Streamflow forecasting is key to effectively managing water resources and preparing for the occurrence of natural calamities being exacerbated by climate change. Here we use the concept of fast and slow flow components to create a new mass-conserving Long Short-Term Memory (LSTM) neural network model. It uses hydrometeorological time series and catchment attributes to predict daily river discharges. Preliminary results evidence improvement in skills for different scores compared to the recent literature.,0
"The ability to predict streamflow is crucial in the efficient management of water resources and in preparing for the amplified impact of natural disasters resulting from climate change. Our approach involves incorporating the concepts of fast and slow flow components to develop a novel Long Short-Term Memory (LSTM) neural network model that conserves mass. This model utilizes hydrometeorological time series and catchment characteristics to forecast daily river discharges. Our preliminary findings reveal enhanced predictive capabilities compared to recent literature, as evidenced by various scores.",1
"1. Deciphering coexistence patterns is a current challenge to understanding diversity maintenance, especially in rich communities where the complexity of these patterns is magnified through indirect interactions that prevent their approximation with classical experimental approaches. 2. We explore cutting-edge Machine Learning techniques called Generative Artificial Intelligence (GenAI) to decipher species coexistence patterns in vegetation patches, training generative adversarial networks (GAN) and variational AutoEncoders (VAE) that are then used to unravel some of the mechanisms behind community assemblage. 3. The GAN accurately reproduces the species composition of real patches as well as the affinity of plant species to different soil types, and the VAE also reaches a high level of accuracy, above 99%. Using the artificially generated patches, we found that high order interactions tend to suppress the positive effects of low order interactions. Finally, by reconstructing successional trajectories we could identify the pioneer species with larger potential to generate a high diversity of distinct patches in terms of species composition. 4. Understanding the complexity of species coexistence patterns in diverse ecological communities requires new approaches beyond heuristic rules. Generative Artificial Intelligence can be a powerful tool to this end as it allows to overcome the inherent dimensionality of this challenge.",0
"The challenge of understanding diversity maintenance in rich communities lies in deciphering coexistence patterns, which are complex due to indirect interactions. Traditional experimental approaches are insufficient, so we have turned to Generative Artificial Intelligence (GenAI) techniques like GAN and VAE. Our research involves training these models to analyze species coexistence patterns in vegetation patches, and we have found that GAN accurately reproduces plant species composition and affinity to different soil types. VAE also reaches high accuracy levels. By using artificially generated patches, we discovered that high order interactions can limit the positive effects of low order interactions. Additionally, we identified pioneer species that have greater potential for generating diverse patches. Overall, GenAI provides a powerful new approach to understanding the complexity of coexistence patterns in diverse ecological communities.",1
"We propose a meta-learning technique for offline discovery of physics-informed neural network (PINN) loss functions. We extend earlier works on meta-learning, and develop a gradient-based meta-learning algorithm for addressing diverse task distributions based on parametrized partial differential equations (PDEs) that are solved with PINNs. Furthermore, based on new theory we identify two desirable properties of meta-learned losses in PINN problems, which we enforce by proposing a new regularization method or using a specific parametrization of the loss function. In the computational examples, the meta-learned losses are employed at test time for addressing regression and PDE task distributions. Our results indicate that significant performance improvement can be achieved by using a shared-among-tasks offline-learned loss function even for out-of-distribution meta-testing. In this case, we solve for test tasks that do not belong to the task distribution used in meta-training, and we also employ PINN architectures that are different from the PINN architecture used in meta-training. To better understand the capabilities and limitations of the proposed method, we consider various parametrizations of the loss function and describe different algorithm design options and how they may affect meta-learning performance.",0
"A meta-learning technique is suggested to discover physics-informed neural network (PINN) loss functions offline. A gradient-based meta-learning algorithm is developed to handle diverse task distributions based on parametrized partial differential equations (PDEs) that are solved with PINNs, building on earlier works on meta-learning. Additionally, two desirable properties of meta-learned losses in PINN problems are identified based on new theory, and a new regularization method or a specific parametrization of the loss function is proposed to enforce them. The meta-learned losses are employed at test time to address regression and PDE task distributions in computational examples. The results show that using a shared-among-tasks offline-learned loss function can significantly improve performance, even for out-of-distribution meta-testing. In this case, test tasks that do not belong to the task distribution used in meta-training are solved, and different PINN architectures are used from those used in meta-training. Various parametrizations of the loss function are considered to better understand the method's capabilities and limitations, and different algorithm design options and their impact on meta-learning performance are described.",1
"(Artificial) neural networks have become increasingly popular in mechanics to accelerate computations with model order reduction techniques and as universal models for a wide variety of materials. However, the major disadvantage of neural networks remains: their numerous parameters are challenging to interpret and explain. Thus, neural networks are often labeled as black boxes, and their results often elude human interpretation. In mechanics, the new and active field of physics-informed neural networks attempts to mitigate this disadvantage by designing deep neural networks on the basis of mechanical knowledge. By using this a priori knowledge, deeper and more complex neural networks became feasible, since the mechanical assumptions could be explained. However, the internal reasoning and explanation of neural network parameters remain mysterious.   Complementary to the physics-informed approach, we propose a first step towards a physics-informing approach, which explains neural networks trained on mechanical data a posteriori. This novel explainable artificial intelligence approach aims at elucidating the black box of neural networks and their high-dimensional representations. Therein, the principal component analysis decorrelates the distributed representations in cell states of RNNs and allows the comparison to known and fundamental functions. The novel approach is supported by a systematic hyperparameter search strategy that identifies the best neural network architectures and training parameters. The findings of three case studies on fundamental constitutive models (hyperelasticity, elastoplasticity, and viscoelasticity) imply that the proposed strategy can help identify numerical and analytical closed-form solutions to characterize new materials.",0
"Mechanics has increasingly adopted artificial neural networks to enhance computations with model order reduction techniques and employ them as universal models for a broad range of materials. However, the challenge of interpreting and explaining their numerous parameters remains a significant drawback, leading to neural networks being deemed ""black boxes"" with incomprehensible results. To tackle this issue in mechanics, the field of physics-informed neural networks has come up with deep neural networks that are designed based on a priori knowledge of mechanics, enabling greater complexity while maintaining transparency. Nonetheless, the internal reasoning and explanation of neural network parameters still remain a mystery. As a complementary approach, we suggest a physics-informing approach that explains neural networks trained on mechanical data a posteriori. This novel explainable artificial intelligence approach aims to clarify the ""black box"" of neural networks and their high-dimensional representations via principal component analysis, which decorrelates the distributed representations in cell states of RNNs. This allows for comparison with known and fundamental functions. The proposed strategy, supported by a systematic hyperparameter search strategy, can identify the best neural network architectures and training parameters and help characterise new materials via numerical and analytical closed-form solutions.",1
"Deep-learning-based image processing has emerged as a valuable tool in recent years owing to its high performance. However, the quality of deep-learning-based methods relies heavily on the amount of training data, and the cost of acquiring a large amount of data is often prohibitive in medical fields. Therefore, we performed CT modality conversion based on deep learning requiring only a small number of unsupervised images. The proposed method is based on generative adversarial networks (GANs) with several extensions tailored for CT images. This method emphasizes the preservation of the structure in the processed images and reduction in the amount of training data. This method was applied to realize the conversion of mega-voltage computed tomography (MVCT) to kilo-voltage computed tomography (kVCT) images. Training was performed using several datasets acquired from patients with head and neck cancer. The size of the datasets ranged from 16 slices (for two patients) to 2745 slices (for 137 patients) of MVCT and 2824 slices of kVCT for 98 patients. The quality of the processed MVCT images was considerably enhanced, and the structural changes in the images were minimized. With an increase in the size of training data, the image quality exhibited a satisfactory convergence from a few hundred slices. In addition to statistical and visual evaluations, these results were clinically evaluated by medical doctors in terms of the accuracy of contouring. We developed an MVCT to kVCT conversion model based on deep learning, which can be trained using a few hundred unpaired images. The stability of the model against the change in the data size was demonstrated. This research promotes the reliable use of deep learning in clinical medicine by partially answering the commonly asked questions: ""Is our data enough? How much data must we prepare?""",0
"In recent years, deep-learning-based image processing has become an effective tool due to its high performance. However, the success of deep-learning-based methods depends heavily on the availability of training data, which can be costly to acquire in the medical field. To address this issue, we utilized a deep-learning-based approach for CT modality conversion that required only a small number of unsupervised images. Our method was derived from generative adversarial networks (GANs) with several extensions customized for CT images. The objective was to preserve the structure of processed images while reducing the amount of training data necessary. We applied this method to convert mega-voltage computed tomography (MVCT) to kilo-voltage computed tomography (kVCT) images using datasets from patients with head and neck cancer. Our datasets varied in size from 16 slices (for two patients) to 2745 slices (for 137 patients) of MVCT and 2824 slices of kVCT for 98 patients. By using our method, we significantly improved the quality of processed MVCT images while minimizing structural changes. We also evaluated our results through statistical, visual, and clinical assessments, including medical doctors' accuracy of contouring. Our research shows that deep learning can be used reliably in clinical medicine, even with a limited number of images, and can partially address the questions of data sufficiency and preparation in medical fields.",1
"This work considers clustering nodes of a largely incomplete graph. Under the problem setting, only a small amount of queries about the edges can be made, but the entire graph is not observable. This problem finds applications in large-scale data clustering using limited annotations, community detection under restricted survey resources, and graph topology inference under hidden/removed node interactions. Prior works tackled this problem from various perspectives, e.g., convex programming-based low-rank matrix completion and active query-based clique finding. Nonetheless, many existing methods are designed for estimating the single-cluster membership of the nodes, but nodes may often have mixed (i.e., multi-cluster) membership in practice. Some query and computational paradigms, e.g., the random query patterns and nuclear norm-based optimization advocated in the convex approaches, may give rise to scalability and implementation challenges. This work aims at learning mixed membership of nodes using queried edges. The proposed method is developed together with a systematic query principle that can be controlled and adjusted by the system designers to accommodate implementation challenges -- e.g., to avoid querying edges that are physically hard to acquire. Our framework also features a lightweight and scalable algorithm with membership learning guarantees. Real-data experiments on crowdclustering and community detection are used to showcase the effectiveness of our method.",0
"The focus of this study is on clustering nodes within an incomplete graph, where only a limited number of edge queries are possible and the entire graph is not visible. This problem has practical applications in data clustering with limited annotations, community detection with limited survey resources, and graph topology inference with hidden or removed node interactions. Previous methods have addressed this problem using various approaches, such as low-rank matrix completion and active query-based clique finding, but they often assume single-cluster membership for nodes, which is not always the case. Additionally, some methods may face scalability and implementation challenges. This study aims to address these limitations by proposing a method that can learn mixed membership of nodes using queried edges. The proposed method is accompanied by a systematic query principle that can be adjusted to accommodate implementation challenges. The study also presents a lightweight and scalable algorithm with membership learning guarantees, and real-data experiments demonstrate the effectiveness of the proposed method in crowdclustering and community detection.",1
"Ensemble data from Earth system models has to be calibrated and post-processed. I propose a novel member-by-member post-processing approach with neural networks. I bridge ideas from ensemble data assimilation with self-attention, resulting into the self-attentive ensemble transformer. Here, interactions between ensemble members are represented as additive and dynamic self-attentive part. As proof-of-concept, I regress global ECMWF ensemble forecasts to 2-metre-temperature fields from the ERA5 reanalysis. I demonstrate that the ensemble transformer can calibrate the ensemble spread and extract additional information from the ensemble. As it is a member-by-member approach, the ensemble transformer directly outputs multivariate and spatially-coherent ensemble members. Therefore, self-attention and the transformer technique can be a missing piece for a non-parametric post-processing of ensemble data with neural networks.",0
"To properly utilize data from Earth system models, calibration and post-processing are necessary. To achieve this, I propose an innovative approach that uses neural networks for member-by-member post-processing. I combine concepts from ensemble data assimilation and self-attention to create the self-attentive ensemble transformer, which represents interactions between ensemble members as dynamic and additive self-attention. To demonstrate its effectiveness, I use the ensemble transformer to regress global ECMWF ensemble forecasts to 2-metre-temperature fields from the ERA5 reanalysis. The results show that the ensemble transformer can successfully calibrate ensemble spread and extract additional information from the ensemble. Additionally, the member-by-member approach allows for direct output of multivariate and spatially-coherent ensemble members. This approach, utilizing self-attention and the transformer technique, can serve as a missing piece for non-parametric post-processing of ensemble data with neural networks.",1
"Multi-agent imitation learning aims to train multiple agents to perform tasks from demonstrations by learning a mapping between observations and actions, which is essential for understanding physical, social, and team-play systems. However, most existing works on modeling multi-agent interactions typically assume that agents make independent decisions based on their observations, ignoring the complex dependence among agents. In this paper, we propose to use copula, a powerful statistical tool for capturing dependence among random variables, to explicitly model the correlation and coordination in multi-agent systems. Our proposed model is able to separately learn marginals that capture the local behavioral patterns of each individual agent, as well as a copula function that solely and fully captures the dependence structure among agents. Extensive experiments on synthetic and real-world datasets show that our model outperforms state-of-the-art baselines across various scenarios in the action prediction task, and is able to generate new trajectories close to expert demonstrations.",0
"The goal of multi-agent imitation learning is to teach multiple agents how to perform tasks through demonstrations by learning a connection between observations and actions. This is important for understanding physical, social, and team-play systems. However, current research on modeling multi-agent interactions often assumes that agents make independent decisions based on their observations, ignoring the intricate relationships between agents. Our paper proposes to use copula, a statistical tool that can capture dependence among random variables, to model the correlation and coordination in multi-agent systems. Our model learns marginals that represent the behavior of each individual agent and a copula function that represents the dependence structure among agents. We conducted experiments on synthetic and real-world datasets, which showed that our model performed better than existing approaches in various scenarios related to action prediction and generated trajectories that were similar to expert demonstrations.",1
"Interpretability in machine learning (ML) is crucial for high stakes decisions and troubleshooting. In this work, we provide fundamental principles for interpretable ML, and dispel common misunderstandings that dilute the importance of this crucial topic. We also identify 10 technical challenge areas in interpretable machine learning and provide history and background on each problem. Some of these problems are classically important, and some are recent problems that have arisen in the last few years. These problems are: (1) Optimizing sparse logical models such as decision trees; (2) Optimization of scoring systems; (3) Placing constraints into generalized additive models to encourage sparsity and better interpretability; (4) Modern case-based reasoning, including neural networks and matching for causal inference; (5) Complete supervised disentanglement of neural networks; (6) Complete or even partial unsupervised disentanglement of neural networks; (7) Dimensionality reduction for data visualization; (8) Machine learning models that can incorporate physics and other generative or causal constraints; (9) Characterization of the ""Rashomon set"" of good models; and (10) Interpretable reinforcement learning. This survey is suitable as a starting point for statisticians and computer scientists interested in working in interpretable machine learning.",0
"The importance of interpretability in machine learning cannot be overstated, as it is necessary for making sound decisions and resolving issues. This study presents essential principles for interpretable machine learning and addresses common misconceptions that undermine the significance of this topic. Furthermore, the research identifies ten technical challenges in interpretable machine learning, covering both classic and recent issues. These include challenges such as optimizing sparse logical models, incorporating physics and causal constraints into machine learning models, and achieving complete supervised and unsupervised disentanglement of neural networks. This study serves as a useful starting point for statisticians and computer scientists who wish to delve into the field of interpretable machine learning.",1
"The amount and variety of data is increasing drastically for several years. These data are often represented as networks, which are then explored with approaches arising from network theory. Recent years have witnessed the extension of network exploration methods to leverage more complex and richer network frameworks. Random walks, for instance, have been extended to explore multilayer networks. However, current random walk approaches are limited in the combination and heterogeneity of network layers they can handle. New analytical and numerical random walk methods are needed to cope with the increasing diversity and complexity of multilayer networks. We propose here MultiXrank, a Python package that enables Random Walk with Restart (RWR) on any kind of multilayer network with an optimized implementation. This package is supported by a universal mathematical formulation of the RWR. We evaluated MultiXrank with leave-one-out cross-validation and link prediction, and introduced protocols to measure the impact of the addition or removal of multilayer network data on prediction performances. We further measured the sensitivity of MultiXrank to input parameters by in-depth exploration of the parameter space. Finally, we illustrate the versatility of MultiXrank with different use-cases of unsupervised node prioritization and supervised classification in the context of human genetic diseases.",0
"For several years, the amount and diversity of data have been growing rapidly. These data often take the form of networks, which are then analyzed using methods derived from network theory. In recent times, network exploration techniques have been expanded to encompass more intricate and varied network structures. For instance, random walks have been extended to explore multilayer networks. However, existing random walk methods are limited in their ability to handle the combination and heterogeneity of network layers. As multilayer networks become more complex and diverse, new analytical and numerical random walk methods are required. To address this issue, we have developed MultiXrank, a Python package that optimally implements Random Walk with Restart (RWR) on any type of multilayer network. This package is supported by a universal mathematical formulation of the RWR. We tested MultiXrank using leave-one-out cross-validation and link prediction, as well as protocols for measuring the impact of adding or removing multilayer network data on prediction performance. We also explored the parameter space to determine the sensitivity of MultiXrank to input parameters. Finally, we demonstrate the versatility of MultiXrank with various applications, including unsupervised node prioritization and supervised classification in the context of human genetic diseases.",1
"Communities in social networks evolve over time as people enter and leave the network and their activity behaviors shift. The task of predicting structural changes in communities over time is known as community evolution prediction. Existing work in this area has focused on the development of frameworks for defining events while using traditional classification methods to perform the actual prediction. We present a novel graph neural network for predicting community evolution events from structural and temporal information. The model (GNAN) includes a group-node attention component which enables support for variable-sized inputs and learned representation of groups based on member and neighbor node features. A comparative evaluation with standard baseline methods is performed and we demonstrate that our model outperforms the baselines. Additionally, we show the effects of network trends on model performance.",0
"The makeup of communities on social media alters as people join and leave the network and alter their behavior. The duty of estimating how communities will change over time is called community evolution prediction. Prior research in this field has revolved around creating frameworks to identify events and using conventional classification methods to make the forecast. Our study introduces a fresh graph neural network (GNAN) that predicts community evolution events using both structural and temporal data. The GNAN model includes group-node attention, which supports inputs of varying sizes and learns about groups based on member and neighbor node characteristics. We carry out a comparative evaluation with traditional baseline methods and demonstrate that our model outperforms them. Furthermore, we examine how network trends impact model performance.",1
"Physics Informed Neural Network (PINN) is a scientific computing framework used to solve both forward and inverse problems modeled by Partial Differential Equations (PDEs). This paper introduces IDRLnet, a Python toolbox for modeling and solving problems through PINN systematically. IDRLnet constructs the framework for a wide range of PINN algorithms and applications. It provides a structured way to incorporate geometric objects, data sources, artificial neural networks, loss metrics, and optimizers within Python. Furthermore, it provides functionality to solve noisy inverse problems, variational minimization, and integral differential equations. New PINN variants can be integrated into the framework easily. Source code, tutorials, and documentation are available at \url{https://github.com/idrl-lab/idrlnet}.",0
"The Physics Informed Neural Network (PINN) is a framework for scientific computing that tackles forward and inverse problems modeled by Partial Differential Equations (PDEs). This paper presents IDRLnet, a Python toolbox that systematically models and solves problems using PINN. IDRLnet facilitates the creation of various PINN algorithms and applications by incorporating geometric objects, data sources, artificial neural networks, loss metrics, and optimizers within Python in a structured manner. Moreover, it allows for solving challenges such as noisy inverse problems, variational minimization, and integral differential equations. The framework can easily integrate new PINN variants. Access to source code, tutorials, and documentation is available at \url{https://github.com/idrl-lab/idrlnet}.",1
"Tensor Networks, a numerical tool originally designed for simulating quantum many-body systems, have recently been applied to solve Machine Learning problems. Exploiting a tree tensor network, we apply a quantum-inspired machine learning technique to a very important and challenging big data problem in high energy physics: the analysis and classification of data produced by the Large Hadron Collider at CERN. In particular, we present how to effectively classify so-called b-jets, jets originating from b-quarks from proton-proton collisions in the LHCb experiment, and how to interpret the classification results. We exploit the Tensor Network approach to select important features and adapt the network geometry based on information acquired in the learning process. Finally, we show how to adapt the tree tensor network to achieve optimal precision or fast response in time without the need of repeating the learning process. These results pave the way to the implementation of high-frequency real-time applications, a key ingredient needed among others for current and future LHCb event classification able to trigger events at the tens of MHz scale.",0
"Tensor Networks were originally created to simulate quantum many-body systems, but they are now being utilized to address Machine Learning problems. By utilizing a tree tensor network, we apply a quantum-inspired machine learning method to a significant and complex big data issue in high energy physics: the categorization and analysis of data generated by the Large Hadron Collider at CERN. Specifically, we explain how to effectively classify ""b-jets,"" which are jets that originate from b-quarks from proton-proton collisions in the LHCb experiment, and how to comprehend the classification findings. We use the Tensor Network approach to choose essential characteristics and modify the network geometry based on knowledge obtained during the learning process. Ultimately, we demonstrate how to adjust the tree tensor network to achieve optimal accuracy or rapid response time without necessitating the repetition of the learning process. These findings pave the way for the development of high-frequency real-time applications, a crucial component necessary for current and future LHCb event classification that can trigger events at the tens of MHz scale.",1
"The troposphere is one of the atmospheric layers where most weather phenomena occur. Temperature variations in the troposphere, especially at 500 hPa, a typical level of the middle troposphere, are significant indicators of future weather changes. Numerical weather prediction is effective for temperature prediction, but its computational complexity hinders a timely response. This paper proposes a novel temperature prediction approach in framework ofphysics-informed deep learning. The new model, called PGnet, builds upon a generative neural network with a mask matrix. The mask is designed to distinguish the low-quality predicted regions generated by the first physical stage. The generative neural network takes the mask as prior for the second-stage refined predictions. A mask-loss and a jump pattern strategy are developed to train the generative neural network without accumulating errors during making time-series predictions. Experiments on ERA5 demonstrate that PGnet can generate more refined temperature predictions than the state-of-the-art.",0
"Most weather phenomena occur in the troposphere, which is an atmospheric layer. Temperature changes, particularly at 500 hPa, a level in the middle troposphere, can indicate future weather patterns. While numerical weather prediction is effective, its complexity can cause delays. To tackle this issue, a new temperature prediction approach called PGnet has been proposed. It utilizes a generative neural network with a mask matrix to distinguish low-quality predictions and refine them in the second stage. A mask-loss and jump pattern strategy have been developed to train the network. Tests on ERA5 data show that PGnet outperforms current methods in generating accurate temperature predictions.",1
"This paper tackles video prediction from a new dimension of predicting spacetime-varying motions that are incessantly changing across both space and time. Prior methods mainly capture the temporal state transitions but overlook the complex spatiotemporal variations of the motion itself, making them difficult to adapt to ever-changing motions. We observe that physical world motions can be decomposed into transient variation and motion trend, while the latter can be regarded as the accumulation of previous motions. Thus, simultaneously capturing the transient variation and the motion trend is the key to make spacetime-varying motions more predictable. Based on these observations, we propose the MotionRNN framework, which can capture the complex variations within motions and adapt to spacetime-varying scenarios. MotionRNN has two main contributions. The first is that we design the MotionGRU unit, which can model the transient variation and motion trend in a unified way. The second is that we apply the MotionGRU to RNN-based predictive models and indicate a new flexible video prediction architecture with a Motion Highway that can significantly improve the ability to predict changeable motions and avoid motion vanishing for stacked multiple-layer predictive models. With high flexibility, this framework can adapt to a series of models for deterministic spatiotemporal prediction. Our MotionRNN can yield significant improvements on three challenging benchmarks for video prediction with spacetime-varying motions.",0
"The aim of this study is to approach video prediction from a unique perspective that involves predicting the constantly changing spacetime-varying motions across both space and time. Previous methods have mainly focused on capturing the temporal state transitions, neglecting the intricate spatiotemporal motion variations, which makes adapting to ever-changing motions difficult. The authors have observed that physical world motions consist of transient variations and motion trends, with the latter being the accumulation of previous motions. Therefore, capturing both the transient variation and motion trend is essential for predicting spacetime-varying motions. To achieve this, the authors propose the MotionRNN framework, which has two key contributions. The first is the MotionGRU unit, which unifies the modeling of transient variation and motion trend. The second is the application of MotionGRU to RNN-based predictive models, resulting in a flexible video prediction architecture with a Motion Highway that can improve the ability to predict changeable motions and prevent motion vanishing. This framework is highly adaptable to a range of models for deterministic spatiotemporal prediction and yields significant improvements on three challenging benchmarks for video prediction with spacetime-varying motions.",1
"Adversarial robustness of deep neural networks has been actively investigated. However, most existing defense approaches are limited to a specific type of adversarial perturbations. Specifically, they often fail to offer resistance to multiple attack types simultaneously, i.e., they lack multi-perturbation robustness. Furthermore, compared to image recognition problems, the adversarial robustness of video recognition models is relatively unexplored. While several studies have proposed how to generate adversarial videos, only a handful of approaches about the defense strategies have been published in the literature. In this paper, we propose one of the first defense strategies against multiple types of adversarial videos for video recognition. The proposed method, referred to as MultiBN, performs adversarial training on multiple adversarial video types using multiple independent batch normalization (BN) layers with a learning-based BN selection module. With a multiple BN structure, each BN brach is responsible for learning the distribution of a single perturbation type and thus provides more precise distribution estimations. This mechanism benefits dealing with multiple perturbation types. The BN selection module detects the attack type of an input video and sends it to the corresponding BN branch, making MultiBN fully automatic and allow end-to-end training. Compared to present adversarial training approaches, the proposed MultiBN exhibits stronger multi-perturbation robustness against different and even unforeseen adversarial video types, ranging from Lp-bounded attacks and physically realizable attacks. This holds true on different datasets and target models. Moreover, we conduct an extensive analysis to study the properties of the multiple BN structure.",0
"There has been a lot of research on the adversarial robustness of deep neural networks. However, current defense methods are usually only effective against a specific type of attack and lack multi-perturbation robustness. Additionally, the robustness of video recognition models has been relatively unexplored compared to image recognition models. While some studies have proposed ways to create adversarial videos, there have been few published defense strategies. This paper presents one of the first defense strategies for video recognition that is effective against multiple types of adversarial videos. The proposed method, called MultiBN, uses multiple independent batch normalization (BN) layers with a learning-based BN selection module. Each BN branch is responsible for learning the distribution of a single type of perturbation, which allows for more precise distribution estimations and better handling of multiple perturbation types. The BN selection module automatically detects the type of attack and sends the video to the corresponding BN branch for processing. The proposed MultiBN shows stronger multi-perturbation robustness against different types of adversarial videos, including Lp-bounded and physically realizable attacks, compared to current approaches. The effectiveness of MultiBN was demonstrated on different datasets and target models. Additionally, the multiple BN structure was extensively analyzed.",1
"Robust physics discovery is of great interest for many scientific and engineering fields. Inspired by the principle that a representative model is the one simplest possible, a new model selection criteria considering both model's Parsimony and Sparsity is proposed. A Parsimony Enhanced Sparse Bayesian Learning (PeSBL) method is developed for discovering the governing Partial Differential Equations (PDEs) of nonlinear dynamical systems. Compared with the conventional Sparse Bayesian Learning (SBL) method, the PeSBL method promotes parsimony of the learned model in addition to its sparsity. In this method, the parsimony of model terms is evaluated using their locations in the prescribed candidate library, for the first time, considering the increased complexity with the power of polynomials and the order of spatial derivatives. Subsequently, the model parameters are updated through Bayesian inference with the raw data. This procedure aims to reduce the error associated with the possible loss of information in data preprocessing and numerical differentiation prior to sparse regression. Results of numerical case studies indicate that the governing PDEs of many canonical dynamical systems can be correctly identified using the proposed PeSBL method from highly noisy data (up to 50% in the current study). Next, the proposed methodology is extended for stochastic PDE learning where all parameters and modeling error are considered as random variables. Hierarchical Bayesian Inference (HBI) is integrated with the proposed framework for stochastic PDE learning from a population of observations. Finally, the proposed PeSBL is demonstrated for system response prediction with uncertainties and anomaly diagnosis. Codes of all demonstrated examples in this study are available on the website: https://github.com/ymlasu.",0
"Many scientific and engineering fields are interested in discovering robust physics. A new model selection criteria has been proposed that considers both Parsimony and Sparsity, inspired by the principle that a simple model is the most representative. The Parsimony Enhanced Sparse Bayesian Learning (PeSBL) method has been developed to discover the governing Partial Differential Equations (PDEs) of nonlinear dynamical systems. Compared to the conventional Sparse Bayesian Learning (SBL) method, PeSBL promotes parsimony as well as sparsity of the learned model. In this method, the parsimony of model terms is evaluated for the first time by considering their locations in the prescribed candidate library, considering the increasing complexity with the power of polynomials and the order of spatial derivatives. Bayesian inference is used to update the model parameters with the raw data, aiming to reduce errors associated with data preprocessing and numerical differentiation prior to sparse regression. Numerical case studies have shown that the PeSBL method can correctly identify the governing PDEs of many canonical dynamical systems from highly noisy data. The proposed methodology has also been extended for stochastic PDE learning, where all parameters and modeling error are considered as random variables. Hierarchical Bayesian Inference (HBI) has been integrated with the proposed framework for stochastic PDE learning from a population of observations. Finally, the proposed PeSBL method has been demonstrated for system response prediction with uncertainties and anomaly diagnosis. All demonstrated examples in this study are available on the website: https://github.com/ymlasu.",1
"Effective environmental planning and management to address climate change could be achieved through extensive environmental modeling with machine learning and conventional physical models. In order to develop and improve these models, practitioners and researchers need comprehensive benchmark datasets that are prepared and processed with environmental expertise that they can rely on. This study presents an extensive dataset of rainfall events for the state of Iowa (2016-2019) acquired from the National Weather Service Next Generation Weather Radar (NEXRAD) system and processed by a quantitative precipitation estimation system. The dataset presented in this study could be used for better disaster monitoring, response and recovery by paving the way for both predictive and prescriptive modeling.",0
"Comprehensive benchmark datasets that are prepared and processed with environmental expertise are necessary for practitioners and researchers to develop and improve environmental planning and management to address climate change. This can be achieved through extensive environmental modeling with both machine learning and conventional physical models. In an effort to provide such a dataset, this study presents an extensive collection of rainfall events for the state of Iowa (2016-2019) obtained from the National Weather Service Next Generation Weather Radar (NEXRAD) system and processed by a quantitative precipitation estimation system. This dataset can be utilized to enhance disaster monitoring, response, and recovery by enabling predictive and prescriptive modeling.",1
"The acquisition of Antimicrobial Multidrug Resistance (AMR) in patients admitted to the Intensive Care Units (ICU) is a major global concern. This study analyses data in the form of multivariate time series (MTS) from 3476 patients recorded at the ICU of University Hospital of Fuenlabrada (Madrid) from 2004 to 2020. 18\% of the patients acquired AMR during their stay in the ICU. The goal of this paper is an early prediction of the development of AMR. Towards that end, we leverage the time-series cluster kernel (TCK) to learn similarities between MTS. To evaluate the effectiveness of TCK as a kernel, we applied several dimensionality reduction techniques for visualization and classification tasks. The experimental results show that TCK allows identifying a group of patients that acquire the AMR during the first 48 hours of their ICU stay, and it also provides good classification capabilities.",0
"The rise of Antimicrobial Multidrug Resistance (AMR) in patients who are admitted to Intensive Care Units (ICU) is a grave concern worldwide. This study examines multivariate time series (MTS) data from 3476 patients who were admitted to the ICU at the University Hospital of Fuenlabrada (Madrid) from 2004 to 2020. During their stay in the ICU, 18% of the patients acquired AMR. The aim of this research is to predict the development of AMR in patients at an early stage. To accomplish this, the time-series cluster kernel (TCK) is utilized to learn similarities between MTS. To assess TCK's effectiveness as a kernel, several dimensionality reduction methods are employed for visualization and classification tasks. The experimental results indicate that TCK can identify a group of patients who acquire AMR in the first 48 hours of their ICU stay and also exhibits good classification capabilities.",1
"Outdoor scene relighting is a challenging problem that requires good understanding of the scene geometry, illumination and albedo. Current techniques are completely supervised, requiring high quality synthetic renderings to train a solution. Such renderings are synthesized using priors learned from limited data. In contrast, we propose a self-supervised approach for relighting. Our approach is trained only on corpora of images collected from the internet without any user-supervision. This virtually endless source of training data allows training a general relighting solution. Our approach first decomposes an image into its albedo, geometry and illumination. A novel relighting is then produced by modifying the illumination parameters. Our solution capture shadow using a dedicated shadow prediction map, and does not rely on accurate geometry estimation. We evaluate our technique subjectively and objectively using a new dataset with ground-truth relighting. Results show the ability of our technique to produce photo-realistic and physically plausible results, that generalizes to unseen scenes.",0
"Relighting an outdoor scene is a complex task that necessitates a comprehensive comprehension of the scene's geometry, albedo, and illumination. The current methods are wholly supervised, necessitating high-quality synthetic renderings to train a solution. These renderings are created using priors learned from a limited dataset. On the other hand, we propose a self-supervised approach for relighting. Our approach is trained on image collections obtained from the internet without any user supervision. This vast amount of training data enables us to train a general relighting solution. Our method first breaks down an image into its albedo, geometry, and illumination. Then, it generates a new relighting by changing the illumination parameters. Our solution includes a dedicated shadow prediction map and does not rely on precise geometry estimation to capture shadows. We evaluated our technique both subjectively and objectively using a new dataset with accurate relighting data. The results demonstrate the capability of our method to create photorealistic and physically plausible outcomes that apply to unfamiliar scenes.",1
"Partition of unity networks (POU-Nets) have been shown capable of realizing algebraic convergence rates for regression and solution of PDEs, but require empirical tuning of training parameters. We enrich POU-Nets with a Gaussian noise model to obtain a probabilistic generalization amenable to gradient-based minimization of a maximum likelihood loss. The resulting architecture provides spatial representations of both noiseless and noisy data as Gaussian mixtures with closed form expressions for variance which provides an estimator of local error. The training process yields remarkably sharp partitions of input space based upon correlation of function values. This classification of training points is amenable to a hierarchical refinement strategy that significantly improves the localization of the regression, allowing for higher-order polynomial approximation to be utilized. The framework scales more favorably to large data sets as compared to Gaussian process regression and allows for spatially varying uncertainty, leveraging the expressive power of deep neural networks while bypassing expensive training associated with other probabilistic deep learning methods. Compared to standard deep neural networks, the framework demonstrates hp-convergence without the use of regularizers to tune the localization of partitions. We provide benchmarks quantifying performance in high/low-dimensions, demonstrating that convergence rates depend only on the latent dimension of data within high-dimensional space. Finally, we introduce a new open-source data set of PDE-based simulations of a semiconductor device and perform unsupervised extraction of a physically interpretable reduced-order basis.",0
"Although Partition of Unity Networks (POU-Nets) have been proven to achieve algebraic convergence rates for solving PDEs and regression, they require empirical tuning of training parameters. To address this, we introduce a Gaussian noise model to enhance POU-Nets and make them more suitable for gradient-based minimization of maximum likelihood loss. With this modification, we can create spatial representations of both clean and noisy data, using Gaussian mixtures with a closed form expression for variance that can provide an estimator of local error. The training process results in precise partitions of input space based on correlation of function values, which can be improved through a hierarchical refinement strategy that allows for higher-order polynomial approximation. This framework is more scalable than Gaussian process regression and allows for spatially varying uncertainty. It also demonstrates hp-convergence without the use of regularizers to tune the localization of partitions, surpassing standard deep neural networks. We present benchmarks quantifying its performance in high/low-dimensions and introduce a new open-source data set of PDE-based simulations of a semiconductor device that we use to perform unsupervised extraction of a physically interpretable reduced-order basis.",1
"Inverse problems are notoriously difficult to solve because they can have no solutions, multiple solutions, or have solutions that vary significantly in response to small perturbations in measurements. Bayesian inference, which poses an inverse problem as a stochastic inference problem, addresses these difficulties and provides quantitative estimates of the inferred field and the associated uncertainty. However, it is difficult to employ when inferring vectors of large dimensions, and/or when prior information is available through previously acquired samples. In this paper, we describe how deep generative adversarial networks can be used to represent the prior distribution in Bayesian inference and overcome these challenges. We apply these ideas to inverse problems that are diverse in terms of the governing physical principles, sources of prior knowledge, type of measurement, and the extent of available information about measurement noise. In each case we apply the proposed approach to infer the most likely solution and quantitative estimates of uncertainty.",0
"Solving inverse problems can be extremely challenging due to the possibility of having no solutions, multiple solutions, or solutions that are highly sensitive to slight changes in measurements. Bayesian inference is a useful method for tackling these issues by treating an inverse problem as a stochastic inference problem and providing numerical estimates for the inferred field and its associated uncertainty. However, applying this method can be difficult when dealing with high-dimensional vectors or when prior information is available from past samples. To address these challenges, we propose the use of deep generative adversarial networks to represent the prior distribution in Bayesian inference. Our approach is applicable to a wide range of inverse problems with varying physical principles, types of measurement, and levels of available information about measurement noise. We demonstrate the effectiveness of our approach by using it to infer the most likely solution and quantify the uncertainty in each case.",1
"The identification of anomalous overdensities in data - group or collective anomaly detection - is a rich problem with a large number of real world applications. However, it has received relatively little attention in the broader ML community, as compared to point anomalies or other types of single instance outliers. One reason for this is the lack of powerful benchmark datasets. In this paper, we first explain how, after the Nobel-prize winning discovery of the Higgs boson, unsupervised group anomaly detection has become a new frontier of fundamental physics (where the motivation is to find new particles and forces). Then we propose a realistic synthetic benchmark dataset (LHCO2020) for the development of group anomaly detection algorithms. Finally, we compare several existing statistically-sound techniques for unsupervised group anomaly detection, and demonstrate their performance on the LHCO2020 dataset.",0
"Detecting anomalous overdensities in data, also known as group or collective anomaly detection, is a complex issue with significant real-world applications. However, compared to point anomalies or other types of single instance outliers, it has not received much attention in the broader ML community due to a lack of robust benchmark datasets. This paper addresses this issue by first discussing how unsupervised group anomaly detection has become a new frontier in fundamental physics after the Nobel Prize-winning discovery of the Higgs boson. We then introduce the LHCO2020 synthetic benchmark dataset for developing group anomaly detection algorithms. Finally, we evaluate the performance of various statistically-sound techniques for unsupervised group anomaly detection on the LHCO2020 dataset.",1
"Robust vision restoration for an underwater image remains a challenging problem. For the lack of aligned underwater-terrestrial image pairs, the unsupervised method is more suited to this task. However, the pure data-driven unsupervised method usually has difficulty in achieving realistic color correction for lack of optical constraint. In this paper, we propose a data- and physics-driven unsupervised architecture that learns underwater vision restoration from unpaired underwater-terrestrial images. For sufficient domain transformation and detail preservation, the underwater degeneration needs to be explicitly constructed based on the optically unambiguous physics law. Thus, we employ the Jaffe-McGlamery degradation theory to design the generation models, and use neural networks to describe the process of underwater degradation. Furthermore, to overcome the problem of invalid gradient when optimizing the hybrid physical-neural model, we fully investigate the intrinsic correlation between the scene depth and the degradation factors for the backscattering estimation, to improve the restoration performance through physical constraints. Our experimental results show that the proposed method is able to perform high-quality restoration for unconstrained underwater images without any supervision. On multiple benchmarks, we outperform several state-of-the-art supervised and unsupervised approaches. We also demonstrate that our methods yield encouraging results on real-world applications.",0
"Restoring vision in underwater images is a complex task that presents many challenges. One of the main obstacles is the lack of aligned underwater-terrestrial image pairs, which makes unsupervised methods more suitable. However, unsupervised methods that rely solely on data often struggle to achieve realistic color correction due to the absence of optical constraints. To address this issue, we propose an unsupervised architecture that combines data and physics-driven techniques to learn how to restore underwater vision from unpaired underwater-terrestrial images. To achieve domain transformation and detail preservation, we use the Jaffe-McGlamery degradation theory to design generation models and neural networks to describe the underwater degradation process. Additionally, we investigate the relationship between scene depth and degradation factors to overcome the problem of invalid gradient when optimizing the hybrid physical-neural model. Our experimental results demonstrate that our proposed method outperforms several state-of-the-art supervised and unsupervised approaches on multiple benchmarks and can effectively restore unconstrained underwater images without supervision. We also show promising results on real-world applications.",1
"After the 2017 TuSimple Lane Detection Challenge, its evaluation based on accuracy and F1 score has become the de facto standard to measure the performance of lane detection methods. In this work, we conduct the first large-scale empirical study to evaluate the robustness of state-of-the-art lane detection methods under physical-world adversarial attacks in autonomous driving. We evaluate 4 major types of lane detection approaches with the conventional evaluation and end-to-end evaluation in autonomous driving scenarios and then discuss the security proprieties of each lane detection model. We demonstrate that the conventional evaluation fails to reflect the robustness in end-to-end autonomous driving scenarios. Our results show that the most robust model on the conventional metrics is the least robust in the end-to-end evaluation. Although the competition dataset and its metrics have played a substantial role in developing performant lane detection methods along with the rapid development of deep neural networks, the conventional evaluation is becoming obsolete and the gap between the metrics and practicality is critical. We hope that our study will help the community make further progress in building a more comprehensive framework to evaluate lane detection models.",0
"The evaluation of lane detection methods based on accuracy and F1 score, established by the 2017 TuSimple Lane Detection Challenge, has become the standard for measuring performance. Our research is the first large-scale study to assess the robustness of cutting-edge lane detection methods against physical-world adversarial attacks in autonomous driving. We evaluated four major lane detection approaches using both conventional and end-to-end evaluations, and analyzed each model's security properties. Our findings revealed that the conventional evaluation is inadequate for assessing robustness in end-to-end autonomous driving scenarios. Interestingly, the most robust model based on conventional metrics was the least robust in the end-to-end evaluation. Although the competition dataset and metrics have been instrumental in advancing lane detection methods, the conventional evaluation is becoming redundant and the gap between metrics and practicality is concerning. We aim to contribute to developing a more comprehensive framework for evaluating lane detection models and encourage further progress in this field.",1
"Neural network pruning is a fruitful area of research with surging interest in high sparsity regimes. Benchmarking in this domain heavily relies on faithful representation of the sparsity of subnetworks, which has been traditionally computed as the fraction of removed connections (direct sparsity). This definition, however, fails to recognize unpruned parameters that detached from input or output layers of underlying subnetworks, potentially underestimating actual effective sparsity: the fraction of inactivated connections. While this effect might be negligible for moderately pruned networks (up to 10-100 compression rates), we find that it plays an increasing role for thinner subnetworks, greatly distorting comparison between different pruning algorithms. For example, we show that effective compression of a randomly pruned LeNet-300-100 can be orders of magnitude larger than its direct counterpart, while no discrepancy is ever observed when using SynFlow for pruning [Tanaka et al., 2020]. In this work, we adopt the lens of effective sparsity to reevaluate several recent pruning algorithms on common benchmark architectures (e.g., LeNet-300-100, VGG-19, ResNet-18) and discover that their absolute and relative performance changes dramatically in this new and more appropriate framework. To aim for effective, rather than direct, sparsity, we develop a low-cost extension to most pruning algorithms. Further, equipped with effective sparsity as a reference frame, we partially reconfirm that random pruning with appropriate sparsity allocation across layers performs as well or better than more sophisticated algorithms for pruning at initialization [Su et al., 2020]. In response to this observation, using a simple analogy of pressure distribution in coupled cylinders from physics, we design novel layerwise sparsity quotas that outperform all existing baselines in the context of random pruning.",0
"The field of neural network pruning is gaining popularity, particularly in high sparsity conditions. To accurately benchmark subnetwork sparsity, it is important to consider the fraction of inactivated connections, rather than simply the fraction of removed connections. This is because unpruned parameters that detach from input or output layers can lead to an underestimation of effective sparsity, especially in thinner subnetworks. In this study, we use effective sparsity as a reference frame to evaluate the performance of several recent pruning algorithms on common benchmark architectures, such as LeNet-300-100, VGG-19, and ResNet-18. We find that their absolute and relative performance significantly changes in this new framework. To achieve effective sparsity, we introduce a low-cost extension to most pruning algorithms and develop novel layerwise sparsity quotas based on a physics analogy of pressure distribution in coupled cylinders. Our results show that random pruning with appropriate sparsity allocation across layers performs as well or better than more sophisticated algorithms for pruning at initialization.",1
"The rapid growth of distributed energy resources potentially increases power grid instability. One promising strategy is to employ data in power grids to efficiently respond to abnormal events (e.g., faults) by detection and location. Unfortunately, most existing works lack physical interpretation and are vulnerable to the practical challenges: sparse observation, insufficient labeled datasets, and stochastic environment. We propose a physics-informed graph learning framework of two stages to handle these challenges when locating faults. Stage- I focuses on informing a graph neural network (GNN) with the geometrical structure of power grids; stage-II employs the physical similarity of labeled and unlabeled data samples to improve the location accuracy. We provide a random walk-based the underpinning of designing our GNNs to address the challenge of sparse observation and augment the correct prediction probability. We compare our approach with three baselines in the IEEE 123-node benchmark system, showing that the proposed method outperforms the others by significant margins, especially when label rates are low. Also, we validate the robustness of our algorithms to out-of-distribution-data (ODD) due to topology changes and load variations. Additionally, we adapt our graph learning framework to the IEEE 37-node test feeder and show high location performance with the proposed training strategy.",0
"The rapid expansion of distributed energy resources has the potential to create instability in power grids. To address this, data can be used to detect and locate abnormal events such as faults. However, many existing methods lack physical interpretation and are susceptible to practical challenges such as sparse observations, insufficient labeled datasets, and stochastic environments. To overcome these challenges, we propose a two-stage physics-informed graph learning framework for fault location. In Stage-I, a graph neural network (GNN) is informed with the geometric structure of power grids, while in Stage-II, physical similarities between labeled and unlabeled data samples are used to improve location accuracy. We employ a random walk-based approach to design our GNNs, which enhances prediction probability and addresses the challenge of sparse observations. Our approach outperforms three baselines on the IEEE 123-node benchmark system, particularly when label rates are low. We also demonstrate the robustness of our algorithms to out-of-distribution data (ODD) due to topology changes and load variations and adapt our framework to the IEEE 37-node test feeder with high location accuracy.",1
"Understanding physical phenomena oftentimes means understanding the underlying dynamical system that governs observational measurements. While accurate prediction can be achieved with black box systems, they often lack interpretability and are less amenable for further expert investigation. Alternatively, the dynamics can be analysed via symbolic regression. In this paper, we extend the approach by (Udrescu et al., 2020) called AIFeynman to the dynamic setting to perform symbolic regression on ODE systems based on observations from the resulting trajectories. We compare this extension to state-of-the-art approaches for symbolic regression empirically on several dynamical systems for which the ground truth equations of increasing complexity are available. Although the proposed approach performs best on this benchmark, we observed difficulties of all the compared symbolic regression approaches on more complex systems, such as Cart-Pole.",0
"To fully comprehend physical phenomena, it is often necessary to understand the underlying dynamical system that governs observational measurements. Although black box systems can provide accurate predictions, they lack interpretability and do not lend themselves well to further expert investigation. Alternatively, symbolic regression can be used to analyze the dynamics. In this study, we build on the AIFeynman approach developed by Udrescu et al. (2020) by applying it to ODE systems and conducting symbolic regression based on resulting trajectory observations. We compare this extension to other state-of-the-art approaches for symbolic regression on various dynamical systems of increasing complexity, where the ground truth equations are known. While our proposed approach performs best on the benchmark, we observed that all compared symbolic regression methods struggle with more complex systems like Cart-Pole.",1
"Offline reinforcement learning proposes to learn policies from large collected datasets without interacting with the physical environment. These algorithms have made it possible to learn useful skills from data that can then be deployed in the environment in real-world settings where interactions may be costly or dangerous, such as autonomous driving or factories. However, current algorithms overfit to the dataset they are trained on and exhibit poor out-of-distribution generalization to the environment when deployed. In this paper, we study the effectiveness of performing data augmentations on the state space, and study 7 different augmentation schemes and how they behave with existing offline RL algorithms. We then combine the best data performing augmentation scheme with a state-of-the-art Q-learning technique, and improve the function approximation of the Q-networks by smoothening out the learned state-action space. We experimentally show that using this Surprisingly Simple Self-Supervision technique in RL (S4RL), we significantly improve over the current state-of-the-art algorithms on offline robot learning environments such as MetaWorld [1] and RoboSuite [2,3], and benchmark datasets such as D4RL [4].",0
"The concept of offline reinforcement learning involves acquiring policies from extensive datasets without any physical interaction with the environment. This method has enabled the acquisition of valuable skills from data, which can be applied in real-world settings, where interactions could prove costly or dangerous, such as in factories or autonomous driving. However, the current algorithms tend to overfit to the training dataset and display poor out-of-distribution generalization when deployed in the environment. In this study, we examine the effectiveness of utilizing data augmentations on the state space by investigating seven augmentation schemes and their behavior with existing offline RL algorithms. We then combine the most effective data augmentation scheme with a state-of-the-art Q-learning technique, improving the Q-networks' function approximation by smoothing out the learned state-action space. Our experimental results demonstrate that this Surprisingly Simple Self-Supervision technique in RL (S4RL) significantly improves upon the current state-of-the-art algorithms in offline robot learning environments, such as MetaWorld [1] and RoboSuite [2,3], as well as benchmark datasets like D4RL [4].",1
"Temperature monitoring during the life time of heat source components in engineering systems becomes essential to guarantee the normal work and the working life of these components. However, prior methods, which mainly use the interpolate estimation to reconstruct the temperature field from limited monitoring points, require large amounts of temperature tensors for an accurate estimation. This may decrease the availability and reliability of the system and sharply increase the monitoring cost. To solve this problem, this work develops a novel physics-informed deep reversible regression models for temperature field reconstruction of heat-source systems (TFR-HSS), which can better reconstruct the temperature field with limited monitoring points unsupervisedly. First, we define the TFR-HSS task mathematically, and numerically model the task, and hence transform the task as an image-to-image regression problem. Then this work develops the deep reversible regression model which can better learn the physical information, especially over the boundary. Finally, considering the physical characteristics of heat conduction as well as the boundary conditions, this work proposes the physics-informed reconstruction loss including four training losses and jointly learns the deep surrogate model with these losses unsupervisedly. Experimental studies have conducted over typical two-dimensional heat-source systems to demonstrate the effectiveness of the proposed method.",0
"Monitoring the temperature of heat source components is crucial for ensuring their normal functioning and longevity in engineering systems. However, traditional methods that rely on interpolating temperature values from limited monitoring points require a large number of temperature tensors to achieve accurate estimations. This can lead to reduced system availability and reliability, as well as increased monitoring costs. To address this issue, this study introduces a novel approach for reconstructing temperature fields in heat-source systems (TFR-HSS) using physics-informed deep reversible regression models. The TFR-HSS task is defined mathematically and modeled numerically, transforming it into an image-to-image regression problem. The deep reversible regression model is developed to better learn the physical information, particularly at the boundary. Furthermore, a physics-informed reconstruction loss is proposed to jointly train the deep surrogate model with four training losses in an unsupervised manner, taking into account the physical characteristics of heat conduction and boundary conditions. Experimental studies conducted on typical two-dimensional heat-source systems demonstrate the effectiveness of the proposed method.",1
"Accurate modeling of boundary conditions is crucial in computational physics. The ever increasing use of neural networks as surrogates for physics-related problems calls for an improved understanding of boundary condition treatment, and its influence on the network accuracy. In this paper, several strategies to impose boundary conditions (namely padding, improved spatial context, and explicit encoding of physical boundaries) are investigated in the context of fully convolutional networks applied to recurrent tasks. These strategies are evaluated on two spatio-temporal evolving problems modeled by partial differential equations: the 2D propagation of acoustic waves (hyperbolic PDE) and the heat equation (parabolic PDE). Results reveal a high sensitivity of both accuracy and stability on the boundary implementation in such recurrent tasks. It is then demonstrated that the choice of the optimal padding strategy is directly linked to the data semantics. Furthermore, the inclusion of additional input spatial context or explicit physics-based rules allows a better handling of boundaries in particular for large number of recurrences, resulting in more robust and stable neural networks, while facilitating the design and versatility of such networks.",0
"In computational physics, accurate modeling of boundary conditions is essential. As neural networks are increasingly being used as substitutes for physics-related problems, it is important to have a better understanding of how to treat boundary conditions and their impact on network accuracy. This study explores three strategies for imposing boundary conditions (padding, improved spatial context, and explicit encoding of physical boundaries) using fully convolutional networks for recurrent tasks. The effectiveness of these strategies is evaluated on two spatio-temporal evolving problems modeled by partial differential equations: the 2D propagation of acoustic waves (hyperbolic PDE) and the heat equation (parabolic PDE). The results show that the accuracy and stability of these tasks are highly dependent on the implementation of boundaries. The optimal padding strategy is found to be directly related to the data semantics. Additionally, incorporating extra input spatial context or explicit physics-based rules improves boundary handling, especially for a large number of recurrences, resulting in more robust and stable neural networks that are also more versatile in design.",1
"Variational Monte Carlo (VMC) is an approach for computing ground-state wavefunctions that has recently become more powerful due to the introduction of neural network-based wavefunction parametrizations. However, efficiently training neural wavefunctions to converge to an energy minimum remains a difficult problem. In this work, we analyze optimization and sampling methods used in VMC and introduce alterations to improve their performance. First, based on theoretical convergence analysis in a noiseless setting, we motivate a new optimizer that we call the Rayleigh-Gauss-Newton method, which can improve upon gradient descent and natural gradient descent to achieve superlinear convergence with little added computational cost. Second, in order to realize this favorable comparison in the presence of stochastic noise, we analyze the effect of sampling error on VMC parameter updates and experimentally demonstrate that it can be reduced by the parallel tempering method. In particular, we demonstrate that RGN can be made robust to energy spikes that occur when new regions of configuration space become available to the sampler over the course of optimization. Finally, putting theory into practice, we apply our enhanced optimization and sampling methods to the transverse-field Ising and XXZ models on large lattices, yielding ground-state energy estimates with remarkably high accuracy after just 200-500 parameter updates.",0
"The use of neural network-based wavefunction parametrizations has strengthened the Variational Monte Carlo (VMC) approach for calculating ground-state wavefunctions. However, effectively training neural wavefunctions to attain an energy minimum remains a challenging task. This study evaluates the optimization and sampling methods utilized in VMC and presents modifications to improve their efficacy. Firstly, a new optimizer, named the Rayleigh-Gauss-Newton method, is motivated based on theoretical convergence analysis in a noise-free setting. This optimizer can achieve superlinear convergence with little additional computational cost, surpassing gradient descent and natural gradient descent. Secondly, the impact of sampling error on VMC parameter updates is assessed, and parallel tempering is shown to be effective in reducing it. RGN is demonstrated to be resilient to energy spikes that arise when new regions of configuration space become available to the sampler during optimization. Finally, the enhanced optimization and sampling methods are applied to the transverse-field Ising and XXZ models on large lattices, yielding highly accurate ground-state energy estimates after only 200-500 parameter updates.",1
"Parametric stochastic simulators are ubiquitous in science, often featuring high-dimensional input parameters and/or an intractable likelihood. Performing Bayesian parameter inference in this context can be challenging. We present a neural simulator-based inference algorithm which simultaneously offers simulation efficiency and fast empirical posterior testability, which is unique among modern algorithms. Our approach is simulation efficient by simultaneously estimating low-dimensional marginal posteriors instead of the joint posterior and by proposing simulations targeted to an observation of interest via a prior suitably truncated by an indicator function. Furthermore, by estimating a locally amortized posterior our algorithm enables efficient empirical tests of the robustness of the inference results. Such tests are important for sanity-checking inference in real-world applications, which do not feature a known ground truth. We perform experiments on a marginalized version of the simulation-based inference benchmark and two complex and narrow posteriors, highlighting the simulator efficiency of our algorithm as well as the quality of the estimated marginal posteriors. Implementation on GitHub.",0
"In science, Parametric stochastic simulators are used frequently, often with high-dimensional input parameters and/or an intractable likelihood, making Bayesian parameter inference difficult. However, our algorithm, which is based on a neural simulator, offers simulation efficiency and fast empirical posterior testability, which is a unique feature among modern algorithms. Our approach estimates low-dimensional marginal posteriors simultaneously and proposes simulations targeted to an observation of interest using a suitably truncated prior with an indicator function. Additionally, our algorithm enables efficient empirical tests of the robustness of the inference results by estimating a locally amortized posterior. These tests are crucial for checking the accuracy of inference in real-world applications without a known ground truth. We conducted experiments on a marginalized version of the simulation-based inference benchmark and two complex and narrow posteriors, demonstrating the simulator efficiency of our algorithm and the quality of the estimated marginal posteriors. The implementation is available on GitHub.",1
"We demonstrate how graph neural networks can be used to solve combinatorial optimization problems. Our approach is broadly applicable to canonical NP-hard problems in the form of quadratic unconstrained binary optimization problems, such as maximum cut, minimum vertex cover, maximum independent set, as well as Ising spin glasses and higher-order generalizations thereof in the form of polynomial unconstrained binary optimization problems. We apply a relaxation strategy to the problem Hamiltonian to generate a differentiable loss function with which we train the graph neural network and apply a simple projection to integer variables once the unsupervised training process has completed. We showcase our approach with numerical results for the canonical maximum cut and maximum independent set problems. We find that the graph neural network optimizer performs on par or outperforms existing solvers, with the ability to scale beyond the state of the art to problems with millions of variables.",0
"Our study illustrates the use of graph neural networks in solving combinatorial optimization problems. Our approach is versatile in tackling standard NP-hard problems like quadratic unconstrained binary optimization problems, including maximum cut, minimum vertex cover, and maximum independent set, as well as more complex problems like Ising spin glasses and their higher-order generalizations in the form of polynomial unconstrained binary optimization problems. We employ a relaxation technique to create a differentiable loss function from the Hamiltonian problem, which we use to train the graph neural network. Once the unsupervised training phase concludes, we apply a basic projection to integer variables. Our method showcases promising results with numerical data for maximum cut and maximum independent set problems. We observe that the graph neural network optimizer performs comparably or surpasses existing solvers with the added advantage of scaling beyond the current state of the art to solve problems containing millions of variables.",1
"In this work, we want to learn to model the dynamics of similar yet distinct groups of interacting objects. These groups follow some common physical laws that exhibit specificities that are captured through some vectorial description. We develop a model that allows us to do conditional generation from any such group given its vectorial description. Unlike previous work on learning dynamical systems that can only do trajectory completion and require a part of the trajectory dynamics to be provided as input in generation time, we do generation using only the conditioning vector with no access to generation time's trajectories. We evaluate our model in the setting of modeling human gait and, in particular pathological human gait.",0
"The aim of our research is to understand how to model the behavior of different groups of interacting objects that share some physical laws but also have distinct characteristics that can be described through vectors. Our proposed model can perform conditional generation based on the vectorial description of any of these groups. This is a departure from previous approaches that only allowed trajectory completion and required some input about the dynamics of the trajectory during generation. Our model can generate output using only the conditioning vector without any knowledge of trajectory dynamics during generation. We test our model by applying it to the study of human gait, specifically pathological human gait.",1
"Braille has empowered visually challenged community to read and write. But at the same time, it has created a gap due to widespread inability of non-Braille users to understand Braille scripts. This gap has fuelled researchers to propose Optical Braille Recognition techniques to convert Braille documents to natural language. The main motivation of this work is to cement the communication gap at academic institutions by translating personal documents of blind students. This has been accomplished by proposing an economical and effective technique which digitizes Braille documents using a smartphone camera. For any given Braille image, a dot detection mechanism based on Hough transform is proposed which is invariant to skewness, noise and other deterrents. The detected dots are then clustered into Braille cells using distance-based clustering algorithm. In succession, the standard physical parameters of each Braille cells are estimated for feature extraction and classification as natural language characters. The comprehensive evaluation of this technique on the proposed dataset of 54 Braille scripts has yielded into accuracy of 98.71%.",0
"The visually impaired community has benefited from Braille as it allows them to read and write. However, this has led to a communication gap as non-Braille users struggle to understand Braille scripts. To address this issue, researchers have proposed Optical Braille Recognition techniques to convert Braille documents into natural language. The aim is to close the communication gap in academic institutions by translating personal documents of blind students. An economical and effective technique has been proposed that uses a smartphone camera to digitize Braille documents. A dot detection mechanism based on Hough transform is used for any given Braille image to detect dots, which are then clustered into Braille cells using a distance-based clustering algorithm. The standard physical parameters of each Braille cell are estimated for feature extraction and classification as natural language characters. The technique was evaluated on a dataset of 54 Braille scripts and achieved an accuracy of 98.71%.",1
"We characterize and remedy a failure mode that may arise from multi-scale dynamics with scale imbalances during training of deep neural networks, such as Physics Informed Neural Networks (PINNs). PINNs are popular machine-learning templates that allow for seamless integration of physical equation models with data. Their training amounts to solving an optimization problem over a weighted sum of data-fidelity and equation-fidelity objectives. Conflicts between objectives can arise from scale imbalances, heteroscedasticity in the data, stiffness of the physical equation, or from catastrophic interference during sequential training. We explain the training pathology arising from this and propose a simple yet effective inverse-Dirichlet weighting strategy to alleviate the issue. We compare with Sobolev training of neural networks, providing the baseline of analytically $\boldsymbol{\epsilon}$-optimal training. We demonstrate the effectiveness of inverse-Dirichlet weighting in various applications, including a multi-scale model of active turbulence, where we show orders of magnitude improvement in accuracy and convergence over conventional PINN training. For inverse modeling using sequential training, we find that inverse-Dirichlet weighting protects a PINN against catastrophic forgetting.",0
"In this article, we address a potential problem that can occur during the training of deep neural networks, particularly Physics Informed Neural Networks (PINNs), due to multi-scale dynamics with imbalanced scales. PINNs are machine-learning models that combine physical equations with data to provide a seamless integration. The training process involves optimizing a weighted sum of data-fidelity and equation-fidelity objectives, which can sometimes conflict due to scale imbalances, heteroscedasticity in the data, stiffness of the physical equation, or catastrophic interference during sequential training. We explain the training issue that arises from this and suggest a solution through an inverse-Dirichlet weighting strategy. We compare this with Sobolev training of neural networks, which provides a baseline of analytically optimal training. We demonstrate the effectiveness of the inverse-Dirichlet weighting approach in several applications, including a multi-scale model of active turbulence, showing a significant improvement in accuracy and convergence compared to conventional PINN training. Furthermore, we discovered that inverse-Dirichlet weighting protects PINNs against catastrophic forgetting during inverse modeling using sequential training.",1
"Symmetric functions, which take as input an unordered, fixed-size set, are known to be universally representable by neural networks that enforce permutation invariance. These architectures only give guarantees for fixed input sizes, yet in many practical applications, including point clouds and particle physics, a relevant notion of generalization should include varying the input size. In this work we treat symmetric functions (of any size) as functions over probability measures, and study the learning and representation of neural networks defined on measures. By focusing on shallow architectures, we establish approximation and generalization bounds under different choices of regularization (such as RKHS and variation norms), that capture a hierarchy of functional spaces with increasing degree of non-linear learning. The resulting models can be learned efficiently and enjoy generalization guarantees that extend across input sizes, as we verify empirically.",0
"Neural networks that enforce permutation invariance are capable of representing symmetric functions, which take an unordered, fixed-size set as input. However, these architectures do not offer any assurances for variable input sizes, which is a crucial aspect in practical applications such as point clouds and particle physics. To address this issue, we consider symmetric functions of any size as functions over probability measures and examine the learning and representation of neural networks defined on measures. By focusing on shallow architectures, we establish approximation and generalization bounds using different regularization techniques (such as RKHS and variation norms) that encapsulate a hierarchy of functional spaces with increasing levels of non-linear learning. Our models can be trained efficiently and provide generalization guarantees that extend to varying input sizes, as demonstrated by our empirical results.",1
"We introduce two quantum algorithms for solving structured prediction problems. We first show that a stochastic gradient descent that uses the quantum minimum finding algorithm and takes its probabilistic failure into account solves the structured prediction problem with a runtime that scales with the square root of the size of the label space, and in $\widetilde O\left(1/\epsilon\right)$ with respect to the precision, $\epsilon$, of the solution. Motivated by robust inference techniques in machine learning, we then introduce another quantum algorithm that solves a smooth approximation of the structured prediction problem with a similar quantum speedup in the size of the label space and a similar scaling in the precision parameter. In doing so, we analyze a variant of stochastic gradient descent for convex optimization in the presence of an additive error in the calculation of the gradients, and show that its convergence rate does not deteriorate if the additive errors are of the order $O(\sqrt\epsilon)$. This algorithm uses quantum Gibbs sampling at temperature $\Omega (\epsilon)$ as a subroutine. Based on these theoretical observations, we propose a method for using quantum Gibbs samplers to combine feedforward neural networks with probabilistic graphical models for quantum machine learning. Our numerical results using Monte Carlo simulations on an image tagging task demonstrate the benefit of the approach.",0
"Two quantum algorithms are presented for solving structured prediction problems. The first algorithm uses a stochastic gradient descent that incorporates the quantum minimum finding algorithm and accounts for its probabilistic failure. This algorithm solves the structured prediction problem with a runtime that scales with the square root of the label space size and in $\widetilde O\left(1/\epsilon\right)$ with respect to the solution's precision. The second algorithm is inspired by robust inference methods in machine learning and solves a smooth approximation of the structured prediction problem with a similar quantum speedup in the label space size and precision parameter scaling. The convergence rate of the stochastic gradient descent for convex optimization is analyzed, and it is shown that the algorithm's convergence rate remains unaffected if the additive errors are of the order $O(\sqrt\epsilon)$. The algorithm uses quantum Gibbs sampling at temperature $\Omega (\epsilon)$ as a subroutine. Based on these theoretical observations, a method is proposed for combining feedforward neural networks with probabilistic graphical models for quantum machine learning using quantum Gibbs samplers. Monte Carlo simulations on an image tagging task demonstrate the effectiveness of the approach.",1
"We introduce a collection of datasets from fundamental physics research -- including particle physics, astroparticle physics, and hadron- and nuclear physics -- for supervised machine learning studies. These datasets, containing hadronic top quarks, cosmic-ray induced air showers, phase transitions in hadronic matter, and generator-level histories, are made public to simplify future work on cross-disciplinary machine learning and transfer learning in fundamental physics. Based on these data, we present a simple yet flexible graph-based neural network architecture that can easily be applied to a wide range of supervised learning tasks in these domains. We show that our approach reaches performance close to state-of-the-art dedicated methods on all datasets. To simplify adaptation for various problems, we provide easy-to-follow instructions on how graph-based representations of data structures, relevant for fundamental physics, can be constructed and provide code implementations for several of them. Implementations are also provided for our proposed method and all reference algorithms.",0
"A set of datasets from various fields of fundamental physics research, such as astroparticle physics, particle physics, and hadron- and nuclear physics, has been introduced for supervised machine learning studies. These datasets, which comprise cosmic-ray induced air showers, hadronic top quarks, phase transitions in hadronic matter, and generator-level histories, have been made public to simplify future work on cross-disciplinary machine learning and transfer learning in fundamental physics. We have presented a graph-based neural network architecture that is both simple and flexible, and can be applied to various supervised learning tasks in these domains using this data. Our approach achieves performance comparable to that of state-of-the-art dedicated methods on all datasets. To aid the adaptation of our method for different problems, we have provided clear instructions on constructing graph-based representations of data structures relevant to fundamental physics, as well as code implementations for several of them, including our proposed method and all reference algorithms.",1
"This article introduces a new physics-based method for rigid point set alignment called Fast Gravitational Approach (FGA). In FGA, the source and target point sets are interpreted as rigid particle swarms with masses interacting in a globally multiply-linked manner while moving in a simulated gravitational force field. The optimal alignment is obtained by explicit modeling of forces acting on the particles as well as their velocities and displacements with second-order ordinary differential equations of motion. Additional alignment cues (point-based or geometric features, and other boundary conditions) can be integrated into FGA through particle masses. We propose a smooth-particle mass function for point mass initialization, which improves robustness to noise and structural discontinuities. To avoid prohibitive quadratic complexity of all-to-all point interactions, we adapt a Barnes-Hut tree for accelerated force computation and achieve quasilinear computational complexity. We show that the new method class has characteristics not found in previous alignment methods such as efficient handling of partial overlaps, inhomogeneous point sampling densities, and coping with large point clouds with reduced runtime compared to the state of the art. Experiments show that our method performs on par with or outperforms all compared competing non-deep-learning-based and general-purpose techniques (which do not assume the availability of training data and a scene prior) in resolving transformations for LiDAR data and gains state-of-the-art accuracy and speed when coping with different types of data disturbances.",0
"The Fast Gravitational Approach (FGA) is a new technique for aligning rigid point sets based on physics. In this method, the sets are viewed as particle swarms with mass that interact with each other through gravitational forces. The alignment is achieved by modeling the forces acting on the particles using second-order differential equations to determine their velocities and displacements. Additional alignment cues can be incorporated by adjusting the particle masses, which are initialized using a smooth-particle mass function to enhance robustness. To speed up the computation, a Barnes-Hut tree is used to avoid quadratic complexity. FGA has several advantages over previous methods, including the ability to handle partial overlaps, varying point densities, and large point clouds with reduced runtime. It also outperforms competing non-deep-learning-based and general-purpose techniques in resolving transformations for LiDAR data and dealing with different types of data disturbances.",1
"Modern day engineering problems are ubiquitously characterized by sophisticated computer codes that map parameters or inputs to an underlying physical process. In other situations, experimental setups are used to model the physical process in a laboratory, ensuring high precision while being costly in materials and logistics. In both scenarios, only limited amount of data can be generated by querying the expensive information source at a finite number of inputs or designs. This problem is compounded further in the presence of a high-dimensional input space. State-of-the-art parameter space dimension reduction methods, such as active subspace, aim to identify a subspace of the original input space that is sufficient to explain the output response. These methods are restricted by their reliance on gradient evaluations or copious data, making them inadequate to expensive problems without direct access to gradients. The proposed methodology is gradient-free and fully Bayesian, as it quantifies uncertainty in both the low-dimensional subspace and the surrogate model parameters. This enables a full quantification of epistemic uncertainty and robustness to limited data availability. It is validated on multiple datasets from engineering and science and compared to two other state-of-the-art methods based on four aspects: a) recovery of the active subspace, b) deterministic prediction accuracy, c) probabilistic prediction accuracy, and d) training time. The comparison shows that the proposed method improves the active subspace recovery and predictive accuracy, in both the deterministic and probabilistic sense, when only few model observations are available for training, at the cost of increased training time.",0
"Sophisticated computer codes and experimental setups are commonly used in modern engineering to map parameters or inputs to physical processes. However, the limited amount of data that can be generated from querying these expensive sources at a finite number of inputs is compounded further in high-dimensional input spaces. State-of-the-art methods for reducing parameter space dimension, such as active subspace, rely on gradient evaluations or copious data, making them unsuitable for expensive problems without direct access to gradients. To address this issue, a fully Bayesian and gradient-free methodology is proposed that quantifies uncertainty in both the low-dimensional subspace and the surrogate model parameters. This enables a full quantification of epistemic uncertainty and robustness to limited data availability. The proposed method is validated on multiple datasets from engineering and science and is compared to two other state-of-the-art methods based on four aspects: recovery of the active subspace, deterministic and probabilistic prediction accuracy, and training time. Results show that the proposed method improves active subspace recovery and predictive accuracy, in both the deterministic and probabilistic sense, when only a few model observations are available for training, albeit with increased training time.",1
"The goal of convective storm nowcasting is local prediction of severe and imminent convective storms. Here, we consider the convective storm nowcasting problem from the perspective of machine learning. First, we use a pixel-wise sampling method to construct spatiotemporal features for nowcasting, and flexibly adjust the proportions of positive and negative samples in the training set to mitigate class-imbalance issues. Second, we employ a concise two-stream convolutional neural network to extract spatial and temporal cues for nowcasting. This simplifies the network structure, reduces the training time requirement, and improves classification accuracy. The two-stream network used both radar and satellite data. In the resulting two-stream, fused convolutional neural network, some of the parameters are entered into a single-stream convolutional neural network, but it can learn the features of many data. Further, considering the relevance of classification and regression tasks, we develop a multi-task learning strategy that predicts the labels used in such tasks. We integrate two-stream multi-task learning into a single convolutional neural network. Given the compact architecture, this network is more efficient and easier to optimize than existing recurrent neural networks.",0
"The objective of convective storm nowcasting is to predict severe and imminent convective storms in a specific area. In this study, we examine the convective storm nowcasting problem from a machine learning perspective. Firstly, we utilize a pixel-wise sampling technique to generate spatiotemporal features for nowcasting. Additionally, we adjust the positive and negative sample proportions in the training set to address class-imbalance issues. Secondly, we use a simple two-stream convolutional neural network to extract spatial and temporal cues for nowcasting. This approach simplifies the network structure, reduces training time, and enhances classification accuracy. The two-stream network incorporates both radar and satellite data. The resulting two-stream fused convolutional neural network combines some of the parameters into a single-stream convolutional neural network, allowing it to learn from a variety of data sources. Furthermore, we develop a multi-task learning strategy that predicts the labels used in classification and regression tasks. We integrate two-stream multi-task learning into a single convolutional neural network, which is more efficient and easier to optimize than existing recurrent neural networks due to its compact architecture.",1
"Invariants and conservation laws convey critical information about the underlying dynamics of a system, yet it is generally infeasible to find them from large-scale data without any prior knowledge or human insight. We propose ConservNet to achieve this goal, a neural network that spontaneously discovers a conserved quantity from grouped data where the members of each group share invariants, similar to a general experimental setting where trajectories from different trials are observed. As a neural network trained with a novel and intuitive loss function called noise-variance loss, ConservNet learns the hidden invariants in each group of multi-dimensional observables in a data-driven, end-to-end manner. Our model successfully discovers underlying invariants from the simulated systems having invariants as well as a real-world double pendulum trajectory. Since the model is robust to various noises and data conditions compared to baseline, our approach is directly applicable to experimental data for discovering hidden conservation laws and further, general relationships between variables.",0
"Extracting information about a system's dynamics from invariants and conservation laws is crucial, but it is challenging to do so without prior knowledge or human input when dealing with large-scale data. Our proposed solution is ConservNet, a neural network that autonomously identifies conserved quantities from grouped data in which each group shares invariants. This approach mimics the general experimental setting where trajectories from different trials are observed. ConservNet uses a novel and intuitive loss function called noise-variance loss to learn the hidden invariants in each group of multi-dimensional observables in an end-to-end, data-driven manner. Our model successfully identified underlying invariants in simulated systems and a real-world double pendulum trajectory, demonstrating its robustness to various noise and data conditions compared to baseline models. Therefore, our approach is directly applicable to experimental data for discovering hidden conservation laws and general relationships between variables.",1
"The quantification of wave loading on offshore structures and components is a crucial element in the assessment of their useful remaining life. In many applications the well-known Morison's equation is employed to estimate the forcing from waves with assumed particle velocities and accelerations. This paper develops a grey-box modelling approach to improve the predictions of the force on structural members. A grey-box model intends to exploit the enhanced predictive capabilities of data-based modelling whilst retaining physical insight into the behaviour of the system; in the context of the work carried out here, this can be considered as physics-informed machine learning. There are a number of possible approaches to establish a grey-box model. This paper demonstrates two means of combining physics (white box) and data-based (black box) components; one where the model is a simple summation of the two components, the second where the white-box prediction is fed into the black box as an additional input. Here Morison's equation is used as the physics-based component in combination with a data-based Gaussian process NARX - a dynamic variant of the more well-known Gaussian process regression. Two key challenges with employing the GP-NARX formulation that are addressed here are the selection of appropriate lag terms and the proper treatment of uncertainty propagation within the dynamic GP. The best performing grey-box model, the residual modelling GP-NARX, was able to achieve a 29.13\% and 5.48\% relative reduction in NMSE over Morison's Equation and a black-box GP-NARX respectively, alongside significant benefits in extrapolative capabilities of the model, in circumstances of low dataset coverage.",0
"The assessment of remaining lifespan for offshore structures and components relies heavily on quantifying wave loading. Morison's equation is often used to estimate wave forcing, assuming particle velocities and accelerations. This paper presents a grey-box modelling approach that combines data-based modelling with physical insight to improve force predictions. This approach is considered physics-informed machine learning. The paper outlines two methods for developing a grey-box model that combines white-box and black-box components. In this study, Morison's equation serves as the physics-based component, combined with a data-based Gaussian process NARX. The paper addresses challenges in selecting appropriate lag terms and propagating uncertainty within the dynamic GP. The best-performing model, residual modelling GP-NARX, achieved a 29.13\% and 5.48\% relative reduction in NMSE compared to Morison's equation and a black-box GP-NARX, respectively. It also demonstrated improved extrapolative capabilities in situations with limited dataset coverage.",1
"This paper proposes a new framework to detect, segment, and estimate the localization of the eyes from a periocular Near-Infra-Red iris image under alcohol consumption. The purpose of the system is to measure the fitness for duty. Fitness systems allow us to determine whether a person is physically or psychologically able to perform their tasks. Our framework is based on an object detector trained from scratch to detect both eyes from a single image. Then, two efficient networks were used for semantic segmentation; a Criss-Cross attention network and DenseNet10, with only 122,514 and 210,732 parameters, respectively. These networks can find the pupil, iris, and sclera. In the end, the binary output eye mask is used for pupil and iris diameter estimation with high precision. Five state-of-the-art algorithms were used for this purpose. A mixed proposal reached the best results. A second contribution is establishing an alcohol behavior curve to detect the alcohol presence utilizing a stream of images captured from an iris instance. Also, a manually labeled database with more than 20k images was created. Our best method obtains a mean Intersection-over-Union of 94.54% with DenseNet10 with only 210,732 parameters and an error of only 1-pixel on average.",0
"A new framework is proposed in this paper for detecting, segmenting, and estimating the location of eyes in a Near-Infra-Red iris image under the influence of alcohol. The system is intended to assess the fitness for duty, which helps to determine if an individual is physically or psychologically capable of performing their tasks. The framework employs an object detector to detect both eyes in a single image and two efficient networks for semantic segmentation, namely a Criss-Cross attention network and DenseNet10, with only 122,514 and 210,732 parameters, respectively. These networks can identify the pupil, iris, and sclera and produce a binary output eye mask that can accurately estimate the pupil and iris diameter. Five different algorithms were utilized, and a mixed proposal produced the best results. Additionally, an alcohol behavior curve was established to detect the presence of alcohol using a stream of iris images, and a database with over 20,000 manually labeled images was created. The DenseNet10 network with only 210,732 parameters achieved the best performance with a mean Intersection-over-Union of 94.54% and an average error of only 1-pixel.",1
"We investigate a correspondence between two formalisms for discrete probabilistic modeling: probabilistic graphical models (PGMs) and tensor networks (TNs), a powerful modeling framework for simulating complex quantum systems. The graphical calculus of PGMs and TNs exhibits many similarities, with discrete undirected graphical models (UGMs) being a special case of TNs. However, more general probabilistic TN models such as Born machines (BMs) employ complex-valued hidden states to produce novel forms of correlation among the probabilities. While representing a new modeling resource for capturing structure in discrete probability distributions, this behavior also renders the direct application of standard PGM tools impossible. We aim to bridge this gap by introducing a hybrid PGM-TN formalism that integrates quantum-like correlations into PGM models in a principled manner, using the physically-motivated concept of decoherence. We first prove that applying decoherence to the entirety of a BM model converts it into a discrete UGM, and conversely, that any subgraph of a discrete UGM can be represented as a decohered BM. This method allows a broad family of probabilistic TN models to be encoded as partially decohered BMs, a fact we leverage to combine the representational strengths of both model families. We experimentally verify the performance of such hybrid models in a sequential modeling task, and identify promising uses of our method within the context of existing applications of graphical models.",0
"Our research explores the relationship between two formalisms used for discrete probabilistic modeling: probabilistic graphical models (PGMs) and tensor networks (TNs), which are commonly used for simulating complex quantum systems. The graphical calculus of PGMs and TNs share many similarities, including the fact that discrete undirected graphical models (UGMs) are a special case of TNs. However, more complex probabilistic TN models, such as Born machines (BMs), use complex-valued hidden states to produce unique correlations among the probabilities. While this behavior provides a new tool for capturing structure in discrete probability distributions, it also makes it impossible to apply standard PGM tools. Our goal is to bridge this gap by introducing a hybrid PGM-TN formalism that integrates quantum-like correlations into PGM models in a principled way, using the concept of decoherence. We prove that applying decoherence to a BM model converts it into a discrete UGM, and that any subgraph of a discrete UGM can be represented as a decohered BM. This approach allows a wide range of probabilistic TN models to be encoded as partially decohered BMs, which enables us to combine the strengths of both model families. We test the performance of these hybrid models in a sequential modeling task and identify potential applications of our method in existing graphical models.",1
"Recently, graph neural networks (GNNs) have achieved remarkable performances for quantum mechanical problems. However, a graph convolution can only cover a localized region, and cannot capture long-range interactions of atoms. This behavior is contrary to theoretical interatomic potentials, which is a fundamental limitation of the spatial based GNNs. In this work, we propose a novel attention-based framework for molecular property prediction tasks. We represent a molecular conformation as a discrete atomic sequence combined by atom-atom distance attributes, named Geometry-aware Transformer (GeoT). In particular, we adopt a Transformer architecture, which has been widely used for sequential data. Our proposed model trains sequential representations of molecular graphs based on globally constructed attentions, maintaining all spatial arrangements of atom pairs. Our method does not suffer from cost intensive computations, such as angle calculations. The experimental results on several public benchmarks and visualization maps verified that keeping the long-range interatomic attributes can significantly improve the model predictability.",0
"Graph neural networks (GNNs) have recently demonstrated impressive performances in quantum mechanical problems. However, graph convolutions are limited to covering only localized regions and cannot capture long-range interactions between atoms, which is in contrast to theoretical interatomic potentials. This spatial limitation of GNNs is a fundamental constraint. To address this, we propose a new attention-based framework called Geometry-aware Transformer (GeoT) for molecular property prediction tasks. We represent molecular structures as a discrete atomic sequence with atom-atom distance attributes and apply the Transformer architecture, which is commonly used for sequential data. Our proposed model trains sequential representations of molecular graphs using globally constructed attentions, thus preserving all spatial arrangements of atom pairs. Our approach circumvents computationally expensive calculations, such as angle calculations, and experimental results on several public benchmarks and visualization maps confirm that maintaining long-range interatomic attributes can significantly improve model predictability.",1
"Physics-informed dynamical system models form critical components of digital twins of the built environment. These digital twins enable the design of energy-efficient infrastructure, but must be properly calibrated to accurately reflect system behavior for downstream prediction and analysis. Dynamical system models of modern buildings are typically described by a large number of parameters and incur significant computational expenditure during simulations. To handle large-scale calibration of digital twins without exorbitant simulations, we propose ANP-BBO: a scalable and parallelizable batch-wise Bayesian optimization (BBO) methodology that leverages attentive neural processes (ANPs).",0
"Dynamical system models that are informed by physics are essential to the creation of digital twins for the built environment. These twins allow for the development of energy-efficient infrastructure, but require accurate calibration to ensure reliable prediction and analysis. Modern building dynamical system models are complex, with numerous parameters, and simulations can be computationally intensive. To address the challenge of large-scale calibration for digital twins without requiring excessive simulations, we suggest using ANP-BBO. This scalable and parallelizable batch-wise Bayesian optimization (BBO) approach employs attentive neural processes (ANPs).",1
"We explore whether Neural Networks (NNs) can {\it discover} the presence of symmetries as they learn to perform a task. For this, we train hundreds of NNs on a {\it decoy task} based on well-controlled Physics templates, where no information on symmetry is provided. We use the output from the last hidden layer of all these NNs, projected to fewer dimensions, as the input for a symmetry classification task, and show that information on symmetry had indeed been identified by the original NN without guidance. As an interdisciplinary application of this procedure, we identify the presence and level of symmetry in artistic paintings from different styles such as those of Picasso, Pollock and Van Gogh.",0
"Our study investigates the potential of Neural Networks (NNs) to detect symmetries while learning a task. To accomplish this, we trained numerous NNs on a controlled Physics task without any knowledge of symmetry. We utilized the output of the final hidden layer of these NNs, condensed to fewer dimensions, as input for a symmetry classification task. Our findings demonstrate that the original NNs were able to detect symmetry without any guidance. To illustrate the interdisciplinary application of our approach, we applied it to paintings by various artists, including Picasso, Pollock, and Van Gogh, to determine the presence and degree of symmetry.",1
"Deep learning based image recognition systems have been widely deployed on mobile devices in today's world. In recent studies, however, deep learning models are shown vulnerable to adversarial examples. One variant of adversarial examples, called adversarial patch, draws researchers' attention due to its strong attack abilities. Though adversarial patches achieve high attack success rates, they are easily being detected because of the visual inconsistency between the patches and the original images. Besides, it usually requires a large amount of data for adversarial patch generation in the literature, which is computationally expensive and time-consuming. To tackle these challenges, we propose an approach to generate inconspicuous adversarial patches with one single image. In our approach, we first decide the patch locations basing on the perceptual sensitivity of victim models, then produce adversarial patches in a coarse-to-fine way by utilizing multiple-scale generators and discriminators. The patches are encouraged to be consistent with the background images with adversarial training while preserving strong attack abilities. Our approach shows the strong attack abilities in white-box settings and the excellent transferability in black-box settings through extensive experiments on various models with different architectures and training methods. Compared to other adversarial patches, our adversarial patches hold the most negligible risks to be detected and can evade human observations, which is supported by the illustrations of saliency maps and results of user evaluations. Lastly, we show that our adversarial patches can be applied in the physical world.",0
"Currently, deep learning-based image recognition systems are widely implemented on mobile devices. However, recent studies have revealed that these models are susceptible to adversarial examples, including a variant called adversarial patch, which has garnered attention due to its potent attack capabilities. Despite its high attack success rates, adversarial patches are easily detected due to their visual inconsistency with the original images. Additionally, generating adversarial patches typically requires a significant amount of data, which is both computationally costly and time-consuming. To overcome these challenges, we propose a method for generating inconspicuous adversarial patches using only a single image. Our approach involves identifying patch locations based on the perceptual sensitivity of victim models and creating patches in a coarse-to-fine manner using multiple-scale generators and discriminators. The patches are trained adversarially to be consistent with the background image while retaining strong attack abilities. Our approach demonstrates robust attack capabilities in both white-box and black-box settings, as evidenced by experiments using various models and training methods. Compared to other types of adversarial patches, our patches have the lowest risk of detection and can evade human observation, as supported by saliency maps and user evaluations. Lastly, we demonstrate that our adversarial patches can be applied in the physical world.",1
"Contrary to the vast literature in modeling, perceiving, and understanding agent-object (e.g., human-object, hand-object, robot-object) interaction in computer vision and robotics, very few past works have studied the task of object-object interaction, which also plays an important role in robotic manipulation and planning tasks. There is a rich space of object-object interaction scenarios in our daily life, such as placing an object on a messy tabletop, fitting an object inside a drawer, pushing an object using a tool, etc. In this paper, we propose a unified affordance learning framework to learn object-object interaction for various tasks. By constructing four object-object interaction task environments using physical simulation (SAPIEN) and thousands of ShapeNet models with rich geometric diversity, we are able to conduct large-scale object-object affordance learning without the need for human annotations or demonstrations. At the core of technical contribution, we propose an object-kernel point convolution network to reason about detailed interaction between two objects. Experiments on large-scale synthetic data and real-world data prove the effectiveness of the proposed approach. Please refer to the project webpage for code, data, video, and more materials: https://cs.stanford.edu/~kaichun/o2oafford",0
"While there is an abundance of literature on modeling, perceiving, and comprehending agent-object interaction in computer vision and robotics, little attention has been given to the study of object-object interaction. However, this type of interaction is crucial in various robotic manipulation and planning tasks and is prevalent in our daily lives, such as placing objects on a cluttered table or pushing objects with tools. In this study, we propose a unified affordance learning framework to facilitate the learning of object-object interaction for various tasks. By employing physical simulation (SAPIEN) and utilizing thousands of ShapeNet models, we can conduct large-scale object-object affordance learning without human annotations or demonstrations. Our technical innovation is the object-kernel point convolution network, which is central to reasoning about the intricate interaction between two objects. Our experiments on both large-scale synthetic data and real-world data demonstrate the effectiveness of our approach. For further information, including code, data, video, and additional materials, please visit our project webpage at https://cs.stanford.edu/~kaichun/o2oafford.",1
"The important recent book by G. Schurz appreciates that the no-free-lunch theorems (NFL) have major implications for the problem of (meta) induction. Here I review the NFL theorems, emphasizing that they do not only concern the case where there is a uniform prior -- they prove that there are ""as many priors"" (loosely speaking) for which any induction algorithm $A$ out-generalizes some induction algorithm $B$ as vice-versa. Importantly though, in addition to the NFL theorems, there are many \textit{free lunch} theorems. In particular, the NFL theorems can only be used to compare the \textit{marginal} expected performance of an induction algorithm $A$ with the marginal expected performance of an induction algorithm $B$. There is a rich set of free lunches which instead concern the statistical correlations among the generalization errors of induction algorithms. As I describe, the meta-induction algorithms that Schurz advocate as a ""solution to Hume's problem"" are just an example of such a free lunch based on correlations among the generalization errors of induction algorithms. I end by pointing out that the prior that Schurz advocates, which is uniform over bit frequencies rather than bit patterns, is contradicted by thousands of experiments in statistical physics and by the great success of the maximum entropy procedure in inductive inference.",0
"In G. Schurz's recent book, the significance of the no-free-lunch theorems (NFL) in relation to (meta) induction is acknowledged. The NFL theorems are reviewed in this article, with an emphasis on the fact that they are not exclusive to situations with a uniform prior. These theorems prove that there are equal numbers of priors for which any induction algorithm $A$ outperforms some induction algorithm $B$ as there are for vice-versa. However, there exist free lunch theorems in addition to the NFL theorems. These free lunches are based on statistical correlations among the generalization errors of induction algorithms, and they cannot be used to compare the marginal expected performance of induction algorithms $A$ and $B$. The meta-induction algorithms that Schurz proposes as a solution to Hume's problem are an example of a free lunch that is based on correlations among the generalization errors of induction algorithms. It is noteworthy that the prior Schurz advocates, which is uniform over bit frequencies, contradicts thousands of experiments in statistical physics and the success of the maximum entropy procedure in inductive inference.",1
"As the real-time digital counterpart of a physical system or process, digital twins are utilized for system simulation and optimization. Neural networks are one way to build a digital twins model by using data especially when a physics-based model is not accurate or even not available. However, for a newly designed system, it takes time to accumulate enough data for neural network moded and only an approximate physics-based model is available. To take advantage of both models, this paper proposed a model that combines the physics-based model and the neural network model to improve the prediction accuracy for the whole life cycle of a system. The proposed model was able to automatically combine the models and boost their prediction performance. Experiments showed that the proposed hybrid model outperformed both the physics-based model and the neural network model.",0
"Digital twins are utilized to simulate and optimize physical systems or processes in real-time. When a physics-based model is inaccurate or not available, neural networks can be used to construct a digital twin model by utilizing data. However, for a newly designed system, it may take some time to accumulate sufficient data for a neural network model, and only an approximate physics-based model may be available. To enhance the prediction accuracy of the entire system life cycle, this study proposes a model that blends the physics-based and neural network models. The proposed model can automatically combine the models, resulting in an improved prediction performance. Experimental findings indicate that the hybrid model outperforms both the physics-based and neural network models.",1
"We introduce Habitat 2.0 (H2.0), a simulation platform for training virtual robots in interactive 3D environments and complex physics-enabled scenarios. We make comprehensive contributions to all levels of the embodied AI stack - data, simulation, and benchmark tasks. Specifically, we present: (i) ReplicaCAD: an artist-authored, annotated, reconfigurable 3D dataset of apartments (matching real spaces) with articulated objects (e.g. cabinets and drawers that can open/close); (ii) H2.0: a high-performance physics-enabled 3D simulator with speeds exceeding 25,000 simulation steps per second (850x real-time) on an 8-GPU node, representing 100x speed-ups over prior work; and, (iii) Home Assistant Benchmark (HAB): a suite of common tasks for assistive robots (tidy the house, prepare groceries, set the table) that test a range of mobile manipulation capabilities. These large-scale engineering contributions allow us to systematically compare deep reinforcement learning (RL) at scale and classical sense-plan-act (SPA) pipelines in long-horizon structured tasks, with an emphasis on generalization to new objects, receptacles, and layouts. We find that (1) flat RL policies struggle on HAB compared to hierarchical ones; (2) a hierarchy with independent skills suffers from 'hand-off problems', and (3) SPA pipelines are more brittle than RL policies.",0
"Habitat 2.0 (H2.0) is a platform that enables virtual robots to be trained in interactive 3D environments and complex physics-enabled scenarios. Our contributions span all levels of the embodied AI stack and include data, simulation, and benchmark tasks. Specifically, we present three components: ReplicaCAD, a dataset of artist-authored, annotated, reconfigurable 3D apartments with articulated objects; H2.0, a high-performance physics-enabled 3D simulator that operates at speeds exceeding 25,000 simulation steps per second; and Home Assistant Benchmark (HAB), a suite of common tasks for assistive robots that test a range of mobile manipulation capabilities. These engineering contributions allow us to compare deep reinforcement learning (RL) at scale and classical sense-plan-act (SPA) pipelines in long-horizon structured tasks, with a focus on generalization to new objects, receptacles, and layouts. Our findings indicate that flat RL policies struggle on HAB compared to hierarchical ones, a hierarchy with independent skills suffers from 'hand-off problems', and SPA pipelines are more brittle than RL policies.",1
"We propose a method of Category-level 6D Object Pose and Size Estimation (COPSE) from a single depth image, without external pose-annotated real-world training data. While previous works exploit visual cues in RGB(D) images, our method makes inferences based on the rich geometric information of the object in the depth channel alone. Essentially, our framework explores such geometric information by learning the unified 3D Orientation-Consistent Representations (3D-OCR) module, and further enforced by the property of Geometry-constrained Reflection Symmetry (GeoReS) module. The magnitude information of object size and the center point is finally estimated by Mirror-Paired Dimensional Estimation (MPDE) module. Extensive experiments on the category-level NOCS benchmark demonstrate that our framework competes with state-of-the-art approaches that require labeled real-world images. We also deploy our approach to a physical Baxter robot to perform manipulation tasks on unseen but category-known instances, and the results further validate the efficacy of our proposed model. Our videos are available in the supplementary material.",0
"Our proposed method, called Category-level 6D Object Pose and Size Estimation (COPSE), can estimate object pose and size from a single depth image without the need for external pose-annotated real-world training data. Unlike previous works that rely on visual cues in RGB(D) images, our approach leverages the rich geometric information provided by the depth channel alone. The COPSE framework accomplishes this by utilizing a unified 3D Orientation-Consistent Representations (3D-OCR) module, which is further enforced by the Geometry-constrained Reflection Symmetry (GeoReS) module to explore the geometric information. The Mirror-Paired Dimensional Estimation (MPDE) module is then used to estimate the magnitude information of object size and center point. Our experiments on the category-level NOCS benchmark demonstrate that our approach competes with state-of-the-art methods that require labeled real-world images. Additionally, we tested our approach on a physical Baxter robot to perform manipulation tasks on unseen but category-known instances, further validating the efficacy of our model. Supplementary videos are available.",1
"Modern magnetic sensor arrays conventionally utilize state of the art low power magnetometers such as parallel and orthogonal fluxgates. Low power fluxgates tend to have large Barkhausen jumps that appear as a dc jump in the fluxgate output. This phenomenon deteriorates the signal fidelity and effectively increases the internal sensor noise. Even if sensors that are more prone to dc jumps can be screened during production, the conventional noise measurement does not always catch the dc jump because of its sparsity. Moreover, dc jumps persist in almost all the sensor cores although at a slower but still intolerable rate. Even if dc jumps can be easily detected in a shielded environment, when deployed in presence of natural noise and clutter, it can be hard to positively detect them. This work fills this gap and presents algorithms that distinguish dc jumps embedded in natural magnetic field data. To improve robustness to noise, we developed two machine learning algorithms that employ temporal and statistical physical-based features of a pre-acquired and well-known experimental data set. The first algorithm employs a support vector machine classifier, while the second is based on a neural network architecture. We compare these new approaches to a more classical kernel-based method. To that purpose, the receiver operating characteristic curve is generated, which allows diagnosis ability of the different classifiers by comparing their performances across various operation points. The accuracy of the machine learning-based algorithms over the classic method is highly emphasized. In addition, high generalization and robustness of the neural network can be concluded, based on the rapid convergence of the corresponding receiver operating characteristic curves.",0
"Conventional modern magnetic sensor arrays use advanced low power magnetometers such as parallel and orthogonal fluxgates. However, low power fluxgates often have large Barkhausen jumps that result in a dc jump in the fluxgate output, causing signal distortion and increased internal sensor noise. Screening sensors susceptible to dc jumps during production may not always catch the sparse phenomenon, and dc jumps persist in most sensor cores. Detecting dc jumps in the presence of natural noise and clutter can also be challenging. This research introduces algorithms that can distinguish dc jumps in natural magnetic field data. To increase noise robustness, two machine learning algorithms were developed that utilize physical-based features of pre-acquired experimental data. The first algorithm employs a support vector machine classifier, while the second uses a neural network architecture. These approaches were compared to a traditional kernel-based method through the generation of receiver operating characteristic curves. The machine learning-based algorithms outperformed the classic method, with the neural network demonstrating high generalization and robustness based on the rapid convergence of the receiver operating characteristic curves.",1
"Partial differential equations (PDEs) play a fundamental role in modeling and simulating problems across a wide range of disciplines. Recent advances in deep learning have shown the great potential of physics-informed neural networks (PINNs) to solve PDEs as a basis for data-driven modeling and inverse analysis. However, the majority of existing PINN methods, based on fully-connected NNs, pose intrinsic limitations to low-dimensional spatiotemporal parameterizations. Moreover, since the initial/boundary conditions (I/BCs) are softly imposed via penalty, the solution quality heavily relies on hyperparameter tuning. To this end, we propose the novel physics-informed convolutional-recurrent learning architectures (PhyCRNet and PhyCRNet-s) for solving PDEs without any labeled data. Specifically, an encoder-decoder convolutional long short-term memory network is proposed for low-dimensional spatial feature extraction and temporal evolution learning. The loss function is defined as the aggregated discretized PDE residuals, while the I/BCs are hard-encoded in the network to ensure forcible satisfaction (e.g., periodic boundary padding). The networks are further enhanced by autoregressive and residual connections that explicitly simulate time marching. The performance of our proposed methods has been assessed by solving three nonlinear PDEs (e.g., 2D Burgers' equations, the $\lambda$-$\omega$ and FitzHugh Nagumo reaction-diffusion equations), and compared against the start-of-the-art baseline algorithms. The numerical results demonstrate the superiority of our proposed methodology in the context of solution accuracy, extrapolability and generalizability.",0
"Modeling and simulating problems across various disciplines rely on Partial differential equations (PDEs). Advances in deep learning have made Physics-informed neural networks (PINNs) a potential solution to solve PDEs for data-driven modeling and inverse analysis. However, current PINN methods based on fully-connected NNs have limitations in low-dimensional spatiotemporal parameterizations. Additionally, the quality of solution depends on hyperparameter tuning as initial/boundary conditions (I/BCs) are softly imposed through penalty. To address this, we propose novel physics-informed convolutional-recurrent learning architectures (PhyCRNet and PhyCRNet-s) to solve PDEs without labeled data. Our approach uses an encoder-decoder convolutional long short-term memory network for low-dimensional spatial feature extraction and temporal evolution learning. The loss function is defined as the aggregated discretized PDE residuals, while I/BCs are hard-encoded in the network to ensure forcible satisfaction. Autoregressive and residual connections further enhance the networks by explicitly simulating time-marching. We evaluated our methodology on three nonlinear PDEs and compared it to state-of-the-art algorithms. Our numerical results demonstrated the superiority of our approach in terms of solution accuracy, extrapolability, and generalizability.",1
"This work considers predicting the relational structure of a hypergraph for a given set of vertices, as common for applications in particle physics, biological systems and other complex combinatorial problems. A problem arises from the number of possible multi-way relationships, or hyperedges, scaling in $\mathcal{O}(2^n)$ for a set of $n$ elements. Simply storing an indicator tensor for all relationships is already intractable for moderately sized $n$, prompting previous approaches to restrict the number of vertices a hyperedge connects. Instead, we propose a recurrent hypergraph neural network that predicts the incidence matrix by iteratively refining an initial guess of the solution. We leverage the property that most hypergraphs of interest are sparsely connected and reduce the memory requirement to $\mathcal{O}(nk)$, where $k$ is the maximum number of positive edges, i.e., edges that actually exist. In order to counteract the linearly growing memory cost from training a lengthening sequence of refinement steps, we further propose an algorithm that applies backpropagation through time on randomly sampled subsequences. We empirically show that our method can match an increase in the intrinsic complexity without a performance decrease and demonstrate superior performance compared to state-of-the-art models.",0
"This research focuses on predicting the relational structure of a hypergraph based on a given set of vertices, which is common in various fields such as particle physics and biological systems. However, a problem arises due to the large number of possible hyperedges, which scales in $\mathcal{O}(2^n)$ for a set of $n$ elements. Storing an indicator tensor for all relationships is not practical even for moderately sized $n$, leading to previous approaches that limit the number of vertices a hyperedge connects. Instead, we propose a recurrent hypergraph neural network that predicts the incidence matrix by refining an initial guess of the solution iteratively. Our method takes advantage of the sparsely connected nature of most hypergraphs of interest, reducing the memory requirement to $\mathcal{O}(nk)$, where $k$ is the maximum number of positive edges. To address the increasing memory cost during training, we also propose an algorithm that uses backpropagation through time on randomly sampled subsequences. We demonstrate through experiments that our method can handle increased complexity without sacrificing performance and outperforms state-of-the-art models.",1
"Gaussian process regression is a widely-applied method for function approximation and uncertainty quantification. The technique has gained popularity recently in the machine learning community due to its robustness and interpretability. The mathematical methods we discuss in this paper are an extension of the Gaussian-process framework. We are proposing advanced kernel designs that only allow for functions with certain desirable characteristics to be elements of the reproducing kernel Hilbert space (RKHS) that underlies all kernel methods and serves as the sample space for Gaussian process regression. These desirable characteristics reflect the underlying physics; two obvious examples are symmetry and periodicity constraints. In addition, non-stationary kernel designs can be defined in the same framework to yield flexible multi-task Gaussian processes. We will show the impact of advanced kernel designs on Gaussian processes using several synthetic and two scientific data sets. The results show that including domain knowledge, communicated through advanced kernel designs, has a significant impact on the accuracy and relevance of the function approximation.",0
"The Gaussian process regression technique is widely used for approximating functions and quantifying uncertainty. It has become popular in the machine learning community due to its interpretability and robustness. In this paper, we present mathematical methods that extend the Gaussian-process framework and propose advanced kernel designs. These designs only allow functions with specific desirable characteristics to be part of the reproducing kernel Hilbert space (RKHS), which serves as the sample space for Gaussian process regression. These desirable characteristics reflect the underlying physics, such as symmetry and periodicity constraints. We also define non-stationary kernel designs in the same framework to obtain flexible multi-task Gaussian processes. By applying advanced kernel designs to synthetic and scientific data sets, we demonstrate the impact on the accuracy and relevance of function approximation. Our results show that incorporating domain knowledge through advanced kernel designs significantly improves the function approximation.",1
"This technical report presents panda-gym, a set Reinforcement Learning (RL) environments for the Franka Emika Panda robot integrated with OpenAI Gym. Five tasks are included: reach, push, slide, pick & place and stack. They all follow a Multi-Goal RL framework, allowing to use goal-oriented RL algorithms. To foster open-research, we chose to use the open-source physics engine PyBullet. The implementation chosen for this package allows to define very easily new tasks or new robots. This report also presents a baseline of results obtained with state-of-the-art model-free off-policy algorithms. panda-gym is open-source at https://github.com/qgallouedec/panda-gym.",0
"In this technical report, panda-gym is introduced as a collection of Reinforcement Learning (RL) environments for the Franka Emika Panda robot, which has been integrated with OpenAI Gym. The package includes five tasks: reach, push, slide, pick & place and stack, all of which follow a Multi-Goal RL framework, making it possible to utilize goal-oriented RL algorithms. PyBullet, an open-source physics engine, was selected to promote open-research. The implementation of this package allows for easy task or robot definition. Additionally, the report provides a baseline of results achieved using state-of-the-art model-free off-policy algorithms. panda-gym is available as an open-source project on https://github.com/qgallouedec/panda-gym.",1
"Solving the ordinary differential equations that govern the power system is an indispensable part in transient stability analysis. However, the traditionally applied methods either carry a significant computational burden, require model simplifications, or use overly conservative surrogate models. Neural networks can circumvent these limitations but are faced with high demands on the used datasets. Furthermore, they are agnostic to the underlying governing equations. Physics-informed neural network tackle this problem and we explore their advantages and challenges in this paper. We illustrate the findings on the Kundur two-area system and highlight possible pathways forward in developing this method further.",0
"Transient stability analysis requires solving the ordinary differential equations that regulate the power system. The methods traditionally used for this purpose entail a substantial computational load, necessitate simplification of the model, or adopt overly cautious surrogate models. Although neural networks offer a way to bypass these limitations, they require extensive datasets and disregard the underlying governing equations. To address this issue, physics-informed neural networks have been developed, and we investigate their benefits and difficulties in this paper. We present our discoveries using the Kundur two-area system as an example and suggest potential directions for advancing this method.",1
"Human mobility drives major societal phenomena including epidemics, economies, and innovation. Historically, mobility was constrained by geographic distance, however, in the globalizing world, language, culture, and history are increasingly important. We propose using the neural embedding model word2vec for studying mobility and capturing its complexity. Word2ec is shown to be mathematically equivalent to the gravity model of mobility, and using three human trajectory datasets, we demonstrate that it encodes nuanced relationships between locations into a vector-space, providing a measure of effective distance that outperforms baselines. Focusing on the case of scientific mobility, we show that embeddings uncover cultural, linguistic, and hierarchical relationships at multiple levels of granularity. Connecting neural embeddings to the gravity model opens up new avenues for the study of mobility.",0
"Major societal phenomena such as epidemics, economies, and innovation are driven by human mobility. In the past, mobility was limited by distance, but in today's globalized world, factors such as language, culture, and history play an increasingly important role. To study and capture the complexity of mobility, we propose utilizing the neural embedding model word2vec. This model is equivalent to the gravity model of mobility, and by analyzing three human trajectory datasets, we demonstrate its ability to encode nuanced relationships between locations into a vector-space. This provides a more effective measure of distance compared to other methods. We focus on scientific mobility as a case study and show that embeddings can uncover cultural, linguistic, and hierarchical relationships across different levels of granularity. By connecting neural embeddings to the gravity model, we open up new possibilities for studying mobility.",1
"The fundamental task of classification given a limited number of training data samples is considered for physical systems with known parametric statistical models. The standalone learning-based and statistical model-based classifiers face major challenges towards the fulfillment of the classification task using a small training set. Specifically, classifiers that solely rely on the physics-based statistical models usually suffer from their inability to properly tune the underlying unobservable parameters, which leads to a mismatched representation of the system's behaviors. Learning-based classifiers, on the other hand, typically rely on a large number of training data from the underlying physical process, which might not be feasible in most practical scenarios. In this paper, a hybrid classification method -- termed HyPhyLearn -- is proposed that exploits both the physics-based statistical models and the learning-based classifiers. The proposed solution is based on the conjecture that HyPhyLearn would alleviate the challenges associated with the individual approaches of learning-based and statistical model-based classifiers by fusing their respective strengths. The proposed hybrid approach first estimates the unobservable model parameters using the available (suboptimal) statistical estimation procedures, and subsequently use the physics-based statistical models to generate synthetic data. Then, the training data samples are incorporated with the synthetic data in a learning-based classifier that is based on domain-adversarial training of neural networks. Specifically, in order to address the mismatch problem, the classifier learns a mapping from the training data and the synthetic data to a common feature space. Simultaneously, the classifier is trained to find discriminative features within this space in order to fulfill the classification task.",0
"This article explores the challenge of classification when dealing with physical systems that have known parametric statistical models and a limited number of training data samples. Both standalone learning-based and statistical model-based classifiers face significant obstacles in achieving accurate classification with a small training set. Physics-based statistical models alone often struggle to properly tune unobservable parameters, leading to a mismatch in the system's behaviors. Learning-based classifiers typically require a large amount of training data, which may not be feasible in practical scenarios. To address these challenges, the authors propose a hybrid classification method called HyPhyLearn that combines both approaches. HyPhyLearn first estimates unobservable model parameters using suboptimal statistical estimation procedures and then generates synthetic data using physics-based statistical models. These synthetic data are then incorporated with the training data in a learning-based classifier that employs domain-adversarial training of neural networks. The classifier learns to map both types of data to a common feature space and find discriminative features within that space to accurately classify the system.",1
"Breakthroughs in machine learning in the last decade have led to `digital intelligence', i.e. machine learning models capable of learning from vast amounts of labeled data to perform several digital tasks such as speech recognition, face recognition, machine translation and so on. The goal of this thesis is to make progress towards designing algorithms capable of `physical intelligence', i.e. building intelligent autonomous navigation agents capable of learning to perform complex navigation tasks in the physical world involving visual perception, natural language understanding, reasoning, planning, and sequential decision making. Despite several advances in classical navigation methods in the last few decades, current navigation agents struggle at long-term semantic navigation tasks. In the first part of the thesis, we discuss our work on short-term navigation using end-to-end reinforcement learning to tackle challenges such as obstacle avoidance, semantic perception, language grounding, and reasoning. In the second part, we present a new class of navigation methods based on modular learning and structured explicit map representations, which leverage the strengths of both classical and end-to-end learning methods, to tackle long-term navigation tasks. We show that these methods are able to effectively tackle challenges such as localization, mapping, long-term planning, exploration and learning semantic priors. These modular learning methods are capable of long-term spatial and semantic understanding and achieve state-of-the-art results on various navigation tasks.",0
"Advancements in machine learning have resulted in the development of ""digital intelligence"", wherein machine learning models can learn from vast amounts of labeled data to perform various digital tasks such as speech recognition, face recognition, and machine translation. This thesis aims to make progress towards creating algorithms that can achieve ""physical intelligence"" by designing intelligent autonomous navigation agents that can learn to perform complex navigation tasks in the physical world. These tasks involve visual perception, natural language understanding, reasoning, planning, and sequential decision making. Despite the progress made in classical navigation methods, current navigation agents face difficulties in long-term semantic navigation tasks. The first part of the thesis outlines our work on short-term navigation using end-to-end reinforcement learning to overcome challenges like obstacle avoidance, semantic perception, language grounding, and reasoning. In the second part, we propose a new class of navigation methods that combine modular learning and structured explicit map representations to leverage the strengths of both classical and end-to-end learning methods. These methods can tackle long-term navigation tasks such as localization, mapping, long-term planning, exploration, and learning semantic priors. These modular learning methods achieve state-of-the-art results on various navigation tasks and are capable of long-term spatial and semantic understanding.",1
"Reconstructing the shape and appearance of real-world objects using measured 2D images has been a long-standing problem in computer vision. In this paper, we introduce a new analysis-by-synthesis technique capable of producing high-quality reconstructions through robust coarse-to-fine optimization and physics-based differentiable rendering.   Unlike most previous methods that handle geometry and reflectance largely separately, our method unifies the optimization of both by leveraging image gradients with respect to both object reflectance and geometry. To obtain physically accurate gradient estimates, we develop a new GPU-based Monte Carlo differentiable renderer leveraging recent advances in differentiable rendering theory to offer unbiased gradients while enjoying better performance than existing tools like PyTorch3D and redner. To further improve robustness, we utilize several shape and material priors as well as a coarse-to-fine optimization strategy to reconstruct geometry. We demonstrate that our technique can produce reconstructions with higher quality than previous methods such as COLMAP and Kinect Fusion.",0
"For a long time, computer vision has faced the challenge of reconstructing the shape and appearance of objects in the real world using 2D images. This paper presents a novel analysis-by-synthesis technique that utilizes robust coarse-to-fine optimization and physics-based differentiable rendering to generate high-quality reconstructions. Unlike previous methods that handle geometry and reflectance separately, our approach integrates the optimization of both by utilizing image gradients with respect to object reflectance and geometry. Our new GPU-based Monte Carlo differentiable renderer yields physically accurate gradient estimates, providing unbiased gradients with better performance than existing tools such as PyTorch3D and redner. To enhance robustness, we also incorporate various shape and material priors and a coarse-to-fine optimization strategy for geometry reconstruction. Our technique surpasses previous methods, such as COLMAP and Kinect Fusion, in generating high-quality reconstructions.",1
"We apply a temporal edge prediction model for weighted dynamic graphs to predict time-dependent changes in molecular structure. Each molecule is represented as a complete graph in which each atom is a vertex and all vertex pairs are connected by an edge weighted by the Euclidean distance between atom pairs. We ingest a sequence of complete molecular graphs into a dynamic graph neural network (GNN) to predict the graph at the next time step. Our dynamic GNN predicts atom-to-atom distances with a mean absolute error of 0.017 \r{A}, which is considered ``chemically accurate'' for molecular simulations. We also explored the transferability of a trained network to new molecular systems and found that finetuning with less than 10% of the total trajectory provides a mean absolute error of the same order of magnitude as that when training from scratch on the full molecular trajectory.",0
"To predict changes in molecular structure over time, we utilize a temporal edge prediction model for weighted dynamic graphs. A complete graph is used to represent each molecule, where every atom is a vertex and edges are weighted based on the Euclidean distance between atom pairs. Using a dynamic graph neural network (GNN), we input a sequence of complete molecular graphs to predict the graph at the next time step. Our dynamic GNN accurately predicts atom-to-atom distances, with a mean absolute error of 0.017 \r{A}, deemed chemically accurate for molecular simulations. Additionally, we investigated the adaptability of a trained network for new molecular systems, discovering that finetuning with less than 10% of the total trajectory results in a mean absolute error of similar magnitude as training from scratch on the full molecular trajectory.",1
"Throughout science and technology, receiver operating characteristic (ROC) curves and associated area under the curve (AUC) measures constitute powerful tools for assessing the predictive abilities of features, markers and tests in binary classification problems. Despite its immense popularity, ROC analysis has been subject to a fundamental restriction, in that it applies to dichotomous (yes or no) outcomes only. Here we introduce ROC movies and universal ROC (UROC) curves that apply to just any linearly ordered outcome, along with an associated coefficient of predictive ability (CPA) measure. CPA equals the area under the UROC curve, and admits appealing interpretations in terms of probabilities and rank based covariances. For binary outcomes CPA equals AUC, and for pairwise distinct outcomes CPA relates linearly to Spearman's coefficient, in the same way that the C index relates linearly to Kendall's coefficient. ROC movies, UROC curves, and CPA nest and generalize the tools of classical ROC analysis, and are bound to supersede them in a wealth of applications. Their usage is illustrated in data examples from biomedicine and meteorology, where rank based measures yield new insights in the WeatherBench comparison of the predictive performance of convolutional neural networks and physical-numerical models for weather prediction.",0
"ROC curves and AUC measures are widely used in science and technology to evaluate the predictive abilities of features, markers, and tests in binary classification problems. However, this approach is limited to dichotomous outcomes. To address this issue, we propose ROC movies and universal ROC (UROC) curves that can be used for any linearly ordered outcome. We also introduce the associated coefficient of predictive ability (CPA) measure, which is equal to the area under the UROC curve and has interpretations in terms of probabilities and rank-based covariances. CPA is equivalent to AUC for binary outcomes and relates linearly to Spearman's coefficient for pairwise distinct outcomes. These new tools generalize classical ROC analysis and can provide valuable insights in various applications, such as biomedicine and meteorology. We demonstrate their usage through examples, including a comparison of the predictive performance of convolutional neural networks and physical-numerical models for weather prediction using rank-based measures.",1
"Designing novel protein sequences for a desired 3D topological fold is a fundamental yet non-trivial task in protein engineering. Challenges exist due to the complex sequence--fold relationship, as well as the difficulties to capture the diversity of the sequences (therefore structures and functions) within a fold. To overcome these challenges, we propose Fold2Seq, a novel transformer-based generative framework for designing protein sequences conditioned on a specific target fold. To model the complex sequence--structure relationship, Fold2Seq jointly learns a sequence embedding using a transformer and a fold embedding from the density of secondary structural elements in 3D voxels. On test sets with single, high-resolution and complete structure inputs for individual folds, our experiments demonstrate improved or comparable performance of Fold2Seq in terms of speed, coverage, and reliability for sequence design, when compared to existing state-of-the-art methods that include data-driven deep generative models and physics-based RosettaDesign. The unique advantages of fold-based Fold2Seq, in comparison to a structure-based deep model and RosettaDesign, become more evident on three additional real-world challenges originating from low-quality, incomplete, or ambiguous input structures. Source code and data are available at https://github.com/IBM/fold2seq.",0
"Creating new protein sequences that conform to a specific 3D topological fold is a crucial but challenging task in protein engineering. The relationship between sequence and fold is complicated, and it's difficult to account for the variety of sequences, structures, and functions within a fold. To address these difficulties, the researchers propose Fold2Seq, a novel transformer-based generative framework for designing protein sequences that align with a particular target fold. Fold2Seq simultaneously learns a sequence embedding and a fold embedding by using a transformer and the density of secondary structural elements in 3D voxels. The researchers conducted experiments on test sets with single, high-resolution and complete structure inputs for individual folds and showed that Fold2Seq has improved or comparable performance to existing state-of-the-art methods, including data-driven deep generative models and physics-based RosettaDesign, in terms of speed, coverage, and reliability for sequence design. Fold2Seq's advantages over structure-based deep models and RosettaDesign become more apparent in three additional real-world challenges that originate from low-quality, incomplete, or ambiguous input structures. The source code and data are available at https://github.com/IBM/fold2seq.",1
"To investigate whether the pleurae, airways and vessels surrounding a nodule on non-contrast computed tomography (CT) can discriminate benign and malignant pulmonary nodules. The LIDC-IDRI dataset, one of the largest publicly available CT database, was exploited for study. A total of 1556 nodules from 694 patients were involved in statistical analysis, where nodules with average scorings <3 and >3 were respectively denoted as benign and malignant. Besides, 339 nodules from 113 patients with diagnosis ground-truth were independently evaluated. Computer algorithms were developed to segment pulmonary structures and quantify the distances to pleural surface, airways and vessels, as well as the counting number and normalized volume of airways and vessels near a nodule. Odds ratio (OR) and Chi-square (\chi^2) testing were performed to demonstrate the correlation between features of surrounding structures and nodule malignancy. A non-parametric receiver operating characteristic (ROC) analysis was conducted in logistic regression to evaluate discrimination ability of each structure. For benign and malignant groups, the average distances from nodules to pleural surface, airways and vessels are respectively (6.56, 5.19), (37.08, 26.43) and (1.42, 1.07) mm. The correlation between nodules and the counting number of airways and vessels that contact or project towards nodules are respectively (OR=22.96, \chi^2=105.04) and (OR=7.06, \chi^2=290.11). The correlation between nodules and the volume of airways and vessels are (OR=9.19, \chi^2=159.02) and (OR=2.29, \chi^2=55.89). The areas-under-curves (AUCs) for pleurae, airways and vessels are respectively 0.5202, 0.6943 and 0.6529. Our results show that malignant nodules are often surrounded by more pulmonary structures compared with benign ones, suggesting that features of these structures could be viewed as lung cancer biomarkers.",0
"The aim of this study was to determine whether the pleurae, airways, and vessels surrounding a pulmonary nodule on non-contrast computed tomography (CT) can distinguish between benign and malignant nodules. To achieve this goal, the researchers used the LIDC-IDRI dataset, which is a publicly available CT database. The study involved 1556 nodules from 694 patients, with nodules that scored <3 and >3 being classified as benign and malignant, respectively. Additionally, 339 nodules from 113 patients with a confirmed diagnosis were independently evaluated. Computer algorithms were developed to segment pulmonary structures and measure the distances to the pleural surface, airways, and vessels, as well as the number and volume of airways and vessels near a nodule. Odds ratios and Chi-square testing were used to analyze the correlation between the features of surrounding structures and nodule malignancy. The study found that malignant nodules were often surrounded by more pulmonary structures compared to benign ones, suggesting that the features of these structures could be used as biomarkers for lung cancer.",1
"The Internet of Things (IoT) collects real-time data of physical systems, such as smart factory, intelligent robot and healtcare system, and provide necessary support for digital twins. Depending on the quality and accuracy, these multi-source data are divided into different fidelity levels. High-fidelity (HF) responses describe the system of interest accurately but are computed costly. In contrast, low-fidelity (LF) responses have a low computational cost but could not meet the required accuracy. Multi-fidelity data fusion (MDF) methods aims to use massive LF samples and small amounts of HF samples to develop an accurate and efficient model for describing the system with a reasonable computation burden. In this paper, we propose a novel generative adversarial network for MDF in digital twins (GAN-MDF). The generator of GAN-MDF is composed of two sub-networks: one extracts the LF features from an input; and the other integrates the input and the extracted LF features to form the input of the subsequent discriminator. The discriminator of GAN-MDF identifies whether the generator output is a real sample generated from HF model. To enhance the stability of GAN-MDF's training, we also introduce the supervised-loss trick to refine the generator weights during each iteration of the adversarial training. Compared with the state-of-the-art methods, the proposed GAN-MDF has the following advantages: 1) it performs well in the case of either nested or unnested sample structure; 2) there is no specific assumption on the data distribution; and 3) it has high robustness even when very few HF samples are provided. The experimental results also support the validity of GAN-MDF.",0
"Real-time data from physical systems such as smart factories, intelligent robots, and healthcare systems are collected by the Internet of Things (IoT) to support digital twins. The accuracy of multi-source data determines their fidelity level, with high-fidelity (HF) responses being the most accurate but computationally costly, and low-fidelity (LF) responses being less accurate but computationally cheaper. Multi-fidelity data fusion (MDF) methods aim to use a large amount of LF data and a small amount of HF data to create an accurate and efficient model of the system. In this study, we propose a novel generative adversarial network for MDF in digital twins (GAN-MDF). GAN-MDF's generator has two sub-networks, one that extracts LF features from an input and another that integrates the input and extracted features to form the input for the discriminator. The discriminator identifies whether the output is a real sample generated from an HF model. To enhance the stability of GAN-MDF's training, a supervised-loss trick is introduced to refine the generator's weights during each adversarial training iteration. GAN-MDF has several advantages over state-of-the-art methods, including its ability to perform well in nested and unnested sample structures, its lack of assumptions about data distribution, and its robustness even with few HF samples. Experimental results support the validity of GAN-MDF.",1
"The rapid development of artificial intelligence and deep learning has provided many opportunities to further enhance the safety, stability, and accuracy of industrial Cyber-Physical Systems (CPS). As indispensable components to many mission-critical CPS assets and equipment, mechanical bearings need to be monitored to identify any trace of abnormal conditions. Most of the data-driven approaches applied to bearing fault diagnosis up-to-date are trained using a large amount of fault data collected a priori. In many practical applications, however, it can be unsafe and time-consuming to collect sufficient data samples for each fault category, making it challenging to train a robust classifier. In this paper, we propose a few-shot learning framework for bearing fault diagnosis based on model-agnostic meta-learning (MAML), which targets for training an effective fault classifier using limited data. In addition, it can leverage the training data and learn to identify new fault scenarios more efficiently. Case studies on the generalization to new artificial faults show that the proposed framework achieves an overall accuracy up to 25% higher than a Siamese network-based benchmark study. Finally, the robustness and the generalization capability of the proposed framework are further validated by applying it to identify real bearing damages using data from artificial damages, which compares favorably against 6 state-of-the-art few-shot learning algorithms using consistent test environments.",0
"The swift advancement of artificial intelligence and deep learning has opened up numerous opportunities to enhance the reliability, safety, and precision of industrial Cyber-Physical Systems (CPS). Mechanical bearings, which are integral components of many mission-critical CPS assets and equipment, require constant monitoring to detect any anomalies. However, most data-based techniques employed for bearing fault diagnosis rely on extensive fault data collected beforehand. Collecting sufficient data for each fault category can be hazardous and time-consuming in practical applications, making it difficult to develop a robust classifier. To address this, we propose a few-shot learning framework for bearing fault diagnosis that employs model-agnostic meta-learning (MAML) to train a reliable fault classifier using limited data. Additionally, it can utilize the training data to identify new fault scenarios more efficiently. Our case studies on the generalization to new artificial faults demonstrate that our proposed framework achieves an overall accuracy up to 25% higher than a Siamese network-based benchmark study. Moreover, our framework's robustness and generalization capability are further validated by applying it to identify real bearing damages using data from artificial damages, which outperforms six state-of-the-art few-shot learning algorithms under consistent test conditions.",1
"We study constrained reinforcement learning (CRL) from a novel perspective by setting constraints directly on state density functions, rather than the value functions considered by previous works. State density has a clear physical and mathematical interpretation, and is able to express a wide variety of constraints such as resource limits and safety requirements. Density constraints can also avoid the time-consuming process of designing and tuning cost functions required by value function-based constraints to encode system specifications. We leverage the duality between density functions and Q functions to develop an effective algorithm to solve the density constrained RL problem optimally and the constrains are guaranteed to be satisfied. We prove that the proposed algorithm converges to a near-optimal solution with a bounded error even when the policy update is imperfect. We use a set of comprehensive experiments to demonstrate the advantages of our approach over state-of-the-art CRL methods, with a wide range of density constrained tasks as well as standard CRL benchmarks such as Safety-Gym.",0
"Our unique approach to studying constrained reinforcement learning (CRL) involves placing constraints directly on state density functions, as opposed to the value functions used in prior research. State density functions have a clear physical and mathematical interpretation, making them an effective way to express various constraints, including safety requirements and resource limitations. By using density constraints, the need for designing and fine-tuning cost functions is eliminated, which is a time-consuming process required by value function-based constraints to encode system specifications. To solve the density-constrained RL problem optimally, we utilize the duality between density functions and Q functions and have developed an effective algorithm. Our approach guarantees that the constraints will be satisfied, and the proposed algorithm converges to a near-optimal solution with a bounded error, even when policy updates are imperfect. Our method is demonstrated to be superior to state-of-the-art CRL techniques through comprehensive experiments on a wide range of density-constrained tasks and standard CRL benchmarks, including Safety-Gym.",1
"Visual place recognition is a fundamental capability for the localization of mobile robots. It places image retrieval in the practical context of physical agents operating in a physical world. It is an active field of research and many different approaches have been proposed and evaluated in many different experiments. In the following, we argue that due to variations of this practical context and individual design decisions, place recognition experiments are barely comparable across different papers and that there is a variety of properties that can change from one experiment to another. We provide an extensive list of such properties and give examples how they can be used to setup a place recognition experiment easier or harder. This might be interesting for different involved parties: (1) people who just want to select a place recognition approach that is suitable for the properties of their particular task at hand, (2) researchers that look for open research questions and are interested in particularly difficult instances, (3) authors that want to create reproducible papers on this topic, and (4) also reviewers that have the task to identify potential problems in papers under review.",0
"The localization of mobile robots heavily relies on their ability to visually recognize places, which brings image retrieval into a practical setting involving physical agents operating in the real world. With numerous approaches proposed and evaluated in various experiments, the field of visual place recognition is continuously evolving. However, due to the distinct practical contexts and design decisions involved, it is difficult to compare findings from different studies, as there are several properties that may vary between experiments. To aid those interested in this field, we present a comprehensive list of such properties and provide examples of how they could impact the difficulty of setting up a place recognition experiment. This information could prove useful for different stakeholders, including those seeking a suitable approach for their specific task, researchers exploring open questions, authors aiming to create replicable studies, and reviewers tasked with identifying potential issues in research papers.",1
"The recent advancements in artificial intelligence (AI) combined with the extensive amount of data generated by today's clinical systems, has led to the development of imaging AI solutions across the whole value chain of medical imaging, including image reconstruction, medical image segmentation, image-based diagnosis and treatment planning. Notwithstanding the successes and future potential of AI in medical imaging, many stakeholders are concerned of the potential risks and ethical implications of imaging AI solutions, which are perceived as complex, opaque, and difficult to comprehend, utilise, and trust in critical clinical applications. Despite these concerns and risks, there are currently no concrete guidelines and best practices for guiding future AI developments in medical imaging towards increased trust, safety and adoption. To bridge this gap, this paper introduces a careful selection of guiding principles drawn from the accumulated experiences, consensus, and best practices from five large European projects on AI in Health Imaging. These guiding principles are named FUTURE-AI and its building blocks consist of (i) Fairness, (ii) Universality, (iii) Traceability, (iv) Usability, (v) Robustness and (vi) Explainability. In a step-by-step approach, these guidelines are further translated into a framework of concrete recommendations for specifying, developing, evaluating, and deploying technically, clinically and ethically trustworthy AI solutions into clinical practice.",0
"The development of imaging AI solutions in medical imaging has been made possible by recent advancements in artificial intelligence (AI) and the extensive amount of data generated by today's clinical systems. These solutions cover the entire value chain of medical imaging, including image reconstruction, medical image segmentation, image-based diagnosis, and treatment planning. However, despite the successes and potential of AI in medical imaging, stakeholders are concerned about the risks and ethical implications of imaging AI solutions. These solutions are perceived as complex, opaque, and difficult to comprehend, utilize, and trust in critical clinical applications. Currently, there are no concrete guidelines and best practices to guide future AI developments in medical imaging towards increased trust, safety, and adoption. To address this gap, this paper introduces guiding principles named FUTURE-AI, consisting of fairness, universality, traceability, usability, robustness, and explainability. These principles are drawn from the accumulated experiences, consensus, and best practices from five large European projects on AI in Health Imaging. In a step-by-step approach, these guidelines are further translated into a framework of concrete recommendations for specifying, developing, evaluating, and deploying technically, clinically, and ethically trustworthy AI solutions into clinical practice.",1
"Self-supervised learning methods can be used to learn meaningful representations from unlabeled data that can be transferred to supervised downstream tasks to reduce the need for labeled data. In this paper, we propose a 3D self-supervised method that is based on the contrastive (SimCLR) method. Additionally, we show that employing Bayesian neural networks (with Monte-Carlo Dropout) during the inference phase can further enhance the results on the downstream tasks. We showcase our models on two medical imaging segmentation tasks: i) Brain Tumor Segmentation from 3D MRI, ii) Pancreas Tumor Segmentation from 3D CT. Our experimental results demonstrate the benefits of our proposed methods in both downstream data-efficiency and performance.",0
The paper proposes a 3D self-supervised method that utilizes the contrastive (SimCLR) method to learn meaningful representations from unlabeled data. This approach can reduce the need for labeled data in supervised downstream tasks. The study also suggests that incorporating Bayesian neural networks (with Monte-Carlo Dropout) during the inference phase can further improve the results on downstream tasks. The models are evaluated on two medical imaging segmentation tasks: Brain Tumor Segmentation from 3D MRI and Pancreas Tumor Segmentation from 3D CT. The experimental results highlight the advantages of the proposed methods in terms of both downstream data-efficiency and performance.,1
"This paper proposes an unsupervised cross-modality domain adaptation approach based on pixel alignment and self-training. Pixel alignment transfers ceT1 scans to hrT2 modality, helping to reduce domain shift in the training segmentation model. Self-training adapts the decision boundary of the segmentation network to fit the distribution of hrT2 scans. Experiment results show that PAST has outperformed the non-UDA baseline significantly, and it received rank-2 on CrossMoDA validation phase Leaderboard with a mean Dice score of 0.8395.",0
"The paper introduces a technique for unsupervised cross-modality domain adaptation that involves pixel alignment and self-training. By aligning ceT1 scans to hrT2 modality, the approach decreases the domain shift in the training segmentation model. In addition, self-training adjusts the segmentation network's decision boundary to match the hrT2 scan distribution. The experimental outcomes show that PAST outperforms the non-UDA baseline substantially, obtaining a rank-2 spot on the CrossMoDA validation phase Leaderboard with an average Dice score of 0.8395.",1
"The success of deep learning methods in medical image segmentation tasks heavily depends on a large amount of labeled data to supervise the training. On the other hand, the annotation of biomedical images requires domain knowledge and can be laborious. Recently, contrastive learning has demonstrated great potential in learning latent representation of images even without any label. Existing works have explored its application to biomedical image segmentation where only a small portion of data is labeled, through a pre-training phase based on self-supervised contrastive learning without using any labels followed by a supervised fine-tuning phase on the labeled portion of data only. In this paper, we establish that by including the limited label in formation in the pre-training phase, it is possible to boost the performance of contrastive learning. We propose a supervised local contrastive loss that leverages limited pixel-wise annotation to force pixels with the same label to gather around in the embedding space. Such loss needs pixel-wise computation which can be expensive for large images, and we further propose two strategies, downsampling and block division, to address the issue. We evaluate our methods on two public biomedical image datasets of different modalities. With different amounts of labeled data, our methods consistently outperform the state-of-the-art contrast-based methods and other semi-supervised learning techniques.",0
"The efficacy of deep learning techniques in medical image segmentation tasks largely relies on a vast amount of labeled data for training supervision. However, the annotation of biomedical images necessitates domain knowledge and can be a labor-intensive task. Recently, contrastive learning has emerged as a promising approach for learning latent representations of images even in the absence of labels. Prior research has explored its application to biomedical image segmentation where only a small proportion of data is labeled, using a pre-training phase based on self-supervised contrastive learning without labels followed by a supervised fine-tuning phase on the labeled data. In this study, we demonstrate that incorporating limited label information in the pre-training phase can enhance the performance of contrastive learning. We propose a supervised local contrastive loss that utilizes limited pixel-wise annotation to bring together pixels with the same label in the embedding space. However, this loss requires pixel-wise computation, which can be computationally intensive for large images. To overcome this challenge, we suggest two strategies, specifically downsampling and block division. We evaluate our methods on two publicly available biomedical image datasets with different modalities. Our results indicate that our methods consistently outperform state-of-the-art contrast-based methods and other semi-supervised learning techniques, regardless of the amount of labeled data.",1
"The success of deep learning heavily depends on the availability of large labeled training sets. However, it is hard to get large labeled datasets in medical image domain because of the strict privacy concern and costly labeling efforts. Contrastive learning, an unsupervised learning technique, has been proved powerful in learning image-level representations from unlabeled data. The learned encoder can then be transferred or fine-tuned to improve the performance of downstream tasks with limited labels. A critical step in contrastive learning is the generation of contrastive data pairs, which is relatively simple for natural image classification but quite challenging for medical image segmentation due to the existence of the same tissue or organ across the dataset. As a result, when applied to medical image segmentation, most state-of-the-art contrastive learning frameworks inevitably introduce a lot of false-negative pairs and result in degraded segmentation quality. To address this issue, we propose a novel positional contrastive learning (PCL) framework to generate contrastive data pairs by leveraging the position information in volumetric medical images. Experimental results on CT and MRI datasets demonstrate that the proposed PCL method can substantially improve the segmentation performance compared to existing methods in both semi-supervised setting and transfer learning setting.",0
"The availability of large labeled training sets plays a crucial role in the success of deep learning. However, obtaining such datasets in the medical image domain is challenging due to privacy concerns and labeling costs. Unsupervised learning techniques such as contrastive learning have proven effective in learning image-level representations from unlabeled data. The encoder learned from this technique can enhance the performance of downstream tasks with limited labels. However, generating contrastive data pairs is challenging in medical image segmentation due to the presence of the same tissue or organ across the dataset, resulting in false-negative pairs and degraded segmentation quality. To address this issue, we propose a novel framework called positional contrastive learning (PCL) that leverages position information in volumetric medical images to generate contrastive data pairs. Our experimental results on CT and MRI datasets demonstrate that the PCL method substantially improves segmentation performance compared to existing methods in both semi-supervised and transfer learning settings.",1
"We introduce $\textit{InExtremIS}$, a weakly supervised 3D approach to train a deep image segmentation network using particularly weak train-time annotations: only 6 extreme clicks at the boundary of the objects of interest. Our fully-automatic method is trained end-to-end and does not require any test-time annotations. From the extreme points, 3D bounding boxes are extracted around objects of interest. Then, deep geodesics connecting extreme points are generated to increase the amount of ""annotated"" voxels within the bounding boxes. Finally, a weakly supervised regularised loss derived from a Conditional Random Field formulation is used to encourage prediction consistency over homogeneous regions. Extensive experiments are performed on a large open dataset for Vestibular Schwannoma segmentation. $\textit{InExtremIS}$ obtained competitive performance, approaching full supervision and outperforming significantly other weakly supervised techniques based on bounding boxes. Moreover, given a fixed annotation time budget, $\textit{InExtremIS}$ outperforms full supervision. Our code and data are available online.",0
"We present a novel 3D approach called $\textit{InExtremIS}$ that employs weak supervision to train a deep image segmentation network. Specifically, we use only 6 extreme clicks at the object boundaries during training and do not require any test-time annotations. Our method is fully automatic and end-to-end trainable. To increase the number of annotated voxels within the objects of interest, we extract 3D bounding boxes around them and generate deep geodesics connecting the extreme points. We then use a weakly supervised regularized loss based on a Conditional Random Field formulation to encourage prediction consistency over homogeneous regions. We evaluate our approach on a large open dataset for Vestibular Schwannoma segmentation and demonstrate its competitive performance, which approaches full supervision and significantly outperforms other weakly supervised techniques based on bounding boxes. Additionally, our approach outperforms full supervision given a fixed annotation time budget. Our code and data are available online.",1
"Transformer architecture has emerged to be successful in a number of natural language processing tasks. However, its applications to medical vision remain largely unexplored. In this study, we present UTNet, a simple yet powerful hybrid Transformer architecture that integrates self-attention into a convolutional neural network for enhancing medical image segmentation. UTNet applies self-attention modules in both encoder and decoder for capturing long-range dependency at different scales with minimal overhead. To this end, we propose an efficient self-attention mechanism along with relative position encoding that reduces the complexity of self-attention operation significantly from $O(n^2)$ to approximate $O(n)$. A new self-attention decoder is also proposed to recover fine-grained details from the skipped connections in the encoder. Our approach addresses the dilemma that Transformer requires huge amounts of data to learn vision inductive bias. Our hybrid layer design allows the initialization of Transformer into convolutional networks without a need of pre-training. We have evaluated UTNet on the multi-label, multi-vendor cardiac magnetic resonance imaging cohort. UTNet demonstrates superior segmentation performance and robustness against the state-of-the-art approaches, holding the promise to generalize well on other medical image segmentations.",0
"While Transformer architecture has proven effective in natural language processing tasks, it remains largely unexplored in the field of medical vision. In this study, we introduce UTNet, a hybrid architecture that combines self-attention with a convolutional neural network to enhance medical image segmentation. Our design incorporates self-attention modules in both the encoder and decoder to capture long-range dependencies across different scales with minimal complexity. To achieve this, we propose an efficient self-attention mechanism with relative position encoding, which significantly reduces the complexity of self-attention from $O(n^2)$ to approximately $O(n)$. Additionally, we introduce a self-attention decoder to recover fine-grained details from the encoder's skipped connections. Our hybrid layer design eliminates the need for pre-training and addresses the challenge of Transformer requiring large amounts of data to learn visual inductive bias. We evaluate UTNet on a multi-label, multi-vendor cardiac magnetic resonance imaging cohort and demonstrate its superior segmentation performance and robustness against state-of-the-art approaches. Overall, UTNet shows promise for generalizing well to other medical image segmentations.",1
"One challenge of object recognition is to generalize to new domains, to more classes and/or to new modalities. This necessitates methods to combine and reuse existing datasets that may belong to different domains, have partial annotations, and/or have different data modalities. This paper formulates this as a multi-source domain adaptation and label unification problem, and proposes a novel method for it. Our method consists of a partially-supervised adaptation stage and a fully-supervised adaptation stage. In the former, partial knowledge is transferred from multiple source domains to the target domain and fused therein. Negative transfer between unmatching label spaces is mitigated via three new modules: domain attention, uncertainty maximization and attention-guided adversarial alignment. In the latter, knowledge is transferred in the unified label space after a label completion process with pseudo-labels. Extensive experiments on three different tasks - image classification, 2D semantic image segmentation, and joint 2D-3D semantic segmentation - show that our method outperforms all competing methods significantly.",0
"Object recognition faces the challenge of generalizing to new domains, more classes, or new modalities. This necessitates the combination and reuse of existing datasets, which may belong to different domains, have partial annotations, or possess varying data modalities. To address this issue, this paper proposes a novel method for multi-source domain adaptation and label unification. The method comprises two stages: a partially-supervised adaptation stage and a fully-supervised adaptation stage. In the former, multiple source domains transfer partial knowledge to the target domain, and negative transfer is mitigated through three modules: domain attention, uncertainty maximization, and attention-guided adversarial alignment. In the latter, knowledge is transferred in the unified label space after a label completion process using pseudo-labels. Extensive experiments on three different tasks demonstrate that our method outperforms all competing methods significantly.",1
"Medical image segmentation is inherently uncertain. For a given image, there may be multiple plausible segmentation hypotheses, and physicians will often disagree on lesion and organ boundaries. To be suited to real-world application, automatic segmentation systems must be able to capture this uncertainty and variability. Thus far, this has been addressed by building deep learning models that, through dropout, multiple heads, or variational inference, can produce a set - infinite, in some cases - of plausible segmentation hypotheses for any given image. However, in clinical practice, it may not be practical to browse all hypotheses. Furthermore, recent work shows that segmentation variability plateaus after a certain number of independent annotations, suggesting that a large enough group of physicians may be able to represent the whole space of possible segmentations. Inspired by this, we propose a simple method to obtain soft labels from the annotations of multiple physicians and train models that, for each image, produce a single well-calibrated output that can be thresholded at multiple confidence levels, according to each application's precision-recall requirements. We evaluated our method on the MICCAI 2021 QUBIQ challenge, showing that it performs well across multiple medical image segmentation tasks, produces well-calibrated predictions, and, on average, performs better at matching physicians' predictions than other physicians.",0
"Medical image segmentation is a complex process that involves uncertainty. Multiple plausible segmentation hypotheses can exist for a given image, and disagreements among physicians regarding lesion and organ boundaries are common. To be effective in real-world applications, automatic segmentation systems must be able to capture this variability. Currently, deep learning models are being used to address this issue by producing an infinite set of plausible segmentation hypotheses through dropout, multiple heads, or variational inference. However, this approach may not be practical in clinical practice, and recent research indicates that a large group of physicians may be able to represent the entire range of possible segmentations. To address this, we propose a simple method that obtains soft labels from multiple physicians' annotations and trains models to produce a single well-calibrated output for each image. This output can be thresholded at multiple confidence levels to meet precision-recall requirements for different applications. Our method was evaluated on the MICCAI 2021 QUBIQ challenge and demonstrated good performance across multiple medical image segmentation tasks. It produced well-calibrated predictions and, on average, matched physicians' predictions better than other physicians.",1
"To mitigate the radiologist's workload, computer-aided diagnosis with the capability to review and analyze medical images is gradually deployed. Deep learning-based region of interest segmentation is among the most exciting use cases. However, this paradigm is restricted in real-world clinical applications due to poor robustness and generalization. The issue is more sinister with a lack of training data. In this paper, we address the challenge from the representation learning point of view. We investigate that the collapsed representations, as one of the main reasons which caused poor robustness and generalization, could be avoided through transfer learning. Therefore, we propose a novel two-stage framework for robust generalized segmentation. In particular, an unsupervised Tile-wise AutoEncoder (T-AE) pretraining architecture is coined to learn meaningful representation for improving the generalization and robustness of the downstream tasks. Furthermore, the learned knowledge is transferred to the segmentation benchmark. Coupled with an image reconstruction network, the representation keeps to be decoded, encouraging the model to capture more semantic features. Experiments of lung segmentation on multi chest X-ray datasets are conducted. Empirically, the related experimental results demonstrate the superior generalization capability of the proposed framework on unseen domains in terms of high performance and robustness to corruption, especially under the scenario of the limited training data.",0
"Computer-aided diagnosis is being introduced to reduce the workload of radiologists, allowing them to review and analyze medical images more efficiently. One of the most exciting use cases is deep learning-based region of interest segmentation. However, this approach faces limitations in real-world clinical settings due to poor robustness and generalization, which are exacerbated by a lack of training data. In this paper, we propose a novel two-stage framework that addresses these issues by focusing on representation learning. We identify collapsed representations as a significant cause of poor generalization and robustness and demonstrate how transfer learning can mitigate this problem. Our framework includes an unsupervised Tile-wise AutoEncoder (T-AE) pretraining architecture that learns meaningful representations to improve the generalization and robustness of the downstream tasks. We also use an image reconstruction network to decode the representation, encouraging the model to capture more semantic features. We conducted experiments on multi chest X-ray datasets to test the framework's lung segmentation capabilities. Our results demonstrate the proposed framework's superior generalization capabilities in terms of high performance and robustness to corruption, especially under limited training data scenarios.",1
"Stereo matching is one of the widely used techniques for inferring depth from stereo images owing to its robustness and speed. It has become one of the major topics of research since it finds its applications in autonomous driving, robotic navigation, 3D reconstruction, and many other fields. Finding pixel correspondences in non-textured, occluded and reflective areas is the major challenge in stereo matching. Recent developments have shown that semantic cues from image segmentation can be used to improve the results of stereo matching. Many deep neural network architectures have been proposed to leverage the advantages of semantic segmentation in stereo matching. This paper aims to give a comparison among the state of art networks both in terms of accuracy and in terms of speed which are of higher importance in real-time applications.",0
"Stereo matching is a popular method for determining depth from stereo images due to its reliability and efficiency. It has gained significant attention in various fields, including autonomous driving, robotic navigation, and 3D modeling. However, determining pixel correspondences in areas that lack texture, are obstructed, or reflect light presents a significant obstacle. Recently, researchers have discovered that semantic clues from image segmentation can enhance the accuracy of stereo matching. Numerous deep neural network designs have been created to take advantage of semantic segmentation's benefits in stereo matching. This article seeks to compare the current state-of-the-art networks in terms of accuracy and speed, which are critical in real-time applications.",1
"In this paper, we proposed a novel mutual consistency network (MC-Net+) to effectively exploit the unlabeled hard regions for semi-supervised medical image segmentation. The MC-Net+ model is motivated by the observation that deep models trained with limited annotations are prone to output highly uncertain and easily mis-classified predictions in the ambiguous regions (e.g. adhesive edges or thin branches) for the image segmentation task. Leveraging these region-level challenging samples can make the semi-supervised segmentation model training more effective. Therefore, our proposed MC-Net+ model consists of two new designs. First, the model contains one shared encoder and multiple sightly different decoders (i.e. using different up-sampling strategies). The statistical discrepancy of multiple decoders' outputs is computed to denote the model's uncertainty, which indicates the unlabeled hard regions. Second, a new mutual consistency constraint is enforced between one decoder's probability output and other decoders' soft pseudo labels. In this way, we minimize the model's uncertainty during training and force the model to generate invariant and low-entropy results in such challenging areas of unlabeled data, in order to learn a generalized feature representation. We compared the segmentation results of the MC-Net+ with five state-of-the-art semi-supervised approaches on three public medical datasets. Extension experiments with two common semi-supervised settings demonstrate the superior performance of our model over other existing methods, which sets a new state of the art for semi-supervised medical image segmentation.",0
"Our paper introduces a novel mutual consistency network (MC-Net+) that effectively takes advantage of unlabeled hard regions in semi-supervised medical image segmentation. The MC-Net+ model is based on the observation that deep models trained with limited annotations often produce uncertain and easily misclassified predictions in ambiguous regions, such as adhesive edges or thin branches, during the image segmentation task. We propose leveraging these region-level challenging samples to improve the effectiveness of semi-supervised segmentation model training. Our proposed MC-Net+ model includes two new designs. Firstly, the model includes one shared encoder and multiple slightly different decoders that use different up-sampling strategies. The statistical discrepancy of multiple decoder outputs is used to indicate the model's uncertainty, which highlights the unlabeled hard regions. Secondly, a new mutual consistency constraint is enforced between one decoder's probability output and other decoders' soft pseudo labels. This approach minimizes the model's uncertainty during training and encourages the generation of invariant and low-entropy results in challenging areas of unlabeled data, leading to the learning of a generalized feature representation. We compared the segmentation results of MC-Net+ with five state-of-the-art semi-supervised approaches on three public medical datasets. Our model outperformed other existing methods in two common semi-supervised settings, setting a new state of the art for semi-supervised medical image segmentation.",1
"Consistency training has proven to be an advanced semi-supervised framework and achieved promising results in medical image segmentation tasks through enforcing an invariance of the predictions over different views of the inputs. However, with the iterative updating of model parameters, the models would tend to reach a coupled state and eventually lose the ability to exploit unlabeled data. To address the issue, we present a novel semi-supervised segmentation model based on parameter decoupling strategy to encourage consistent predictions from diverse views. Specifically, we first adopt a two-branch network to simultaneously produce predictions for each image. During the training process, we decouple the two prediction branch parameters by quadratic cosine distance to construct different views in latent space. Based on this, the feature extractor is constrained to encourage the consistency of probability maps generated by classifiers under diversified features. In the overall training process, the parameters of feature extractor and classifiers are updated alternately by consistency regularization operation and decoupling operation to gradually improve the generalization performance of the model. Our method has achieved a competitive result over the state-of-the-art semi-supervised methods on the Atrial Segmentation Challenge dataset, demonstrating the effectiveness of our framework. Code is available at https://github.com/BX0903/PDC.",0
"The effectiveness of consistency training in medical image segmentation tasks has been proven, as it enforces prediction invariance across different input views. However, the iterative updating of model parameters can lead to a loss of unlabeled data exploitation. To address this issue, we propose a novel semi-supervised segmentation model that uses a parameter decoupling strategy to encourage consistent predictions from diverse views. Our approach involves using a two-branch network to simultaneously produce predictions for each image and decoupling the two prediction branch parameters by quadratic cosine distance to construct different views in latent space. The feature extractor is then constrained to encourage consistency of probability maps generated by classifiers under diversified features. Throughout the training process, the parameters of the feature extractor and classifiers are updated alternatively through consistency regularization and decoupling operations to improve the model's generalization performance. Our method has shown competitive results over state-of-the-art semi-supervised methods on the Atrial Segmentation Challenge dataset, demonstrating the effectiveness of our framework. The code is available at https://github.com/BX0903/PDC.",1
"To ensure safety in automated driving, the correct perception of the situation inside the car is as important as its environment. Thus, seat occupancy detection and classification of detected instances play an important role in interior sensing. By the knowledge of the seat occupancy status, it is possible to, e.g., automate the airbag deployment control. Furthermore, the presence of a driver, which is necessary for partially automated driving cars at the automation levels two to four can be verified. In this work, we compare different statistical methods from the field of image segmentation to approach the problem of background-foreground segmentation in camera based interior sensing. In the recent years, several methods based on different techniques have been developed and applied to images or videos from different applications. The peculiarity of the given scenarios of interior sensing is, that the foreground instances and the background both contain static as well as dynamic elements. In data considered in this work, even the camera position is not completely fixed. We review and benchmark three different methods ranging, i.e., Gaussian Mixture Models (GMM), Morphological Snakes and a deep neural network, namely a Mask R-CNN. In particular, the limitations of the classical methods, GMM and Morphological Snakes, for interior sensing are shown. Furthermore, it turns, that it is possible to overcome these limitations by deep learning, e.g.\ using a Mask R-CNN. Although only a small amount of ground truth data was available for training, we enabled the Mask R-CNN to produce high quality background-foreground masks via transfer learning. Moreover, we demonstrate that certain augmentation as well as pre- and post-processing methods further enhance the performance of the investigated methods.",0
"The proper perception of the interior environment is just as crucial as the external surroundings for ensuring safety in autonomous driving. Therefore, the identification and classification of occupied seats are vital for interior sensing. This information can be utilized to automate the deployment of airbags and verify the presence of a driver, both of which are essential for partially autonomous vehicles at levels two to four of automation. In this study, we assess different statistical techniques for background-foreground segmentation in camera-based interior sensing. The challenge in this context is that both the foreground and background contain static and dynamic elements, and the camera is not always in a fixed position. We compare and evaluate three methods, namely Gaussian Mixture Models, Morphological Snakes, and a deep neural network called Mask R-CNN, to identify their limitations and potential. We found that deep learning approaches, like Mask R-CNN, outperform classical methods like GMM and Morphological Snakes. Despite a limited amount of ground truth data, the Mask R-CNN was able to produce high-quality background-foreground masks using transfer learning. Additionally, we demonstrate that certain augmentation and pre- and post-processing techniques can further improve the performance of these methods.",1
"High-quality training data play a key role in image segmentation tasks. Usually, pixel-level annotations are expensive, laborious and time-consuming for the large volume of training data. To reduce labelling cost and improve segmentation quality, interactive segmentation methods have been proposed, which provide the result with just a few clicks. However, their performance does not meet the requirements of practical segmentation tasks in terms of speed and accuracy. In this work, we propose EdgeFlow, a novel architecture that fully utilizes interactive information of user clicks with edge-guided flow. Our method achieves state-of-the-art performance without any post-processing or iterative optimization scheme. Comprehensive experiments on benchmarks also demonstrate the superiority of our method. In addition, with the proposed method, we develop an efficient interactive segmentation tool for practical data annotation tasks. The source code and tool is avaliable at https://github.com/PaddlePaddle/PaddleSeg.",0
"The role of high-quality training data is crucial in image segmentation tasks. However, obtaining pixel-level annotations can be expensive, laborious, and time-consuming, especially for a large volume of training data. To address this issue, interactive segmentation methods have been proposed to reduce labelling costs and improve segmentation quality. Despite their effectiveness, these methods do not meet the speed and accuracy requirements of practical segmentation tasks. To overcome this limitation, we propose EdgeFlow, which fully utilizes interactive information of user clicks with edge-guided flow. Our method achieves state-of-the-art performance without the need for post-processing or iterative optimization schemes. Comprehensive experiments on benchmarks further validate the superiority of our approach. Using EdgeFlow, we also develop an efficient interactive segmentation tool for practical data annotation tasks. The source code and tool are available at https://github.com/PaddlePaddle/PaddleSeg.",1
"Semantic segmentation of fine-resolution urban scene images plays a vital role in extensive practical applications, such as land cover mapping, urban change detection, environmental protection and economic assessment. Driven by rapid developments in deep learning technologies, convolutional neural networks (CNNs) have dominated the semantic segmentation task for many years. Convolutional neural networks adopt hierarchical feature representation and have strong local context extraction. However, the local property of the convolution layer limits the network from capturing global information that is crucial for improving fine-resolution image segmentation. Recently, Transformer comprise a hot topic in the computer vision domain. Vision Transformer demonstrates the great capability of global information modelling, boosting many vision tasks, such as image classification, object detection and especially semantic segmentation. In this paper, we propose an efficient hybrid Transformer (EHT) for semantic segmentation of urban scene images. EHT takes advantage of CNNs and Transformer, learning global-local context to strengthen the feature representation. Extensive experiments demonstrate that EHT has higher efficiency with competitive accuracy compared with state-of-the-art benchmark methods. Specifically, the proposed EHT achieves a 67.0% mIoU on the UAVid test set and outperforms other lightweight models significantly. The code will be available soon.",0
"The segmentation of fine-resolution urban images is essential for various practical applications such as land cover mapping, environmental protection, and economic assessment. Convolutional neural networks (CNNs) have been the dominant approach for semantic segmentation due to their hierarchical feature representation and robust local context extraction. However, CNNs are limited in capturing global information required for improving fine-resolution image segmentation. Recently, Transformer has emerged as a popular method for global information modeling in computer vision. In this study, we introduce an efficient hybrid Transformer (EHT) that combines CNNs and Transformer to achieve stronger feature representation by learning global-local context. Our experiments show that EHT performs better than other lightweight models, achieving a 67.0% mIoU on the UAVid test set. The code for EHT will be available soon.",1
"Generalising deep models to new data from new centres (termed here domains) remains a challenge. This is largely attributed to shifts in data statistics (domain shifts) between source and unseen domains. Recently, gradient-based meta-learning approaches where the training data are split into meta-train and meta-test sets to simulate and handle the domain shifts during training have shown improved generalisation performance. However, the current fully supervised meta-learning approaches are not scalable for medical image segmentation, where large effort is required to create pixel-wise annotations. Meanwhile, in a low data regime, the simulated domain shifts may not approximate the true domain shifts well across source and unseen domains. To address this problem, we propose a novel semi-supervised meta-learning framework with disentanglement. We explicitly model the representations related to domain shifts. Disentangling the representations and combining them to reconstruct the input image allows unlabeled data to be used to better approximate the true domain shifts for meta-learning. Hence, the model can achieve better generalisation performance, especially when there is a limited amount of labeled data. Experiments show that the proposed method is robust on different segmentation tasks and achieves state-of-the-art generalisation performance on two public benchmarks.",0
"The challenge of applying deep models to new data from different centres, or domains, is due to shifts in data statistics, known as domain shifts. Gradient-based meta-learning approaches have shown improved generalisation performance by simulating and handling domain shifts during training through splitting the data into meta-train and meta-test sets. However, fully supervised meta-learning approaches are not scalable for medical image segmentation, which requires a large effort to create pixel-wise annotations. Additionally, simulated domain shifts may not approximate the true domain shifts well in a low data regime. To overcome these limitations, we propose a semi-supervised meta-learning framework with disentanglement that models representations related to domain shifts. By disentangling these representations and combining them to reconstruct the input image, we can use unlabeled data to better approximate true domain shifts for meta-learning, resulting in better generalisation performance, especially when there is a limited amount of labeled data. Our experiments demonstrate the proposed method's robustness on different segmentation tasks and its achievement of state-of-the-art generalisation performance on two public benchmarks.",1
"Image segmentation algorithms often depend on appearance models that characterize the distribution of pixel values in different image regions. We describe a new approach for estimating appearance models directly from an image, without explicit consideration of the pixels that make up each region. Our approach is based on novel algebraic expressions that relate local image statistics to the appearance of spatially coherent regions. We describe two algorithms that can use the aforementioned algebraic expressions to estimate appearance models directly from an image. The first algorithm solves a system of linear and quadratic equations using a least squares formulation. The second algorithm is a spectral method based on an eigenvector computation. We present experimental results that demonstrate the proposed methods work well in practice and lead to effective image segmentation algorithms.",0
"Appearance models, which determine the distribution of pixel values in various image regions, are crucial for image segmentation algorithms. However, we introduce a new technique to estimate appearance models without explicitly considering the pixels in each region. Our approach employs innovative algebraic expressions that link local image statistics to the appearance of contiguous regions. Two algorithms based on these expressions are presented, with one solving linear and quadratic equations via a least squares formulation, while the other is a spectral approach that utilizes eigenvector computation. Our experimental results demonstrate that these methods are practical and produce successful image segmentation algorithms.",1
"The CNN-based methods have achieved impressive results in medical image segmentation, but it failed to capture the long-range dependencies due to the inherent locality of convolution operation. Transformer-based methods are popular in vision tasks recently because of its capacity of long-range dependencies and get a promising performance. However, it lacks in modeling local context, although some works attempted to embed convolutional layer to overcome this problem and achieved some improvement, but it makes the feature inconsistent and fails to leverage the natural multi-scale features of hierarchical transformer, which limit the performance of models. In this paper, taking medical image segmentation as an example, we present MISSFormer, an effective and powerful Medical Image Segmentation tranSFormer. MISSFormer is a hierarchical encoder-decoder network and has two appealing designs: 1) A feed forward network is redesigned with the proposed Enhanced Transformer Block, which makes features aligned adaptively and enhances the long-range dependencies and local context. 2) We proposed Enhanced Transformer Context Bridge, a context bridge with the enhanced transformer block to model the long-range dependencies and local context of multi-scale features generated by our hierarchical transformer encoder. Driven by these two designs, the MISSFormer shows strong capacity to capture more valuable dependencies and context in medical image segmentation. The experiments on multi-organ and cardiac segmentation tasks demonstrate the superiority, effectiveness and robustness of our MISSFormer, the exprimental results of MISSFormer trained from scratch even outperforms state-of-the-art methods pretrained on ImageNet, and the core designs can be generalized to other visual segmentation tasks. The code will be released in Github.",0
"Although CNN-based techniques have achieved impressive results in medical image segmentation, they fail to capture long-range dependencies due to the convolution operation's inherent locality. Transformer-based methods, which have gained popularity in vision tasks because of their ability to model long-range dependencies, show promise. However, they struggle with modeling local context, despite attempts to embed convolutional layers to address this issue, and fail to leverage the natural multi-scale features of hierarchical transformers, limiting model performance. This paper proposes MISSFormer, a powerful and effective Medical Image Segmentation tranSFormer, as an example of medical image segmentation. MISSFormer is a hierarchical encoder-decoder network with two appealing designs. Firstly, the proposed Enhanced Transformer Block enhances the alignment of features and promotes long-range dependencies and local context. Secondly, the Enhanced Transformer Context Bridge models the long-range dependencies and local context of multi-scale features generated by the hierarchical transformer encoder. The MISSFormer can capture more valuable dependencies and context in medical image segmentation and show superior effectiveness and robustness in multi-organ and cardiac segmentation tasks. The experimental results of MISSFormer trained from scratch even outperform those of state-of-the-art methods pre-trained on ImageNet. The core designs can be generalized to other visual segmentation tasks, and the code will be available on Github.",1
"Deep learning has become in recent years a cornerstone tool fueling key innovations in the industry, such as autonomous driving. To attain good performances, the neural network architecture used for a given application must be chosen with care. These architectures are often handcrafted and therefore prone to human biases and sub-optimal selection. Neural Architecture Search (NAS) is a framework introduced to mitigate such risks by jointly optimizing the network architectures and its weights. Albeit its novelty, it was applied on complex tasks with significant results - e.g. semantic image segmentation. In this technical paper, we aim to evaluate its ability to tackle a challenging operational task: semantic segmentation of objects of interest in satellite imagery. Designing a NAS framework is not trivial and has strong dependencies to hardware constraints. We therefore motivate our NAS approach selection and provide corresponding implementation details. We also present novel ideas to carry out other such use-case studies.",0
"In recent years, deep learning has emerged as a crucial tool driving innovation in industries such as autonomous driving. However, the success of a neural network architecture in a specific application depends on careful selection. Unfortunately, these architectures are often crafted by humans, making them prone to biases and suboptimal choices. To address this issue, Neural Architecture Search (NAS) was introduced to optimize both the network architecture and weights simultaneously. Despite its novelty, NAS has already shown promising results in complex tasks like semantic image segmentation. In this technical paper, we evaluate the potential of NAS in tackling the challenging operational task of semantic segmentation in satellite imagery, which requires careful consideration of hardware constraints. We explain our approach for selecting a NAS framework and provide implementation details, including novel ideas for future use-case studies.",1
"Tensor networks are efficient factorisations of high dimensional tensors into a network of lower order tensors. They have been most commonly used to model entanglement in quantum many-body systems and more recently are witnessing increased applications in supervised machine learning. In this work, we formulate image segmentation in a supervised setting with tensor networks. The key idea is to first lift the pixels in image patches to exponentially high dimensional feature spaces and using a linear decision hyper-plane to classify the input pixels into foreground and background classes. The high dimensional linear model itself is approximated using the matrix product state (MPS) tensor network. The MPS is weight-shared between the non-overlapping image patches resulting in our strided tensor network model. The performance of the proposed model is evaluated on three 2D- and one 3D- biomedical imaging datasets. The performance of the proposed tensor network segmentation model is compared with relevant baseline methods. In the 2D experiments, the tensor network model yeilds competitive performance compared to the baseline methods while being more resource efficient.",0
"Tensor networks are networks of lower order tensors that efficiently factorise high dimensional tensors. They have commonly been used to model quantum many-body systems' entanglement and are increasingly being used in supervised machine learning. In this study, we present a supervised approach to image segmentation using tensor networks. We first elevate the pixels in image patches to high dimensional feature spaces and classify them into foreground and background classes using a linear decision hyper-plane. The high dimensional linear model is approximated using matrix product state (MPS) tensor networks. The MPS is shared between non-overlapping image patches, resulting in our strided tensor network model. We evaluate the model's performance on three 2D- and one 3D- biomedical imaging datasets and compare it with relevant baseline methods. Our experiments show that the tensor network model performs competitively with baseline methods while being more resource-efficient in 2D experiments.",1
"Simultaneous segmentation of multiple organs from different medical imaging modalities is a crucial task as it can be utilized for computer-aided diagnosis, computer-assisted surgery, and therapy planning. Thanks to the recent advances in deep learning, several deep neural networks for medical image segmentation have been introduced successfully for this purpose. In this paper, we focus on learning a deep multi-organ segmentation network that labels voxels. In particular, we examine the critical choice of a loss function in order to handle the notorious imbalance problem that plagues both the input and output of a learning model. The input imbalance refers to the class-imbalance in the input training samples (i.e., small foreground objects embedded in an abundance of background voxels, as well as organs of varying sizes). The output imbalance refers to the imbalance between the false positives and false negatives of the inference model. In order to tackle both types of imbalance during training and inference, we introduce a new curriculum learning based loss function. Specifically, we leverage Dice similarity coefficient to deter model parameters from being held at bad local minima and at the same time gradually learn better model parameters by penalizing for false positives/negatives using a cross entropy term. We evaluated the proposed loss function on three datasets: whole body positron emission tomography (PET) scans with 5 target organs, magnetic resonance imaging (MRI) prostate scans, and ultrasound echocardigraphy images with a single target organ i.e., left ventricular. We show that a simple network architecture with the proposed integrative loss function can outperform state-of-the-art methods and results of the competing methods can be improved when our proposed loss is used.",0
"The segmentation of multiple organs from different medical imaging modalities is a critical task that has various applications such as computer-aided diagnosis, computer-assisted surgery, and therapy planning. Recent advances in deep learning have led to the successful introduction of several deep neural networks for medical image segmentation. This paper focuses on the learning of a deep multi-organ segmentation network that labels voxels. The choice of a loss function is crucial in handling the imbalance problem that affects both the input and output of a learning model. The input imbalance refers to the class-imbalance in the input training samples, while the output imbalance refers to the imbalance between the false positives and false negatives of the inference model. To address both types of imbalance during training and inference, a new curriculum learning based loss function is introduced. This loss function leverages the Dice similarity coefficient to prevent the model parameters from being held at bad local minima and gradually learn better parameters by penalizing false positives/negatives using a cross-entropy term. The proposed loss function is evaluated on three datasets and is shown to outperform state-of-the-art methods. The results of competing methods can also be improved when the proposed loss function is used.",1
"Semi-supervised learning (SSL) uses unlabeled data to compensate for the scarcity of annotated images and the lack of method generalization to unseen domains, two usual problems in medical segmentation tasks. In this work, we propose POPCORN, a novel method combining consistency regularization and pseudo-labeling designed for image segmentation. The proposed framework uses high-level regularization to constrain our segmentation model to use similar latent features for images with similar segmentations. POPCORN estimates a proximity graph to select data from easiest ones to more difficult ones, in order to ensure accurate pseudo-labeling and to limit confirmation bias. Applied to multiple sclerosis lesion segmentation, our method demonstrates competitive results compared to other state-of-the-art SSL strategies.",0
"To address the issues of insufficient annotated images and limited generalization to new domains in medical segmentation tasks, semi-supervised learning (SSL) utilizes unlabeled data. In this study, we introduce a new method called POPCORN that combines pseudo-labeling and consistency regularization for image segmentation. The proposed approach employs high-level regularization to ensure that the segmentation model utilizes similar latent features for images with similar segmentations. POPCORN generates a proximity graph to select data from the easiest to the most difficult in order to provide accurate pseudo-labeling while limiting confirmation bias. Our method is applied to multiple sclerosis lesion segmentation, and it is found that it performs competitively against other state-of-the-art SSL strategies.",1
"Modern deep neural networks struggle to transfer knowledge and generalize across domains when deploying to real-world applications. Domain generalization (DG) aims to learn a universal representation from multiple source domains to improve the network generalization ability on unseen target domains. Previous DG methods mostly focus on the data-level consistency scheme to advance the generalization capability of deep networks, without considering the synergistic regularization of different consistency schemes. In this paper, we present a novel Hierarchical Consistency framework for Domain Generalization (HCDG) by ensembling Extrinsic Consistency and Intrinsic Consistency. Particularly, for Extrinsic Consistency, we leverage the knowledge across multiple source domains to enforce data-level consistency. Also, we design a novel Amplitude Gaussian-mixing strategy for Fourier-based data augmentation to enhance such consistency. For Intrinsic Consistency, we perform task-level consistency for the same instance under the dual-task form. We evaluate the proposed HCDG framework on two medical image segmentation tasks, i.e., optic cup/disc segmentation on fundus images and prostate MRI segmentation. Extensive experimental results manifest the effectiveness and versatility of our HCDG framework. Code will be available once accept.",0
"Current deep neural networks face difficulties in transferring knowledge and generalizing across different domains when deployed in real-world applications. The objective of domain generalization (DG) is to develop a universal representation through the learning of multiple source domains, thereby enhancing the network's generalization capability for unseen target domains. However, previous DG methods have primarily focused on data-level consistency schemes, neglecting the importance of the synergistic regularization of different consistency schemes. This paper introduces a novel Hierarchical Consistency framework for Domain Generalization (HCDG) that uses Extrinsic Consistency and Intrinsic Consistency ensembling. Extrinsic Consistency utilizes knowledge across multiple source domains to enforce data-level consistency, while a novel Amplitude Gaussian-mixing strategy for Fourier-based data augmentation enhances this consistency. Intrinsic Consistency performs task-level consistency for the same instance under the dual-task form. We evaluate the effectiveness and versatility of the proposed HCDG framework on two medical image segmentation tasks: optic cup/disc segmentation on fundus images and prostate MRI segmentation. Our extensive experimental results demonstrate the effectiveness of the HCDG framework. Once accepted, the code will be available.",1
"Deep neural networks have been a prevailing technique in the field of medical image processing. However, the most popular convolutional neural networks (CNNs) based methods for medical image segmentation are imperfect because they model long-range dependencies by stacking layers or enlarging filters. Transformers and the self-attention mechanism are recently proposed to effectively learn long-range dependencies by modeling all pairs of word-to-word attention regardless of their positions. The idea has also been extended to the computer vision field by creating and treating image patches as embeddings. Considering the computation complexity for whole image self-attention, current transformer-based models settle for a rigid partitioning scheme that potentially loses informative relations. Besides, current medical transformers model global context on full resolution images, leading to unnecessary computation costs. To address these issues, we developed a novel method to integrate multi-scale attention and CNN feature extraction using a pyramidal network architecture, namely Pyramid Medical Transformer (PMTrans). The PMTrans captured multi-range relations by working on multi-resolution images. An adaptive partitioning scheme was implemented to retain informative relations and to access different receptive fields efficiently. Experimental results on three medical image datasets (gland segmentation, MoNuSeg, and HECKTOR datasets) showed that PMTrans outperformed the latest CNN-based and transformer-based models for medical image segmentation.",0
"Medical image processing has widely adopted deep neural networks, including the popular convolutional neural networks (CNNs) for segmentation. However, CNNs are not ideal for modeling long-range dependencies. To address this, transformers and the self-attention mechanism have been proposed, which can learn long-range dependencies by modeling all pairs of attention. This idea has been extended to computer vision by treating image patches as embeddings. However, current transformer-based models face challenges in computational complexity and global context modeling. To overcome these issues, a new approach called Pyramid Medical Transformer (PMTrans) has been developed, which integrates multi-scale attention and CNN feature extraction using a pyramidal network architecture. PMTrans captures multi-range relations by working on multi-resolution images, while an adaptive partitioning scheme is implemented to retain informative relations efficiently. Experimental results on three medical image datasets demonstrate that PMTrans outperforms current CNN-based and transformer-based models for medical image segmentation.",1
"We propose a novel neural-network-based method to perform matting of videos depicting people that does not require additional user input such as trimaps. Our architecture achieves temporal stability of the resulting alpha mattes by using motion-estimation-based smoothing of image-segmentation algorithm outputs, combined with convolutional-LSTM modules on U-Net skip connections.   We also propose a fake-motion algorithm that generates training clips for the video-matting network given photos with ground-truth alpha mattes and background videos. We apply random motion to photos and their mattes to simulate movement one would find in real videos and composite the result with the background clips. It lets us train a deep neural network operating on videos in an absence of a large annotated video dataset and provides ground-truth training-clip foreground optical flow for use in loss functions.",0
"Our innovative approach involves a neural network method for video matting of individuals without the need for extra user input, such as trimaps. To achieve stable alpha mattes over time, we employ motion estimation-based smoothing of image-segmentation algorithms and convolutional-LSTM modules on U-Net skip connections in our architecture. Additionally, we propose a fake-motion algorithm that creates training clips for the video-matting network using photos with ground-truth alpha mattes and background videos. This algorithm simulates the natural movement found in real videos by randomly applying motion to photos and their mattes, then compositing the outcome with background clips. This method allows us to train a deep neural network on videos without a significant annotated video dataset and provides ground-truth training-clip foreground optical flow for use in loss functions.",1
"Image segmentation is a common and challenging task in autonomous driving. Availability of sufficient pixel-level annotations for the training data is a hurdle. Active learning helps learning from small amounts of data by suggesting the most promising samples for labeling. In this work, we propose a new pool-based method for active learning, which proposes promising patches extracted from full image, in each acquisition step. The problem is framed in an exploration-exploitation framework by combining an embedding based on Uniform Manifold Approximation to model representativeness with entropy as uncertainty measure to model informativeness. We applied our proposed method to the autonomous driving datasets CamVid and Cityscapes and performed a quantitative comparison with state-of-the-art baselines. We find that our active learning method achieves better performance compared to previous methods.",0
"Autonomous driving involves a challenging task of image segmentation, which is hindered by the scarcity of pixel-level annotations in the training data. To overcome this challenge, active learning has been utilized to recommend promising samples for labeling from small amounts of data. This study presents a new pool-based approach to active learning, which suggests promising patches extracted from the full image in each acquisition step. The approach is framed in an exploration-exploitation framework that combines Uniform Manifold Approximation-based embedding to model representativeness with entropy as an uncertainty measure to model informativeness. The proposed method was implemented on two autonomous driving datasets, CamVid and Cityscapes, and compared quantitatively with state-of-the-art baselines. The results show that the proposed active learning approach outperforms previous methods.",1
"Most recent semantic segmentation methods adopt a U-Net framework with an encoder-decoder architecture. It is still challenging for U-Net with a simple skip connection scheme to model the global multi-scale context: 1) Not each skip connection setting is effective due to the issue of incompatible feature sets of encoder and decoder stage, even some skip connection negatively influence the segmentation performance; 2) The original U-Net is worse than the one without any skip connection on some datasets. Based on our findings, we propose a new segmentation framework, named UCTransNet (with a proposed CTrans module in U-Net), from the channel perspective with attention mechanism. Specifically, the CTrans module is an alternate of the U-Net skip connections, which consists of a sub-module to conduct the multi-scale Channel Cross fusion with Transformer (named CCT) and a sub-module Channel-wise Cross-Attention (named CCA) to guide the fused multi-scale channel-wise information to effectively connect to the decoder features for eliminating the ambiguity. Hence, the proposed connection consisting of the CCT and CCA is able to replace the original skip connection to solve the semantic gaps for an accurate automatic medical image segmentation. The experimental results suggest that our UCTransNet produces more precise segmentation performance and achieves consistent improvements over the state-of-the-art for semantic segmentation across different datasets and conventional architectures involving transformer or U-shaped framework. Code: https://github.com/McGregorWwww/UCTransNet.",0
"Recent methods for semantic segmentation typically use a U-Net framework with an encoder-decoder architecture. However, it remains challenging for U-Net with a simple skip connection method to model the global multi-scale context. This is because not all skip connection settings are effective due to the issue of incompatible feature sets of the encoder and decoder stages, and some skip connections may negatively impact segmentation performance. Additionally, the original U-Net is inferior to one without any skip connection on some datasets. To address these issues, we propose a new segmentation framework called UCTransNet, which incorporates a CTrans module in U-Net from a channel perspective with an attention mechanism. The CTrans module is an alternative to skip connections and includes a sub-module for multi-scale Channel Cross fusion with Transformer and a sub-module for Channel-wise Cross-Attention to guide the fused multi-scale channel-wise information to effectively connect to the decoder features and eliminate ambiguity. Our proposed connection consisting of the CCT and CCA can replace the original skip connection, solving semantic gaps for accurate automatic medical image segmentation. Experimental results demonstrate that UCTransNet produces more precise segmentation performance and achieves consistent improvements over state-of-the-art methods for semantic segmentation across different datasets and conventional architectures involving transformer or U-shaped framework. Our code is available at https://github.com/McGregorWwww/UCTransNet.",1
"Detection faults in seismic data is a crucial step for seismic structural interpretation, reservoir characterization and well placement. Some recent works regard it as an image segmentation task. The task of image segmentation requires huge labels, especially 3D seismic data, which has a complex structure and lots of noise. Therefore, its annotation requires expert experience and a huge workload. In this study, we present lambda-BCE and lambda-smooth L1loss to effectively train 3D-CNN by some slices from 3D seismic data, so that the model can learn the segmentation of 3D seismic data from a few 2D slices. In order to fully extract information from limited data and suppress seismic noise, we propose an attention module that can be used for active supervision training and embedded in the network. The attention heatmap label is generated by the original label, and letting it supervise the attention module using the lambda-smooth L1loss. The experiment demonstrates the effectiveness of our loss function, the method can extract 3D seismic features from a few 2D slice labels. And it also shows the advanced performance of the attention module, which can significantly suppress the noise in the seismic data while increasing the model's sensitivity to the foreground. Finally, on the public test set, we only use the 2D slice labels training that accounts for 3.3% of the 3D volume label, and achieve similar performance to the 3D volume label training.",0
"The identification of faults in seismic data is a crucial step for interpreting seismic structures, characterizing reservoirs, and placing wells. Recent research has considered this task as an image segmentation problem, which requires extensive labeling, particularly for 3D seismic data due to its complex structure and high levels of noise. This labeling process is a significant workload that demands expert experience. In this study, we propose the use of lambda-BCE and lambda-smooth L1loss to train a 3D-CNN model on a few 2D slices of 3D seismic data to learn its segmentation effectively. To extract information from limited data and reduce seismic noise, we introduce an attention module that can be integrated into the network for active supervision training. The attention heatmap label is generated from the original label and used to supervise the attention module with the lambda-smooth L1loss. Our experiment proves the effectiveness of our loss function, which extracts 3D seismic features from a small number of 2D slice labels. The attention module also demonstrates advanced performance, significantly reducing seismic noise while enhancing the model's sensitivity to the foreground. Finally, we achieve similar performance to 3D volume label training by using only 3.3% of the 3D volume label for training with 2D slice labels in the public test set.",1
"Machine learning has been utilized to perform tasks in many different domains such as classification, object detection, image segmentation and natural language analysis. Data labeling has always been one of the most important tasks in machine learning. However, labeling large amounts of data increases the monetary cost in machine learning. As a result, researchers started to focus on reducing data annotation and labeling costs. Transfer learning was designed and widely used as an efficient approach that can reasonably reduce the negative impact of limited data, which in turn, reduces the data preparation cost. Even transferring previous knowledge from a source domain reduces the amount of data needed in a target domain. However, large amounts of annotated data are still demanded to build robust models and improve the prediction accuracy of the model. Therefore, researchers started to pay more attention on auto annotation and labeling. In this survey paper, we provide a review of previous techniques that focuses on optimized data annotation and labeling for video, audio, and text data.",0
"Machine learning has been employed in various fields to perform tasks such as natural language analysis, image segmentation, object detection, and classification. Data labeling is a crucial task in this process, but it can be costly when dealing with large amounts of data. To reduce data annotation and labeling costs, researchers have explored transfer learning, an effective approach that leverages previous knowledge from a source domain to reduce the need for data in a target domain. Despite this, creating robust models and improving prediction accuracy still requires a significant amount of annotated data. As a result, auto annotation and labeling have become an area of focus for researchers. This survey paper reviews previous techniques that optimize data annotation and labeling for video, audio, and text data.",1
"Ultra-high resolution image segmentation has raised increasing interests in recent years due to its realistic applications. In this paper, we innovate the widely used high-resolution image segmentation pipeline, in which an ultra-high resolution image is partitioned into regular patches for local segmentation and then the local results are merged into a high-resolution semantic mask. In particular, we introduce a novel locality-aware contextual correlation based segmentation model to process local patches, where the relevance between local patch and its various contexts are jointly and complementarily utilized to handle the semantic regions with large variations. Additionally, we present a contextual semantics refinement network that associates the local segmentation result with its contextual semantics, and thus is endowed with the ability of reducing boundary artifacts and refining mask contours during the generation of final high-resolution mask. Furthermore, in comprehensive experiments, we demonstrate that our model outperforms other state-of-the-art methods in public benchmarks. Our released codes are available at https://github.com/liqiokkk/FCtL.",0
"In recent years, there has been a growing interest in ultra-high resolution image segmentation due to its practical applications. This study aims to improve the commonly used high-resolution image segmentation pipeline by dividing an ultra-high resolution image into regular patches for local segmentation. The local results are then combined to create a high-resolution semantic mask. The study introduces a new segmentation model that utilizes locality-aware contextual correlation to process local patches, using the relevance between the local patch and its various contexts to handle semantic regions with significant variations. Additionally, a contextual semantics refinement network is presented that connects the local segmentation result with its contextual semantics, effectively reducing boundary artifacts and refining mask contours when generating the final high-resolution mask. The study includes comprehensive experiments demonstrating that this model outperforms other state-of-the-art methods in public benchmarks. The released codes for this study can be accessed at https://github.com/liqiokkk/FCtL.",1
"Motivated by a $2$-dimensional (unsupervised) image segmentation task whereby local regions of pixels are clustered via edge detection methods, a more general probabilistic mathematical framework is devised. Critical thresholds are calculated that indicate strong correlation between randomly-generated, high dimensional data points that have been projected into structures in a partition of a bounded, $2$-dimensional area, of which, an image is a special case. A neighbor concept for structures in the partition is defined and a critical radius is uncovered. Measured from a central structure in localized regions of the partition, the radius indicates strong, long and short range correlation in the count of occupied structures. The size of a short interval of radii is estimated upon which the transition from short-to-long range correlation is virtually assured, which defines a demarcation of when an image ceases to be ""interesting"".",0
"The development of a probabilistic mathematical framework was inspired by an unsupervised task of segmenting images in two dimensions using edge detection methods. The framework identifies critical thresholds that demonstrate a strong correlation between high-dimensional data points that are projected into structures within a partition of a bounded, two-dimensional area, such as an image. The partition also defines a neighbor concept for structures, and a critical radius is established to determine strong, long and short-range correlations in the count of occupied structures within localized regions of the partition. By estimating the size of a short interval of radii, the transition from short-to-long range correlation can be determined, providing a demarcation point for when an image is no longer considered ""interesting.""",1
"Semantic segmentation models trained on public datasets have achieved great success in recent years. However, these models didn't consider the personalization issue of segmentation though it is important in practice. In this paper, we address the problem of personalized image segmentation. The objective is to generate more accurate segmentation results on unlabeled personalized images by investigating the data's personalized traits. To open up future research in this area, we collect a large dataset containing various users' personalized images called PIS (Personalized Image Semantic Segmentation). We also survey some recent researches related to this problem and report their performance on our dataset. Furthermore, by observing the correlation among a user's personalized images, we propose a baseline method that incorporates the inter-image context when segmenting certain images. Extensive experiments show that our method outperforms the existing methods on the proposed dataset. The code and the PIS dataset will be made publicly available.",0
"While semantic segmentation models trained on public datasets have been successful in recent years, they have failed to address the issue of personalization, which is crucial in practical applications. In this paper, we aim to tackle this problem by generating more accurate segmentation results on unlabeled personalized images through investigating personalized traits in the data. To enable future research in this area, we have gathered a sizeable dataset called PIS (Personalized Image Semantic Segmentation), which contains various personalized images from different users. We have also conducted a survey of recent studies relating to this problem and have evaluated their performance on our dataset. Additionally, we have proposed a baseline method that incorporates inter-image context when segmenting specific images by analyzing the relationship among a user's personalized images. Our extensive experiments have shown that our method surpasses existing methods on the proposed dataset. The code and the PIS dataset will be made available to the public.",1
"Image segmentation is often ambiguous at the level of individual image patches and requires contextual information to reach label consensus. In this paper we introduce Segmenter, a transformer model for semantic segmentation. In contrast to convolution-based methods, our approach allows to model global context already at the first layer and throughout the network. We build on the recent Vision Transformer (ViT) and extend it to semantic segmentation. To do so, we rely on the output embeddings corresponding to image patches and obtain class labels from these embeddings with a point-wise linear decoder or a mask transformer decoder. We leverage models pre-trained for image classification and show that we can fine-tune them on moderate sized datasets available for semantic segmentation. The linear decoder allows to obtain excellent results already, but the performance can be further improved by a mask transformer generating class masks. We conduct an extensive ablation study to show the impact of the different parameters, in particular the performance is better for large models and small patch sizes. Segmenter attains excellent results for semantic segmentation. It outperforms the state of the art on both ADE20K and Pascal Context datasets and is competitive on Cityscapes.",0
"The process of image segmentation can be unclear when examining individual image patches, and additional contextual information is necessary to arrive at a consensus regarding labeling. This paper introduces Segmenter, a semantic segmentation transformer model. Our method differs from convolution-based approaches in that it can model global context from the outset and consistently throughout the network. We expand upon the Vision Transformer (ViT) to create a semantic segmentation transformer model by using output embeddings from image patches and applying a point-wise linear decoder or a mask transformer decoder to obtain class labels. Our approach fine-tunes pre-trained image classification models using moderately sized datasets available for semantic segmentation. The linear decoder produces excellent results, with even better performance achieved through a mask transformer that generates class masks. We conducted an extensive study to analyze the impact of various parameters, finding that large models and small patch sizes lead to better performance. Segmenter achieves outstanding results for semantic segmentation, surpassing the state-of-the-art on both ADE20K and Pascal Context datasets and remaining competitive on Cityscapes.",1
"Elevator button recognition is a critical function to realize the autonomous operation of elevators. However, challenging image conditions and various image distortions make it difficult to recognize buttons accurately. To fill this gap, we propose a novel deep learning-based approach, which aims to autonomously correct perspective distortions of elevator button images based on button corner detection results. First, we leverage a novel image segmentation model and the Hough Transform method to obtain button segmentation and button corner detection results. Then, pixel coordinates of standard button corners are used as reference features to estimate camera motions for correcting perspective distortions. Fifteen elevator button images are captured from different angles of view as the dataset. The experimental results demonstrate that our proposed approach is capable of estimating camera motions and removing perspective distortions of elevator button images with high accuracy.",0
"Recognizing elevator buttons accurately is a crucial function for achieving autonomous elevator operation. However, recognizing buttons accurately is difficult due to challenging image conditions and various image distortions. To address this issue, we propose a new deep learning-based approach that autonomously corrects perspective distortions of elevator button images based on button corner detection results. First, we use a novel image segmentation model and the Hough Transform method to obtain button segmentation and button corner detection results. Then, we use the pixel coordinates of standard button corners as reference features to estimate camera motions for correcting perspective distortions. We captured fifteen elevator button images from different angles of view to create our dataset. Our experimental findings demonstrate that our proposed approach can estimate camera motions and remove perspective distortions of elevator button images with high accuracy.",1
"Deep learning has achieved remarkable success in medicalimage segmentation, but it usually requires a large numberof images labeled with fine-grained segmentation masks, andthe annotation of these masks can be very expensive andtime-consuming. Therefore, recent methods try to use un-supervised domain adaptation (UDA) methods to borrow in-formation from labeled data from other datasets (source do-mains) to a new dataset (target domain). However, due tothe absence of labels in the target domain, the performance ofUDA methods is much worse than that of the fully supervisedmethod. In this paper, we propose a weakly supervised do-main adaptation setting, in which we can partially label newdatasets with bounding boxes, which are easier and cheaperto obtain than segmentation masks. Accordingly, we proposea new weakly-supervised domain adaptation method calledBox-Adapt, which fully explores the fine-grained segmenta-tion mask in the source domain and the weak bounding boxin the target domain. Our Box-Adapt is a two-stage methodthat first performs joint training on the source and target do-mains, and then conducts self-training with the pseudo-labelsof the target domain. We demonstrate the effectiveness of ourmethod in the liver segmentation task. Weakly supervised do-main adaptation",0
"Medical image segmentation has seen impressive success through deep learning, although it typically necessitates a large number of labeled images with detailed segmentation masks. Creating these masks can be both costly and time-consuming. Therefore, recent approaches have attempted to use unsupervised domain adaptation (UDA) methods to leverage labeled data from other datasets (source domains) to a novel dataset (target domain). However, due to the absence of labels in the target domain, UDA methods have inferior performance compared to fully supervised methods. In this study, we propose a weakly supervised domain adaptation setting, enabling us to partially label new datasets with bounding boxes that are easier and cheaper to obtain than segmentation masks. Consequently, we propose a novel weakly supervised domain adaptation method, Box-Adapt, which fully explores the fine-grained segmentation mask in the source domain and the weak bounding box in the target domain. Box-Adapt is a two-stage method that initially performs joint training on the source and target domains, followed by self-training with the pseudo-labels of the target domain. We demonstrate the efficacy of our approach in liver segmentation tasks.",1
"Co-occurrent visual pattern makes aggregating contextual information a common paradigm to enhance the pixel representation for semantic image segmentation. The existing approaches focus on modeling the context from the perspective of the whole image, i.e., aggregating the image-level contextual information. Despite impressive, these methods weaken the significance of the pixel representations of the same category, i.e., the semantic-level contextual information. To address this, this paper proposes to augment the pixel representations by aggregating the image-level and semantic-level contextual information, respectively. First, an image-level context module is designed to capture the contextual information for each pixel in the whole image. Second, we aggregate the representations of the same category for each pixel where the category regions are learned under the supervision of the ground-truth segmentation. Third, we compute the similarities between each pixel representation and the image-level contextual information, the semantic-level contextual information, respectively. At last, a pixel representation is augmented by weighted aggregating both the image-level contextual information and the semantic-level contextual information with the similarities as the weights. Integrating the image-level and semantic-level context allows this paper to report state-of-the-art accuracy on four benchmarks, i.e., ADE20K, LIP, COCOStuff and Cityscapes.",0
"Aggregating contextual information to enhance pixel representation for semantic image segmentation is a common paradigm due to the co-occurrent visual pattern. However, existing approaches tend to focus on modeling the context from an image-level perspective, which weakens the significance of pixel representations for the same category. To solve this issue, this paper proposes a method that augments the pixel representations by separately aggregating image-level and semantic-level contextual information. First, an image-level context module captures contextual information for each pixel in the image. Second, representations for the same category are aggregated for each pixel using ground-truth segmentation. Third, similarities between each pixel representation and image-level and semantic-level contextual information are computed. Finally, pixel representations are augmented by weighted aggregation of both contextual information types. Integrating both image-level and semantic-level context leads to state-of-the-art accuracy on four benchmarks: ADE20K, LIP, COCOStuff, and Cityscapes.",1
"Thanks to their ability to learn flexible data-driven losses, Generative Adversarial Networks (GANs) are an integral part of many semi- and weakly-supervised methods for medical image segmentation. GANs jointly optimise a generator and an adversarial discriminator on a set of training data. After training has completed, the discriminator is usually discarded and only the generator is used for inference. But should we discard discriminators? In this work, we argue that training stable discriminators produces expressive loss functions that we can re-use at inference to detect and correct segmentation mistakes. First, we identify key challenges and suggest possible solutions to make discriminators re-usable at inference. Then, we show that we can combine discriminators with image reconstruction costs (via decoders) to further improve the model. Our method is simple and improves the test-time performance of pre-trained GANs. Moreover, we show that it is compatible with standard post-processing techniques and it has potentials to be used for Online Continual Learning. With our work, we open new research avenues for re-using adversarial discriminators at inference.",0
"Generative Adversarial Networks (GANs) have become a crucial aspect of many semi- and weakly-supervised methods for medical image segmentation due to their ability to learn flexible data-driven losses. During training, GANs optimize a generator and an adversarial discriminator using a set of training data, with the discriminator typically discarded after training and only the generator used for inference. However, this raises the question of whether we should discard the discriminators. This study argues that training stable discriminators can result in expressive loss functions that can be reused at inference to identify and correct segmentation errors. The study outlines the challenges and potential solutions for reusing discriminators at inference, and also demonstrates how combining discriminators with image reconstruction costs can further improve the model's performance. This approach is straightforward and enhances the test-time performance of pre-trained GANs, while also being compatible with standard post-processing techniques and offering potential for Online Continual Learning. This research opens up new avenues for reusing adversarial discriminators at inference.",1
"This paper studies the context aggregation problem in semantic image segmentation. The existing researches focus on improving the pixel representations by aggregating the contextual information within individual images. Though impressive, these methods neglect the significance of the representations of the pixels of the corresponding class beyond the input image. To address this, this paper proposes to mine the contextual information beyond individual images to further augment the pixel representations. We first set up a feature memory module, which is updated dynamically during training, to store the dataset-level representations of various categories. Then, we learn class probability distribution of each pixel representation under the supervision of the ground-truth segmentation. At last, the representation of each pixel is augmented by aggregating the dataset-level representations based on the corresponding class probability distribution. Furthermore, by utilizing the stored dataset-level representations, we also propose a representation consistent learning strategy to make the classification head better address intra-class compactness and inter-class dispersion. The proposed method could be effortlessly incorporated into existing segmentation frameworks (e.g., FCN, PSPNet, OCRNet and DeepLabV3) and brings consistent performance improvements. Mining contextual information beyond image allows us to report state-of-the-art performance on various benchmarks: ADE20K, LIP, Cityscapes and COCO-Stuff.",0
"The objective of this study is to examine the context aggregation issue in semantic image segmentation. Previous studies have concentrated on strengthening pixel representations by integrating contextual information within individual images. While these methods are impressive, they fail to consider the importance of pixel representations of the corresponding class beyond the input image. To address this, the paper suggests extracting contextual information beyond individual images to enhance pixel representations. A feature memory module is established to store dataset-level representations of different categories, which is dynamically updated during training. The class probability distribution of each pixel representation is learned under the guidance of the ground-truth segmentation. Finally, the corresponding class probability distribution is used to aggregate the dataset-level representations to enhance the pixel representation. Furthermore, a representation consistent learning strategy is proposed by utilizing the stored dataset-level representations to enhance the classification head's ability to address intra-class compactness and inter-class dispersion. The proposed method can be easily integrated into existing segmentation frameworks such as FCN, PSPNet, OCRNet, and DeepLabV3, resulting in consistent performance improvements. By mining contextual information beyond the image, the study achieved state-of-the-art performance on various benchmarks such as ADE20K, LIP, Cityscapes, and COCO-Stuff.",1
"Transformers have shown impressive performance in various natural language processing and computer vision tasks, due to the capability of modeling long-range dependencies. Recent progress has demonstrated to combine such transformers with CNN-based semantic image segmentation models is very promising. However, it is not well studied yet on how well a pure transformer based approach can achieve for image segmentation. In this work, we explore a novel framework for semantic image segmentation, which is encoder-decoder based Fully Transformer Networks (FTN). Specifically, we first propose a Pyramid Group Transformer (PGT) as the encoder for progressively learning hierarchical features, while reducing the computation complexity of the standard visual transformer(ViT). Then, we propose a Feature Pyramid Transformer (FPT) to fuse semantic-level and spatial-level information from multiple levels of the PGT encoder for semantic image segmentation. Surprisingly, this simple baseline can achieve new state-of-the-art results on multiple challenging semantic segmentation benchmarks, including PASCAL Context, ADE20K and COCO-Stuff. The source code will be released upon the publication of this work.",0
"The ability to model long-range dependencies has made transformers highly effective in natural language processing and computer vision tasks. Recent advancements have shown that combining transformers with CNN-based semantic image segmentation models is a promising approach. However, the effectiveness of a pure transformer-based approach for image segmentation has not been extensively studied. In this study, we introduce a novel framework for semantic image segmentation called Fully Transformer Networks (FTN), which is an encoder-decoder based approach. We propose a Pyramid Group Transformer (PGT) as the encoder to learn hierarchical features progressively, while reducing the computation complexity of the standard visual transformer (ViT). Additionally, we introduce a Feature Pyramid Transformer (FPT) to fuse semantic-level and spatial-level information from multiple levels of the PGT encoder for semantic image segmentation. Surprisingly, this straightforward approach outperforms existing state-of-the-art methods on challenging semantic segmentation benchmarks such as PASCAL Context, ADE20K, and COCO-Stuff. The source code will be made available upon publication of this research.",1
"The application of deep learning to medical image segmentation has been hampered due to the lack of abundant pixel-level annotated data. Few-shot Semantic Segmentation (FSS) is a promising strategy for breaking the deadlock. However, a high-performing FSS model still requires sufficient pixel-level annotated classes for training to avoid overfitting, which leads to its performance bottleneck in medical image segmentation due to the unmet need for annotations. Thus, semi-supervised FSS for medical images is accordingly proposed to utilize unlabeled data for further performance improvement. Nevertheless, existing semi-supervised FSS methods has two obvious defects: (1) neglecting the relationship between the labeled and unlabeled data; (2) using unlabeled data directly for end-to-end training leads to degenerated representation learning. To address these problems, we propose a novel semi-supervised FSS framework for medical image segmentation. The proposed framework employs Poisson learning for modeling data relationship and propagating supervision signals, and Spatial Consistency Calibration for encouraging the model to learn more coherent representations. In this process, unlabeled samples do not involve in end-to-end training, but provide supervisory information for query image segmentation through graph-based learning. We conduct extensive experiments on three medical image segmentation datasets (i.e. ISIC skin lesion segmentation, abdominal organs segmentation for MRI and abdominal organs segmentation for CT) to demonstrate the state-of-the-art performance and broad applicability of the proposed framework.",0
"Due to the scarcity of pixel-level annotated data, the application of deep learning in medical image segmentation has been hindered. Few-shot Semantic Segmentation (FSS) has shown promise in overcoming this challenge, but a successful FSS model still requires sufficient annotated classes to avoid overfitting. In medical image segmentation, this bottleneck is exacerbated by the lack of annotations. To address this, a semi-supervised FSS approach has been proposed that utilizes unlabeled data to improve performance. However, existing methods have two issues: they do not consider the relationship between labeled and unlabeled data, and using unlabeled data directly for end-to-end training leads to poor representation learning. To overcome these problems, we propose a novel semi-supervised FSS framework for medical image segmentation that employs Poisson learning to model data relationships and propagate supervision signals, and Spatial Consistency Calibration to encourage coherent representations. Unlabeled samples are not included in end-to-end training but instead provide supervisory information through graph-based learning. We demonstrate the effectiveness and versatility of our framework on three medical image segmentation datasets: ISIC skin lesion segmentation, abdominal organs segmentation for MRI, and abdominal organs segmentation for CT.",1
"Deep reinforcement learning augments the reinforcement learning framework and utilizes the powerful representation of deep neural networks. Recent works have demonstrated the remarkable successes of deep reinforcement learning in various domains including finance, medicine, healthcare, video games, robotics, and computer vision. In this work, we provide a detailed review of recent and state-of-the-art research advances of deep reinforcement learning in computer vision. We start with comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. We then propose a categorization of deep reinforcement learning methodologies and discuss their advantages and limitations. In particular, we divide deep reinforcement learning into seven main categories according to their applications in computer vision, i.e. (i)landmark localization (ii) object detection; (iii) object tracking; (iv) registration on both 2D image and 3D image volumetric data (v) image segmentation; (vi) videos analysis; and (vii) other applications. Each of these categories is further analyzed with reinforcement learning techniques, network design, and performance. Moreover, we provide a comprehensive analysis of the existing publicly available datasets and examine source code availability. Finally, we present some open issues and discuss future research directions on deep reinforcement learning in computer vision",0
"The utilization of deep neural networks has significantly enhanced the reinforcement learning framework, resulting in the emergence of deep reinforcement learning. Various domains such as finance, medicine, healthcare, video games, robotics, and computer vision have witnessed the exceptional achievements of deep reinforcement learning. This study closely examines the recent and state-of-the-art research advances in deep reinforcement learning in computer vision. The review commences by comprehending the theories of deep learning, reinforcement learning, and deep reinforcement learning. Additionally, the authors categorize deep reinforcement learning methodologies according to their applications in computer vision. The seven main categories include landmark localization, object detection, object tracking, registration on both 2D image and 3D image volumetric data, image segmentation, video analysis, and other applications. Each category is further analyzed with reinforcement learning techniques, network design, and performance. The paper also provides a comprehensive analysis of publicly available datasets and examines the availability of source code. Finally, open issues and future research directions on deep reinforcement learning in computer vision are discussed.",1
"Segmentation of images is a long-standing challenge in medical AI. This is mainly due to the fact that training a neural network to perform image segmentation requires a significant number of pixel-level annotated data, which is often unavailable. To address this issue, we propose a semi-supervised image segmentation technique based on the concept of multi-view learning. In contrast to the previous art, we introduce an adversarial form of dual-view training and employ a critic to formulate the learning problem in multi-view training as a min-max problem. Thorough quantitative and qualitative evaluations on several datasets indicate that our proposed method outperforms state-of-the-art medical image segmentation algorithms consistently and comfortably. The code is publicly available at https://github.com/himashi92/Duo-SegNet",0
"Medical AI has long struggled with segmenting images, as neural networks require a large amount of annotated data at the pixel level, which is often unavailable. To overcome this obstacle, we suggest a semi-supervised approach to image segmentation using multi-view learning. Our method differs from previous techniques as we utilize dual-view training with an adversarial component and a critic to formulate the learning problem as a min-max problem. Our evaluations on various datasets demonstrate that our approach surpasses state-of-the-art algorithms for medical image segmentation both quantitatively and qualitatively. The code for our proposed method is publicly accessible on https://github.com/himashi92/Duo-SegNet.",1
"We investigate Referring Image Segmentation (RIS), which outputs a segmentation map corresponding to the given natural language description. To solve RIS efficiently, we need to understand each word's relationship with other words, each region in the image to other regions, and cross-modal alignment between linguistic and visual domains. We argue that one of the limiting factors in the recent methods is that they do not handle these interactions simultaneously. To this end, we propose a novel architecture called JRNet, which uses a Joint Reasoning Module(JRM) to concurrently capture the inter-modal and intra-modal interactions. The output of JRM is passed through a novel Cross-Modal Multi-Level Fusion (CMMLF) module which further refines the segmentation masks by exchanging contextual information across visual hierarchy through linguistic features acting as a bridge. We present thorough ablation studies and validate our approach's performance on four benchmark datasets, showing considerable performance gains over the existing state-of-the-art methods.",0
"Our focus is on Referring Image Segmentation (RIS), which generates a segmentation map based on natural language descriptions. Efficiently solving RIS requires an understanding of word relationships, region connections, and cross-modal alignment between linguistic and visual domains. However, recent methods have not handled these interactions simultaneously, which limits their effectiveness. To address this, we propose the JRNet architecture, which includes a Joint Reasoning Module (JRM) to capture inter-modal and intra-modal interactions concurrently. The output of JRM is refined by passing it through the Cross-Modal Multi-Level Fusion (CMMLF) module, which exchanges contextual information across visual hierarchy through linguistic features. We confirm our approach's effectiveness through thorough ablation studies and demonstrate improved performance on four benchmark datasets compared to existing state-of-the-art methods.",1
"Pre-training a recognition model with contrastive learning on a large dataset of unlabeled data has shown great potential to boost the performance of a downstream task, e.g., image classification. However, in domains such as medical imaging, collecting unlabeled data can be challenging and expensive. In this work, we propose to adapt contrastive learning to work with meta-label annotations, for improving the model's performance in medical image segmentation even when no additional unlabeled data is available. Meta-labels such as the location of a 2D slice in a 3D MRI scan or the type of device used, often come for free during the acquisition process. We use the meta-labels for pre-training the image encoder as well as to regularize a semi-supervised training, in which a reduced set of annotated data is used for training. Finally, to fully exploit the weak annotations, a self-paced learning approach is used to help the learning and discriminate useful labels from noise. Results on three different medical image segmentation datasets show that our approach: i) highly boosts the performance of a model trained on a few scans, ii) outperforms previous contrastive and semi-supervised approaches, and iii) reaches close to the performance of a model trained on the full data.",0
"Training a recognition model for a downstream task, like image classification, using contrastive learning on a large set of unlabeled data has proven to be effective. However, obtaining unlabeled data can be difficult and costly in domains like medical imaging. To address this issue, we suggest using meta-label annotations, such as the location of a 2D slice in a 3D MRI scan or the type of device used, to adapt contrastive learning and improve the model's performance in medical image segmentation. We use the meta-labels to pre-train the image encoder and regulate a semi-supervised training with a limited set of annotated data. Additionally, we apply a self-paced learning approach to fully utilize the weak annotations and distinguish useful labels from noise. Our approach significantly enhances the model's performance on a few scans, surpasses previous contrastive and semi-supervised methods, and achieves results almost as good as a model trained on the entire dataset. We demonstrate these outcomes on three distinct medical image segmentation datasets.",1
"Federated learning (FL) for medical image segmentation becomes more challenging in multi-task settings where clients might have different categories of labels represented in their data. For example, one client might have patient data with ""healthy'' pancreases only while datasets from other clients may contain cases with pancreatic tumors. The vanilla federated averaging algorithm makes it possible to obtain more generalizable deep learning-based segmentation models representing the training data from multiple institutions without centralizing datasets. However, it might be sub-optimal for the aforementioned multi-task scenarios. In this paper, we investigate heterogeneous optimization methods that show improvements for the automated segmentation of pancreas and pancreatic tumors in abdominal CT images with FL settings.",0
"Medical image segmentation using federated learning (FL) becomes more complex when dealing with multi-task situations where clients have different categories of labels in their data. For instance, one client may have data with ""healthy"" pancreases, while other clients' datasets could have pancreatic tumors. Although the vanilla federated averaging algorithm allows for obtaining deep learning-based segmentation models that are more generalizable and represent the training data from multiple institutions without centralizing datasets, it might not be optimal for multi-task scenarios. This paper explores heterogeneous optimization methods that enhance the automated segmentation of pancreas and pancreatic tumors in abdominal CT images under FL settings.",1
"Membership inference attacks (MIA) try to detect if data samples were used to train a neural network model, e.g. to detect copyright abuses. We show that models with higher dimensional input and output are more vulnerable to MIA, and address in more detail models for image translation and semantic segmentation, including medical image segmentation. We show that reconstruction-errors can lead to very effective MIA attacks as they are indicative of memorization. Unfortunately, reconstruction error alone is less effective at discriminating between non-predictable images used in training and easy to predict images that were never seen before. To overcome this, we propose using a novel predictability error that can be computed for each sample, and its computation does not require a training set. Our membership error, obtained by subtracting the predictability error from the reconstruction error, is shown to achieve high MIA accuracy on an extensive number of benchmarks.",0
"The objective of membership inference attacks (MIA) is to identify whether a neural network model has been trained using certain data samples, such as those used for detecting copyright violations. Our research indicates that MIA is more successful when targeting models with higher dimensional input and output, particularly those used for image translation and semantic segmentation, including medical image segmentation. We discovered that reconstruction errors can be used for MIA attacks by detecting memorization; however, this method is not effective in distinguishing between non-predictable images used during training and easily predictable images that were not previously seen. To address this limitation, we proposed a new method called predictability error, which can be calculated for each sample without the need for a training set. By subtracting the predictability error from the reconstruction error, we obtained a membership error that achieved high MIA accuracy across several benchmarks.",1
"Weakly supervised image segmentation trained with image-level labels usually suffers from inaccurate coverage of object areas during the generation of the pseudo groundtruth. This is because the object activation maps are trained with the classification objective and lack the ability to generalize. To improve the generality of the objective activation maps, we propose a region prototypical network RPNet to explore the cross-image object diversity of the training set. Similar object parts across images are identified via region feature comparison. Object confidence is propagated between regions to discover new object areas while background regions are suppressed. Experiments show that the proposed method generates more complete and accurate pseudo object masks, while achieving state-of-the-art performance on PASCAL VOC 2012 and MS COCO. In addition, we investigate the robustness of the proposed method on reduced training sets.",0
"Image segmentation trained with weak supervision using image-level labels often results in inaccurate object coverage due to the generation of pseudo groundtruths. This is because the object activation maps lack the ability to generalize, as they are trained with the classification objective. To address this issue, we introduce the region prototypical network (RPNet), which explores cross-image object diversity in the training set to improve the generality of the objective activation maps. RPNet identifies similar object parts across images using region feature comparison and propagates object confidence between regions to discover new object areas while suppressing background regions. Experimental results demonstrate that our proposed method generates more complete and accurate pseudo object masks, achieving state-of-the-art performance on PASCAL VOC 2012 and MS COCO. We also evaluate the robustness of our method on reduced training sets.",1
"Automated segmentation in medical image analysis is a challenging task that requires a large amount of manually labeled data. However, most existing learning-based approaches usually suffer from limited manually annotated medical data, which poses a major practical problem for accurate and robust medical image segmentation. In addition, most existing semi-supervised approaches are usually not robust compared with the supervised counterparts, and also lack explicit modeling of geometric structure and semantic information, both of which limit the segmentation accuracy. In this work, we present SimCVD, a simple contrastive distillation framework that significantly advances state-of-the-art voxel-wise representation learning. We first describe an unsupervised training strategy, which takes two views of an input volume and predicts their signed distance maps of object boundaries in a contrastive objective, with only two independent dropout as mask. This simple approach works surprisingly well, performing on the same level as previous fully supervised methods with much less labeled data. We hypothesize that dropout can be viewed as a minimal form of data augmentation and makes the network robust to representation collapse. Then, we propose to perform structural distillation by distilling pair-wise similarities. We evaluate SimCVD on two popular datasets: the Left Atrial Segmentation Challenge (LA) and the NIH pancreas CT dataset. The results on the LA dataset demonstrate that, in two types of labeled ratios (i.e., 20% and 10%), SimCVD achieves an average Dice score of 90.85% and 89.03% respectively, a 0.91% and 2.22% improvement compared to previous best results. Our method can be trained in an end-to-end fashion, showing the promise of utilizing SimCVD as a general framework for downstream tasks, such as medical image synthesis and registration.",0
"The task of automated segmentation in medical image analysis is difficult and requires a significant amount of manually labeled data. However, current learning-based methods are often limited by the lack of annotated medical data, which results in inaccurate and unreliable medical image segmentation. Furthermore, semi-supervised approaches are not as robust as supervised methods and do not adequately model geometric structure and semantic information, leading to limited segmentation accuracy. To address these issues, we introduce SimCVD, a contrastive distillation framework that enhances voxel-wise representation learning. Our unsupervised training strategy uses two views of an input volume to predict signed distance maps of object boundaries in a contrastive objective, with only two independent dropout masks. This simple approach performs as well as previous fully supervised methods with less labeled data, and dropout is viewed as a minimal form of data augmentation that prevents representation collapse. We also propose performing structural distillation by distilling pair-wise similarities. We evaluate SimCVD on two popular datasets, the Left Atrial Segmentation Challenge (LA) and the NIH pancreas CT dataset. Results on the LA dataset show that SimCVD achieves an average Dice score of 90.85% and 89.03% for labeled ratios of 20% and 10%, respectively, which is a 0.91% and 2.22% improvement compared to previous best results. Our method can be trained end-to-end and holds promise for downstream tasks such as medical image synthesis and registration.",1
"Accurate automatic liver and tumor segmentation plays a vital role in treatment planning and disease monitoring. Recently, deep convolutional neural network (DCNNs) has obtained tremendous success in 2D and 3D medical image segmentation. However, 2D DCNNs cannot fully leverage the inter-slice information, while 3D DCNNs are computationally expensive and memory intensive. To address these issues, we first propose a novel dense-sparse training flow from a data perspective, in which, densely adjacent slices and sparsely adjacent slices are extracted as inputs for regularizing DCNNs, thereby improving the model performance. Moreover, we design a 2.5D light-weight nnU-Net from a network perspective, in which, depthwise separable convolutions are adopted to improve the efficiency. Extensive experiments on the LiTS dataset have demonstrated the superiority of the proposed method.",0
"Precise automatic segmentation of the liver and tumors is crucial for proper treatment planning and monitoring of diseases. While deep convolutional neural networks (DCNNs) have proven to be successful in 2D and 3D medical image segmentation, 2D DCNNs cannot fully utilize inter-slice information, while 3D DCNNs are computationally expensive and require high memory usage. To overcome these limitations, we propose a unique approach using a dense-sparse training flow that extracts densely and sparsely adjacent slices as inputs to improve DCNN model performance. Additionally, we introduce a 2.5D lightweight nnU-Net that utilizes depthwise separable convolutions to enhance efficiency. Our method outperforms existing techniques, as demonstrated in extensive experiments using the LiTS dataset.",1
"Unmanned aerial vehicles (UAVs) equipped with multiple complementary sensors have tremendous potential for fast autonomous or remote-controlled semantic scene analysis, e.g., for disaster examination. In this work, we propose a UAV system for real-time semantic inference and fusion of multiple sensor modalities. Semantic segmentation of LiDAR scans and RGB images, as well as object detection on RGB and thermal images, run online onboard the UAV computer using lightweight CNN architectures and embedded inference accelerators. We follow a late fusion approach where semantic information from multiple modalities augments 3D point clouds and image segmentation masks while also generating an allocentric semantic map. Our system provides augmented semantic images and point clouds with $\approx\,$9$\,$Hz. We evaluate the integrated system in real-world experiments in an urban environment.",0
"The potential of unmanned aerial vehicles (UAVs) equipped with various sensors for fast autonomous or remote-controlled semantic scene analysis, such as disaster examination, is enormous. This study presents a UAV system that performs real-time semantic inference and fusion of multiple sensor modalities. The UAV computer conducts semantic segmentation of LiDAR scans and RGB images, as well as object detection on RGB and thermal images, online. The system adopts a late fusion approach, where semantic information from various modalities enhances 3D point clouds and image segmentation masks, and generates an allocentric semantic map. Our system produces augmented semantic images and point clouds at approximately 9 Hz. We evaluate the integrated system in real-world experiments in an urban setting.",1
"The random walker method for image segmentation is a popular tool for semi-automatic image segmentation, especially in the biomedical field. However, its linear asymptotic run time and memory requirements make application to 3D datasets of increasing sizes impractical. We propose a hierarchical framework that, to the best of our knowledge, is the first attempt to overcome these restrictions for the random walker algorithm and achieves sublinear run time and constant memory complexity. The goal of this framework is -- rather than improving the segmentation quality compared to the baseline method -- to make interactive segmentation on out-of-core datasets possible. The method is evaluated quantitavely on synthetic data and the CT-ORG dataset where the expected improvements in algorithm run time while maintaining high segmentation quality are confirmed. The incremental (i.e., interaction update) run time is demonstrated to be in seconds on a standard PC even for volumes of hundreds of Gigabytes in size. In a small case study the applicability to large real world from current biomedical research is demonstrated. An implementation of the presented method is publicly available in version 5.2 of the widely used volume rendering and processing software Voreen (https://www.uni-muenster.de/Voreen/).",0
"The random walker technique is a well-known approach for semi-automatic image segmentation, particularly in the biomedical sector. However, due to its linear asymptotic run time and memory requirements, using it for 3D datasets of growing sizes is not feasible. To address this issue, we have introduced a hierarchical framework that is the first attempt to overcome these limitations for the random walker algorithm and achieve sublinear run time and constant memory complexity. Our aim is not to improve the segmentation quality compared to the baseline method, but to make interactive segmentation possible on out-of-core datasets. We tested our method on synthetic data and the CT-ORG dataset, and confirmed the expected improvements in algorithm run time while maintaining high segmentation quality. The incremental run time for interaction updates is only seconds on a standard PC, even for volumes of hundreds of Gigabytes in size. In a small case study, we demonstrated the applicability of the method to large real-world biomedical research datasets. An implementation of our method is now publicly accessible in version 5.2 of the popular volume rendering and processing software Voreen (https://www.uni-muenster.de/Voreen/).",1
"In this work, we address the challenging task of few-shot segmentation. Previous few-shot segmentation methods mainly employ the information of support images as guidance for query image segmentation. Although some works propose to build cross-reference between support and query images, their extraction of query information still depends on the support images. We here propose to extract the information from the query itself independently to benefit the few-shot segmentation task. To this end, we first propose a prior extractor to learn the query information from the unlabeled images with our proposed global-local contrastive learning. Then, we extract a set of predetermined priors via this prior extractor. With the obtained priors, we generate the prior region maps for query images, which locate the objects, as guidance to perform cross interaction with support features. In such a way, the extraction of query information is detached from the support branch, overcoming the limitation by support, and could obtain more informative query clues to achieve better interaction. Without bells and whistles, the proposed approach achieves new state-of-the-art performance for the few-shot segmentation task on PASCAL-5$^{i}$ and COCO datasets.",0
"This study addresses the complex task of few-shot segmentation. Existing approaches for few-shot segmentation rely on support images to guide the segmentation of query images. While some studies suggest creating a cross-reference between support and query images, the extraction of query information still depends on support images. In this paper, we propose extracting information from query images independently to enhance few-shot segmentation. We introduce a prior extractor that learns query information from unlabeled images using global-local contrastive learning. We then extract predetermined priors using this extractor and use them to generate prior region maps for query images, which locate objects and guide cross interaction with support features. This approach detaches the extraction of query information from the support branch, overcomes the limitations of support, and obtains more informative query clues for better interaction. Our approach achieves state-of-the-art performance for few-shot segmentation on PASCAL-5$^{i}$ and COCO datasets without any additional features.",1
"In this paper, we present a new network named Attention Aware Network (AASeg) for real time semantic image segmentation. Our network incorporates spatial and channel information using Spatial Attention (SA) and Channel Attention (CA) modules respectively. It also uses dense local multi-scale context information using Multi Scale Context (MSC) module. The feature maps are concatenated individually to produce the final segmentation map. We demonstrate the effectiveness of our method using a comprehensive analysis, quantitative experimental results and ablation study using Cityscapes, ADE20K and Camvid datasets. Our network performs better than most previous architectures with a 74.4\% Mean IOU on Cityscapes test dataset while running at 202.7 FPS.",0
"The Attention Aware Network (AASeg) is introduced in this study as a new network for real-time semantic image segmentation. Our network incorporates Spatial Attention (SA) and Channel Attention (CA) modules to incorporate spatial and channel information, respectively. Additionally, our network utilizes Multi Scale Context (MSC) module to incorporate dense local multi-scale context information. The final segmentation map is produced by concatenating the feature maps individually. We prove the effectiveness of our method through a comprehensive analysis, quantitative experimental results, and ablation study using Cityscapes, ADE20K, and Camvid datasets. Our network outperforms most previous architectures, achieving a 74.4% Mean IOU on Cityscapes test dataset with a running speed of 202.7 FPS.",1
"The development of high quality medical image segmentation algorithms depends on the availability of large datasets with pixel-level labels. The challenges of collecting such datasets, especially in case of 3D volumes, motivate to develop approaches that can learn from other types of labels that are cheap to obtain, e.g. bounding boxes. We focus on 3D medical images with their corresponding 3D bounding boxes which are considered as series of per-slice non-tight 2D bounding boxes. While current weakly-supervised approaches that use 2D bounding boxes as weak labels can be applied to medical image segmentation, we show that their success is limited in cases when the assumption about the tightness of the bounding boxes breaks. We propose a new bounding box correction framework which is trained on a small set of pixel-level annotations to improve the tightness of a larger set of non-tight bounding box annotations. The effectiveness of our solution is demonstrated by evaluating a known weakly-supervised segmentation approach with and without the proposed bounding box correction algorithm. When the tightness is improved by our solution, the results of the weakly-supervised segmentation become much closer to those of the fully-supervised one.",0
"To develop accurate medical image segmentation algorithms, a large dataset with pixel-level labels is necessary. However, collecting such datasets, especially for 3D volumes, is challenging. This has led to the development of methods that can learn from other types of labels that are easier to obtain, such as bounding boxes. Our focus is on 3D medical images and their corresponding 3D bounding boxes, which consist of a series of per-slice non-tight 2D bounding boxes. While weakly-supervised approaches that use 2D bounding boxes as weak labels can be applied to medical image segmentation, their success is limited when the bounding boxes are not tight. To address this, we propose a new bounding box correction framework that is trained on a small set of pixel-level annotations to improve the tightness of a larger set of non-tight bounding box annotations. Our solution improves the results of a known weakly-supervised segmentation approach, bringing them closer to those of a fully-supervised one.",1
"Contrastive Learning (CL) is a recent representation learning approach, which encourages inter-class separability and intra-class compactness in learned image representations. Since medical images often contain multiple semantic classes in an image, using CL to learn representations of local features (as opposed to global) is important. In this work, we present a novel semi-supervised 2D medical segmentation solution that applies CL on image patches, instead of full images. These patches are meaningfully constructed using the semantic information of different classes obtained via pseudo labeling. We also propose a novel consistency regularization (CR) scheme, which works in synergy with CL. It addresses the problem of confirmation bias, and encourages better clustering in the feature space. We evaluate our method on four public medical segmentation datasets and a novel histopathology dataset that we introduce. Our method obtains consistent improvements over state-of-the-art semi-supervised segmentation approaches for all datasets.",0
"The approach of Contrastive Learning (CL) is a recent development in representation learning, which emphasizes the separation of different classes while maintaining compactness within each class in learned image representations. In medical images, where multiple semantic classes are often present, it is crucial to use CL to learn representations of local features rather than global ones. This work proposes a new semi-supervised 2D medical segmentation solution that utilizes CL on image patches, rather than full images, which are constructed meaningfully using semantic information from different classes obtained via pseudo labeling. Additionally, a new consistency regularization (CR) scheme is proposed to address confirmation bias and promote better clustering in the feature space. The proposed method is evaluated on four public medical segmentation datasets and a new histopathology dataset, demonstrating consistent improvements over state-of-the-art semi-supervised segmentation approaches for all datasets.",1
"Domain adaptation (DA) has drawn high interest for its capacity to adapt a model trained on labeled source data to perform well on unlabeled or weakly labeled target data from a different domain. Most common DA techniques require concurrent access to the input images of both the source and target domains. However, in practice, privacy concerns often impede the availability of source images in the adaptation phase. This is a very frequent DA scenario in medical imaging, where, for instance, the source and target images could come from different clinical sites. We introduce a source-free domain adaptation for image segmentation. Our formulation is based on minimizing a label-free entropy loss defined over target-domain data, which we further guide with a domain-invariant prior on the segmentation regions. Many priors can be derived from anatomical information. Here, a class ratio prior is estimated from anatomical knowledge and integrated in the form of a Kullback Leibler (KL) divergence in our overall loss function. Furthermore, we motivate our overall loss with an interesting link to maximizing the mutual information between the target images and their label predictions. We show the effectiveness of our prior aware entropy minimization in a variety of domain-adaptation scenarios, with different modalities and applications, including spine, prostate, and cardiac segmentation. Our method yields comparable results to several state of the art adaptation techniques, despite having access to much less information, as the source images are entirely absent in our adaptation phase. Our straightforward adaptation strategy uses only one network, contrary to popular adversarial techniques, which are not applicable to a source-free DA setting. Our framework can be readily used in a breadth of segmentation problems, and our code is publicly available: https://github.com/mathilde-b/SFDA",0
"Domain adaptation (DA) is a highly sought-after technique that enables a model trained on labeled source data to perform well on unlabeled or weakly labeled target data from a different domain. However, most DA techniques necessitate simultaneous access to the input images of both the source and target domains, which is often impeded by privacy concerns in practice. This is a prevalent DA scenario in medical imaging, where the source and target images may come from different clinical sites. To address this issue, we present a source-free domain adaptation approach for image segmentation. Our approach involves minimizing a label-free entropy loss based on target-domain data, which is further guided by a domain-invariant prior on the segmentation regions, derived from anatomical information. We estimate a class ratio prior from anatomical knowledge and integrate it in the form of a Kullback Leibler (KL) divergence in our overall loss function. In addition, we establish a connection between maximizing the mutual information between the target images and their label predictions and our overall loss function. Our approach yields results comparable to several state-of-the-art adaptation techniques, despite having access to much less information. Our framework is simple and utilizes only one network, unlike popular adversarial techniques that are not suitable for a source-free DA setting. It can be applied to a variety of segmentation problems, and our code is available at https://github.com/mathilde-b/SFDA.",1
"Semantic segmentation of medical images is an essential first step in computer-aided diagnosis systems for many applications. However, given many disparate imaging modalities and inherent variations in the patient data, it is difficult to consistently achieve high accuracy using modern deep neural networks (DNNs). This has led researchers to propose interactive image segmentation techniques where a medical expert can interactively correct the output of a DNN to the desired accuracy. However, these techniques often need separate training data with the associated human interactions, and do not generalize to various diseases, and types of medical images. In this paper, we suggest a novel conditional inference technique for DNNs which takes the intervention by a medical expert as test time constraints and performs inference conditioned upon these constraints. Our technique is generic can be used for medical images from any modality. Unlike other methods, our approach can correct multiple structures simultaneously and add structures missed at initial segmentation. We report an improvement of 13.3, 12.5, 17.8, 10.2, and 12.4 times in user annotation time than full human annotation for the nucleus, multiple cells, liver and tumor, organ, and brain segmentation respectively. We report a time saving of 2.8, 3.0, 1.9, 4.4, and 8.6 fold compared to other interactive segmentation techniques. Our method can be useful to clinicians for diagnosis and post-surgical follow-up with minimal intervention from the medical expert. The source-code and the detailed results are available here [1].",0
"The initial stage in computer-aided diagnosis systems for various applications involves semantic segmentation of medical images. However, it is challenging to attain high accuracy consistently due to the diverse imaging modalities and inherent variations in patient data, with modern deep neural networks (DNNs). Researchers have proposed interactive image segmentation techniques where a medical professional can correct the output of a DNN interactively to achieve the desired accuracy. However, these techniques require separate training data and human interactions, which do not generalize to various diseases and types of medical images. In this study, we propose a novel conditional inference technique for DNNs that considers medical expert intervention as test time constraints and performs inference conditioned on these constraints. Our approach is generic and can be used for medical images from any modality. Unlike other methods, our approach can correct multiple structures simultaneously and add structures missed at initial segmentation. Compared to full human annotation, our technique decreased user annotation time by 13.3, 12.5, 17.8, 10.2, and 12.4 times for nucleus, multiple cells, liver and tumor, organ, and brain segmentation, respectively. Our method saves time by 2.8, 3.0, 1.9, 4.4, and 8.6 times compared to other interactive segmentation techniques. Clinicians can use our method for diagnosis and post-surgical follow-up with minimal intervention from the medical expert. The source-code and detailed results are available in [1].",1
"Recent advances in brain clearing and imaging have made it possible to image entire mammalian brains at sub-micron resolution. These images offer the potential to assemble brain-wide atlases of projection neuron morphology, but manual neuron reconstruction remains a bottleneck. In this paper we present a probabilistic method which combines a hidden Markov state process that encodes neuron geometric properties with a random field appearance model of the flourescence process. Our method utilizes dynamic programming to efficiently compute the global maximizers of what we call the ""most probable"" neuron path. We applied our algorithm to the output of image segmentation models where false negatives severed neuronal processes, and showed that it can follow axons in the presence of noise or nearby neurons. Our method has the potential to be integrated into a semi or fully automated reconstruction pipeline. Additionally, it creates a framework for conditioning the probability to fixed start and endpoints through which users can intervene with hard constraints to, for example, rule out certain reconstructions, or assign axons to particular cell bodies.",0
"Recent advancements in brain imaging and clearing techniques have enabled the imaging of entire mammalian brains at a sub-micron resolution. These images have the potential to create brain-wide atlases of projection neuron morphology. However, manual neuron reconstruction is still a major obstacle. This paper proposes a probabilistic method that utilizes a hidden Markov state process to encode neuron geometry along with a random field appearance model of the fluorescence process. The method utilizes dynamic programming to efficiently compute the global maximum of the ""most probable"" neuron path. The algorithm was applied to images where false negatives severed neuronal processes, and it was shown that it can track axons in the presence of noise or nearby neurons. The proposed method has the potential to be integrated into a semi or fully automated reconstruction pipeline. The method also provides a framework for conditioning the probability to fixed start and endpoints, allowing users to intervene with hard constraints to rule out certain reconstructions or assign axons to specific cell bodies.",1
"Quantifying uncertainty in medical image segmentation applications is essential, as it is often connected to vital decision-making. Compelling attempts have been made in quantifying the uncertainty in image segmentation architectures, e.g. to learn a density segmentation model conditioned on the input image. Typical work in this field restricts these learnt densities to be strictly Gaussian. In this paper, we propose to use a more flexible approach by introducing Normalizing Flows (NFs), which enables the learnt densities to be more complex and facilitate more accurate modeling for uncertainty. We prove this hypothesis by adopting the Probabilistic U-Net and augmenting the posterior density with an NF, allowing it to be more expressive. Our qualitative as well as quantitative (GED and IoU) evaluations on the multi-annotated and single-annotated LIDC-IDRI and Kvasir-SEG segmentation datasets, respectively, show a clear improvement. This is mostly apparent in the quantification of aleatoric uncertainty and the increased predictive performance of up to 14 percent. This result strongly indicates that a more flexible density model should be seriously considered in architectures that attempt to capture segmentation ambiguity through density modeling. The benefit of this improved modeling will increase human confidence in annotation and segmentation, and enable eager adoption of the technology in practice.",0
"Accurately measuring uncertainty in medical image segmentation is crucial for making important decisions. Previous attempts to quantify uncertainty in image segmentation models have been limited to Gaussian density models. However, in this paper, we propose a more flexible approach using Normalizing Flows (NFs) to create more complex density models that better capture uncertainty. We tested this hypothesis by using NFs to augment the posterior density in a Probabilistic U-Net model and evaluating the results on the LIDC-IDRI and Kvasir-SEG datasets. Our findings show a significant improvement in predicting uncertainty and segmentation accuracy, with up to a 14 percent increase in performance. This demonstrates the importance of adopting more flexible density models in segmentation architectures to increase human confidence in annotation and segmentation and encourage widespread adoption of this technology.",1
"Shape modelling (with methods that output shapes) is a new and important task in Bayesian nonparametrics and bioinformatics. In this work, we focus on Bayesian nonparametric methods for capturing shapes by partitioning a space using curves. In related work, the classical Mondrian process is used to partition spaces recursively with axis-aligned cuts, and is widely applied in multi-dimensional and relational data. The Mondrian process outputs hyper-rectangles. Recently, the random tessellation process was introduced as a generalization of the Mondrian process, partitioning a domain with non-axis aligned cuts in an arbitrary dimensional space, and outputting polytopes. Motivated by these processes, in this work, we propose a novel parallelized Bayesian nonparametric approach to partition a domain with curves, enabling complex data-shapes to be acquired. We apply our method to HIV-1-infected human macrophage image dataset, and also simulated datasets sets to illustrate our approach. We compare to support vector machines, random forests and state-of-the-art computer vision methods such as simple linear iterative clustering super pixel image segmentation. We develop an R package that is available at \url{https://github.com/ShufeiGe/Shape-Modeling-with-Spline-Partitions}.",0
"The task of shape modelling, which involves producing shapes, is a crucial and modern objective in Bayesian nonparametrics and bioinformatics. This study concentrates on Bayesian nonparametric techniques that use curves to divide a space to capture shapes. In prior studies, the Mondrian process has been utilized to partition spaces recursively using axis-aligned cuts and is commonly used in multidimensional and relational data. The output of the Mondrian process is hyper-rectangles. Recently, the random tessellation method was introduced as an extension of the Mondrian process, dividing a domain using non-axis aligned cuts in any dimension space and generating polytopes. Based on these methods, this research proposes a new parallelized Bayesian nonparametric approach that uses curves to partition a domain, allowing for intricate data shapes to be obtained. To illustrate our approach, we use it on a dataset of HIV-1-infected human macrophages and simulated datasets. We compare our approach to support vector machines, random forests, and cutting-edge computer vision techniques like simple linear iterative clustering super pixel image segmentation. We have also created an R package that can be found at \url{https://github.com/ShufeiGe/Shape-Modeling-with-Spline-Partitions}.",1
"While improving prediction accuracy has been the focus of machine learning in recent years, this alone does not suffice for reliable decision-making. Deploying learning systems in consequential settings also requires calibrating and communicating the uncertainty of predictions. To convey instance-wise uncertainty for prediction tasks, we show how to generate set-valued predictions from a black-box predictor that control the expected loss on future test points at a user-specified level. Our approach provides explicit finite-sample guarantees for any dataset by using a holdout set to calibrate the size of the prediction sets. This framework enables simple, distribution-free, rigorous error control for many tasks, and we demonstrate it in five large-scale machine learning problems: (1) classification problems where some mistakes are more costly than others; (2) multi-label classification, where each observation has multiple associated labels; (3) classification problems where the labels have a hierarchical structure; (4) image segmentation, where we wish to predict a set of pixels containing an object of interest; and (5) protein structure prediction. Lastly, we discuss extensions to uncertainty quantification for ranking, metric learning and distributionally robust learning.",0
"Although machine learning has been primarily focused on improving prediction accuracy in recent years, this alone is insufficient for dependable decision-making. To effectively implement learning systems in consequential settings, it is necessary to both calibrate and communicate the uncertainty of predictions. We present a method for generating set-valued predictions from a black-box predictor that regulates the expected loss on future test points at a level specified by the user, in order to communicate instance-wise uncertainty for prediction tasks. Our approach utilizes a holdout set to calibrate the size of the prediction sets and provides explicit finite-sample guarantees for any dataset. This framework offers straightforward, distribution-free, and rigorous error control for many tasks, including five large-scale machine learning problems: (1) classification problems where certain mistakes are more costly than others; (2) multi-label classification with multiple associated labels for each observation; (3) classification problems with hierarchical label structures; (4) image segmentation for predicting a set of pixels containing an object of interest; and (5) protein structure prediction. Finally, we discuss extensions to uncertainty quantification for ranking, metric learning, and distributionally robust learning.",1
"Although having achieved great success in medical image segmentation, deep convolutional neural networks usually require a large dataset with manual annotations for training and are difficult to generalize to unseen classes. Few-shot learning has the potential to address these challenges by learning new classes from only a few labeled examples. In this work, we propose a new framework for few-shot medical image segmentation based on prototypical networks. Our innovation lies in the design of two key modules: 1) a context relation encoder (CRE) that uses correlation to capture local relation features between foreground and background regions; and 2) a recurrent mask refinement module that repeatedly uses the CRE and a prototypical network to recapture the change of context relationship and refine the segmentation mask iteratively. Experiments on two abdomen CT datasets and an abdomen MRI dataset show the proposed method obtains substantial improvement over the state-of-the-art methods by an average of 16.32%, 8.45% and 6.24% in terms of DSC, respectively. Code is publicly available.",0
"Though deep convolutional neural networks have achieved great success in medical image segmentation, they typically necessitate a large dataset with manual annotations for effective training and struggle to generalize to new classes. However, few-shot learning offers a promising solution by enabling the learning of new classes with only a few labeled examples. To this end, we propose a novel prototypical network-based framework for few-shot medical image segmentation, featuring two key modules: a context relation encoder (CRE) that leverages correlation to capture local relation features between foreground and background regions, and a recurrent mask refinement module that utilizes the CRE and a prototypical network to iteratively refine the segmentation mask and recapture changes in context relationship. Our experiments on two abdomen CT datasets and an abdomen MRI dataset demonstrate significant improvement over state-of-the-art methods, with an average increase of 16.32%, 8.45%, and 6.24% in DSC, respectively. Our code is publicly available.",1
"Semi-supervised learning (SSL) uses unlabeled data during training to learn better models. Previous studies on SSL for medical image segmentation focused mostly on improving model generalization to unseen data. In some applications, however, our primary interest is not generalization but to obtain optimal predictions on a specific unlabeled database that is fully available during model development. Examples include population studies for extracting imaging phenotypes. This work investigates an often overlooked aspect of SSL, transduction. It focuses on the quality of predictions made on the unlabeled data of interest when they are included for optimization during training, rather than improving generalization. We focus on the self-training framework and explore its potential for transduction. We analyze it through the lens of Information Gain and reveal that learning benefits from the use of calibrated or under-confident models. Our extensive experiments on a large MRI database for multi-class segmentation of traumatic brain lesions shows promising results when comparing transductive with inductive predictions. We believe this study will inspire further research on transductive learning, a well-suited paradigm for medical image analysis.",0
"Semi-supervised learning (SSL) is a technique that uses unlabeled data during training to improve model performance. While previous research has focused on enhancing model generalization to unseen data in medical image segmentation, there are instances where obtaining optimal predictions on a specific unlabeled database is the primary objective, such as in population studies for imaging phenotypes. This study examines the often-neglected aspect of SSL, transduction, which prioritizes the quality of predictions on the unlabeled data of interest during training instead of improving generalization. We investigate the potential of transduction in the self-training framework and evaluate it using Information Gain. Our results suggest that calibrated or under-confident models are beneficial for learning. We conduct extensive experiments on a large MRI dataset for multi-class segmentation of traumatic brain lesions, and the comparison of transductive with inductive predictions shows promising results. We anticipate that this study will encourage further research on transductive learning, which is well-suited for medical image analysis.",1
"When confronted with objects of unknown types in an image, humans can effortlessly and precisely tell their visual boundaries. This recognition mechanism and underlying generalization capability seem to contrast to state-of-the-art image segmentation networks that rely on large-scale category-aware annotated training samples. In this paper, we make an attempt towards building models that explicitly account for visual boundary knowledge, in hope to reduce the training effort on segmenting unseen categories. Specifically, we investigate a new task termed as Boundary Knowledge Translation (BKT). Given a set of fully labeled categories, BKT aims to translate the visual boundary knowledge learned from the labeled categories, to a set of novel categories, each of which is provided only a few labeled samples. To this end, we propose a Translation Segmentation Network (Trans-Net), which comprises a segmentation network and two boundary discriminators. The segmentation network, combined with a boundary-aware self-supervised mechanism, is devised to conduct foreground segmentation, while the two discriminators work together in an adversarial manner to ensure an accurate segmentation of the novel categories under light supervision. Exhaustive experiments demonstrate that, with only tens of labeled samples as guidance, Trans-Net achieves close results on par with fully supervised methods.",0
"Humans possess the ability to effortlessly and accurately identify the visual boundaries of unfamiliar objects in images, which contrasts with current image segmentation networks that require large-scale annotated training data for specific categories. This paper aims to address this issue by developing models that incorporate visual boundary knowledge to reduce the training required for segmenting new categories. The proposed method is called Boundary Knowledge Translation (BKT), which translates visual boundary knowledge from fully labeled categories to novel categories with only a few labeled samples. The Translation Segmentation Network (Trans-Net) is introduced, which consists of a segmentation network and two boundary discriminators. The segmentation network, with a boundary-aware self-supervised mechanism, performs foreground segmentation, while the two discriminators work together adversarially to ensure precise segmentation of the new categories with limited supervision. The results of numerous experiments demonstrate that Trans-Net can achieve comparable results to fully supervised methods with only a small number of labeled samples.",1
"Machine learning techniques have been paramount throughout the last years, being applied in a wide range of tasks, such as classification, object recognition, person identification, and image segmentation. Nevertheless, conventional classification algorithms, e.g., Logistic Regression, Decision Trees, and Bayesian classifiers, might lack complexity and diversity, not suitable when dealing with real-world data. A recent graph-inspired classifier, known as the Optimum-Path Forest, has proven to be a state-of-the-art technique, comparable to Support Vector Machines and even surpassing it in some tasks. This paper proposes a Python-based Optimum-Path Forest framework, denoted as OPFython, where all of its functions and classes are based upon the original C language implementation. Additionally, as OPFython is a Python-based library, it provides a more friendly environment and a faster prototyping workspace than the C language.",0
"Over the last few years, machine learning techniques have been extensively used in various tasks like classification, object recognition, person identification, and image segmentation. However, traditional classification algorithms such as Logistic Regression, Decision Trees, and Bayesian classifiers may not be adequate when dealing with complex real-world data due to their lack of diversity and complexity. In contrast, the Optimum-Path Forest, a graph-inspired classifier, has emerged as a state-of-the-art technique, surpassing even Support Vector Machines in certain tasks. This paper introduces OPFython, a Python-based Optimum-Path Forest framework that offers a more user-friendly environment and faster prototyping workspace than the original C language implementation. All functions and classes in OPFython are based on the C language implementation.",1
"Deep learning has not been routinely employed for semantic segmentation of seabed environment for synthetic aperture sonar (SAS) imagery due to the implicit need of abundant training data such methods necessitate. Abundant training data, specifically pixel-level labels for all images, is usually not available for SAS imagery due to the complex logistics (e.g., diver survey, chase boat, precision position information) needed for obtaining accurate ground-truth. Many hand-crafted feature based algorithms have been proposed to segment SAS in an unsupervised fashion. However, there is still room for improvement as the feature extraction step of these methods is fixed. In this work, we present a new iterative unsupervised algorithm for learning deep features for SAS image segmentation. Our proposed algorithm alternates between clustering superpixels and updating the parameters of a convolutional neural network (CNN) so that the feature extraction for image segmentation can be optimized. We demonstrate the efficacy of our method on a realistic benchmark dataset. Our results show that the performance of our proposed method is considerably better than current state-of-the-art methods in SAS image segmentation.",0
"The utilization of deep learning in semantic segmentation of seabed environment for synthetic aperture sonar (SAS) imagery has been limited due to the requirement of abundant training data. Obtaining pixel-level labels for all images is difficult for SAS imagery as it involves complex logistics such as diver survey, chase boat, and precision position information to obtain accurate ground-truth. Unsupervised algorithms based on hand-crafted features have been proposed for SAS segmentation, but they have fixed feature extraction steps and can be improved. This study introduces an iterative unsupervised algorithm to learn deep features for SAS image segmentation. The proposed algorithm alternates between clustering superpixels and updating the parameters of a convolutional neural network (CNN) to optimize feature extraction for image segmentation. The study demonstrates the effectiveness of the method on a realistic benchmark dataset and shows that it outperforms current state-of-the-art methods in SAS image segmentation.",1
"We introduce a new image segmentation task, termed Entity Segmentation (ES) with the aim to segment all visual entities in an image without considering semantic category labels. It has many practical applications in image manipulation/editing where the segmentation mask quality is typically crucial but category labels are less important. In this setting, all semantically-meaningful segments are equally treated as categoryless entities and there is no thing-stuff distinction. Based on our unified entity representation, we propose a center-based entity segmentation framework with two novel modules to improve mask quality. Experimentally, both our new task and framework demonstrate superior advantages as against existing work. In particular, ES enables the following: (1) merging multiple datasets to form a large training set without the need to resolve label conflicts; (2) any model trained on one dataset can generalize exceptionally well to other datasets with unseen domains. Our code is made publicly available at https://github.com/dvlab-research/Entity.",0
"Our team has developed a new task for image segmentation called Entity Segmentation (ES). The purpose of ES is to segment all visual entities in an image without considering semantic category labels. This task has many practical applications in image manipulation and editing where the quality of the segmentation mask is crucial, but category labels are less important. In this context, all semantically-meaningful segments are equally treated as categoryless entities without a thing-stuff distinction. We have proposed a center-based entity segmentation framework based on our unified entity representation, which includes two novel modules designed to improve mask quality. Our new task and framework have been experimentally proven to provide superior advantages compared to existing work. Specifically, ES allows for the merging of multiple datasets to form a large training set without the need to resolve label conflicts, and any model trained on one dataset can generalize exceptionally well to other datasets with unseen domains. We have made our code publicly available at https://github.com/dvlab-research/Entity.",1
"Humanitarian actions require accurate information to efficiently delegate support operations. Such information can be maps of building footprints, building functions, and population densities. While the access to this information is comparably easy in industrialized countries thanks to reliable census data and national geo-data infrastructures, this is not the case for developing countries, where that data is often incomplete or outdated. Building maps derived from remote sensing images may partially remedy this challenge in such countries, but are not always accurate due to different landscape configurations and lack of validation data. Even when they exist, building footprint layers usually do not reveal more fine-grained building properties, such as the number of stories or the building's function (e.g., office, residential, school, etc.). In this project we aim to automate building footprint and function mapping using heterogeneous data sources. In a first step, we intend to delineate buildings from satellite data, using deep learning models for semantic image segmentation. Building functions shall be retrieved by parsing social media data like for instance tweets, as well as ground-based imagery, to automatically identify different buildings functions and retrieve further information such as the number of building stories. Building maps augmented with those additional attributes make it possible to derive more accurate population density maps, needed to support the targeted provision of humanitarian aid.",0
"To efficiently allocate aid operations, accurate information is crucial for humanitarian efforts. This includes maps of building footprints, functions, and population densities. However, obtaining this data can be challenging in developing countries where census data and geo-data infrastructures are often incomplete or outdated. While remote sensing images can partially remedy this issue, their accuracy is limited by landscape configurations and lack of validation data. Additionally, building footprint layers do not provide detailed building properties. To address these challenges, our project aims to automate building footprint and function mapping through various data sources. This involves using deep learning models to delineate buildings from satellite data and parsing social media data and ground-based imagery to identify building functions and other details such as the number of stories. By augmenting building maps with this information, we can derive more accurate population density maps to better support targeted provision of humanitarian aid.",1
"The latest advances in computer-assisted precision medicine are making it feasible to move from population-wide models that are useful to discover aggregate patterns that hold for group-based analysis to patient-specific models that can drive patient-specific decisions with regard to treatment choices, and predictions of outcomes of treatment. Body Composition is recognized as an important driver and risk factor for a wide variety of diseases, as well as a predictor of individual patient-specific clinical outcomes to treatment choices or surgical interventions. 3D CT images are routinely acquired in the oncological worklows and deliver accurate rendering of internal anatomy and therefore can be used opportunistically to assess the amount of skeletal muscle and adipose tissue compartments. Powerful tools of artificial intelligence such as deep learning are making it feasible now to segment the entire 3D image and generate accurate measurements of all internal anatomy. These will enable the overcoming of the severe bottleneck that existed previously, namely, the need for manual segmentation, which was prohibitive to scale to the hundreds of 2D axial slices that made up a 3D volumetric image. Automated tools such as presented here will now enable harvesting whole-body measurements from 3D CT or MRI images, leading to a new era of discovery of the drivers of various diseases based on individual tissue, organ volume, shape, and functional status. These measurements were hitherto unavailable thereby limiting the field to a very small and limited subset. These discoveries and the potential to perform individual image segmentation with high speed and accuracy are likely to lead to the incorporation of these 3D measures into individual specific treatment planning models related to nutrition, aging, chemotoxicity, surgery and survival after the onset of a major disease such as cancer.",0
"Computer-assisted precision medicine has made significant advancements, allowing for a shift from population-wide models to patient-specific models that can inform treatment choices and predict outcomes. Body composition is a crucial factor in disease risk and treatment outcomes, and 3D CT images are routinely used to assess skeletal muscle and adipose tissue compartments. Artificial intelligence, specifically deep learning, now allows for automated segmentation of entire 3D images, providing accurate measurements of internal anatomy. This breakthrough overcomes the previous bottleneck of manual segmentation, enabling the discovery of individual tissue and organ volume, shape, and function. These measurements were previously unavailable, but now have the potential to inform individualized treatment planning related to nutrition, aging, chemotoxicity, surgery, and survival after the onset of diseases like cancer.",1
"We introduce a method that allows to automatically segment images into semantically meaningful regions without human supervision. Derived regions are consistent across different images and coincide with human-defined semantic classes on some datasets. In cases where semantic regions might be hard for human to define and consistently label, our method is still able to find meaningful and consistent semantic classes. In our work, we use pretrained StyleGAN2~\cite{karras2020analyzing} generative model: clustering in the feature space of the generative model allows to discover semantic classes. Once classes are discovered, a synthetic dataset with generated images and corresponding segmentation masks can be created. After that a segmentation model is trained on the synthetic dataset and is able to generalize to real images. Additionally, by using CLIP~\cite{radford2021learning} we are able to use prompts defined in a natural language to discover some desired semantic classes. We test our method on publicly available datasets and show state-of-the-art results.",0
"Our proposed approach enables automatic segmentation of images into semantically significant regions without the need for human intervention. The resulting regions are consistent across various images and match human-defined semantic classes on certain datasets. Even in cases where the definition and labeling of semantic regions might be challenging for humans, our method is capable of identifying meaningful and consistent semantic classes. Our technique employs a pre-trained StyleGAN2 generative model to cluster the feature space, thereby discovering semantic classes. Subsequently, a synthetic dataset containing generated images and corresponding segmentation masks is created, and a segmentation model is trained on this dataset to enable generalization to real images. Additionally, our method leverages CLIP to utilize prompts in natural language to discover desired semantic classes. We evaluate our approach on publicly available datasets and demonstrate its state-of-the-art performance.",1
"Accurate image segmentation plays a crucial role in medical image analysis, yet it faces great challenges of various shapes, diverse sizes, and blurry boundaries. To address these difficulties, square kernel-based encoder-decoder architecture has been proposed and widely used, but its performance remains still unsatisfactory. To further cope with these challenges, we present a novel double-branch encoder architecture. Our architecture is inspired by two observations: 1) Since the discrimination of features learned via square convolutional kernels needs to be further improved, we propose to utilize non-square vertical and horizontal convolutional kernels in the double-branch encoder, so features learned by the two branches can be expected to complement each other. 2) Considering that spatial attention can help models to better focus on the target region in a large-sized image, we develop an attention loss to further emphasize the segmentation on small-sized targets. Together, the above two schemes give rise to a novel double-branch encoder segmentation framework for medical image segmentation, namely Crosslink-Net. The experiments validate the effectiveness of our model on four datasets. The code is released at https://github.com/Qianyu1226/Crosslink-Net.",0
"The accurate segmentation of images is critical for medical image analysis, but it faces significant challenges due to various shapes, sizes, and blurry boundaries. The square kernel-based encoder-decoder architecture has been proposed and widely used to address these difficulties, but its performance remains unsatisfactory. To overcome these challenges, we introduce a new double-branch encoder architecture. Our inspiration comes from two observations: firstly, the discrimination of features learned through square convolutional kernels requires further improvement, so we propose to employ non-square vertical and horizontal convolutional kernels in the double-branch encoder. Secondly, we develop an attention loss that can help models to better focus on the target region in a large-sized image. The combination of these two approaches results in a novel double-branch encoder segmentation framework for medical image segmentation, called Crosslink-Net. The experiments confirm the effectiveness of our model on four datasets, and the code is available at https://github.com/Qianyu1226/Crosslink-Net.",1
"The paper proposes a novel approach for gray scale images segmentation. It is based on multiple features extraction from single feature per image pixel, namely its intensity value, using Echo state network. The newly extracted features -- reservoir equilibrium states -- reveal hidden image characteristics that improve its segmentation via a clustering algorithm. Moreover, it was demonstrated that the intrinsic plasticity tuning of reservoir fits its equilibrium states to the original image intensity distribution thus allowing for its better segmentation. The proposed approach is tested on the benchmark image Lena.",0
"A new technique for segmenting gray scale images is presented in the paper, which involves extracting multiple features from a single feature per pixel, specifically its intensity value, using Echo state network. The reservoir equilibrium states obtained from the newly extracted features provide insight into the hidden traits of the image, which enhance its segmentation through a clustering algorithm. Additionally, the study demonstrated that the intrinsic plasticity tuning of reservoir effectively aligns its equilibrium states with the original image intensity distribution, which leads to improved segmentation. The efficacy of this approach is evaluated on the commonly used Lena benchmark image.",1
"Learning segmentation from noisy labels is an important task for medical image analysis due to the difficulty in acquiring highquality annotations. Most existing methods neglect the pixel correlation and structural prior in segmentation, often producing noisy predictions around object boundaries. To address this, we adopt a superpixel representation and develop a robust iterative learning strategy that combines noise-aware training of segmentation network and noisy label refinement, both guided by the superpixels. This design enables us to exploit the structural constraints in segmentation labels and effectively mitigate the impact of label noise in learning. Experiments on two benchmarks show that our method outperforms recent state-of-the-art approaches, and achieves superior robustness in a wide range of label noises. Code is available at https://github.com/gaozhitong/SP_guided_Noisy_Label_Seg.",0
"Medical image analysis requires learning segmentation from noisy labels as quality annotations are difficult to obtain. However, current methods overlook pixel correlation and structural prior in segmentation, leading to imprecise predictions near object boundaries. To overcome this, we utilize a superpixel representation and develop an iterative learning approach that combines noise-aware training of the segmentation network with noisy label refinement, both guided by the superpixels. This approach enables us to exploit structural constraints in segmentation labels and effectively reduce the impact of label noise on learning. Our experiments on two benchmarks demonstrate that our method surpasses recent state-of-the-art approaches and exhibits superior robustness across a wide range of label noises. Our code is available at https://github.com/gaozhitong/SP_guided_Noisy_Label_Seg.",1
"In this paper, we propose a novel evaluation metric for performance evaluation of semantic segmentation. In recent years, many studies have tried to train pixel-level classifiers on large-scale image datasets to perform accurate semantic segmentation. The goal of semantic segmentation is to assign a class label of each pixel in the scene. It has various potential applications in computer vision fields e.g., object detection, classification, scene understanding and Etc. To validate the proposed wIoU evaluation metric, we tested state-of-the art methods on public benchmark datasets (e.g., KITTI) based on the proposed wIoU metric and compared with other conventional evaluation metrics.",0
"A new performance evaluation metric for semantic segmentation is suggested in this paper. Numerous studies have attempted to train pixel-level classifiers on extensive image datasets to achieve precise semantic segmentation in recent years. Semantic segmentation aims to assign a class label to every pixel in a scene and has numerous potential applications in computer vision, such as object detection, classification, and scene understanding. To verify the efficacy of the proposed wIoU evaluation metric, we put state-of-the-art methods through their paces on public benchmark datasets (e.g., KITTI) using the suggested wIoU metric and compared it to other conventional evaluation metrics.",1
"Deep learning techniques for 3D brain vessel image segmentation have not been as successful as in the segmentation of other organs and tissues. This can be explained by two factors. First, deep learning techniques tend to show poor performances at the segmentation of relatively small objects compared to the size of the full image. Second, due to the complexity of vascular trees and the small size of vessels, it is challenging to obtain the amount of annotated training data typically needed by deep learning methods. To address these problems, we propose a novel annotation-efficient deep learning vessel segmentation framework. The framework avoids pixel-wise annotations, only requiring weak patch-level labels to discriminate between vessel and non-vessel 2D patches in the training set, in a setup similar to the CAPTCHAs used to differentiate humans from bots in web applications. The user-provided weak annotations are used for two tasks: 1) to synthesize pixel-wise pseudo-labels for vessels and background in each patch, which are used to train a segmentation network, and 2) to train a classifier network. The classifier network allows to generate additional weak patch labels, further reducing the annotation burden, and it acts as a noise filter for poor quality images. We use this framework for the segmentation of the cerebrovascular tree in Time-of-Flight angiography (TOF) and Susceptibility-Weighted Images (SWI). The results show that the framework achieves state-of-the-art accuracy, while reducing the annotation time by ~77% w.r.t. learning-based segmentation methods using pixel-wise labels for training.",0
"The segmentation of 3D brain vessel images using deep learning techniques has been less successful than that of other organs and tissues. This is due to two reasons: firstly, the performance of deep learning techniques is typically poor when segmenting relatively small objects in comparison to the size of the entire image. Secondly, obtaining the necessary amount of annotated training data is challenging due to the complexity of vascular trees and the small size of vessels. To combat these issues, we propose a new deep learning framework for vessel segmentation that is annotation-efficient. This framework avoids pixel-wise annotations and instead uses weak patch-level labels to differentiate between vessel and non-vessel 2D patches in the training set. The user-provided weak annotations are used for two tasks: to synthesize pixel-wise pseudo-labels for vessels and background in each patch, which are used to train a segmentation network, and to train a classifier network. This classifier network generates additional weak patch labels, thus reducing the annotation burden and serving as a noise filter for poor quality images. Our framework achieves state-of-the-art accuracy in segmenting the cerebrovascular tree in Time-of-Flight angiography and Susceptibility-Weighted Images, while reducing annotation time by approximately 77% compared to learning-based segmentation methods that use pixel-wise labels for training.",1
"Medical image segmentation plays an essential role in developing computer-assisted diagnosis and therapy systems, yet still faces many challenges. In the past few years, the popular encoder-decoder architectures based on CNNs (e.g., U-Net) have been successfully applied in the task of medical image segmentation. However, due to the locality of convolution operations, they demonstrate limitations in learning global context and long-range spatial relations. Recently, several researchers try to introduce transformers to both the encoder and decoder components with promising results, but the efficiency requires further improvement due to the high computational complexity of transformers. In this paper, we propose LeViT-UNet, which integrates a LeViT Transformer module into the U-Net architecture, for fast and accurate medical image segmentation. Specifically, we use LeViT as the encoder of the LeViT-UNet, which better trades off the accuracy and efficiency of the Transformer block. Moreover, multi-scale feature maps from transformer blocks and convolutional blocks of LeViT are passed into the decoder via skip-connection, which can effectively reuse the spatial information of the feature maps. Our experiments indicate that the proposed LeViT-UNet achieves better performance comparing to various competing methods on several challenging medical image segmentation benchmarks including Synapse and ACDC. Code and models will be publicly available at https://github.com/apple1986/LeViT_UNet.",0
"Medical image segmentation is crucial for computer-assisted diagnosis and therapy systems, but it still faces numerous challenges. Although popular encoder-decoder architectures based on CNNs, such as U-Net, have been successfully applied in medical image segmentation, their convolution operations are limited in learning global context and long-range spatial relations. Some researchers have attempted to introduce transformers to both the encoder and decoder components, but their efficiency requires further improvement due to high computational complexity. This paper proposes LeViT-UNet, which integrates a LeViT Transformer module into the U-Net architecture for fast and accurate medical image segmentation. LeViT is used as the encoder of the LeViT-UNet, which better balances the accuracy and efficiency of the Transformer block. Multi-scale feature maps from transformer blocks and convolutional blocks of LeViT are passed into the decoder via a skip-connection, effectively reusing the spatial information of the feature maps. The proposed LeViT-UNet outperforms various competing methods on challenging medical image segmentation benchmarks including Synapse and ACDC. Code and models will be publicly available at https://github.com/apple1986/LeViT_UNet.",1
"The balance between high accuracy and high speed has always been a challenging task in semantic image segmentation. Compact segmentation networks are more widely used in the case of limited resources, while their performances are constrained. In this paper, motivated by the residual learning and global aggregation, we propose a simple yet general and effective knowledge distillation framework called double similarity distillation (DSD) to improve the classification accuracy of all existing compact networks by capturing the similarity knowledge in pixel and category dimensions, respectively. Specifically, we propose a pixel-wise similarity distillation (PSD) module that utilizes residual attention maps to capture more detailed spatial dependencies across multiple layers. Compared with exiting methods, the PSD module greatly reduces the amount of calculation and is easy to expand. Furthermore, considering the differences in characteristics between semantic segmentation task and other computer vision tasks, we propose a category-wise similarity distillation (CSD) module, which can help the compact segmentation network strengthen the global category correlation by constructing the correlation matrix. Combining these two modules, DSD framework has no extra parameters and only a minimal increase in FLOPs. Extensive experiments on four challenging datasets, including Cityscapes, CamVid, ADE20K, and Pascal VOC 2012, show that DSD outperforms current state-of-the-art methods, proving its effectiveness and generality. The code and models will be publicly available.",0
"Achieving high accuracy and high speed in semantic image segmentation has always been a challenging task. When resources are limited, compact segmentation networks are more commonly used, but their performance is constrained. In this paper, we propose a knowledge distillation framework called double similarity distillation (DSD) that captures similarity knowledge in pixel and category dimensions to improve the classification accuracy of all existing compact networks. Our framework includes a pixel-wise similarity distillation (PSD) module that uses residual attention maps to capture detailed spatial dependencies across multiple layers, reducing calculation and being easy to expand. Additionally, we propose a category-wise similarity distillation (CSD) module to improve the compact segmentation network's global category correlation by constructing the correlation matrix. Our DSD framework has no extra parameters and only a minimal increase in FLOPs. Extensive experiments on four challenging datasets, including Cityscapes, CamVid, ADE20K, and Pascal VOC 2012, demonstrate that DSD outperforms current state-of-the-art methods, proving its effectiveness and generality. The code and models will be publicly available.",1
"In a class of piecewise-constant image segmentation models, we propose to incorporate a weighted difference of anisotropic and isotropic total variation (AITV) to regularize the partition boundaries in an image. In particular, we replace the total variation regularization in the Chan-Vese segmentation model and a fuzzy region competition model by the proposed AITV. To deal with the nonconvex nature of AITV, we apply the difference-of-convex algorithm (DCA), in which the subproblems can be minimized by the primal-dual hybrid gradient method with linesearch. The convergence of the DCA scheme is analyzed. In addition, a generalization to color image segmentation is discussed. In the numerical experiments, we compare the proposed models with the classic convex approaches and the two-stage segmentation methods (smoothing and then thresholding) on various images, showing that our models are effective in image segmentation and robust with respect to impulsive noises.",0
"We suggest incorporating a weighted difference of anisotropic and isotropic total variation (AITV) into piecewise-constant image segmentation models to regulate partition boundaries in images. Our proposed AITV replaces total variation regularization in both Chan-Vese and fuzzy region competition models. To handle the nonconvex nature of AITV, we apply the difference-of-convex algorithm (DCA) using the primal-dual hybrid gradient method with linesearch to minimize subproblems. We analyze the convergence of the DCA scheme and discuss its generalization for color image segmentation. Our proposed models are compared with classic convex approaches and two-stage segmentation methods in numerical experiments on various images, demonstrating their effectiveness in image segmentation and robustness against impulsive noises.",1
"The attractiveness of a property is one of the most interesting, yet challenging, categories to model. Image characteristics are used to describe certain attributes, and to examine the influence of visual factors on the price or timeframe of the listing. In this paper, we propose a set of techniques for the extraction of visual features for efficient numerical inclusion in modern-day predictive algorithms. We discuss techniques such as Shannon's entropy, calculating the center of gravity, employing image segmentation, and using Convolutional Neural Networks. After comparing these techniques as applied to a set of property-related images (indoor, outdoor, and satellite), we conclude the following: (i) the entropy is the most efficient single-digit visual measure for housing price prediction; (ii) image segmentation is the most important visual feature for the prediction of housing lifespan; and (iii) deep image features can be used to quantify interior characteristics and contribute to captivation modeling. The set of 40 image features selected here carries a significant amount of predictive power and outperforms some of the strongest metadata predictors. Without any need to replace a human expert in a real-estate appraisal process, we conclude that the techniques presented in this paper can efficiently describe visible characteristics, thus introducing perceived attractiveness as a quantitative measure into the predictive modeling of housing.",0
"Modeling the attractiveness of a property is a challenging task that involves analyzing image characteristics and their influence on the listing's price and timeframe. This paper proposes techniques for efficiently extracting visual features and including them in modern predictive algorithms. The techniques discussed include Shannon's entropy, center of gravity calculation, image segmentation, and Convolutional Neural Networks. After comparing these techniques on a set of property-related images, the study concludes that entropy is the most efficient visual measure for housing price prediction, image segmentation is crucial for predicting housing lifespan, and deep image features can quantify interior characteristics and contribute to captivation modeling. The selected set of 40 image features carries significant predictive power and surpasses some of the strongest metadata predictors. The techniques presented in this paper can efficiently describe visible characteristics and introduce perceived attractiveness as a quantitative measure in the predictive modeling of housing, without replacing human expertise in real-estate appraisal processes.",1
"Scarcity of high quality annotated images remains a limiting factor for training accurate image segmentation models. While more and more annotated datasets become publicly available, the number of samples in each individual database is often small. Combining different databases to create larger amounts of training data is appealing yet challenging due to the heterogeneity as a result of differences in data acquisition and annotation processes, often yielding incompatible or even conflicting information. In this paper, we investigate and propose several strategies for learning from partially overlapping labels in the context of abdominal organ segmentation. We find that combining a semi-supervised approach with an adaptive cross entropy loss can successfully exploit heterogeneously annotated data and substantially improve segmentation accuracy compared to baseline and alternative approaches.",0
"The dearth of top-notch annotated images poses a constraint on developing precise image segmentation models. Although more annotated datasets are now openly accessible, the quantity of samples in each individual repository is usually meager. The idea of merging various databases to create a larger pool of training data is attractive, but it is a daunting task due to the incongruity resulting from the differences in data acquisition and annotation procedures. This often produces contradictory or incompatible data. This research delves into studying and proposing various techniques to learn from partially overlapping labels while focusing on abdominal organ segmentation. The paper concludes that combining a semi-supervised method with an adaptive cross entropy loss can efficiently utilize heterogeneously annotated data and significantly enhance segmentation accuracy compared to baseline and alternative methods.",1
"In recent years, computer-aided diagnosis has become an increasingly popular topic. Methods based on convolutional neural networks have achieved good performance in medical image segmentation and classification. Due to the limitations of the convolution operation, the long-term spatial features are often not accurately obtained. Hence, we propose a TransClaw U-Net network structure, which combines the convolution operation with the transformer operation in the encoding part. The convolution part is applied for extracting the shallow spatial features to facilitate the recovery of the image resolution after upsampling. The transformer part is used to encode the patches, and the self-attention mechanism is used to obtain global information between sequences. The decoding part retains the bottom upsampling structure for better detail segmentation performance. The experimental results on Synapse Multi-organ Segmentation Datasets show that the performance of TransClaw U-Net is better than other network structures. The ablation experiments also prove the generalization performance of TransClaw U-Net.",0
"Computer-aided diagnosis has become a popular topic in recent years, with convolutional neural networks achieving good performance in medical image segmentation and classification. However, the limitations of the convolution operation often result in inaccurately obtained long-term spatial features. To address this issue, we propose the TransClaw U-Net network structure, which combines the convolution operation with the transformer operation in the encoding part. The convolution part extracts shallow spatial features to aid in image resolution recovery after upsampling, while the transformer part encodes patches and uses self-attention to obtain global information between sequences. The decoding part retains the bottom upsampling structure for better detail segmentation performance. Experimentation on Synapse Multi-organ Segmentation Datasets demonstrate that TransClaw U-Net outperforms other network structures, and ablation experiments confirm its generalization performance.",1
"Convolutional neural networks (CNNs) have led to significant improvements in tasks involving semantic segmentation of images. CNNs are vulnerable in the area of biomedical image segmentation because of distributional gap between two source and target domains with different data modalities which leads to domain shift. Domain shift makes data annotations in new modalities necessary because models must be retrained from scratch. Unsupervised domain adaptation (UDA) is proposed to adapt a model to new modalities using solely unlabeled target domain data. Common UDA algorithms require access to data points in the source domain which may not be feasible in medical imaging due to privacy concerns. In this work, we develop an algorithm for UDA in a privacy-constrained setting, where the source domain data is inaccessible. Our idea is based on encoding the information from the source samples into a prototypical distribution that is used as an intermediate distribution for aligning the target domain distribution with the source domain distribution. We demonstrate the effectiveness of our algorithm by comparing it to state-of-the-art medical image semantic segmentation approaches on two medical image semantic segmentation datasets.",0
"Significant advancements in semantic image segmentation tasks have been achieved through the use of convolutional neural networks (CNNs). However, CNNs are not as effective in biomedical image segmentation due to the existence of a distributional gap between the source and target domains with varying data modalities, leading to domain shift. To address this, unsupervised domain adaptation (UDA) is suggested as a means of adapting a model to new modalities using only unlabeled target domain data. Unfortunately, common UDA techniques require data points in the source domain, which may not be feasible in medical imaging due to privacy concerns. Therefore, we propose a UDA algorithm that operates in a privacy-constrained setting where source domain data is inaccessible. Our approach involves encoding the information from the source samples into a prototypical distribution, which serves as an intermediate distribution for aligning the target domain distribution with the source domain distribution. We evaluate the performance of our algorithm against state-of-the-art medical image semantic segmentation methods on two medical image semantic segmentation datasets, demonstrating its effectiveness.",1
"The segmentation of medical images is a fundamental step in automated clinical decision support systems. Existing medical image segmentation methods based on supervised deep learning, however, remain problematic because of their reliance on large amounts of labelled training data. Although medical imaging data repositories continue to expand, there has not been a commensurate increase in the amount of annotated data. Hence, we propose a new spatial guided self-supervised clustering network (SGSCN) for medical image segmentation, where we introduce multiple loss functions designed to aid in grouping image pixels that are spatially connected and have similar feature representations. It iteratively learns feature representations and clustering assignment of each pixel in an end-to-end fashion from a single image. We also propose a context-based consistency loss that better delineates the shape and boundaries of image regions. It enforces all the pixels belonging to a cluster to be spatially close to the cluster centre. We evaluated our method on 2 public medical image datasets and compared it to existing conventional and self-supervised clustering methods. Experimental results show that our method was most accurate for medical image segmentation.",0
"In automated clinical decision support systems, the segmentation of medical images is a crucial stage. However, supervised deep learning methods for medical image segmentation have limitations due to their reliance on large amounts of labeled data. Despite the growth of medical imaging data repositories, there has not been a proportional increase in annotated data. Therefore, we propose a new method called SGSCN for medical image segmentation that employs multiple loss functions to group pixels that are spatially connected and have similar features. Our method iteratively learns feature representations and clustering assignments for each pixel from a single image. Additionally, we introduce a context-based consistency loss that better defines the shape and boundaries of image regions by requiring all pixels in a cluster to be close to the cluster center. We evaluated our approach on two public medical image datasets and compared it to conventional and self-supervised clustering methods. Our experimental results indicate that our method is the most accurate for medical image segmentation.",1
"Domain Adaptation (DA) methods are widely used in medical image segmentation tasks to tackle the problem of differently distributed train (source) and test (target) data. We consider the supervised DA task with a limited number of annotated samples from the target domain. It corresponds to one of the most relevant clinical setups: building a sufficiently accurate model on the minimum possible amount of annotated data. Existing methods mostly fine-tune specific layers of the pretrained Convolutional Neural Network (CNN). However, there is no consensus on which layers are better to fine-tune, e.g. the first layers for images with low-level domain shift or the deeper layers for images with high-level domain shift. To this end, we propose SpotTUnet - a CNN architecture that automatically chooses the layers which should be optimally fine-tuned. More specifically, on the target domain, our method additionally learns the policy that indicates whether a specific layer should be fine-tuned or reused from the pretrained network. We show that our method performs at the same level as the best of the nonflexible fine-tuning methods even under the extreme scarcity of annotated data. Secondly, we show that SpotTUnet policy provides a layer-wise visualization of the domain shift impact on the network, which could be further used to develop robust domain generalization methods. In order to extensively evaluate SpotTUnet performance, we use a publicly available dataset of brain MR images (CC359), characterized by explicit domain shift. We release a reproducible experimental pipeline.",0
"Medical image segmentation tasks frequently utilize Domain Adaptation (DA) methods to address the challenge of differently distributed train (source) and test (target) data. The supervised DA task with a limited number of annotated samples from the target domain is particularly relevant in clinical settings where building an accurate model with minimal annotated data is crucial. Current methods mainly fine-tune specific layers of the pretrained Convolutional Neural Network (CNN), but there is no consensus on which layers to fine-tune. To address this issue, we introduce SpotTUnet, a CNN architecture that automatically selects the optimal layers for fine-tuning. SpotTUnet also learns a policy on the target domain to determine whether a specific layer should be fine-tuned or reused from the pretrained network. Our method performs as well as the best nonflexible fine-tuning methods even with minimal annotated data, and our policy provides a layer-wise visualization of the domain shift impact on the network, which can aid in developing robust domain generalization methods. We evaluate the performance of SpotTUnet on a publicly available dataset of brain MR images (CC359) with explicit domain shift and provide a reproducible experimental pipeline.",1
"A large labeled dataset is a key to the success of supervised deep learning, but for medical image segmentation, it is highly challenging to obtain sufficient annotated images for model training. In many scenarios, unannotated images are abundant and easy to acquire. Self-supervised learning (SSL) has shown great potentials in exploiting raw data information and representation learning. In this paper, we propose Hierarchical Self-Supervised Learning (HSSL), a new self-supervised framework that boosts medical image segmentation by making good use of unannotated data. Unlike the current literature on task-specific self-supervised pretraining followed by supervised fine-tuning, we utilize SSL to learn task-agnostic knowledge from heterogeneous data for various medical image segmentation tasks. Specifically, we first aggregate a dataset from several medical challenges, then pre-train the network in a self-supervised manner, and finally fine-tune on labeled data. We develop a new loss function by combining contrastive loss and classification loss and pretrain an encoder-decoder architecture for segmentation tasks. Our extensive experiments show that multi-domain joint pre-training benefits downstream segmentation tasks and outperforms single-domain pre-training significantly. Compared to learning from scratch, our new method yields better performance on various tasks (e.g., +0.69% to +18.60% in Dice scores with 5% of annotated data). With limited amounts of training data, our method can substantially bridge the performance gap w.r.t. denser annotations (e.g., 10% vs.~100% of annotated data).",0
"Supervised deep learning requires a large labeled dataset for success, but obtaining sufficient annotated medical images for segmentation is highly challenging. However, unannotated images are often abundant and easily accessible. Self-supervised learning has shown potential in utilizing raw data information and representation learning. This paper proposes a new framework, called Hierarchical Self-Supervised Learning, which enhances medical image segmentation by utilizing unannotated data. Unlike current literature, this framework uses SSL to learn task-agnostic knowledge from various medical image segmentation tasks rather than task-specific self-supervised pretraining. The framework aggregates a dataset from several medical challenges and pre-trains the network in a self-supervised manner before fine-tuning on labeled data. The framework utilizes a new loss function that combines contrastive loss and classification loss and pretrains an encoder-decoder architecture. The experiments demonstrate that multi-domain joint pre-training outperforms single-domain pre-training and yields better performance on various tasks. The proposed method can substantially bridge the performance gap with denser annotations, even with limited amounts of training data.",1
"Medical image segmentation - the prerequisite of numerous clinical needs - has been significantly prospered by recent advances in convolutional neural networks (CNNs). However, it exhibits general limitations on modeling explicit long-range relation, and existing cures, resorting to building deep encoders along with aggressive downsampling operations, leads to redundant deepened networks and loss of localized details. Hence, the segmentation task awaits a better solution to improve the efficiency of modeling global contexts while maintaining a strong grasp of low-level details. In this paper, we propose a novel parallel-in-branch architecture, TransFuse, to address this challenge. TransFuse combines Transformers and CNNs in a parallel style, where both global dependency and low-level spatial details can be efficiently captured in a much shallower manner. Besides, a novel fusion technique - BiFusion module is created to efficiently fuse the multi-level features from both branches. Extensive experiments demonstrate that TransFuse achieves the newest state-of-the-art results on both 2D and 3D medical image sets including polyp, skin lesion, hip, and prostate segmentation, with significant parameter decrease and inference speed improvement.",0
"Recent advancements in convolutional neural networks (CNNs) have significantly improved medical image segmentation, which is essential for numerous clinical requirements. However, CNNs have limitations in modeling long-range relations explicitly. The current solution involves developing deep encoders with downsampling operations, leading to deepened networks and loss of localized details. Therefore, a better approach is required to enhance global context modeling while maintaining low-level details. In this study, we propose TransFuse, a novel parallel-in-branch architecture that combines Transformers and CNNs to address this challenge. TransFuse captures global dependency and spatial details efficiently in a shallower manner and uses a BiFusion module to fuse multi-level features from both branches. Our experiments demonstrate that TransFuse achieves the latest state-of-the-art results on 2D and 3D medical image sets such as polyp, skin lesion, hip, and prostate segmentation with a significant reduction in parameters and improved inference speed.",1
"The reliability of Deep Learning systems depends on their accuracy but also on their robustness against adversarial perturbations to the input data. Several attacks and defenses have been proposed to improve the performance of Deep Neural Networks under the presence of adversarial noise in the natural image domain. However, robustness in computer-aided diagnosis for volumetric data has only been explored for specific tasks and with limited attacks. We propose a new framework to assess the robustness of general medical image segmentation systems. Our contributions are two-fold: (i) we propose a new benchmark to evaluate robustness in the context of the Medical Segmentation Decathlon (MSD) by extending the recent AutoAttack natural image classification framework to the domain of volumetric data segmentation, and (ii) we present a novel lattice architecture for RObust Generic medical image segmentation (ROG). Our results show that ROG is capable of generalizing across different tasks of the MSD and largely surpasses the state-of-the-art under sophisticated adversarial attacks.",0
"Deep Learning systems need to be both accurate and robust against adversarial perturbations to be reliable. While several attacks and defenses have been proposed to improve the performance of Deep Neural Networks in natural image domains, robustness in computer-aided diagnosis for volumetric data remains limited. To address this, we propose a new framework to evaluate the robustness of general medical image segmentation systems. Our contributions include a new benchmark to assess robustness using the Medical Segmentation Decathlon (MSD) and a novel lattice architecture for RObust Generic medical image segmentation (ROG). Our results demonstrate that ROG outperforms the state-of-the-art under sophisticated adversarial attacks and can generalize across different MSD tasks.",1
"In medical image segmentation, it is difficult to mark ambiguous areas accurately with binary masks, especially when dealing with small lesions. Therefore, it is a challenge for radiologists to reach a consensus by using binary masks under the condition of multiple annotations. However, these areas may contain anatomical structures that are conducive to diagnosis. Uncertainty is introduced to study these situations. Nevertheless, the uncertainty is usually measured by the variances between predictions in a multiple trial way. It is not intuitive, and there is no exact correspondence in the image. Inspired by image matting, we introduce matting as a soft segmentation method and a new perspective to deal with and represent uncertain regions into medical scenes, namely medical matting. More specifically, because there is no available medical matting dataset, we first labeled two medical datasets with alpha matte. Secondly, the matting method applied to the natural image is not suitable for the medical scene, so we propose a new architecture to generate binary masks and alpha matte in a row. Thirdly, the uncertainty map is introduced to highlight the ambiguous regions from the binary results and improve the matting performance. Evaluated on these datasets, the proposed model outperformed state-of-the-art matting algorithms by a large margin, and alpha matte is proved to be a more efficient labeling form than a binary mask.",0
"Accurately marking ambiguous areas in medical image segmentation, especially small lesions, is challenging with binary masks. Radiologists struggle to reach a consensus using binary masks when dealing with multiple annotations, despite the potential diagnostic benefits of anatomical structures in these areas. The use of uncertainty in such situations is often measured by variances between predictions in multiple trials, which lacks intuition and exact correspondence in the image. To address this, we propose medical matting as a soft segmentation method that represents uncertain regions in medical scenes. As there is no available medical matting dataset, we labeled two medical datasets with alpha matte. Since the matting method applied to natural images is not suitable for medical scenes, we introduce a new architecture that generates binary masks and alpha matte in a series. We also introduce an uncertainty map to highlight ambiguous regions and enhance the matting performance. Our proposed model outperformed state-of-the-art matting algorithms by a significant margin, and alpha matte proved to be a more efficient labeling form than binary masks.",1
"Probabilistic finite mixture models are widely used for unsupervised clustering. These models can often be improved by adapting them to the topology of the data. For instance, in order to classify spatially adjacent data points similarly, it is common to introduce a Laplacian constraint on the posterior probability that each data point belongs to a class. Alternatively, the mixing probabilities can be treated as free parameters, while assuming Gauss-Markov or more complex priors to regularize those mixing probabilities. However, these approaches are constrained by the shape of the prior and often lead to complicated or intractable inference. Here, we propose a new parametrization of the Dirichlet distribution to flexibly regularize the mixing probabilities of over-parametrized mixture distributions. Using the Expectation-Maximization algorithm, we show that our approach allows us to define any linear update rule for the mixing probabilities, including spatial smoothing regularization as a special case. We then show that this flexible design can be extended to share class information between multiple mixture models. We apply our algorithm to artificial and natural image segmentation tasks, and we provide quantitative and qualitative comparison of the performance of Gaussian and Student-t mixtures on the Berkeley Segmentation Dataset. We also demonstrate how to propagate class information across the layers of deep convolutional neural networks in a probabilistically optimal way, suggesting a new interpretation for feedback signals in biological visual systems. Our flexible approach can be easily generalized to adapt probabilistic mixture models to arbitrary data topologies.",0
"Unsupervised clustering often uses probabilistic finite mixture models, which can benefit from adaptation to the data's topology. To classify adjacent data points similarly, a Laplacian constraint on the posterior probability of each data point belonging to a class is commonly used. However, prior shapes can constrain approaches and lead to complicated inferences. We propose a new parametrization of the Dirichlet distribution to flexibly regulate mixing probabilities of over-parametrized mixture distributions. Our approach allows for any linear update rule for mixing probabilities, including spatial smoothing regularization. This flexible design can be extended to share class information between multiple mixture models. We demonstrate our algorithm's effectiveness in artificial and natural image segmentation tasks and propagate class information across deep convolutional neural networks in a probabilistically optimal way. Our flexible approach can easily adapt probabilistic mixture models to arbitrary data topologies.",1
"Assigning meaning to parts of image data is the goal of semantic image segmentation. Machine learning methods, specifically supervised learning is commonly used in a variety of tasks formulated as semantic segmentation. One of the major challenges in the supervised learning approaches is expressing and collecting the rich knowledge that experts have with respect to the meaning present in the image data. Towards this, typically a fixed set of labels is specified and experts are tasked with annotating the pixels, patches or segments in the images with the given labels. In general, however, the set of classes does not fully capture the rich semantic information present in the images. For example, in medical imaging such as histology images, the different parts of cells could be grouped and sub-grouped based on the expertise of the pathologist.   To achieve such a precise semantic representation of the concepts in the image, we need access to the full depth of knowledge of the annotator. In this work, we develop a novel approach to collect segmentation annotations from experts based on psychometric testing. Our method consists of the psychometric testing procedure, active query selection, query enhancement, and a deep metric learning model to achieve a patch-level image embedding that allows for semantic segmentation of images. We show the merits of our method with evaluation on the synthetically generated image, aerial image and histology image.",0
"The objective of semantic image segmentation is to assign significance to various parts of image data. In many cases, supervised learning through machine learning is utilized to accomplish this task. However, one of the biggest challenges in this approach is the difficulty of expressing and collecting the vast knowledge that specialists possess regarding the meaning present in image data. Typically, a predetermined set of labels is designated, and experts are responsible for labeling the pixels, patches, or segments in images with these labels. Unfortunately, this set of classes is often insufficient to fully capture the nuanced semantic information inherent in images. This is particularly evident in medical imaging, such as histology images, where a pathologist's expertise may group and sub-group the various parts of cells in different ways. To achieve a more precise semantic representation of image concepts, it is crucial to have access to the full breadth of knowledge possessed by the annotator. In this study, we propose a novel method of collecting segmentation annotations from experts through psychometric testing. Our approach incorporates a psychometric testing procedure, active query selection, query enhancement, and a deep metric learning model that produces a patch-level image embedding capable of semantic image segmentation. We demonstrate the effectiveness of our method through evaluations on synthetically generated images, aerial images, and histology images.",1
"Semi-supervised learning has attracted great attention in the field of machine learning, especially for medical image segmentation tasks, since it alleviates the heavy burden of collecting abundant densely annotated data for training. However, most of existing methods underestimate the importance of challenging regions (e.g. small branches or blurred edges) during training. We believe that these unlabeled regions may contain more crucial information to minimize the uncertainty prediction for the model and should be emphasized in the training process. Therefore, in this paper, we propose a novel Mutual Consistency Network (MC-Net) for semi-supervised left atrium segmentation from 3D MR images. Particularly, our MC-Net consists of one encoder and two slightly different decoders, and the prediction discrepancies of two decoders are transformed as an unsupervised loss by our designed cycled pseudo label scheme to encourage mutual consistency. Such mutual consistency encourages the two decoders to have consistent and low-entropy predictions and enables the model to gradually capture generalized features from these unlabeled challenging regions. We evaluate our MC-Net on the public Left Atrium (LA) database and it obtains impressive performance gains by exploiting the unlabeled data effectively. Our MC-Net outperforms six recent semi-supervised methods for left atrium segmentation, and sets the new state-of-the-art performance on the LA database.",0
"In the realm of machine learning, semi-supervised learning has garnered significant attention, particularly for medical image segmentation tasks. This approach reduces the need to gather a large amount of densely annotated data for training purposes. However, many current methods lack consideration for challenging regions during training, such as small branches or blurred edges. We contend that these unlabeled regions could contain crucial information for minimizing uncertainty in model prediction and thus should be emphasized during training. To address this issue, we present a novel Mutual Consistency Network (MC-Net) for semi-supervised left atrium segmentation from 3D MR images. Our MC-Net comprises one encoder and two decoders with slightly differing predictions, which are transformed into an unsupervised loss to encourage mutual consistency. This approach encourages consistent and low-entropy predictions, allowing the model to capture generalized features from challenging regions. Our evaluation of MC-Net on the public Left Atrium (LA) database demonstrates impressive performance gains by effectively exploiting unlabeled data. MC-Net outperforms six recent semi-supervised methods for left atrium segmentation, setting a new state-of-the-art performance on the LA database.",1
"Over the past decade, Deep Convolutional Neural Networks have been widely adopted for medical image segmentation and shown to achieve adequate performance. However, due to the inherent inductive biases present in the convolutional architectures, they lack understanding of long-range dependencies in the image. Recently proposed Transformer-based architectures that leverage self-attention mechanism encode long-range dependencies and learn representations that are highly expressive. This motivates us to explore Transformer-based solutions and study the feasibility of using Transformer-based network architectures for medical image segmentation tasks. Majority of existing Transformer-based network architectures proposed for vision applications require large-scale datasets to train properly. However, compared to the datasets for vision applications, for medical imaging the number of data samples is relatively low, making it difficult to efficiently train transformers for medical applications. To this end, we propose a Gated Axial-Attention model which extends the existing architectures by introducing an additional control mechanism in the self-attention module. Furthermore, to train the model effectively on medical images, we propose a Local-Global training strategy (LoGo) which further improves the performance. Specifically, we operate on the whole image and patches to learn global and local features, respectively. The proposed Medical Transformer (MedT) is evaluated on three different medical image segmentation datasets and it is shown that it achieves better performance than the convolutional and other related transformer-based architectures. Code: https://github.com/jeya-maria-jose/Medical-Transformer",0
"Medical image segmentation has seen the widespread adoption of Deep Convolutional Neural Networks over the last decade, which have demonstrated satisfactory performance. However, these architectures lack an understanding of long-range dependencies in images due to their inherent inductive biases. Recently, Transformer-based architectures utilizing self-attention mechanisms have been proposed to encode long-range dependencies and learn highly expressive representations, prompting the exploration of Transformer-based solutions for medical image segmentation tasks. However, most existing Transformer-based network architectures require large-scale datasets to train properly, which is a challenge for medical imaging due to the relatively low number of data samples. To address this, a Gated Axial-Attention model is proposed, which introduces an additional control mechanism in the self-attention module. Moreover, a Local-Global training strategy (LoGo) is proposed to effectively train the model on medical images, operating on the whole image and patches to learn global and local features, respectively. The proposed Medical Transformer (MedT) is evaluated on three different medical image segmentation datasets, demonstrating superior performance compared to convolutional and other related transformer-based architectures. The code for MedT is available on GitHub.",1
"Imperfect labels limit the quality of predictions learned by deep neural networks. This is particularly relevant in medical image segmentation, where reference annotations are difficult to collect and vary significantly even across expert annotators. Prior work on mitigating label noise focused on simple models of mostly uniform noise. In this work, we explore biased and unbiased errors artificially introduced to brain tumour annotations on MRI data. We found that supervised and semi-supervised segmentation methods are robust or fairly robust to unbiased errors but sensitive to biased errors. It is therefore important to identify the sorts of errors expected in medical image labels and especially mitigate the biased errors.",0
"The effectiveness of deep neural networks in predicting outcomes is restricted by inaccurate labels. This is especially true for medical image segmentation, where collecting reference annotations is challenging and even expert annotators have varying opinions. Prior research has concentrated on reducing label noise using basic models that are predominantly uniform. In this study, we investigated the impact of intentionally introducing prejudiced and unbiased mistakes to brain tumor annotations in MRI data. Our findings show that supervised and semi-supervised segmentation techniques are sturdy or relatively sturdy when it comes to unbiased errors, but they are susceptible to biased errors. It is, therefore, crucial to identify the types of errors that may arise in medical image labels and focus on reducing biased errors specifically.",1
"Despite recent progress of automatic medical image segmentation techniques, fully automatic results usually fail to meet the clinical use and typically require further refinement. In this work, we propose a quality-aware memory network for interactive segmentation of 3D medical images. Provided by user guidance on an arbitrary slice, an interaction network is firstly employed to obtain an initial 2D segmentation. The quality-aware memory network subsequently propagates the initial segmentation estimation bidirectionally over the entire volume. Subsequent refinement based on additional user guidance on other slices can be incorporated in the same manner. To further facilitate interactive segmentation, a quality assessment module is introduced to suggest the next slice to segment based on the current segmentation quality of each slice. The proposed network has two appealing characteristics: 1) The memory-augmented network offers the ability to quickly encode past segmentation information, which will be retrieved for the segmentation of other slices; 2) The quality assessment module enables the model to directly estimate the qualities of segmentation predictions, which allows an active learning paradigm where users preferentially label the lowest-quality slice for multi-round refinement. The proposed network leads to a robust interactive segmentation engine, which can generalize well to various types of user annotations (e.g., scribbles, boxes). Experimental results on various medical datasets demonstrate the superiority of our approach in comparison with existing techniques.",0
"Although automatic medical image segmentation techniques have made progress recently, their fully automatic results often do not meet clinical standards and require further refinement. Our study introduces a quality-aware memory network for interactive segmentation of 3D medical images. This network uses an interaction network to obtain an initial 2D segmentation based on user guidance on an arbitrary slice. The quality-aware memory network then propagates the initial segmentation bidirectionally over the entire volume and incorporates refinement based on additional user guidance on other slices. To enhance interactive segmentation, a quality assessment module suggests the next slice to segment based on the current segmentation quality of each slice. Our network has two beneficial features: the memory-augmented network quickly encodes past segmentation information, and the quality assessment module estimates segmentation prediction qualities, allowing for an active learning paradigm. Our proposed network produces a robust interactive segmentation engine that can generalize well to various types of user annotations and outperforms existing techniques according to experimental results on various medical datasets.",1
"Clustering is an unsupervised machine learning method grouping data samples into clusters of similar objects. In practice, clustering has been used in numerous applications such as banking customers profiling, document retrieval, image segmentation, and e-commerce recommendation engines. However, the existing clustering techniques present significant limitations, from which is the dependability of their stability on the initialization parameters (e.g. number of clusters, centroids). Different solutions were presented in the literature to overcome this limitation (i.e. internal and external validation metrics). However, these solutions require high computational complexity and memory consumption, especially when dealing with big data. In this paper, we apply the recent object detection Deep Learning (DL) model, named YOLO-v5, to detect the initial clustering parameters such as the number of clusters with their sizes and centroids. Mainly, the proposed solution consists of adding a DL-based initialization phase making the clustering algorithms free of initialization. Two model solutions are provided in this work, one for isolated clusters and the other one for overlapping clusters. The features of the incoming dataset determine which model to use. Moreover, The results show that the proposed solution can provide near-optimal clusters initialization parameters with low computational and resources overhead compared to existing solutions.",0
"Clustering is a machine learning technique that groups data samples into clusters based on their similarities, and has been widely used in various applications including banking, document retrieval, image segmentation, and e-commerce recommendation engines. However, the current clustering methods have limitations, particularly in terms of their dependence on initialization parameters such as the number of clusters and centroids. Although different solutions have been proposed to address this issue, they often require high computational complexity and memory consumption, which is challenging when dealing with big data. To overcome this limitation, we propose a Deep Learning (DL) model called YOLO-v5, which can detect the initial clustering parameters such as the number of clusters, their sizes, and centroids. Our solution includes a DL-based initialization phase that eliminates the need for manual initialization of clustering algorithms. We present two models, one for isolated clusters and the other for overlapping clusters, depending on the features of the dataset. Our results demonstrate that our proposed solution can provide near-optimal clusters initialization parameters with low computational and resource overhead compared to existing methods.",1
"A strong visual object tracker nowadays relies on its well-crafted modules, which typically consist of manually-designed network architectures to deliver high-quality tracking results. Not surprisingly, the manual design process becomes a particularly challenging barrier, as it demands sufficient prior experience, enormous effort, intuition and perhaps some good luck. Meanwhile, neural architecture search has gaining grounds in practical applications such as image segmentation, as a promising method in tackling the issue of automated search of feasible network structures. In this work, we propose a novel cell-level differentiable architecture search mechanism to automate the network design of the tracking module, aiming to adapt backbone features to the objective of a tracking network during offline training. The proposed approach is simple, efficient, and with no need to stack a series of modules to construct a network. Our approach is easy to be incorporated into existing trackers, which is empirically validated using different differentiable architecture search-based methods and tracking objectives. Extensive experimental evaluations demonstrate the superior performance of our approach over five commonly-used benchmarks. Meanwhile, our automated searching process takes 41 (18) hours for the second (first) order DARTS method on the TrackingNet dataset.",0
"Nowadays, a reliable visual object tracker depends on well-crafted modules, often consisting of manually-designed network architectures to produce high-quality tracking results. However, the manual design process is challenging, requiring prior experience, great effort, intuition, and luck. In contrast, neural architecture search has become a popular method for automated search of feasible network structures, especially in practical applications like image segmentation. In this study, we introduce a new cell-level differentiable architecture search mechanism to automate the network design of the tracking module, which adapts backbone features to the objective of a tracking network during offline training. Our approach is simple, efficient, and eliminates the need to stack multiple modules to construct a network. It can easily be incorporated into existing trackers and has been empirically validated using different differentiable architecture search-based methods and tracking objectives. Our extensive experimental evaluations show that our approach outperforms five commonly-used benchmarks. The automated searching process takes 41 (18) hours for the second (first) order DARTS method on the TrackingNet dataset.",1
"Deep learning-based segmentation methods are vulnerable to unforeseen data distribution shifts during deployment, e.g. change of image appearances or contrasts caused by different scanners, unexpected imaging artifacts etc. In this paper, we present a cooperative framework for training image segmentation models and a latent space augmentation method for generating hard examples. Both contributions improve model generalization and robustness with limited data. The cooperative training framework consists of a fast-thinking network (FTN) and a slow-thinking network (STN). The FTN learns decoupled image features and shape features for image reconstruction and segmentation tasks. The STN learns shape priors for segmentation correction and refinement. The two networks are trained in a cooperative manner. The latent space augmentation generates challenging examples for training by masking the decoupled latent space in both channel-wise and spatial-wise manners. We performed extensive experiments on public cardiac imaging datasets. Using only 10 subjects from a single site for training, we demonstrated improved cross-site segmentation performance and increased robustness against various unforeseen imaging artifacts compared to strong baseline methods. Particularly, cooperative training with latent space data augmentation yields 15% improvement in terms of average Dice score when compared to a standard training method.",0
"During deployment, deep learning-based segmentation methods can be negatively impacted by changes in image appearances or contrasts caused by different scanners, unexpected imaging artifacts, and other unforeseen data distribution shifts. This paper introduces a cooperative framework for training image segmentation models and a latent space augmentation method to generate challenging examples, both of which improve model generalization and robustness with limited data. The framework comprises a fast-thinking network (FTN) and a slow-thinking network (STN), with the FTN learning decoupled image features and shape features for image reconstruction and segmentation tasks, while the STN learns shape priors for segmentation correction and refinement. The two networks are trained cooperatively, and the latent space augmentation generates challenging examples for training by masking the decoupled latent space in both channel-wise and spatial-wise manners. Extensive experiments on public cardiac imaging datasets demonstrate that using only 10 subjects from a single site for training, the proposed method yields improved cross-site segmentation performance and increased robustness against unforeseen imaging artifacts compared to strong baseline methods. Specifically, cooperative training with latent space data augmentation results in a 15% improvement in terms of average Dice score compared to a standard training method.",1
"Semantic segmentation is one of the basic, yet essential scene understanding tasks for an autonomous agent. The recent developments in supervised machine learning and neural networks have enjoyed great success in enhancing the performance of the state-of-the-art techniques for this task. However, their superior performance is highly reliant on the availability of a large-scale annotated dataset. In this paper, we propose a novel fully unsupervised semantic segmentation method, the so-called Information Maximization and Adversarial Regularization Segmentation (InMARS). Inspired by human perception which parses a scene into perceptual groups, rather than analyzing each pixel individually, our proposed approach first partitions an input image into meaningful regions (also known as superpixels). Next, it utilizes Mutual-Information-Maximization followed by an adversarial training strategy to cluster these regions into semantically meaningful classes. To customize an adversarial training scheme for the problem, we incorporate adversarial pixel noise along with spatial perturbations to impose photometrical and geometrical invariance on the deep neural network. Our experiments demonstrate that our method achieves the state-of-the-art performance on two commonly used unsupervised semantic segmentation datasets, COCO-Stuff, and Potsdam.",0
"For an autonomous agent, semantic segmentation is a crucial task to comprehend a scene. Recent advancements in supervised machine learning and neural networks have made significant progress in improving the performance of state-of-the-art techniques for this task. However, their effectiveness heavily depends on having a large annotated dataset. Our proposed approach, Information Maximization and Adversarial Regularization Segmentation (InMARS), is a novel fully unsupervised semantic segmentation method. Inspired by how humans perceive a scene by grouping perceptual regions, our approach partitions an input image into meaningful superpixels. We use Mutual-Information-Maximization and an adversarial training strategy to cluster these regions into semantically meaningful classes. To make the adversarial training scheme more suitable for the problem, we incorporate adversarial pixel noise and spatial perturbations to impose photometrical and geometrical invariance on the deep neural network. Our experiments show that our method outperforms state-of-the-art on two commonly used unsupervised semantic segmentation datasets, COCO-Stuff, and Potsdam.",1
"Tensor networks provide an efficient approximation of operations involving high dimensional tensors and have been extensively used in modelling quantum many-body systems. More recently, supervised learning has been attempted with tensor networks, primarily focused on tasks such as image classification. In this work, we propose a novel formulation of tensor networks for supervised image segmentation which allows them to operate on high resolution medical images. We use the matrix product state (MPS) tensor network on non-overlapping patches of a given input image to predict the segmentation mask by learning a pixel-wise linear classification rule in a high dimensional space. The proposed model is end-to-end trainable using backpropagation. It is implemented as a Strided Tensor Network to reduce the parameter complexity. The performance of the proposed method is evaluated on two public medical imaging datasets and compared to relevant baselines. The evaluation shows that the strided tensor network yields competitive performance compared to CNN-based models while using fewer resources. Additionally, based on the experiments we discuss the feasibility of using fully linear models for segmentation tasks.",0
"Tensor networks have been widely utilized for approximating high dimensional tensor operations in modeling quantum many-body systems. Recently, tensor networks have also been explored in supervised learning, particularly for image classification. This research proposes a unique tensor network formulation for supervised image segmentation, which can operate on high resolution medical images. The matrix product state (MPS) tensor network is used on non-overlapping patches of the input image to predict the segmentation mask by learning a pixel-wise linear classification rule in a high dimensional space. The proposed model is end-to-end trainable using backpropagation and implemented as a Strided Tensor Network to reduce parameter complexity. The study assesses the performance of the proposed method on two public medical imaging datasets and compares it with relevant baselines. Results demonstrate that the strided tensor network performs competitively compared to CNN-based models with fewer resources. Additionally, based on the experiments, the feasibility of using fully linear models for segmentation tasks is discussed.",1
"Most existing deep learning-based frameworks for image segmentation assume that a unique ground truth is known and can be used for performance evaluation. This is true for many applications, but not all. Myocardial segmentation of Myocardial Contrast Echocardiography (MCE), a critical task in automatic myocardial perfusion analysis, is an example. Due to the low resolution and serious artifacts in MCE data, annotations from different cardiologists can vary significantly, and it is hard to tell which one is the best. In this case, how can we find a good way to evaluate segmentation performance and how do we train the neural network? In this paper, we address the first problem by proposing a new extended Dice to effectively evaluate the segmentation performance when multiple accepted ground truth is available. Then based on our proposed metric, we solve the second problem by further incorporating the new metric into a loss function that enables neural networks to flexibly learn general features of myocardium. Experiment results on our clinical MCE data set demonstrate that the neural network trained with the proposed loss function outperforms those existing ones that try to obtain a unique ground truth from multiple annotations, both quantitatively and qualitatively. Finally, our grading study shows that using extended Dice as an evaluation metric can better identify segmentation results that need manual correction compared with using Dice.",0
"Many deep learning-based frameworks for image segmentation assume that a single ground truth is available for performance evaluation. However, this is not always the case, as seen in the example of myocardial segmentation in Myocardial Contrast Echocardiography (MCE). The low resolution and artifacts in MCE data result in variations in annotations from different cardiologists, making it difficult to determine the best ground truth. To address this challenge, we propose an extended Dice as a new metric to evaluate segmentation performance when multiple accepted ground truths are available. We then incorporate this metric into a loss function to train neural networks to learn general features of myocardium. Our experimental results on clinical MCE data show that our approach outperforms existing methods that try to obtain a unique ground truth from multiple annotations. Additionally, our grading study demonstrates that using extended Dice as an evaluation metric can better identify segmentation results that require manual correction compared to using Dice alone.",1
"We study image segmentation from an information-theoretic perspective, proposing a novel adversarial method that performs unsupervised segmentation by partitioning images into maximally independent sets. More specifically, we group image pixels into foreground and background, with the goal of minimizing predictability of one set from the other. An easily computed loss drives a greedy search process to maximize inpainting error over these partitions. Our method does not involve training deep networks, is computationally cheap, class-agnostic, and even applicable in isolation to a single unlabeled image. Experiments demonstrate that it achieves a new state-of-the-art in unsupervised segmentation quality, while being substantially faster and more general than competing approaches.",0
"Our approach to studying image segmentation is based on the information-theoretic viewpoint, where we introduce a novel adversarial technique for unsupervised segmentation. Our method involves partitioning images into sets that are maximally independent, achieved by grouping pixels into foreground and background. The ultimate objective is to minimize the predictability of one set from the other, which is accomplished using a readily computable loss function that drives a greedy search process to maximize inpainting error. Unlike other methods that require deep network training or are limited to specific classes, our approach is computationally efficient, applicable to a single unlabeled image, and universally adaptable. Our experiments show that our method outperforms existing unsupervised segmentation techniques in terms of speed and robustness, achieving a new state-of-the-art level of quality.",1
"This paper proposes two important contributions for conditional Generative Adversarial Networks (cGANs) to improve the wide variety of applications that exploit this architecture. The first main contribution is an analysis of cGANs to show that they are not explicitly conditional. In particular, it will be shown that the discriminator and subsequently the cGAN does not automatically learn the conditionality between inputs. The second contribution is a new method, called acontrario, that explicitly models conditionality for both parts of the adversarial architecture via a novel acontrario loss that involves training the discriminator to learn unconditional (adverse) examples. This leads to a novel type of data augmentation approach for GANs (acontrario learning) which allows to restrict the search space of the generator to conditional outputs using adverse examples. Extensive experimentation is carried out to evaluate the conditionality of the discriminator by proposing a probability distribution analysis. Comparisons with the cGAN architecture for different applications show significant improvements in performance on well known datasets including, semantic image synthesis, image segmentation and monocular depth prediction using different metrics including Fr\'echet Inception Distance(FID), mean Intersection over Union (mIoU), Root Mean Square Error log (RMSE log) and Number of statistically-Different Bins (NDB)",0
"In this paper, two significant enhancements for conditional Generative Adversarial Networks (cGANs) are presented. The first contribution is an analysis of cGANs which demonstrates that they lack explicit conditionality. The discriminator and cGAN do not automatically learn the relationship between inputs. The second contribution is a new approach called acontrario. It explicitly models conditionality for both parts of the adversarial architecture using a novel acontrario loss. The discriminator is trained to learn unconditional (adverse) examples, leading to a new type of data augmentation approach for GANs (acontrario learning). This approach allows the generator to restrict the search space of conditional outputs using adverse examples. The paper presents an extensive experiment to evaluate the conditionality of the discriminator through a probability distribution analysis. Comparisons are made with the cGAN architecture for different applications, including semantic image synthesis, image segmentation, and monocular depth prediction using various metrics such as Fr\'echet Inception Distance (FID), mean Intersection over Union (mIoU), Root Mean Square Error log (RMSE log), and Number of statistically-Different Bins (NDB). Significant improvements in performance are observed on well-known datasets.",1
"Semantic, instance, and panoptic segmentations have been addressed using different and specialized frameworks despite their underlying connections. This paper presents a unified, simple, and effective framework for these essentially similar tasks. The framework, named K-Net, segments both instances and semantic categories consistently by a group of learnable kernels, where each kernel is responsible for generating a mask for either a potential instance or a stuff class. To remedy the difficulties of distinguishing various instances, we propose a kernel update strategy that enables each kernel dynamic and conditional on its meaningful group in the input image. K-Net can be trained in an end-to-end manner with bipartite matching, and its training and inference are naturally NMS-free and box-free. Without bells and whistles, K-Net surpasses all previous state-of-the-art single-model results of panoptic segmentation on MS COCO and semantic segmentation on ADE20K with 52.1% PQ and 54.3% mIoU, respectively. Its instance segmentation performance is also on par with Cascade Mask R-CNNon MS COCO with 60%-90% faster inference speeds. Code and models will be released at https://github.com/open-mmlab/mmdetection.",0
"Different frameworks have been developed to address semantic, instance, and panoptic segmentations, despite their underlying similarities. This study introduces a unified and effective framework, named K-Net, that can consistently segment both instances and semantic categories using a group of learnable kernels. Each kernel generates a mask for either a potential instance or a stuff class. To address the challenges in distinguishing various instances, the study proposes a dynamic and conditional kernel update strategy that allows each kernel to adapt to its meaningful group in the input image. K-Net can be trained end-to-end using bipartite matching, and its training and inference processes do not require non-maximum suppression or bounding boxes. K-Net outperforms previous state-of-the-art single-model results in panoptic segmentation on MS COCO and semantic segmentation on ADE20K, achieving 52.1% PQ and 54.3% mIoU, respectively, without any additional features. Its instance segmentation performance is also comparable to that of Cascade Mask R-CNN on MS COCO, but with 60%-90% faster inference speeds. The study will release the code and models on https://github.com/open-mmlab/mmdetection.",1
"Deep learning has proven to be a highly effective problem-solving tool for object detection and image segmentation across various domains such as healthcare and autonomous driving. At the heart of this performance lies neural architecture design which relies heavily on domain knowledge and prior experience on the researchers' behalf. More recently, this process of finding the most optimal architectures, given an initial search space of possible operations, was automated by Neural Architecture Search (NAS). In this paper, we evaluate the robustness of one such algorithm known as Efficient NAS (ENAS) against data agnostic poisoning attacks on the original search space with carefully designed ineffective operations. By evaluating algorithm performance on the CIFAR-10 dataset, we empirically demonstrate how our novel search space poisoning (SSP) approach and multiple-instance poisoning attacks exploit design flaws in the ENAS controller to result in inflated prediction error rates for child networks. Our results provide insights into the challenges to surmount in using NAS for more adversarially robust architecture search.",0
"Object detection and image segmentation have benefited greatly from deep learning in various domains, including healthcare and autonomous driving. The success of these models is largely attributed to the neural architecture design, which heavily relies on domain knowledge and prior experience of researchers. Recently, Neural Architecture Search (NAS) has automated the process of finding the most optimal architectures given an initial search space of possible operations. Our paper evaluates the effectiveness of Efficient NAS (ENAS) against data agnostic poisoning attacks on the original search space with carefully designed ineffective operations. We empirically demonstrate the flaws in the ENAS controller by using our novel search space poisoning (SSP) approach and multiple-instance poisoning attacks on the CIFAR-10 dataset, resulting in inflated prediction error rates for child networks. Our results highlight the challenges in using NAS for more adversarially robust architecture search.",1
"The recent vision transformer(i.e.for image classification) learns non-local attentive interaction of different patch tokens. However, prior arts miss learning the cross-scale dependencies of different pixels, the semantic correspondence of different labels, and the consistency of the feature representations and semantic embeddings, which are critical for biomedical segmentation. In this paper, we tackle the above issues by proposing a unified transformer network, termed Multi-Compound Transformer (MCTrans), which incorporates rich feature learning and semantic structure mining into a unified framework. Specifically, MCTrans embeds the multi-scale convolutional features as a sequence of tokens and performs intra- and inter-scale self-attention, rather than single-scale attention in previous works. In addition, a learnable proxy embedding is also introduced to model semantic relationship and feature enhancement by using self-attention and cross-attention, respectively. MCTrans can be easily plugged into a UNet-like network and attains a significant improvement over the state-of-the-art methods in biomedical image segmentation in six standard benchmarks. For example, MCTrans outperforms UNet by 3.64%, 3.71%, 4.34%, 2.8%, 1.88%, 1.57% in Pannuke, CVC-Clinic, CVC-Colon, Etis, Kavirs, ISIC2018 dataset, respectively. Code is available at https://github.com/JiYuanFeng/MCTrans.",0
"The latest vision transformer, which is designed for image classification, has the ability to learn non-local attentive interaction among various patch tokens. However, past approaches have neglected to learn crucial aspects of biomedical segmentation, such as cross-scale dependencies of different pixels, semantic correspondence of different labels, and consistency of feature representations and semantic embeddings. To address these issues, we present a Multi-Compound Transformer (MCTrans), which combines rich feature learning and semantic structure mining in a unified framework. MCTrans embeds multi-scale convolutional features as a sequence of tokens and employs intra- and inter-scale self-attention, as opposed to the single-scale attention used in earlier works. Moreover, we introduce a learnable proxy embedding to model semantic relationships and feature enhancement by using self-attention and cross-attention, respectively. MCTrans can be easily integrated into a UNet-like network and achieves a significant improvement in biomedical image segmentation over state-of-the-art methods in six standard benchmarks. For instance, in Pannuke, CVC-Clinic, CVC-Colon, Etis, Kavirs, and ISIC2018 dataset, MCTrans outperforms UNet by 3.64%, 3.71%, 4.34%, 2.8%, 1.88%, and 1.57%, respectively. The code for MCTrans is available at https://github.com/JiYuanFeng/MCTrans.",1
"Transformer, which can benefit from global (long-range) information modeling using self-attention mechanisms, has been successful in natural language processing and 2D image classification recently. However, both local and global features are crucial for dense prediction tasks, especially for 3D medical image segmentation. In this paper, we for the first time exploit Transformer in 3D CNN for MRI Brain Tumor Segmentation and propose a novel network named TransBTS based on the encoder-decoder structure. To capture the local 3D context information, the encoder first utilizes 3D CNN to extract the volumetric spatial feature maps. Meanwhile, the feature maps are reformed elaborately for tokens that are fed into Transformer for global feature modeling. The decoder leverages the features embedded by Transformer and performs progressive upsampling to predict the detailed segmentation map. Extensive experimental results on both BraTS 2019 and 2020 datasets show that TransBTS achieves comparable or higher results than previous state-of-the-art 3D methods for brain tumor segmentation on 3D MRI scans. The source code is available at https://github.com/Wenxuan-1119/TransBTS",0
"Recently, the Transformer has been successful in natural language processing and 2D image classification due to its ability to model global (long-range) information using self-attention mechanisms. However, when it comes to dense prediction tasks, such as 3D medical image segmentation, both local and global features are essential. In this study, we propose a novel network called TransBTS for MRI Brain Tumor Segmentation, which exploits the Transformer in 3D CNN for the first time. The encoder initially employs 3D CNN to extract volumetric spatial feature maps to capture local 3D context information. The feature maps are then reformed for tokens that are fed into the Transformer for global feature modeling. The decoder uses the features embedded by the Transformer and performs progressive upsampling to predict the detailed segmentation map. Extensive experimental results on both BraTS 2019 and 2020 datasets show that TransBTS achieves comparable or higher results than previous state-of-the-art 3D methods for brain tumor segmentation on 3D MRI scans. The source code for TransBTS is available at https://github.com/Wenxuan-1119/TransBTS.",1
"Fully convolutional U-shaped neural networks have largely been the dominant approach for pixel-wise image segmentation. In this work, we tackle two defects that hinder their deployment in real-world applications: 1) Predictions lack uncertainty quantification that may be crucial to many decision-making systems; 2) Large memory storage and computational consumption demanding extensive hardware resources. To address these issues and improve their practicality we demonstrate a few-parameter compact Bayesian convolutional architecture, that achieves a marginal improvement in accuracy in comparison to related work using significantly fewer parameters and compute operations. The architecture combines parameter-efficient operations such as separable convolutions, bilinear interpolation, multi-scale feature propagation and Bayesian inference for per-pixel uncertainty quantification through Monte Carlo Dropout. The best performing configurations required fewer than 2.5 million parameters on diverse challenging datasets with few observations.",0
"The primary method for image segmentation has been fully convolutional U-shaped neural networks. However, these networks have two shortcomings that limit their usefulness in the real world. Firstly, they do not provide a measure of uncertainty, which can be crucial for decision-making systems. Secondly, they require a large amount of memory and computational resources. To address these issues, we have developed a compact Bayesian convolutional architecture that achieves a slightly better accuracy than other related work while using significantly fewer parameters and operations. This architecture employs parameter-efficient techniques such as separable convolutions, bilinear interpolation, multi-scale feature propagation, and Bayesian inference for per-pixel uncertainty quantification through Monte Carlo Dropout. The best-performing configurations required fewer than 2.5 million parameters on various challenging datasets with limited observations.",1
"In this work, we present a simple yet effective framework to address the domain translation problem between different sensor modalities with unique data formats. By relying only on the semantics of the scene, our modular generative framework can, for the first time, synthesize a panoramic color image from a given full 3D LiDAR point cloud. The framework starts with semantic segmentation of the point cloud, which is initially projected onto a spherical surface. The same semantic segmentation is applied to the corresponding camera image. Next, our new conditional generative model adversarially learns to translate the predicted LiDAR segment maps to the camera image counterparts. Finally, generated image segments are processed to render the panoramic scene images. We provide a thorough quantitative evaluation on the SemanticKitti dataset and show that our proposed framework outperforms other strong baseline models.   Our source code is available at https://github.com/halmstad-University/TITAN-NET",0
"We have developed a framework that can solve the domain translation problem when dealing with different sensor modalities that have unique data formats. Our approach is simple but highly effective, relying solely on the scene's semantics. For the first time, we can generate a panoramic color image using a complete 3D LiDAR point cloud thanks to our modular generative framework. Our framework begins by performing semantic segmentation on the point cloud, initially projected onto a spherical surface. The same segmentation is then applied to the corresponding camera image. Our new conditional generative model is then trained adversarially to translate the predicted LiDAR segment maps into the camera image counterparts. Finally, we process the generated image segments to render panoramic scene images. We conducted a comprehensive quantitative evaluation on the SemanticKitti dataset and found that our proposed framework outperforms other strong baseline models. Our source code is available at https://github.com/halmstad-University/TITAN-NET.",1
"High-resolution image segmentation remains challenging and error-prone due to the enormous size of intermediate feature maps. Conventional methods avoid this problem by using patch based approaches where each patch is segmented independently. However, independent patch segmentation induces errors, particularly at the patch boundary due to the lack of contextual information in very high-resolution images where the patch size is much smaller compared to the full image. To overcome these limitations, in this paper, we propose a novel framework to segment a particular patch by incorporating contextual information from its neighboring patches. This allows the segmentation network to see the target patch with a wider field of view without the need of larger feature maps. Comparative analysis from a number of experiments shows that our proposed framework is able to segment high resolution images with significantly improved mean Intersection over Union and overall accuracy.",0
"Segmenting high-resolution images with accuracy remains challenging due to the large size of intermediate feature maps. Traditional patch-based methods are used to avoid this issue, but they often produce errors at the patch boundary due to the lack of contextual information. This is especially true for very high-resolution images, where the patch size is much smaller than the full image. To overcome this limitation, we present a new framework in this paper that incorporates contextual information from neighboring patches to segment a particular patch. This enables the segmentation network to have a wider field of view without requiring larger feature maps. Our proposed approach significantly improves mean Intersection over Union and overall accuracy in high-resolution image segmentation, as demonstrated in several experiments.",1
"The scarcity of labeled data often impedes the application of deep learning to the segmentation of medical images. Semi-supervised learning seeks to overcome this limitation by exploiting unlabeled examples in the learning process. In this paper, we present a novel semi-supervised segmentation method that leverages mutual information (MI) on categorical distributions to achieve both global representation invariance and local smoothness. In this method, we maximize the MI for intermediate feature embeddings that are taken from both the encoder and decoder of a segmentation network. We first propose a global MI loss constraining the encoder to learn an image representation that is invariant to geometric transformations. Instead of resorting to computationally-expensive techniques for estimating the MI on continuous feature embeddings, we use projection heads to map them to a discrete cluster assignment where MI can be computed efficiently. Our method also includes a local MI loss to promote spatial consistency in the feature maps of the decoder and provide a smoother segmentation. Since mutual information does not require a strict ordering of clusters in two different assignments, we incorporate a final consistency regularization loss on the output which helps align the cluster labels throughout the network. We evaluate the method on four challenging publicly-available datasets for medical image segmentation. Experimental results show our method to outperform recently-proposed approaches for semi-supervised segmentation and provide an accuracy near to full supervision while training with very few annotated images.",0
"Deep learning for medical image segmentation is often limited by the scarcity of labeled data. To overcome this, semi-supervised learning can utilize unlabeled examples in the learning process. A novel semi-supervised segmentation method is presented in this paper, which uses mutual information (MI) on categorical distributions to achieve both global representation invariance and local smoothness. The MI is maximized for intermediate feature embeddings taken from both the encoder and decoder of a segmentation network. A global MI loss is proposed first to constrain the encoder to learn an image representation that is invariant to geometric transformations. Projection heads are used to map continuous feature embeddings to a discrete cluster assignment for efficient MI computation. A local MI loss is also included to promote spatial consistency in the feature maps of the decoder for smoother segmentation. A final consistency regularization loss is incorporated to align cluster labels throughout the network. The method is evaluated on four publicly-available datasets for medical image segmentation and outperforms recently-proposed approaches for semi-supervised segmentation, providing high accuracy even with very few annotated images.",1
"Unsupervised domain adaptation (UDA) aims to transfer knowledge learned from a labeled source domain to an unlabeled and unseen target domain, which is usually trained on data from both domains. Access to the source domain data at the adaptation stage, however, is often limited, due to data storage or privacy issues. To alleviate this, in this work, we target source free UDA for segmentation, and propose to adapt an ``off-the-shelf"" segmentation model pre-trained in the source domain to the target domain, with an adaptive batch-wise normalization statistics adaptation framework. Specifically, the domain-specific low-order batch statistics, i.e., mean and variance, are gradually adapted with an exponential momentum decay scheme, while the consistency of domain shareable high-order batch statistics, i.e., scaling and shifting parameters, is explicitly enforced by our optimization objective. The transferability of each channel is adaptively measured first from which to balance the contribution of each channel. Moreover, the proposed source free UDA framework is orthogonal to unsupervised learning methods, e.g., self-entropy minimization, which can thus be simply added on top of our framework. Extensive experiments on the BraTS 2018 database show that our source free UDA framework outperformed existing source-relaxed UDA methods for the cross-subtype UDA segmentation task and yielded comparable results for the cross-modality UDA segmentation task, compared with a supervised UDA methods with the source data.",0
"The goal of unsupervised domain adaptation (UDA) is to apply knowledge gained from a labeled source domain to an unlabeled and unfamiliar target domain, which is typically trained on data from both domains. However, access to the source domain data during the adaptation phase is often restricted due to data storage or privacy concerns. To address this issue, this study focuses on source-free UDA for segmentation and suggests adapting a pre-trained segmentation model from the source domain to the target domain using an adaptive batch-wise normalization statistics adaptation framework. The low-order batch statistics that are specific to the domain are gradually adjusted using an exponential momentum decay scheme. The optimization objective explicitly enforces the consistency of domain-shareable high-order batch statistics, such as scaling and shifting parameters. First, the transferability of each channel is adaptively measured to balance the contribution of each channel. Furthermore, the proposed source-free UDA framework is separate from unsupervised learning methods such as self-entropy minimization, which can be added to our framework with ease. Extensive experiments on the BraTS 2018 database demonstrate that our source-free UDA framework outperforms existing source-relaxed UDA methods for the cross-subtype UDA segmentation task and yields comparable results for the cross-modality UDA segmentation task when compared to supervised UDA methods that use the source data.",1
"Semantic segmentation from very fine resolution (VFR) urban scene images plays a significant role in several application scenarios including autonomous driving, land cover classification, and urban planning, etc. However, the tremendous details contained in the VFR image severely limit the potential of the existing deep learning approaches. More seriously, the considerable variations in scale and appearance of objects further deteriorate the representational capacity of those se-mantic segmentation methods, leading to the confusion of adjacent objects. Addressing such is-sues represents a promising research field in the remote sensing community, which paves the way for scene-level landscape pattern analysis and decision making. In this manuscript, we pro-pose a bilateral awareness network (BANet) which contains a dependency path and a texture path to fully capture the long-range relationships and fine-grained details in VFR images. Specif-ically, the dependency path is conducted based on the ResT, a novel Transformer backbone with memory-efficient multi-head self-attention, while the texture path is built on the stacked convo-lution operation. Besides, using the linear attention mechanism, a feature aggregation module (FAM) is designed to effectively fuse the dependency features and texture features. Extensive experiments conducted on the three large-scale urban scene image segmentation datasets, i.e., ISPRS Vaihingen dataset, ISPRS Potsdam dataset, and UAVid dataset, demonstrate the effective-ness of our BANet. Specifically, a 64.6% mIoU is achieved on the UAVid dataset.",0
"Several applications, such as autonomous driving, land cover classification, and urban planning, require semantic segmentation from very fine resolution (VFR) urban scene images. However, the high level of detail in these images limits the potential of existing deep learning approaches. Additionally, variations in object scale and appearance further diminish the representational capacity of semantic segmentation methods, causing confusion between adjacent objects. Addressing these challenges is an important research area in the remote sensing community, enabling scene-level landscape pattern analysis and decision making. To tackle these issues, we propose a bilateral awareness network (BANet) that incorporates a dependency path and a texture path to capture both long-range relationships and fine-grained details in VFR images. The dependency path is based on ResT, a novel Transformer backbone with memory-efficient multi-head self-attention, while the texture path relies on stacked convolution operation. To effectively fuse dependency and texture features, we use a linear attention mechanism to design a feature aggregation module (FAM). Our extensive experiments on three large-scale urban scene image segmentation datasets, including ISPRS Vaihingen dataset, ISPRS Potsdam dataset, and UAVid dataset, demonstrate the effectiveness of BANet, achieving a 64.6% mIoU on the UAVid dataset.",1
"Transmission electron microscopy (TEM) is one of the primary tools to show microstructural characterization of materials as well as film thickness. However, manual determination of film thickness from TEM images is time-consuming as well as subjective, especially when the films in question are very thin and the need for measurement precision is very high. Such is the case for head overcoat (HOC) thickness measurements in the magnetic hard disk drive industry. It is therefore necessary to develop software to automatically measure HOC thickness. In this paper, for the first time, we propose a HOC layer segmentation method using NASNet-Large as an encoder and then followed by a decoder architecture, which is one of the most commonly used architectures in deep learning for image segmentation. To further improve segmentation results, we are the first to propose a post-processing layer to remove irrelevant portions in the segmentation result. To measure the thickness of the segmented HOC layer, we propose a regressive convolutional neural network (RCNN) model as well as orthogonal thickness calculation methods. Experimental results demonstrate a higher dice score for our model which has lower mean squared error and outperforms current state-of-the-art manual measurement.",0
"TEM is a crucial tool for microstructural characterization and film thickness determination. However, manual measurement of film thickness is time-consuming and subjective, particularly for thin films where precise measurement is essential. The magnetic hard disk drive industry requires automated measurement of head overcoat (HOC) thickness. In this study, we propose a HOC layer segmentation method using a deep learning encoder-decoder architecture. We also introduce a post-processing layer to remove irrelevant portions, and employ a regressive convolutional neural network (RCNN) model and orthogonal thickness calculation methods to measure the segmented HOC layer's thickness. Our experimental results indicate superior performance compared to manual measurement, with a higher dice score, lower mean squared error, and outperforming current state-of-the-art methods.",1
"Despite the success of deep learning methods in medical image segmentation tasks, the human-level performance relies on massive training data with high-quality annotations, which are expensive and time-consuming to collect. The fact is that there exist low-quality annotations with label noise, which leads to suboptimal performance of learned models. Two prominent directions for segmentation learning with noisy labels include pixel-wise noise robust training and image-level noise robust training. In this work, we propose a novel framework to address segmenting with noisy labels by distilling effective supervision information from both pixel and image levels. In particular, we explicitly estimate the uncertainty of every pixel as pixel-wise noise estimation, and propose pixel-wise robust learning by using both the original labels and pseudo labels. Furthermore, we present an image-level robust learning method to accommodate more information as the complements to pixel-level learning. We conduct extensive experiments on both simulated and real-world noisy datasets. The results demonstrate the advantageous performance of our method compared to state-of-the-art baselines for medical image segmentation with noisy labels.",0
"While deep learning methods have proven successful in medical image segmentation tasks, achieving human-level performance requires extensive training data with high-quality annotations, which can be costly and time-consuming to obtain. Unfortunately, low-quality annotations with label noise can lead to suboptimal performance of learned models. Two approaches to segmentation learning with noisy labels are pixel-wise noise robust training and image-level noise robust training. In this study, we propose a novel framework for segmenting with noisy labels by extracting effective supervision information from both pixel and image levels. Specifically, we estimate the uncertainty of every pixel as pixel-wise noise estimation and use both original and pseudo labels for pixel-wise robust learning. Additionally, we introduce an image-level robust learning method to incorporate more information. We conduct extensive experiments on simulated and real-world noisy datasets and demonstrate the superior performance of our method compared to state-of-the-art baselines for medical image segmentation with noisy labels.",1
"Learning multi-modal representations is an essential step towards real-world robotic applications, and various multi-modal fusion models have been developed for this purpose. However, we observe that existing models, whose objectives are mostly based on joint training, often suffer from learning inferior representations of each modality. We name this problem Modality Failure, and hypothesize that the imbalance of modalities and the implicit bias of common objectives in fusion method prevent encoders of each modality from sufficient feature learning. To this end, we propose a new multi-modal learning method, Uni-Modal Teacher, which combines the fusion objective and uni-modal distillation to tackle the modality failure problem. We show that our method not only drastically improves the representation of each modality, but also improves the overall multi-modal task performance. Our method can be effectively generalized to most multi-modal fusion approaches. We achieve more than 3% improvement on the VGGSound audio-visual classification task, as well as improving performance on the NYU depth V2 RGB-D image segmentation task.",0
"Developing multi-modal representations is crucial for practical robotic applications, and several fusion models have been created for this purpose. However, we have noticed that these models, which generally rely on joint training, often struggle to learn high-quality representations of each modality. We have named this issue Modality Failure, and we believe that the fusion method's inherent bias and the imbalance of modalities are to blame for the encoders' insufficient feature learning. To address this issue, we have created a new multi-modal learning approach called Uni-Modal Teacher, which combines uni-modal distillation with the fusion objective to tackle the Modality Failure problem. Our research shows that our method significantly improves the individual modality representation and overall multi-modal task performance. Our method can be applied to most multi-modal fusion techniques, and it has achieved over 3% improvement in the VGGSound audio-visual classification task and improved performance in the NYU depth V2 RGB-D image segmentation task.",1
"Many approaches to 3D image segmentation are based on hierarchical clustering of supervoxels into image regions. Here we describe a distributed algorithm capable of handling a tremendous number of supervoxels. The algorithm works recursively, the regions are divided into chunks that are processed independently in parallel by multiple workers. At each round of the recursive procedure, the chunk size in all dimensions are doubled until a single chunk encompasses the entire image. The final result is provably independent of the chunking scheme, and the same as if the entire image were processed without division into chunks. This is nontrivial because a pair of adjacent regions is scored by some statistical property (e.g. mean or median) of the affinities at the interface, and the interface may extend over arbitrarily many chunks. The trick is to delay merge decisions for regions that touch chunk boundaries, and only complete them in a later round after the regions are fully contained within a chunk. We demonstrate the algorithm by clustering an affinity graph with over 1.5 trillion edges between 135 billion supervoxels derived from a 3D electron microscopic brain image.",0
"Numerous methods for segmenting 3D images involve hierarchical clustering of supervoxels to create image regions. This article introduces a distributed algorithm that can handle an enormous quantity of supervoxels. The algorithm operates recursively, dividing regions into chunks that multiple workers can process independently in parallel. The chunk size increases by double in all dimensions each round until one chunk encompasses the whole image. The final outcome remains the same regardless of the chunking scheme, which is significant because statistical properties (e.g., mean or median) score adjacent regions at the interface, which may span countless chunks. To address this issue, the algorithm delays merge decisions for regions touching chunk boundaries and only completes them later when fully contained within a chunk. The algorithm's effectiveness is demonstrated by clustering an affinity graph with over 1.5 trillion edges between 135 billion supervoxels derived from a 3D electron microscopic brain image.",1
"Vision Transformers (ViT) have been shown to attain highly competitive performance for a wide range of vision applications, such as image classification, object detection and semantic image segmentation. In comparison to convolutional neural networks, the Vision Transformer's weaker inductive bias is generally found to cause an increased reliance on model regularization or data augmentation (``AugReg'' for short) when training on smaller training datasets. We conduct a systematic empirical study in order to better understand the interplay between the amount of training data, AugReg, model size and compute budget. As one result of this study we find that the combination of increased compute and AugReg can yield models with the same performance as models trained on an order of magnitude more training data: we train ViT models of various sizes on the public ImageNet-21k dataset which either match or outperform their counterparts trained on the larger, but not publicly available JFT-300M dataset.",0
"ViT models have demonstrated outstanding performance in a wide range of vision tasks, including image classification, object detection, and semantic image segmentation. However, compared to convolutional neural networks, ViTs tend to have a weaker inductive bias, which can lead to increased dependency on model regularization or data augmentation (known as ""AugReg"") when working with smaller training datasets. To better understand the relationship between training data, AugReg, model size, and compute budget, we conducted a systematic empirical study. Our findings indicate that by increasing compute and AugReg, we can achieve comparable model performance to those trained on significantly more training data. Specifically, we trained ViT models of various sizes on the publicly available ImageNet-21k dataset, which either matched or exceeded the performance of models trained on the larger, non-public JFT-300M dataset.",1
We present a novel approach that combines machine learning based interactive image segmentation using supervoxels with a clustering method for the automated identification of similarly colored images in large data sets which enables a guided reuse of classifiers. Our approach solves the problem of significant color variability prevalent and often unavoidable in biological and medical images which typically leads to deteriorated segmentation and quantification accuracy thereby greatly reducing the necessary training effort. This increase in efficiency facilitates the quantification of much larger numbers of images thereby enabling interactive image analysis for recent new technological advances in high-throughput imaging. The presented methods are applicable for almost any image type and represent a useful tool for image analysis tasks in general.,0
"Our approach is innovative as it combines machine learning-based interactive image segmentation with supervoxels and a clustering method for identifying similarly colored images in large data sets. This allows for a guided reuse of classifiers and solves the problem of color variability that is common in biological and medical images. The result is an increase in efficiency and a reduction in necessary training effort, which enables the quantification of larger numbers of images and facilitates interactive image analysis for recent technological advances in high-throughput imaging. Our methods are applicable to any image type and provide a valuable tool for image analysis tasks in general.",1
"The joint use of multiple imaging modalities for medical image segmentation has been widely studied in recent years. The fusion of information from different modalities has demonstrated to improve the segmentation accuracy, with respect to mono-modal segmentations, in several applications. However, acquiring multiple modalities is usually not possible in a clinical setting due to a limited number of physicians and scanners, and to limit costs and scan time. Most of the time, only one modality is acquired. In this paper, we propose KD-Net, a framework to transfer knowledge from a trained multi-modal network (teacher) to a mono-modal one (student). The proposed method is an adaptation of the generalized distillation framework where the student network is trained on a subset (1 modality) of the teacher's inputs (n modalities). We illustrate the effectiveness of the proposed framework in brain tumor segmentation with the BraTS 2018 dataset. Using different architectures, we show that the student network effectively learns from the teacher and always outperforms the baseline mono-modal network in terms of segmentation accuracy.",0
"In recent years, extensive research has been conducted on using multiple imaging modalities for medical image segmentation. Various applications have shown that combining information from different modalities can increase segmentation accuracy compared to using a single modality. However, due to limited resources and high costs, it is often not feasible to acquire multiple modalities in a clinical setting. Therefore, we propose KD-Net, a framework that transfers knowledge from a trained multi-modal network to a mono-modal one. We use the generalized distillation framework to train the student network on a subset of inputs from the teacher network. We demonstrate the effectiveness of this approach in brain tumor segmentation with the BraTS 2018 dataset. Our results show that the student network learns from the teacher network and consistently outperforms the baseline mono-modal network in terms of segmentation accuracy, using different architectures.",1
"Accurate segmentation of medical images into anatomically meaningful regions is critical for the extraction of quantitative indices or biomarkers. The common pipeline for segmentation comprises regions of interest detection stage and segmentation stage, which are independent of each other and typically performed using separate deep learning networks. The performance of the segmentation stage highly relies on the extracted set of spatial features and the receptive fields. In this work, we propose an end-to-end network, called Trilateral Attention Network (TaNet), for real-time detection and segmentation in medical images. TaNet has a module for region localization, and three segmentation pathways: 1) handcrafted pathway with hand-designed convolutional kernels, 2) detail pathway with regular convolutional kernels, and 3) a global pathway to enlarge the receptive field. The first two pathways encode rich handcrafted and low-level features extracted by hand-designed and regular kernels while the global pathway encodes high-level context information. By jointly training the network for localization and segmentation using different sets of features, TaNet achieved superior performance, in terms of accuracy and speed, when evaluated on an echocardiography dataset for cardiac segmentation. The code and models will be made publicly available in TaNet Github page.",0
"Precise division of medical images into anatomically significant regions is crucial for obtaining quantitative indices or biomarkers. Typically, segmentation is performed through a two-stage process involving region detection and segmentation, which are executed separately using different deep learning networks. The effectiveness of the segmentation stage hinges heavily on the extracted spatial features and receptive fields. Here, we propose a real-time end-to-end network, TaNet, for detection and segmentation in medical images. TaNet features a region localization module and three segmentation pathways: 1) a handcrafted pathway that uses hand-designed convolutional kernels, 2) a detail pathway that uses regular convolutional kernels, and 3) a global pathway that enlarges the receptive field. The first two pathways capture rich handcrafted and low-level features using hand-designed and regular kernels, while the global pathway captures high-level context information. By simultaneously training the network for localization and segmentation using different sets of features, TaNet outperforms other models in terms of accuracy and speed when tested on an echocardiography dataset for cardiac segmentation. The TaNet Github page will provide access to the code and models.",1
"In this work, we address the task of referring image segmentation (RIS), which aims at predicting a segmentation mask for the object described by a natural language expression. Most existing methods focus on establishing unidirectional or directional relationships between visual and linguistic features to associate two modalities together, while the multi-scale context is ignored or insufficiently modeled. Multi-scale context is crucial to localize and segment those objects that have large scale variations during the multi-modal fusion process. To solve this problem, we propose a simple yet effective Cascaded Multi-modal Fusion (CMF) module, which stacks multiple atrous convolutional layers in parallel and further introduces a cascaded branch to fuse visual and linguistic features. The cascaded branch can progressively integrate multi-scale contextual information and facilitate the alignment of two modalities during the multi-modal fusion process. Experimental results on four benchmark datasets demonstrate that our method outperforms most state-of-the-art methods. Code is available at https://github.com/jianhua2022/CMF-Refseg.",0
"This study focuses on referring image segmentation (RIS), a task that involves predicting a segmentation mask for an object described by natural language. Existing methods primarily establish one-way or directional associations between visual and linguistic features, neglecting or inadequately modeling multi-scale context. The multi-scale context is essential for identifying and segmenting objects with significant scale variations in the multi-modal fusion process. To tackle this issue, we present a straightforward yet effective approach called the Cascaded Multi-modal Fusion (CMF) module. This module employs multiple atrous convolutional layers in parallel and incorporates a cascaded branch to fuse visual and linguistic features. The cascaded branch gradually integrates multi-scale contextual information and helps align the two modalities during the multi-modal fusion process. Our method surpasses most state-of-the-art approaches, as demonstrated by experimental results on four benchmark datasets. The code is available at https://github.com/jianhua2022/CMF-Refseg.",1
"This paper addresses the domain shift problem for segmentation. As a solution, we propose OLVA, a novel and lightweight unsupervised domain adaptation method based on a Variational Auto-Encoder (VAE) and Optimal Transport (OT) theory. Thanks to the VAE, our model learns a shared cross-domain latent space that follows a normal distribution, which reduces the domain shift. To guarantee valid segmentations, our shared latent space is designed to model the shape rather than the intensity variations. We further rely on an OT loss to match and align the remaining discrepancy between the two domains in the latent space. We demonstrate OLVA's effectiveness for the segmentation of multiple cardiac structures on the public Multi-Modality Whole Heart Segmentation (MM-WHS) dataset, where the source domain consists of annotated 3D MR images and the unlabelled target domain of 3D CTs. Our results show remarkable improvements with an additional margin of 12.5\% dice score over concurrent generative training approaches.",0
"In this paper, we tackle the domain shift problem in segmentation and propose a solution called OLVA. OLVA is an unsupervised domain adaptation method that uses a VAE and OT theory to address the issue. By using the VAE, our model is able to learn a cross-domain latent space that follows a normal distribution, which reduces the domain shift. To ensure valid segmentations, our shared latent space models the shape rather than the intensity variations. Additionally, we use an OT loss to match and align the remaining discrepancies between the two domains in the latent space. We demonstrate the effectiveness of OLVA on the MM-WHS dataset, where the source domain is made up of annotated 3D MR images and the unlabelled target domain is made up of 3D CTs. Our results show significant improvements with a 12.5% dice score margin over other generative training approaches.",1
"mmWave radars offer excellent depth resolution owing to their high bandwidth at mmWave radio frequencies. Yet, they suffer intrinsically from poor angular resolution, that is an order-of-magnitude worse than camera systems, and are therefore not a capable 3-D imaging solution in isolation. We propose Metamoran, a system that combines the complimentary strengths of radar and camera systems to obtain depth images at high azimuthal resolutions at distances of several tens of meters with high accuracy, all from a single fixed vantage point. Metamoran enables rich long-range depth imaging outdoors with applications to roadside safety infrastructure, surveillance and wide-area mapping. Our key insight is to use the high azimuth resolution from cameras using computer vision techniques, including image segmentation and monocular depth estimation, to obtain object shapes and use these as priors for our novel specular beamforming algorithm. We also design this algorithm to work in cluttered environments with weak reflections and in partially occluded scenarios. We perform a detailed evaluation of Metamoran's depth imaging and sensing capabilities in 200 diverse scenes at a major U.S. city. Our evaluation shows that Metamoran estimates the depth of an object up to 60~m away with a median error of 28~cm, an improvement of 13$\times$ compared to a naive radar+camera baseline and 23$\times$ compared to monocular depth estimation.",0
"Due to their high bandwidth at mmWave radio frequencies, mmWave radars are capable of providing excellent depth resolution. However, they suffer from poor angular resolution, which is significantly worse than camera systems, making them unsuitable for 3-D imaging in isolation. To address this limitation, we introduce Metamoran, a system that combines the strengths of radar and camera systems to obtain high-accuracy depth images at high azimuthal resolutions from a single fixed vantage point. Our approach leverages computer vision techniques, including image segmentation and monocular depth estimation, to obtain object shapes and use them as priors for our novel specular beamforming algorithm. We designed this algorithm to operate effectively in cluttered environments with weak reflections and in partially occluded scenarios. Our evaluation of Metamoran's depth imaging and sensing capabilities in 200 diverse scenes at a major U.S. city demonstrates that it can estimate the depth of an object up to 60~m away with a median error of 28~cm. This represents a significant improvement over a naive radar+camera baseline and monocular depth estimation, with improvements of 13$\times$ and 23$\times$, respectively. Metamoran has potential for use in outdoor applications such as roadside safety infrastructure, surveillance, and wide-area mapping.",1
"This paper reports a CPU-level real-time stereo matching method for surgical images (10 Hz on 640 * 480 image with a single core of i5-9400). The proposed method is built on the fast ''dense inverse searching'' algorithm, which estimates the disparity of the stereo images. The overlapping image patches (arbitrary squared image segment) from the images at different scales are aligned based on the photometric consistency presumption. We propose a Bayesian framework to evaluate the probability of the optimized patch disparity at different scales. Moreover, we introduce a spatial Gaussian mixed probability distribution to address the pixel-wise probability within the patch. In-vivo and synthetic experiments show that our method can handle ambiguities resulted from the textureless surfaces and the photometric inconsistency caused by the Lambertian reflectance. Our Bayesian method correctly balances the probability of the patch for stereo images at different scales. Experiments indicate that the estimated depth has higher accuracy and fewer outliers than the baseline methods in the surgical scenario.",0
"The aim of this paper is to present a real-time stereo matching method for surgical images at the CPU level. The proposed method is based on the fast ''dense inverse searching'' algorithm, which can estimate the disparity of the stereo images. To align the overlapping image patches from different scales, we rely on the photometric consistency presumption. A Bayesian framework is introduced to evaluate the optimized patch disparity's probability at different scales. Furthermore, we use a spatial Gaussian mixed probability distribution to address the pixel-wise probability within the patch. Our method can handle ambiguities caused by the textureless surfaces and the photometric inconsistency caused by the Lambertian reflectance. In-vivo and synthetic experiments prove that our Bayesian method can correctly balance the probability of the patch for stereo images at different scales. The estimated depth has higher accuracy and fewer outliers than the baseline methods in the surgical scenario.",1
"We introduce a new method for generating color images from sketches or edge maps. Current methods either require some form of additional user-guidance or are limited to the ""paired"" translation approach. We argue that segmentation information could provide valuable guidance for sketch colorization. To this end, we propose to leverage semantic image segmentation, as provided by a general purpose panoptic segmentation network, to create an additional adversarial loss function. Our loss function can be integrated to any baseline GAN model. Our method is not limited to datasets that contain segmentation labels, and it can be trained for ""unpaired"" translation tasks. We show the effectiveness of our method on four different datasets spanning scene level indoor, outdoor, and children book illustration images using qualitative, quantitative and user study analysis. Our model improves its baseline up to 35 points on the FID metric. Our code and pretrained models can be found at https://github.com/giddyyupp/AdvSegLoss.",0
"The presented paper proposes a novel technique for producing colored images from sketches or edge maps. Existing approaches either require human intervention or are restricted to paired translation. The authors contend that segmentation data could offer valuable guidance for coloring sketches. Therefore, they suggest using a general-purpose panoptic segmentation network to create an extra adversarial loss function. This loss function can be incorporated into any baseline GAN model. The proposed approach is not limited to datasets with segmentation labels, and it can be trained for unpaired translation tasks. The authors demonstrate the efficacy of their method on four diverse datasets, including indoor and outdoor scenes and children's book illustrations, using various qualitative, quantitative, and user study analyses. The proposed model outperforms the baseline models by up to 35 points on the FID metric. The code and pretrained models are available at https://github.com/giddyyupp/AdvSegLoss.",1
"Automatic medical image segmentation has made great progress benefit from the development of deep learning. However, most existing methods are based on convolutional neural networks (CNNs), which fail to build long-range dependencies and global context connections due to the limitation of receptive field in convolution operation. Inspired by the success of Transformer in modeling the long-range contextual information, some researchers have expended considerable efforts in designing the robust variants of Transformer-based U-Net. Moreover, the patch division used in vision transformers usually ignores the pixel-level intrinsic structural features inside each patch. To alleviate these problems, we propose a novel deep medical image segmentation framework called Dual Swin Transformer U-Net (DS-TransUNet), which might be the first attempt to concurrently incorporate the advantages of hierarchical Swin Transformer into both encoder and decoder of the standard U-shaped architecture to enhance the semantic segmentation quality of varying medical images. Unlike many prior Transformer-based solutions, the proposed DS-TransUNet first adopts dual-scale encoder subnetworks based on Swin Transformer to extract the coarse and fine-grained feature representations of different semantic scales. As the core component for our DS-TransUNet, a well-designed Transformer Interactive Fusion (TIF) module is proposed to effectively establish global dependencies between features of different scales through the self-attention mechanism. Furthermore, we also introduce the Swin Transformer block into decoder to further explore the long-range contextual information during the up-sampling process. Extensive experiments across four typical tasks for medical image segmentation demonstrate the effectiveness of DS-TransUNet, and show that our approach significantly outperforms the state-of-the-art methods.",0
"Thanks to the progress of deep learning, automatic medical image segmentation has advanced greatly. However, current methods mainly rely on convolutional neural networks (CNNs) which have limited receptive fields, resulting in a lack of long-range dependencies and global context connections. Researchers have attempted to address this issue by designing robust variants of Transformer-based U-Net, inspired by the success of Transformer in modeling long-range contextual information. Unfortunately, the patch division used in vision transformers disregards intrinsic pixel-level structural features present within each patch. To overcome these limitations, we propose a novel deep medical image segmentation framework called Dual Swin Transformer U-Net (DS-TransUNet). This approach is the first to concurrently integrate the hierarchical Swin Transformer into both the encoder and decoder of the standard U-shaped architecture to enhance the semantic segmentation quality of varying medical images. Unlike prior Transformer-based solutions, DS-TransUNet first utilizes dual-scale encoder subnetworks based on Swin Transformer to extract coarse and fine-grained feature representations of different semantic scales. A well-designed Transformer Interactive Fusion (TIF) module is then introduced as the core component of DS-TransUNet to establish effective global dependencies between features of different scales through self-attention. Additionally, the Swin Transformer block is integrated into the decoder to explore long-range contextual information during the up-sampling process. Our extensive experiments across four typical tasks for medical image segmentation demonstrate the effectiveness of DS-TransUNet, and show that our approach significantly outperforms the state-of-the-art methods.",1
"Deep learning has demonstrated significant improvements in medical image segmentation using a sufficiently large amount of training data with manual labels. Acquiring well-representative labels requires expert knowledge and exhaustive labors. In this paper, we aim to boost the performance of semi-supervised learning for medical image segmentation with limited labels using a self-ensembling contrastive learning technique. To this end, we propose to train an encoder-decoder network at image-level with small amounts of labeled images, and more importantly, we learn latent representations directly at feature-level by imposing contrastive loss on unlabeled images. This method strengthens intra-class compactness and inter-class separability, so as to get a better pixel classifier. Moreover, we devise a student encoder for online learning and an exponential moving average version of it, called teacher encoder, to improve the performance iteratively in a self-ensembling manner. To construct contrastive samples with unlabeled images, two sampling strategies that exploit structure similarity across medical images and utilize pseudo-labels for construction, termed region-aware and anatomical-aware contrastive sampling, are investigated. We conduct extensive experiments on an MRI and a CT segmentation dataset and demonstrate that in a limited label setting, the proposed method achieves state-of-the-art performance. Moreover, the anatomical-aware strategy that prepares contrastive samples on-the-fly using pseudo-labels realizes better contrastive regularization on feature representations.",0
"By utilizing a significant amount of manually labeled training data, deep learning has shown considerable advancements in medical image segmentation. However, obtaining these well-represented labels requires a great deal of expert knowledge and labor. Therefore, this study seeks to enhance the performance of semi-supervised learning for medical image segmentation with limited labels by using a self-ensembling contrastive learning technique. The proposed method trains an encoder-decoder network at image-level with a small number of labeled images and learns latent representations directly at feature-level by imposing contrastive loss on unlabeled images. This strategy improves pixel classification by strengthening intra-class compactness and inter-class separability. Furthermore, the study introduces a student encoder for online learning and a teacher encoder, which is an exponential moving average version of the student encoder, to enhance performance iteratively in a self-ensembling manner. To construct contrastive samples with unlabeled images, the study investigates two sampling strategies, region-aware and anatomical-aware contrastive sampling, that exploit structure similarity across medical images and utilize pseudo-labels for construction. The experiments conducted on an MRI and a CT segmentation dataset demonstrate that the proposed method achieves state-of-the-art performance in a limited label setting. Additionally, the anatomical-aware strategy that prepares contrastive samples on-the-fly using pseudo-labels achieves better contrastive regularization on feature representations.",1
"The segmentation of nanoscale electron microscopy (EM) images is crucial but challenging in connectomics. Recent advances in deep learning have demonstrated the significant potential of automatic segmentation for tera-scale EM images. However, none of the existing segmentation methods are error-free, and they require proofreading, which is typically implemented as an interactive, semi-automatic process via manual intervention. Herein, we propose a fully automatic proofreading method based on reinforcement learning. The main idea is to model the human decision process in proofreading using a reinforcement agent to achieve fully automatic proofreading. We systematically design the proposed system by combining multiple reinforcement learning agents in a hierarchical manner, where each agent focuses only on a specific task while preserving dependency between agents. Furthermore, we also demonstrate that the episodic task setting of reinforcement learning can efficiently manage a combination of merge and split errors concurrently presented in the input. We demonstrate the efficacy of the proposed system by comparing it with state-of-the-art proofreading methods using various testing examples.",0
"In connectomics, the segmentation of nanoscale electron microscopy (EM) images is a crucial yet challenging task. Recent advancements in deep learning have shown the potential of automatic segmentation for tera-scale EM images. However, existing segmentation methods are prone to errors and necessitate proofreading, which typically requires manual intervention. To address this, we present a fully automatic proofreading method based on reinforcement learning. Our approach models the human decision process in proofreading using a reinforcement agent to achieve fully automatic proofreading. We design the system by combining multiple reinforcement learning agents in a hierarchical manner, with each agent focusing on a specific task while preserving dependency between agents. Moreover, we demonstrate that the episodic task setting of reinforcement learning can efficiently manage a combination of merge and split errors concurrently presented in the input. We compare the efficacy of the proposed system with state-of-the-art proofreading methods using various testing examples.",1
"Medical image segmentation is one of the important tasks of computer-aided diagnosis in medical image analysis. Since most medical images have the characteristics of blurred boundaries and uneven intensity distribution, through existing segmentation methods, the discontinuity within the target area and the discontinuity of the target boundary are likely to lead to rough or even erroneous boundary delineation. In this paper, we propose a new iterative refined interactive segmentation method for medical images based on agent reinforcement learning, which focuses on the problem of target segmentation boundaries. We model the dynamic process of drawing the target contour in a certain order as a Markov Decision Process (MDP) based on a deep reinforcement learning method. In the dynamic process of continuous interaction between the agent and the image, the agent tracks the boundary point by point in order within a limited length range until the contour of the target is completely drawn. In this process, the agent can quickly improve the segmentation performance by exploring an interactive policy in the image. The method we proposed is simple and effective. At the same time, we evaluate our method on the cardiac MRI scan data set. Experimental results show that our method has a better segmentation effect on the left ventricle in a small number of medical image data sets, especially in terms of segmentation boundaries, this method is better than existing methods. Based on our proposed method, the dynamic generation process of the predicted contour trajectory of the left ventricle will be displayed online at https://github.com/H1997ym/LV-contour-trajectory.",0
"Medical image segmentation is a critical aspect of computer-aided diagnosis in medical image analysis. Most medical images exhibit blurred boundaries and uneven intensity distribution, making existing segmentation methods prone to rough or erroneous boundary delineation due to target area discontinuity. To address this issue, we introduce a novel iterative refined interactive segmentation method for medical images using agent reinforcement learning. Our approach focuses on target segmentation boundaries and models the dynamic process of drawing the target contour in a specific order as a Markov Decision Process (MDP) using deep reinforcement learning. Our agent tracks the boundary point by point within a limited range until the target contour is entirely drawn. By exploring an interactive policy within the image, our method quickly improves segmentation performance. We evaluate our method on a cardiac MRI scan dataset, and results show superior segmentation performance on the left ventricle, particularly in terms of segmentation boundaries, when compared to existing methods. We provide dynamic generation of the predicted contour trajectory of the left ventricle online at https://github.com/H1997ym/LV-contour-trajectory. Overall, our method is simple, effective, and has promising applications in medical image analysis.",1
"This paper addresses fast semantic segmentation on video.Video segmentation often calls for real-time, or even fasterthan real-time, processing. One common recipe for conserving computation arising from feature extraction is to propagate features of few selected keyframes. However, recent advances in fast image segmentation make these solutions less attractive. To leverage fast image segmentation for furthering video segmentation, we propose a simple yet efficient propagation framework. Specifically, we perform lightweight flow estimation in 1/8-downscaled image space for temporal warping in segmentation outpace space. Moreover, we introduce a guided spatially-varying convolution for fusing segmentations derived from the previous and current frames, to mitigate propagation error and enable lightweight feature extraction on non-keyframes. Experimental results on Cityscapes and CamVid show that our scheme achieves the state-of-the-art accuracy-throughput trade-off on video segmentation.",0
"The aim of this paper is to discuss the speedy semantic segmentation of video. In video segmentation, it is often necessary to process data in real-time or even faster. One way to save computation time when extracting features is to only use keyframes. However, this approach is becoming less popular due to recent advancements in fast image segmentation. To utilize these advancements for video segmentation, the authors suggest a straightforward yet effective propagation framework. This involves performing lightweight flow estimation in 1/8-downscaled image space for temporal warping in segmentation outpace space. Additionally, they introduce a guided spatially-varying convolution to combine segmentations from previous and current frames, reducing propagation error and enabling lightweight feature extraction on non-keyframes. The authors conducted experiments on Cityscapes and CamVid, and their findings reveal that their method achieves the best accuracy-throughput trade-off for video segmentation.",1
"There are many approaches that use weak-supervision to train networks to segment 2D images. By contrast, existing 3D approaches rely on full-supervision of a subset of 2D slices of the 3D image volume. In this paper, we propose an approach that is truly weakly-supervised in the sense that we only need to provide a sparse set of 3D point on the surface of target objects, an easy task that can be quickly done. We use the 3D points to deform a 3D template so that it roughly matches the target object outlines and we introduce an architecture that exploits the supervision provided by coarse template to train a network to find accurate boundaries.   We evaluate the performance of our approach on Computed Tomography (CT), Magnetic Resonance Imagery (MRI) and Electron Microscopy (EM) image datasets. We will show that it outperforms a more traditional approach to weak-supervision in 3D at a reduced supervision cost.",0
"Numerous methods employ weak-supervision to train networks for segmenting 2D images, whereas existing 3D approaches necessitate full-supervision of a subset of 2D slices in the 3D image volume. This study proposes a genuinely weakly-supervised approach that only requires a sparse set of 3D points on the surface of target objects, which is a simple task that can be quickly executed. The 3D points are employed to alter a 3D template to roughly match the target object outlines, and the authors introduce an architecture that utilizes the supervision provided by the coarse template to train a network to locate precise boundaries. The performance of this approach is evaluated on Computed Tomography (CT), Magnetic Resonance Imagery (MRI), and Electron Microscopy (EM) image datasets, and the results indicate that it outperforms a more conventional weak-supervision approach in 3D at a lower supervision cost.",1
"Classical supervised methods commonly used often suffer from the requirement of an abudant number of training samples and are unable to generalize on unseen datasets. As a result, the broader application of any trained model is very limited in clinical settings. However, few-shot approaches can minimize the need for enormous reliable ground truth labels that are both labor intensive and expensive. To this end, we propose to exploit an optimization-based implicit model agnostic meta-learning {iMAML} algorithm in a few-shot setting for medical image segmentation. Our approach can leverage the learned weights from a diverse set of training samples and can be deployed on a new unseen dataset. We show that unlike classical few-shot learning approaches, our method has improved generalization capability. To our knowledge, this is the first work that exploits iMAML for medical image segmentation. Our quantitative results on publicly available skin and polyp datasets show that the proposed method outperforms the naive supervised baseline model and two recent few-shot segmentation approaches by large margins.",0
"Supervised methods in the classical sense often require a large number of training samples and cannot effectively generalize to new datasets, limiting their potential applications in clinical settings. However, few-shot approaches can reduce the need for extensive, costly ground truth labeling. We propose utilizing an iMAML algorithm in a few-shot setting for medical image segmentation, which can utilize learned weights from multiple training samples and be applied to new, unseen datasets. Our method exhibits superior generalization capabilities compared to traditional few-shot approaches. This is the first instance of iMAML being utilized for medical image segmentation, and our results on skin and polyp datasets show significant improvement over the supervised baseline model and two recent few-shot segmentation approaches.",1
"While cloud/sky image segmentation has extensive real-world applications, a large amount of labelled data is needed to train a highly accurate models to perform the task. Scarcity of such volumes of cloud/sky images with corresponding ground-truth binary maps makes it highly difficult to train such complex image segmentation models. In this paper, we demonstrate the effectiveness of using Generative Adversarial Networks (GANs) to generate data to augment the training set in order to increase the prediction accuracy of image segmentation model. We further present a way to estimate ground-truth binary maps for the GAN-generated images to facilitate their effective use as augmented images. Finally, we validate our work with different statistical techniques.",0
"The task of cloud/sky image segmentation has numerous practical applications, but it requires a significant amount of labeled data to train models that can accurately perform the task. Unfortunately, there is a scarcity of such data, which makes it challenging to train complex image segmentation models. To address this issue, we propose using Generative Adversarial Networks (GANs) to generate data that can augment the training set and improve the accuracy of the prediction. We also offer a method for estimating ground-truth binary maps for the GAN-generated images, which ensures that they are effectively utilized as augmented images. Finally, we validate our approach using various statistical techniques.",1
"Contemporary domain adaptive semantic segmentation aims to address data annotation challenges by assuming that target domains are completely unannotated. However, annotating a few target samples is usually very manageable and worthwhile especially if it improves the adaptation performance substantially. This paper presents SSDAS, a Semi-Supervised Domain Adaptive image Segmentation network that employs a few labeled target samples as anchors for adaptive and progressive feature alignment between labeled source samples and unlabeled target samples. We position the few labeled target samples as references that gauge the similarity between source and target features and guide adaptive inter-domain alignment for learning more similar source features. In addition, we replace the dissimilar source features by high-confidence target features continuously during the iterative training process, which achieves progressive intra-domain alignment between confident and unconfident target features. Extensive experiments show the proposed SSDAS greatly outperforms a number of baselines, i.e., UDA-based semantic segmentation and SSDA-based image classification. In addition, SSDAS is complementary and can be easily incorporated into UDA-based methods with consistent improvements in domain adaptive semantic segmentation.",0
"The current approach to domain adaptive semantic segmentation assumes that the target domains have no annotations. However, annotating a small number of target samples can greatly enhance adaptation performance. This paper introduces SSDAS, a Semi-Supervised Domain Adaptive image Segmentation network that utilizes a few labeled target samples to align features between labeled source samples and unlabeled target samples in a progressive and adaptive manner. The labeled target samples are used as reference points to measure the similarity between source and target features, guiding inter-domain alignment and improving the similarity of source features. Moreover, the training process continuously replaces dissimilar source features with high-confidence target features, resulting in progressive intra-domain alignment. Extensive experiments demonstrate that SSDAS outperforms several baselines, including UDA-based semantic segmentation and SSDA-based image classification. Additionally, SSDAS can be easily integrated into UDA-based methods to enhance domain adaptive semantic segmentation.",1
"In applied image segmentation tasks, the ability to provide numerous and precise labels for training is paramount to the accuracy of the model at inference time. However, this overhead is often neglected, and recently proposed segmentation architectures rely heavily on the availability and fidelity of ground truth labels to achieve state-of-the-art accuracies. Failure to acknowledge the difficulty in creating adequate ground truths can lead to an over-reliance on pre-trained models or a lack of adoption in real-world applications. We introduce Points2Polygons (P2P), a model which makes use of contextual metric learning techniques that directly addresses this problem. Points2Polygons performs well against existing fully-supervised segmentation baselines with limited training data, despite using lightweight segmentation models (U-Net with a ResNet18 backbone) and having access to only weak labels in the form of object centroids and no pre-training. We demonstrate this on several different small but non-trivial datasets. We show that metric learning using contextual data provides key insights for self-supervised tasks in general, and allow segmentation models to easily generalize across traditionally label-intensive domains in computer vision.",0
"The accuracy of a model during inference in applied image segmentation tasks largely depends on the availability of precise labels for training. However, this crucial aspect is often overlooked, and modern segmentation architectures heavily rely on ground truth labels to achieve state-of-the-art accuracies. Failing to recognize the difficulty in creating adequate ground truths can result in a dependency on pre-trained models or a lack of adoption in real-world applications. To address this issue, we present Points2Polygons (P2P), a model that utilizes contextual metric learning techniques. Even with limited training data and weak labels in the form of object centroids and no pre-training, P2P outperforms existing fully-supervised segmentation baselines using lightweight segmentation models (U-Net with a ResNet18 backbone). We demonstrate this on several small but non-trivial datasets. Our study shows that metric learning using contextual data provides crucial insights for self-supervised tasks and allows segmentation models to easily generalize across traditionally label-intensive domains in computer vision.",1
"Contrastive learning has shown superior performance in embedding global and spatial invariant features in computer vision (e.g., image classification). However, its overall success of embedding local and spatial variant features is still limited, especially for semantic segmentation. In a per-pixel prediction task, more than one label can exist in a single image for segmentation (e.g., an image contains both cat, dog, and grass), thereby it is difficult to define 'positive' or 'negative' pairs in a canonical contrastive learning setting. In this paper, we propose an attention-guided supervised contrastive learning approach to highlight a single semantic object every time as the target. With our design, the same image can be embedded to different semantic clusters with semantic attention (i.e., coerce semantic masks) as an additional input channel. To achieve such attention, a novel two-stage training strategy is presented. We evaluate the proposed method on multi-organ medical image segmentation task, as our major task, with both in-house data and BTCV 2015 datasets. Comparing with the supervised and semi-supervised training state-of-the-art in the backbone of ResNet-50, our proposed pipeline yields substantial improvement of 5.53% and 6.09% in Dice score for both medical image segmentation cohorts respectively. The performance of the proposed method on natural images is assessed via PASCAL VOC 2012 dataset, and achieves 2.75% substantial improvement.",0
"While contrastive learning has proven successful in embedding global and spatially invariant features for image classification, it still struggles with embedding local and spatially variant features, particularly in semantic segmentation. This is due to the difficulty of defining positive and negative pairs in images containing multiple labels. To address this challenge, we introduce an attention-guided supervised contrastive learning approach that highlights a single semantic object as the target. Our design allows for the same image to be embedded into different semantic clusters with semantic attention as an additional input channel. To achieve this attention, we present a novel two-stage training strategy and evaluate our method on multi-organ medical image segmentation tasks, achieving substantial improvements compared to state-of-the-art supervised and semi-supervised training methods. We also evaluate our approach on natural images using the PASCAL VOC 2012 dataset and achieve a significant improvement in performance.",1
"Applications such as autonomous vehicles and medical screening use deep learning models to localize and identify hundreds of objects in a single frame. In the past, it has been shown how an attacker can fool these models by placing an adversarial patch within a scene. However, these patches must be placed in the target location and do not explicitly alter the semantics elsewhere in the image.   In this paper, we introduce a new type of adversarial patch which alters a model's perception of an image's semantics. These patches can be placed anywhere within an image to change the classification or semantics of locations far from the patch. We call this new class of adversarial examples `remote adversarial patches' (RAP).   We implement our own RAP called IPatch and perform an in-depth analysis on image segmentation RAP attacks using five state-of-the-art architectures with eight different encoders on the CamVid street view dataset. Moreover, we demonstrate that the attack can be extended to object recognition models with preliminary results on the popular YOLOv3 model. We found that the patch can change the classification of a remote target region with a success rate of up to 93% on average.",0
"Deep learning models are utilized in various applications like medical screening and autonomous vehicles to locate and identify numerous objects within a single frame. Previous studies have demonstrated the ability of attackers to deceive these models by placing an adversarial patch within the scene. However, these patches are limited to the target location and do not affect the semantics of other parts of the image. This study introduces a new kind of adversarial patch, which modifies the model's perception of an image's semantics and can be placed anywhere in the image, altering the classification or semantics of locations far from the patch. This new class of adversarial examples is referred to as `remote adversarial patches' (RAP). The study presents IPatch, a self-made RAP, and conducts a thorough analysis of RAP attacks on image segmentation using five state-of-the-art architectures with eight different encoders on the CamVid street view dataset. Additionally, the study shows that the attack can be extended to object recognition models, with preliminary results on the popular YOLOv3 model. The findings reveal that the patch can change the classification of a remote target region with an average success rate of up to 93%.",1
"Simultaneous localisation and categorization of objects in medical images, also referred to as medical object detection, is of high clinical relevance because diagnostic decisions often depend on rating of objects rather than e.g. pixels. For this task, the cumbersome and iterative process of method configuration constitutes a major research bottleneck. Recently, nnU-Net has tackled this challenge for the task of image segmentation with great success. Following nnU-Net's agenda, in this work we systematize and automate the configuration process for medical object detection. The resulting self-configuring method, nnDetection, adapts itself without any manual intervention to arbitrary medical detection problems while achieving results en par with or superior to the state-of-the-art. We demonstrate the effectiveness of nnDetection on two public benchmarks, ADAM and LUNA16, and propose 10 further medical object detection tasks on public data sets for comprehensive method evaluation. Code is at https://github.com/MIC-DKFZ/nnDetection .",0
"Detecting and categorizing objects in medical images is crucial for making accurate diagnostic decisions. However, configuring the methods for this task can be time-consuming and a major research challenge. nnU-Net has had great success in automating the configuration process for image segmentation, and this work builds on that success by developing nnDetection, a self-configuring method for medical object detection. nnDetection is able to adapt to various medical detection problems and achieves results comparable to or better than current state-of-the-art methods. The effectiveness of nnDetection is demonstrated on two public benchmarks, ADAM and LUNA16, and 10 additional medical object detection tasks are proposed for further evaluation. Code for nnDetection is available on GitHub at https://github.com/MIC-DKFZ/nnDetection.",1
"Performing inference in graphs is a common task within several machine learning problems, e.g., image segmentation, community detection, among others. For a given undirected connected graph, we tackle the statistical problem of exactly recovering an unknown ground-truth binary labeling of the nodes from a single corrupted observation of each edge. Such problem can be formulated as a quadratic combinatorial optimization problem over the boolean hypercube, where it has been shown before that one can (with high probability and in polynomial time) exactly recover the ground-truth labeling of graphs that have an isoperimetric number that grows with respect to the number of nodes (e.g., complete graphs, regular expanders). In this work, we apply a powerful hierarchy of relaxations, known as the sum-of-squares (SoS) hierarchy, to the combinatorial problem. Motivated by empirical evidence on the improvement in exact recoverability, we center our attention on the degree-4 SoS relaxation and set out to understand the origin of such improvement from a graph theoretical perspective. We show that the solution of the dual of the relaxed problem is related to finding edge weights of the Johnson and Kneser graphs, where the weights fulfill the SoS constraints and intuitively allow the input graph to increase its algebraic connectivity. Finally, as byproduct of our analysis, we derive a novel Cheeger-type lower bound for the algebraic connectivity of graphs with signed edge weights.",0
"In machine learning, performing inference in graphs is a common task for various applications, such as image segmentation and community detection. This study focuses on the statistical problem of recovering an unknown binary labeling of nodes in a given undirected connected graph from a single corrupted observation of each edge. The problem is formulated as a quadratic combinatorial optimization problem, which can be solved with high probability and in polynomial time for graphs with a growing isoperimetric number, like complete graphs and regular expanders. The sum-of-squares hierarchy is used as a powerful relaxation technique to improve exact recoverability. The degree-4 SoS relaxation is analyzed to understand its improvement from a graph theoretical perspective. The dual of the relaxed problem is related to finding edge weights of Johnson and Kneser graphs, which allow the input graph to increase its algebraic connectivity. As a byproduct, a novel Cheeger-type lower bound for the algebraic connectivity of graphs with signed edge weights is derived.",1
"Identification of abnormalities in red blood cells (RBC) is key to diagnosing a range of medical conditions from anaemia to liver disease. Currently this is done manually, a time-consuming and subjective process. This paper presents an automated process utilising the advantages of machine learning to increase capacity and standardisation of cell abnormality detection, and its performance is analysed. Three different machine learning technologies were used: a Support Vector Machine (SVM), a classical machine learning technology; TabNet, a deep learning architecture for tabular data; U-Net, a semantic segmentation network designed for medical image segmentation. A critical issue was the highly imbalanced nature of the dataset which impacts the efficacy of machine learning. To address this, synthesising minority class samples in feature space was investigated via Synthetic Minority Over-sampling Technique (SMOTE) and cost-sensitive learning. A combination of these two methods is investigated to improve the overall performance. These strategies were found to increase sensitivity to minority classes. The impact of unknown cells on semantic segmentation is demonstrated, with some evidence of the model applying learning of labelled cells to these anonymous cells. These findings indicate both classical models and new deep learning networks as promising methods in automating RBC abnormality detection.",0
"Diagnosing various medical conditions ranging from anaemia to liver disease requires the identification of abnormalities in red blood cells (RBC). However, the current process for this task is time-consuming and subjective, as it is done manually. This study aims to automate the process of RBC abnormality detection by utilizing the benefits of machine learning, which can increase capacity and standardization. Three different machine learning technologies were utilized: a classical machine learning technology called Support Vector Machine (SVM), a deep learning architecture called TabNet designed for tabular data, and U-Net, a semantic segmentation network designed for medical image segmentation. The highly imbalanced dataset was a critical issue that impacted the efficacy of machine learning, and to address this, Synthetic Minority Over-sampling Technique (SMOTE) and cost-sensitive learning were investigated. Combining these two methods improved overall performance and increased sensitivity to minority classes. The study also demonstrated the impact of unknown cells on semantic segmentation. The findings suggest that both classical models and new deep learning networks are promising methods for automating RBC abnormality detection.",1
"Despite much recent work, detecting out-of-distribution (OOD) inputs and adversarial attacks (AA) for computer vision models remains a challenge. In this work, we introduce a novel technique, DAAIN, to detect OOD inputs and AA for image segmentation in a unified setting. Our approach monitors the inner workings of a neural network and learns a density estimator of the activation distribution. We equip the density estimator with a classification head to discriminate between regular and anomalous inputs. To deal with the high-dimensional activation-space of typical segmentation networks, we subsample them to obtain a homogeneous spatial and layer-wise coverage. The subsampling pattern is chosen once per monitored model and kept fixed for all inputs. Since the attacker has access to neither the detection model nor the sampling key, it becomes harder for them to attack the segmentation network, as the attack cannot be backpropagated through the detector. We demonstrate the effectiveness of our approach using an ESPNet trained on the Cityscapes dataset as segmentation model, an affine Normalizing Flow as density estimator and use blue noise to ensure homogeneous sampling. Our model can be trained on a single GPU making it compute efficient and deployable without requiring specialized accelerators.",0
"Despite extensive efforts, the detection of out-of-distribution inputs and adversarial attacks in computer vision models remains a formidable task. In this study, we propose a novel technique called DAAIN that can detect both out-of-distribution inputs and adversarial attacks for image segmentation in a unified framework. Our method utilizes a neural network's internal processes and establishes a density estimator of the activation distribution. We enhance the density estimator with a classification head that can differentiate between regular and anomalous inputs. To address the high-dimensional activation-space of typical segmentation networks, we subsample them to ensure uniform spatial and layer-wise coverage. The subsampling pattern is selected once for each monitored model and is unchangeable for all inputs. Since the detection model and the sampling key are inaccessible to the attacker, it becomes more difficult for them to attack the segmentation network, as the attack cannot be backpropagated through the detector. We demonstrate the efficacy of our approach using an ESPNet trained on the Cityscapes dataset as a segmentation model, an affine Normalizing Flow as a density estimator, and blue noise to ensure uniform sampling. Our model is computationally efficient, can be trained on a single GPU, and can be deployed without requiring specialized accelerators.",1
"Currently, developments of deep learning techniques are providing instrumental to identify, classify, and quantify patterns in medical images. Segmentation is one of the important applications in medical image analysis. In this regard, U-Net is the predominant approach to medical image segmentation tasks. However, we found that those U-Net based models have limitations in several aspects, for example, millions of parameters in the U-Net consuming considerable computation resource and memory, lack of global information, and missing some tough objects. Therefore, we applied two modifications to improve the U-Net model: 1) designed and added the dilated channel-wise CNN module, 2) simplified the U shape network. Based on these two modifications, we proposed a novel light-weight architecture -- Channel-wise Feature Pyramid Network for Medicine (CFPNet-M). To evaluate our method, we selected five datasets with different modalities: thermography, electron microscopy, endoscopy, dermoscopy, and digital retinal images. And we compared its performance with several models having different parameter scales. This paper also involves our previous studies of DC-UNet and some commonly used light-weight neural networks. We applied the Tanimoto similarity instead of the Jaccard index for gray-level image measurements. By comparison, CFPNet-M achieves comparable segmentation results on all five medical datasets with only 0.65 million parameters, which is about 2% of U-Net, and 8.8 MB memory. Meanwhile, the inference speed can reach 80 FPS on a single RTX 2070Ti GPU with the 256 by 192 pixels input size.",0
"Deep learning techniques are currently being used to identify, classify, and quantify patterns in medical images. Medical image analysis relies heavily on segmentation, in which U-Net is the predominant approach. However, U-Net has limitations, such as consuming extensive computation resources and memory, lacking global information, and missing tough objects. To address these limitations, we made two modifications to the U-Net model: 1) designed and added the dilated channel-wise CNN module, and 2) simplified the U shape network to create a novel architecture called Channel-wise Feature Pyramid Network for Medicine (CFPNet-M). We evaluated CFPNet-M on five datasets with different modalities and compared its performance with several models of different parameter scales, including our previous studies of DC-UNet and commonly used light-weight neural networks. We used Tanimoto similarity instead of Jaccard index for gray-level image measurements. Compared to U-Net, CFPNet-M achieved comparable segmentation results on all five medical datasets with only 0.65 million parameters, which is about 2% of U-Net, and 8.8 MB memory. Additionally, the inference speed reached 80 FPS on a single RTX 2070Ti GPU with a 256 by 192 pixels input size.",1
"As the most economical and routine auxiliary examination in the diagnosis of root canal treatment, oral X-ray has been widely used by stomatologists. It is still challenging to segment the tooth root with a blurry boundary for the traditional image segmentation method. To this end, we propose a model for high-resolution segmentation based on polynomial curve fitting with landmark detection (HS-PCL). It is based on detecting multiple landmarks evenly distributed on the edge of the tooth root to fit a smooth polynomial curve as the segmentation of the tooth root, thereby solving the problem of fuzzy edge. In our model, a maximum number of the shortest distances algorithm (MNSDA) is proposed to automatically reduce the negative influence of the wrong landmarks which are detected incorrectly and deviate from the tooth root on the fitting result. Our numerical experiments demonstrate that the proposed approach not only reduces Hausdorff95 (HD95) by 33.9% and Average Surface Distance (ASD) by 42.1% compared with the state-of-the-art method, but it also achieves excellent results on the minute quantity of datasets, which greatly improves the feasibility of automatic root canal therapy evaluation by medical image computing.",0
"Stomatologists widely use oral X-ray as an economical and routine auxiliary examination in the diagnosis of root canal treatment. However, traditional image segmentation methods face challenges in segmenting the tooth root due to its blurry boundary. To address this issue, we propose a high-resolution segmentation model, HS-PCL, based on polynomial curve fitting with landmark detection. This model detects multiple landmarks evenly distributed on the edge of the tooth root to fit a smooth polynomial curve for accurate segmentation. Our model also includes a maximum number of shortest distances algorithm (MNSDA) to minimize the negative impact of incorrectly detected landmarks on the fitting result. Our numerical experiments demonstrate that the proposed approach significantly reduces Hausdorff95 (HD95) and Average Surface Distance (ASD) when compared to the state-of-the-art method. Moreover, our approach achieves excellent results on a small dataset, making it feasible for automatic root canal therapy evaluation by medical image computing.",1
"Estimating the amount of electricity that can be produced by rooftop photovoltaic systems is a time-consuming process that requires on-site measurements, a difficult task to achieve on a large scale. In this paper, we present an approach to estimate the solar potential of rooftops based on their location and architectural characteristics, as well as the amount of solar radiation they receive annually. Our technique uses computer vision to achieve semantic segmentation of roof sections and roof objects on the one hand, and a machine learning model based on structured building features to predict roof pitch on the other hand. We then compute the azimuth and maximum number of solar panels that can be installed on a rooftop with geometric approaches. Finally, we compute precise shading masks and combine them with solar irradiation data that enables us to estimate the yearly solar potential of a rooftop.",0
"A challenging and time-consuming task is to determine the amount of electricity that can be generated by rooftop photovoltaic systems, especially on a large scale, due to the requirement of on-site measurements. This paper proposes an alternative approach to estimate the solar potential of rooftops by considering their location, architectural characteristics, and annual solar radiation. The proposed method employs computer vision to achieve semantic segmentation of roof sections and objects and a machine learning model to predict roof pitch. Additionally, we use geometric approaches to determine the azimuth and maximum number of solar panels that can be installed on the rooftop. Finally, we compute precise shading masks and combine them with solar irradiation data to estimate the yearly solar potential of the rooftop.",1
"Quantitative bone single-photon emission computed tomography (QBSPECT) has the potential to provide a better quantitative assessment of bone metastasis than planar bone scintigraphy due to its ability to better quantify activity in overlapping structures. An important element of assessing response of bone metastasis is accurate image segmentation. However, limited by the properties of QBSPECT images, the segmentation of anatomical regions-of-interests (ROIs) still relies heavily on the manual delineation by experts. This work proposes a fast and robust automated segmentation method for partitioning a QBSPECT image into lesion, bone, and background. We present a new unsupervised segmentation loss function and its semi- and supervised variants for training a convolutional neural network (ConvNet). The loss functions were developed based on the objective function of the classical Fuzzy C-means (FCM) algorithm. We conducted a comprehensive study to compare our proposed methods with ConvNets trained using supervised loss functions and conventional clustering methods. The Dice similarity coefficient (DSC) and several other metrics were used as figures of merit as applied to the task of delineating lesion and bone in both simulated and clinical SPECT/CT images. We experimentally demonstrated that the proposed methods yielded good segmentation results on a clinical dataset even though the training was done using realistic simulated images. A ConvNet-based image segmentation method that uses novel loss functions was developed and evaluated. The method can operate in unsupervised, semi-supervised, or fully-supervised modes depending on the availability of annotated training data. The results demonstrated that the proposed method provides fast and robust lesion and bone segmentation for QBSPECT/CT. The method can potentially be applied to other medical image segmentation applications.",0
"Quantitative bone single-photon emission computed tomography (QBSPECT) shows promise for providing a more precise assessment of bone metastasis than planar bone scintigraphy because it can more accurately measure activity in overlapping structures. However, accurately segmenting anatomical regions-of-interests (ROIs) remains a challenge due to limitations in QBSPECT images, which still require manual delineation by experts. This study proposes a new automated segmentation method that partitions a QBSPECT image into lesion, bone, and background. The method uses an unsupervised segmentation loss function and its semi- and supervised variants to train a convolutional neural network (ConvNet), based on the objective function of the classical Fuzzy C-means (FCM) algorithm. The proposed method was compared to ConvNets trained using supervised loss functions and conventional clustering methods, using the Dice similarity coefficient (DSC) and other metrics to assess lesion and bone delineation in both simulated and clinical SPECT/CT images. Results showed that the proposed method yielded good segmentation results on clinical datasets, even when trained using realistic simulated images. The method can operate in unsupervised, semi-supervised, or fully-supervised modes, and has potential for use in other medical image segmentation applications.",1
"Generative flows and diffusion models have been predominantly trained on ordinal data, for example natural images. This paper introduces two extensions of flows and diffusion for categorical data such as language or image segmentation: Argmax Flows and Multinomial Diffusion. Argmax Flows are defined by a composition of a continuous distribution (such as a normalizing flow), and an argmax function. To optimize this model, we learn a probabilistic inverse for the argmax that lifts the categorical data to a continuous space. Multinomial Diffusion gradually adds categorical noise in a diffusion process, for which the generative denoising process is learned. We demonstrate that our method outperforms existing dequantization approaches on text modelling and modelling on image segmentation maps in log-likelihood.",0
"The training of generative flows and diffusion models has primarily focused on ordinal data, specifically natural images. This research article presents two novel approaches to extend flows and diffusion models to categorical data, such as language or image segmentation. These approaches include Argmax Flows, which utilize a continuous distribution and an argmax function, and Multinomial Diffusion, which gradually incorporates categorical noise through a generative denoising process. To optimize our models, we develop a probabilistic inverse to lift categorical data to a continuous space. Our results demonstrate that our techniques outperform existing dequantization methods for text modeling and image segmentation mapping in log-likelihood.",1
"In this paper, we show how uncertainty estimation can be leveraged to enable safety critical image segmentation in autonomous driving, by triggering a fallback behavior if a target accuracy cannot be guaranteed. We introduce a new uncertainty measure based on disagreeing predictions as measured by a dissimilarity function. We propose to estimate this dissimilarity by training a deep neural architecture in parallel to the task-specific network. It allows this observer to be dedicated to the uncertainty estimation, and let the task-specific network make predictions. We propose to use self-supervision to train the observer, which implies that our method does not require additional training data. We show experimentally that our proposed approach is much less computationally intensive at inference time than competing methods (e.g. MCDropout), while delivering better results on safety-oriented evaluation metrics on the CamVid dataset, especially in the case of glare artifacts.",0
"This paper demonstrates how uncertainty estimation can facilitate safe image segmentation for autonomous driving by activating a fallback behavior when a certain level of accuracy cannot be ensured. The authors introduce a novel measure of uncertainty based on divergent predictions as determined by a dissimilarity function. To estimate this dissimilarity, the authors train a deep neural architecture concurrently with the task-specific network. The observer is exclusively dedicated to uncertainty estimation, leaving the task-specific network to make predictions. The authors employ self-supervision to train the observer, eliminating the need for additional training data. The experimental results indicate that the proposed approach is more efficient at inference time than competing methods, such as MCDropout, while also achieving superior results on safety-focused evaluation metrics on the CamVid dataset, particularly in the presence of glare artifacts.",1
"We propose a novel method for fine-grained high-quality image segmentation of both objects and scenes. Inspired by dilation and erosion from morphological image processing techniques, we treat the pixel level segmentation problems as squeezing object boundary. From this perspective, we propose \textbf{Boundary Squeeze} module: a novel and efficient module that squeezes the object boundary from both inner and outer directions which leads to precise mask representation. To generate such squeezed representation, we propose a new bidirectionally flow-based warping process and design specific loss signals to supervise the learning process. Boundary Squeeze Module can be easily applied to both instance and semantic segmentation tasks as a plug-and-play module by building on top of existing models. We show that our simple yet effective design can lead to high qualitative results on several different datasets and we also provide several different metrics on boundary to prove the effectiveness over previous work. Moreover, the proposed module is light-weighted and thus has potential for practical usage. Our method yields large gains on COCO, Cityscapes, for both instance and semantic segmentation and outperforms previous state-of-the-art PointRend in both accuracy and speed under the same setting. Code and model will be available.",0
"Our innovative approach proposes a method for precise image segmentation of objects and scenes. We drew inspiration from morphological image processing techniques, specifically dilation and erosion, and viewed pixel level segmentation as a boundary squeezing problem. As a result, we developed the Boundary Squeeze module, which efficiently squeezes object boundaries from both inner and outer directions, producing accurate mask representations. Our bidirectional flow-based warping process and specific loss signals ensure the creation of such squeezed representations. The module can be seamlessly integrated as a plug-and-play component to existing models for both instance and semantic segmentation tasks. Our design yields impressive qualitative results on various datasets, supported by several boundary metrics that prove its superiority over previous work. Additionally, our module is light-weight and practical for everyday usage. Our method outperforms the previous state-of-the-art PointRend in both accuracy and speed on COCO and Cityscapes. The code and model will be publicly available.",1
"Interactive single-image segmentation is ubiquitous in the scientific and commercial imaging software. In this work, we focus on the single-image segmentation problem only with some seeds such as scribbles. Inspired by the dynamic receptive field in the human being's visual system, we propose the Gaussian dynamic convolution (GDC) to fast and efficiently aggregate the contextual information for neural networks. The core idea is randomly selecting the spatial sampling area according to the Gaussian distribution offsets. Our GDC can be easily used as a module to build lightweight or complex segmentation networks. We adopt the proposed GDC to address the typical single-image segmentation tasks. Furthermore, we also build a Gaussian dynamic pyramid Pooling to show its potential and generality in common semantic segmentation. Experiments demonstrate that the GDC outperforms other existing convolutions on three benchmark segmentation datasets including Pascal-Context, Pascal-VOC 2012, and Cityscapes. Additional experiments are also conducted to illustrate that the GDC can produce richer and more vivid features compared with other convolutions. In general, our GDC is conducive to the convolutional neural networks to form an overall impression of the image.",0
"Single-image segmentation with interactive features is widely used in both scientific and commercial imaging software. This study focuses on the problem of single-image segmentation with selected seeds, such as scribbles. To enhance contextual information aggregation for neural networks, we propose the Gaussian dynamic convolution (GDC) inspired by the dynamic receptive field in human visual systems. The GDC module randomly selects the spatial sampling area based on Gaussian distribution offsets, allowing for efficient and fast information aggregation. The GDC module is adaptable to lightweight or complex segmentation networks and applied to typical single-image segmentation tasks. Additionally, a Gaussian dynamic pyramid pooling is built to showcase its potential and versatility in common semantic segmentation. The GDC outperforms other convolutions on three benchmark segmentation datasets, including Pascal-Context, Pascal-VOC 2012, and Cityscapes. Further experiments show that the GDC produces richer and more vivid features than other convolutions. Overall, our proposed GDC module is an effective tool for convolutional neural networks to gain an in-depth understanding of the image.",1
"We present a Neural Network based Handwritten Text Recognition (HTR) model architecture that can be trained to recognize full pages of handwritten or printed text without image segmentation. Being based on Image to Sequence architecture, it can extract text present in an image and then sequence it correctly without imposing any constraints regarding orientation, layout and size of text and non-text. Further, it can also be trained to generate auxiliary markup related to formatting, layout and content. We use character level vocabulary, thereby enabling language and terminology of any subject. The model achieves a new state-of-art in paragraph level recognition on the IAM dataset. When evaluated on scans of real world handwritten free form test answers - beset with curved and slanted lines, drawings, tables, math, chemistry and other symbols - it performs better than all commercially available HTR cloud APIs. It is deployed in production as part of a commercial web application.",0
"Our proposed architecture for Handwritten Text Recognition (HTR) is based on a Neural Network and can recognize whole pages of handwritten or printed text without requiring image segmentation. It uses an Image to Sequence model, allowing it to extract text from images and sequence it accurately without any limitations on orientation, layout, or text size. Additionally, it can be trained to generate auxiliary markup related to formatting, layout, and content. By using character-level vocabulary, it can recognize language and terminology from any subject. Our model achieves the highest accuracy in paragraph-level recognition on the IAM dataset. It performs better than all commercially available HTR cloud APIs when evaluated on real-world handwritten free form test answers, which may include curved and slanted lines, drawings, tables, and various symbols related to math and chemistry. This model is currently being used in a commercial web application.",1
"This paper presents a game, controlled by computer vision, in identification of hand gestures (hand-tracking). The proposed work is based on image segmentation and construction of a convex hull with Jarvis Algorithm , and determination of the pattern based on the extraction of area characteristics in the convex hull.",0
"In this article, a computer vision-controlled game is introduced that uses hand-tracking to identify hand gestures. The method involves image segmentation and creating a convex hull using the Jarvis Algorithm. The pattern is determined through the extraction of area characteristics in the convex hull.",1
"Active contours Model (ACM) has been extensively used in computer vision and image processing. In recent studies, Convolutional Neural Networks (CNNs) have been combined with active contours replacing the user in the process of contour evolution and image segmentation to eliminate limitations associated with ACM's dependence on parameters of the energy functional and initialization. However, prior works did not aim for automatic initialization which is addressed here. In addition to manual initialization, current methods are highly sensitive to initial location and fail to delineate borders accurately. We propose a fully automatic image segmentation method to address problems of manual initialization, insufficient capture range, and poor convergence to boundaries, in addition to the problem of assignment of energy functional parameters. We train two CNNs, which predict active contour weighting parameters and generate a ground truth mask to extract Distance Transform (DT) and an initialization circle. Distance transform is used to form a vector field pointing from each pixel of the image towards the closest point on the boundary, the size of which is equal to the Euclidean distance map. We evaluate our method on four publicly available datasets including two building instance segmentation datasets, Vaihingen and Bing huts, and two mammography image datasets, INBreast and DDSM-BCRP. Our approach outperforms latest research by 0.59 ans 2.39 percent in mean Intersection-over-Union (mIoU), 7.38 and 8.62 percent in Boundary F-score (BoundF) for Vaihingen and Bing huts datasets, respectively. Dice similarity coefficient for the INBreast and DDSM-BCRP datasets is 94.23% and 90.89%, respectively indicating our method is comparable to state-of-the-art frameworks.",0
"Computer vision and image processing rely heavily on the Active Contours Model (ACM). Recent studies have combined ACM with Convolutional Neural Networks (CNNs) to replace the user in contour evolution and image segmentation, eliminating limitations associated with ACM's dependence on energy functional parameters and initialization. However, prior works did not focus on automatic initialization. Current methods are sensitive to initial location and fail to accurately delineate borders. To address these issues, we propose a fully automatic image segmentation method. We train two CNNs to predict active contour weighting parameters and generate a ground truth mask to extract Distance Transform (DT) and an initialization circle. Our approach outperforms the latest research in mean Intersection-over-Union (mIoU) and Boundary F-score (BoundF) for four publicly available datasets, including two building instance segmentation datasets (Vaihingen and Bing huts) and two mammography image datasets (INBreast and DDSM-BCRP). The Dice similarity coefficient for the INBreast and DDSM-BCRP datasets is 94.23% and 90.89%, respectively, indicating that our method is comparable to state-of-the-art frameworks.",1
"Image Segmentation has been an active field of research as it has a wide range of applications, ranging from automated disease detection to self-driving cars. In recent years, various research papers proposed different loss functions used in case of biased data, sparse segmentation, and unbalanced dataset. In this paper, we introduce SemSegLoss, a python package consisting of some of the well-known loss functions widely used for image segmentation. It is developed with the intent to help researchers in the development of novel loss functions and perform an extensive set of experiments on model architectures for various applications. The ease-of-use and flexibility of the presented package have allowed reducing the development time and increased evaluation strategies of machine learning models for semantic segmentation. Furthermore, different applications that use image segmentation can use SemSegLoss because of the generality of its functions. This wide range of applications will lead to the development and growth of AI across all industries.",0
"The field of Image Segmentation has been an area of active research due to its diverse range of applications, including automated disease detection and self-driving cars. Recently, several research papers have proposed different loss functions to address issues such as biased data, sparse segmentation, and unbalanced datasets. This paper introduces SemSegLoss, a python package that includes well-known loss functions for image segmentation. The package is designed to assist researchers in developing novel loss functions and conducting extensive experiments on model architectures for various applications. The package's ease-of-use and flexibility have reduced development time and increased evaluation strategies for machine learning models used in semantic segmentation. Its functions are generally applicable, making it useful for different applications that require image segmentation. The package's broad scope of applications will contribute to the growth and development of AI across all industries.",1
"Recent research has shown that numerous human-interpretable directions exist in the latent space of GANs. In this paper, we develop an automatic procedure for finding directions that lead to foreground-background image separation, and we use these directions to train an image segmentation model without human supervision. Our method is generator-agnostic, producing strong segmentation results with a wide range of different GAN architectures. Furthermore, by leveraging GANs pretrained on large datasets such as ImageNet, we are able to segment images from a range of domains without further training or finetuning. Evaluating our method on image segmentation benchmarks, we compare favorably to prior work while using neither human supervision nor access to the training data. Broadly, our results demonstrate that automatically extracting foreground-background structure from pretrained deep generative models can serve as a remarkably effective substitute for human supervision.",0
"According to recent research, there are various understandable paths in the latent space of GANs. In this study, we have created an automated procedure that identifies paths that can be used for foreground-background image separation. These paths have been used to train an image segmentation model without any human intervention. Our approach can be applied to different GAN architectures and produces powerful segmentation outcomes. Additionally, by utilizing GANs that have been pretrained on vast datasets, like ImageNet, we can segment images from various domains without requiring further training or finetuning. Our method has been evaluated on image segmentation benchmarks and has been shown to perform better than previous methods without the need for human supervision or access to the training data. Overall, our findings demonstrate that automatically extracting foreground-background structure from pretrained deep generative models can provide an effective alternative to human supervision.",1
"Recent works in medical image segmentation have actively explored various deep learning architectures or objective functions to encode high-level features from volumetric data owing to limited image annotations. However, most existing approaches tend to ignore cross-volume global context and define context relations in the decision space. In this work, we propose a novel voxel-level Siamese representation learning method for abdominal multi-organ segmentation to improve representation space. The proposed method enforces voxel-wise feature relations in the representation space for leveraging limited datasets more comprehensively to achieve better performance. Inspired by recent progress in contrastive learning, we suppressed voxel-wise relations from the same class to be projected to the same point without using negative samples. Moreover, we introduce a multi-resolution context aggregation method that aggregates features from multiple hidden layers, which encodes both the global and local contexts for segmentation. Our experiments on the multi-organ dataset outperformed the existing approaches by 2% in Dice score coefficient. The qualitative visualizations of the representation spaces demonstrate that the improvements were gained primarily by a disentangled feature space.",0
"In the field of medical image segmentation, recent studies have extensively explored different deep learning architectures or objective functions to extract high-level features from volumetric data, due to limited image annotations. However, most current methods tend to overlook global context across volumes and establish context relations in the decision space. In this study, we propose a novel approach for abdominal multi-organ segmentation, which involves voxel-level Siamese representation learning to enhance representation space. Our method focuses on enforcing voxel-wise feature relations in the representation space to better utilize limited datasets and achieve improved performance. We were inspired by recent advancements in contrastive learning and avoided projecting voxel-wise relations from the same class onto the same point, without using negative samples. Additionally, we introduce a multi-resolution context aggregation approach that combines features from multiple hidden layers to encode both global and local contexts for segmentation. Our experiments on the multi-organ dataset demonstrated that our approach outperforms existing methods by 2% in Dice score coefficient. Visualization of the representation spaces showed that the improvements were mainly due to a disentangled feature space.",1
"Medical image segmentation models are typically supervised by expert annotations at the pixel-level, which can be expensive to acquire. In this work, we propose a method that combines the high quality of pixel-level expert annotations with the scale of coarse DNN-generated saliency maps for training multi-label semantic segmentation models. We demonstrate the application of our semi-supervised method, which we call CheXseg, on multi-label chest X-ray interpretation. We find that CheXseg improves upon the performance (mIoU) of fully-supervised methods that use only pixel-level expert annotations by 9.7% and weakly-supervised methods that use only DNN-generated saliency maps by 73.1%. Our best method is able to match radiologist agreement on three out of ten pathologies and reduces the overall performance gap by 57.2% as compared to weakly-supervised methods.",0
"Typically, medical image segmentation models rely on costly expert annotations at the pixel-level for supervision. However, we propose a new approach that leverages the precision of pixel-level annotations and the scalability of DNN-generated saliency maps to train multi-label semantic segmentation models. Our approach, called CheXseg, is demonstrated in the context of multi-label chest X-ray interpretation. We show that CheXseg outperforms fully-supervised methods using only expert annotations by 9.7% and weakly-supervised methods using only DNN-generated saliency maps by 73.1%. Our best method achieves radiologist-level agreement for three out of ten pathologies and narrows the performance gap by 57.2% compared to weakly-supervised approaches.",1
"Scalable sensor simulation is an important yet challenging open problem for safety-critical domains such as self-driving. Current works in image simulation either fail to be photorealistic or do not model the 3D environment and the dynamic objects within, losing high-level control and physical realism. In this paper, we present GeoSim, a geometry-aware image composition process which synthesizes novel urban driving scenarios by augmenting existing images with dynamic objects extracted from other scenes and rendered at novel poses. Towards this goal, we first build a diverse bank of 3D objects with both realistic geometry and appearance from sensor data. During simulation, we perform a novel geometry-aware simulation-by-composition procedure which 1) proposes plausible and realistic object placements into a given scene, 2) render novel views of dynamic objects from the asset bank, and 3) composes and blends the rendered image segments. The resulting synthetic images are realistic, traffic-aware, and geometrically consistent, allowing our approach to scale to complex use cases. We demonstrate two such important applications: long-range realistic video simulation across multiple camera sensors, and synthetic data generation for data augmentation on downstream segmentation tasks. Please check https://tmux.top/publication/geosim/ for high-resolution video results.",0
"The issue of scalable sensor simulation is a significant but challenging problem in high-stakes fields like self-driving vehicles. Current approaches to image simulation either lack photorealism or do not incorporate the 3D environment and dynamic objects, resulting in a lack of control and physical realism. In this study, we introduce GeoSim, a process that uses geometry to compose images and create novel urban driving scenarios by adding dynamic objects from other scenes at new angles to existing images. We begin by creating a collection of 3D objects with realistic geometry and appearance from sensor data. During simulation, we use a novel geometry-aware simulation-by-composition method that 1) suggests plausible and realistic object placements, 2) generates new views of dynamic objects from the asset bank, and 3) blends the rendered image segments. The resulting synthetic images are realistic, traffic-aware, and consistent geometrically, allowing for scalability in complex use cases. We demonstrate the effectiveness of our approach in two important applications: long-range realistic video simulation across multiple cameras and synthetic data generation for data augmentation in downstream segmentation tasks. For high-resolution video results, please visit https://tmux.top/publication/geosim/.",1
"Given a natural language expression and an image/video, the goal of referring segmentation is to produce the pixel-level masks of the entities described by the subject of the expression. Previous approaches tackle this problem by implicit feature interaction and fusion between visual and linguistic modalities in a one-stage manner. However, human tends to solve the referring problem in a progressive manner based on informative words in the expression, i.e., first roughly locating candidate entities and then distinguishing the target one. In this paper, we propose a Cross-Modal Progressive Comprehension (CMPC) scheme to effectively mimic human behaviors and implement it as a CMPC-I (Image) module and a CMPC-V (Video) module to improve referring image and video segmentation models. For image data, our CMPC-I module first employs entity and attribute words to perceive all the related entities that might be considered by the expression. Then, the relational words are adopted to highlight the target entity as well as suppress other irrelevant ones by spatial graph reasoning. For video data, our CMPC-V module further exploits action words based on CMPC-I to highlight the correct entity matched with the action cues by temporal graph reasoning. In addition to the CMPC, we also introduce a simple yet effective Text-Guided Feature Exchange (TGFE) module to integrate the reasoned multimodal features corresponding to different levels in the visual backbone under the guidance of textual information. In this way, multi-level features can communicate with each other and be mutually refined based on the textual context. Combining CMPC-I or CMPC-V with TGFE can form our image or video version referring segmentation frameworks and our frameworks achieve new state-of-the-art performances on four referring image segmentation benchmarks and three referring video segmentation benchmarks respectively.",0
"The objective of referring segmentation is to create pixel-level masks for the entities described in a natural language expression and an image or video. Previous approaches have used implicit feature interaction and fusion between visual and linguistic modalities in a one-stage process. However, humans tend to solve the referring problem progressively by first roughly locating candidate entities and then distinguishing the target one. To mimic this behavior, we propose a Cross-Modal Progressive Comprehension (CMPC) scheme, which includes a CMPC-I (Image) module and a CMPC-V (Video) module to enhance image and video segmentation models. Our CMPC-I module uses entity and attribute words to perceive all related entities and then uses relational words to highlight the target entity and suppress irrelevant ones by spatial graph reasoning. For video data, our CMPC-V module uses action words based on CMPC-I to highlight the correct entity matched with the action cues by temporal graph reasoning. We also introduce a Text-Guided Feature Exchange (TGFE) module to integrate reasoned multimodal features corresponding to different levels in the visual backbone under the guidance of textual information. Combining CMPC with TGFE results in our image or video version referring segmentation frameworks, which achieve new state-of-the-art performances on four referring image segmentation benchmarks and three referring video segmentation benchmarks.",1
"Automated segmentation in medical image analysis is a challenging task that requires a large amount of manually labeled data. However, manually annotating medical data is often laborious, and most existing learning-based approaches fail to accurately delineate object boundaries without effective geometric constraints. Contrastive learning, a sub-area of self-supervised learning, has recently been noted as a promising direction in multiple application fields. In this work, we present a novel Contrastive Voxel-wise Representation Learning (CVRL) method with geometric constraints to learn global-local visual representations for volumetric medical image segmentation with limited annotations. Our framework can effectively learn global and local features by capturing 3D spatial context and rich anatomical information. Specifically, we introduce a voxel-to-volume contrastive algorithm to learn global information from 3D images, and propose to perform local voxel-to-voxel contrast to explicitly make use of local cues in the embedding space. Moreover, we integrate an elastic interaction-based active contour model as a geometric regularization term to enable fast and reliable object delineations in an end-to-end learning manner. Results on the Atrial Segmentation Challenge dataset demonstrate superiority of our proposed scheme, especially in a setting with a very limited number of annotated data.",0
"Segmenting medical images automatically is a challenging task that requires a vast amount of manually labeled data. However, manually annotating medical data is often a tedious process, and most existing learning-based methods fail to accurately define object boundaries without effective geometric constraints. Recently, contrastive learning, a subfield of self-supervised learning, has been identified as a promising approach in several application fields. In this study, we introduce a novel Contrastive Voxel-wise Representation Learning (CVRL) method with geometric constraints to learn global-local visual representations for volumetric medical image segmentation with limited annotations. Our framework effectively captures 3D spatial context and rich anatomical information to learn global and local features. Specifically, we propose a voxel-to-volume contrastive algorithm to learn global information from 3D images and a local voxel-to-voxel contrast to use local cues in the embedding space explicitly. Additionally, we incorporate an elastic interaction-based active contour model as a geometric regularization term to achieve fast and reliable object delineation in an end-to-end learning manner. Our proposed scheme outperforms existing methods, especially in a setting with a limited number of annotated data, as demonstrated on the Atrial Segmentation Challenge dataset.",1
"A connectivity graph of neurons at the resolution of single synapses provides scientists with a tool for understanding the nervous system in health and disease. Recent advances in automatic image segmentation and synapse prediction in electron microscopy (EM) datasets of the brain have made reconstructions of neurons possible at the nanometer scale. However, automatic segmentation sometimes struggles to segment large neurons correctly, requiring human effort to proofread its output. General proofreading involves inspecting large volumes to correct segmentation errors at the pixel level, a visually intensive and time-consuming process. This paper presents the design and implementation of an analytics framework that streamlines proofreading, focusing on connectivity-related errors. We accomplish this with automated likely-error detection and synapse clustering that drives the proofreading effort with highly interactive 3D visualizations. In particular, our strategy centers on proofreading the local circuit of a single cell to ensure a basic level of completeness. We demonstrate our framework's utility with a user study and report quantitative and subjective feedback from our users. Overall, users find the framework more efficient for proofreading, understanding evolving graphs, and sharing error correction strategies.",0
"Scientists can gain a deeper understanding of the nervous system and its functioning in both healthy and diseased states by analyzing a connectivity graph of neurons at the level of individual synapses. Recent advancements in automated image segmentation and synapse prediction in electron microscopy (EM) datasets of the brain have made it possible to reconstruct neurons at the nanometer scale. However, automatic segmentation often struggles with large neurons, necessitating manual proofreading to correct any errors. This process is time-consuming and visually intensive, requiring inspectors to scrutinize large volumes at the pixel level. To streamline this proofreading process, we have designed and implemented an analytics framework that prioritizes connectivity-related errors. We have achieved this by using automated error detection and synapse clustering to drive highly interactive 3D visualizations. Our approach focuses on proofreading the local circuit of a single cell to ensure basic completeness. We have demonstrated the effectiveness of our framework through a user study, receiving positive quantitative and subjective feedback from our users who found it more efficient for proofreading, understanding evolving graphs, and sharing error correction strategies.",1
"Image segmentation refers to the separation of objects from the background, and has been one of the most challenging aspects of digital image processing. Practically it is impossible to design a segmentation algorithm which has 100% accuracy, and therefore numerous segmentation techniques have been proposed in the literature, each with certain limitations. In this paper, a novel Falling-Ball algorithm is presented, which is a region-based segmentation algorithm, and an alternative to watershed transform (based on waterfall model). The proposed algorithm detects the catchment basins by assuming that a ball falling from hilly terrains will stop in a catchment basin. Once catchment basins are identified, the association of each pixel with one of the catchment basin is obtained using multi-criterion fuzzy logic. Edges are constructed by dividing image into different catchment basins with the help of a membership function. Finally closed contour algorithm is applied to find closed regions and objects within closed regions are segmented using intensity information. The performance of the proposed algorithm is evaluated both objectively as well as subjectively. Simulation results show that the proposed algorithms gives superior performance over conventional Sobel edge detection methods and the watershed segmentation algorithm. For comparative analysis, various comparison methods are used for demonstrating the superiority of proposed methods over existing segmentation methods.",0
"The process of image segmentation involves separating objects from their background, which is a particularly challenging task in digital image processing. Since there is no segmentation algorithm that can achieve complete accuracy, many techniques have been proposed, each with their own limitations. This paper introduces a new method called the Falling-Ball algorithm, which is a region-based segmentation approach that offers an alternative to the commonly used watershed transform. The algorithm detects catchment basins by assuming that a ball rolling down a hill will stop in a basin. This information is used to associate each pixel with a specific basin using fuzzy logic. The image is then divided into different basins using a membership function, and closed regions are identified through a closed contour algorithm. Finally, objects within these regions are segmented using intensity information. The proposed algorithm performs better than the conventional Sobel edge detection and watershed segmentation methods, as demonstrated through objective and subjective evaluations. Comparative analysis also shows the superiority of this approach over existing segmentation methods.",1
"Food image segmentation is a critical and indispensible task for developing health-related applications such as estimating food calories and nutrients. Existing food image segmentation models are underperforming due to two reasons: (1) there is a lack of high quality food image datasets with fine-grained ingredient labels and pixel-wise location masks -- the existing datasets either carry coarse ingredient labels or are small in size; and (2) the complex appearance of food makes it difficult to localize and recognize ingredients in food images, e.g., the ingredients may overlap one another in the same image, and the identical ingredient may appear distinctly in different food images. In this work, we build a new food image dataset FoodSeg103 (and its extension FoodSeg154) containing 9,490 images. We annotate these images with 154 ingredient classes and each image has an average of 6 ingredient labels and pixel-wise masks. In addition, we propose a multi-modality pre-training approach called ReLeM that explicitly equips a segmentation model with rich and semantic food knowledge. In experiments, we use three popular semantic segmentation methods (i.e., Dilated Convolution based, Feature Pyramid based, and Vision Transformer based) as baselines, and evaluate them as well as ReLeM on our new datasets. We believe that the FoodSeg103 (and its extension FoodSeg154) and the pre-trained models using ReLeM can serve as a benchmark to facilitate future works on fine-grained food image understanding. We make all these datasets and methods public at \url{https://xiongweiwu.github.io/foodseg103.html}.",0
"Developing health-related applications, such as estimating food calories and nutrients, requires accurate food image segmentation. However, existing models underperform due to the lack of high-quality datasets with fine-grained ingredient labels and location masks, as well as the difficulty in recognizing overlapping ingredients with distinct appearances. To address these issues, we introduce the FoodSeg103 dataset, containing 9,490 images with 154 annotated ingredient classes and pixel-wise masks. Additionally, we propose the ReLeM pre-training approach to equip segmentation models with rich and semantic food knowledge. We evaluate ReLeM and three popular segmentation methods as baselines on our datasets and make all datasets and methods publicly available to facilitate future research in fine-grained food image understanding.",1
"Although deep models have greatly improved the accuracy and robustness of image segmentation, obtaining segmentation results with highly accurate boundaries and fine structures is still a challenging problem. In this paper, we propose a simple yet powerful Boundary-Aware Segmentation Network (BASNet), which comprises a predict-refine architecture and a hybrid loss, for highly accurate image segmentation. The predict-refine architecture consists of a densely supervised encoder-decoder network and a residual refinement module, which are respectively used to predict and refine a segmentation probability map. The hybrid loss is a combination of the binary cross entropy, structural similarity and intersection-over-union losses, which guide the network to learn three-level (ie, pixel-, patch- and map- level) hierarchy representations. We evaluate our BASNet on two reverse tasks including salient object segmentation, camouflaged object segmentation, showing that it achieves very competitive performance with sharp segmentation boundaries. Importantly, BASNet runs at over 70 fps on a single GPU which benefits many potential real applications. Based on BASNet, we further developed two (close to) commercial applications: AR COPY & PASTE, in which BASNet is integrated with augmented reality for ""COPYING"" and ""PASTING"" real-world objects, and OBJECT CUT, which is a web-based tool for automatic object background removal. Both applications have already drawn huge amount of attention and have important real-world impacts. The code and two applications will be publicly available at: https://github.com/NathanUA/BASNet.",0
"Despite significant improvements in accuracy and robustness of image segmentation with deep models, achieving precise segmentation results with detailed boundaries and structures remains a difficult challenge. Our paper introduces a Boundary-Aware Segmentation Network (BASNet) that employs a predict-refine architecture and a hybrid loss for highly accurate image segmentation. The predict-refine architecture comprises a densely supervised encoder-decoder network and a residual refinement module to predict and refine a segmentation probability map. The hybrid loss combines binary cross entropy, structural similarity, and intersection-over-union losses, enabling the network to learn three-level hierarchy representations. We evaluate BASNet on two tasks, salient and camouflaged object segmentation, and show that it produces sharp segmentation boundaries and competitive performance. BASNet runs at over 70 fps on a single GPU, making it suitable for real-time applications. We have developed two commercial applications, AR COPY & PASTE and OBJECT CUT, based on BASNet, which have already garnered significant attention and impact. The code and applications will be publicly available at https://github.com/NathanUA/BASNet.",1
"Training neural networks with auxiliary tasks is a common practice for improving the performance on a main task of interest. Two main challenges arise in this multi-task learning setting: (i) designing useful auxiliary tasks; and (ii) combining auxiliary tasks into a single coherent loss. Here, we propose a novel framework, AuxiLearn, that targets both challenges based on implicit differentiation. First, when useful auxiliaries are known, we propose learning a network that combines all losses into a single coherent objective function. This network can learn non-linear interactions between tasks. Second, when no useful auxiliary task is known, we describe how to learn a network that generates a meaningful, novel auxiliary task. We evaluate AuxiLearn in a series of tasks and domains, including image segmentation and learning with attributes in the low data regime, and find that it consistently outperforms competing methods.",0
"A common practice for enhancing the performance on a main task is to train neural networks with auxiliary tasks. However, this multi-task learning approach comes with two main challenges: (i) designing effective auxiliary tasks; and (ii) combining auxiliary tasks into a unified loss. To tackle both challenges, we have developed a new framework, AuxiLearn, which utilizes implicit differentiation. In cases where useful auxiliary tasks are known, we suggest training a network that merges all losses into a single objective function, allowing for non-linear interactions between tasks. Alternatively, when no useful auxiliary task is known, we outline how to train a network that generates a meaningful auxiliary task. Our evaluation of AuxiLearn in various tasks and domains, such as image segmentation and learning with attributes in low data situations, shows that it consistently outperforms other methods.",1
"Segmenting an entire 3D image often has high computational complexity and requires large memory consumption; by contrast, performing volumetric segmentation in a slice-by-slice manner is efficient but does not fully leverage the 3D data. To address this challenge, we propose a multi-dimensional attention network (MDA-Net) to efficiently integrate slice-wise, spatial, and channel-wise attention into a U-Net based network, which results in high segmentation accuracy with a low computational cost. We evaluate our model on the MICCAI iSeg and IBSR datasets, and the experimental results demonstrate consistent improvements over existing methods.",0
"The segmentation of a complete 3D image can be complex and memory-intensive, while segmenting volumetrically slice by slice is efficient but not optimal for 3D data. To overcome this issue, we introduce the multi-dimensional attention network (MDA-Net), which integrates slice-wise, spatial, and channel-wise attention into a U-Net based network. This approach offers high accuracy segmentation with low computational costs. The model was tested on the MICCAI iSeg and IBSR datasets, and the results showed significant improvements compared to existing methods.",1
"Active contour models have been widely used in image segmentation, and the level set method (LSM) is the most popular approach for solving the models, via implicitly representing the contour by a level set function. However, the LSM suffers from high computational burden and numerical instability, requiring additional regularization terms or re-initialization techniques. In this paper, we use characteristic functions to implicitly represent the contours, propose a new representation to the geodesic active contours and derive an efficient algorithm termed as the iterative convolution-thresholding method (ICTM). Compared to the LSM, the ICTM is simpler and much more efficient. In addition, the ICTM enjoys most desired features of the level set-based methods. Extensive experiments, on 2D synthetic, 2D ultrasound, 3D CT, and 3D MR images for nodule, organ and lesion segmentation, demonstrate that the proposed method not only obtains comparable or even better segmentation results (compared to the LSM) but also achieves significant acceleration.",0
"Active contour models are commonly used for image segmentation, and the level set method (LSM) is the favored approach for solving these models. However, the LSM can be problematic due to high computational demands and numerical instability, necessitating additional regularization terms or re-initialization techniques. In this study, we propose the use of characteristic functions to represent contours implicitly and introduce a new representation for geodesic active contours. We also introduce an efficient algorithm called the iterative convolution-thresholding method (ICTM), which is significantly simpler and more efficient than the LSM. The ICTM has most of the desirable features of level set-based methods. Extensive experiments on 2D synthetic, 2D ultrasound, 3D CT, and 3D MR images for nodule, organ, and lesion segmentation demonstrate that the proposed method not only achieves comparable or even better segmentation results (compared to the LSM) but also achieves significant acceleration.",1
"Minimal paths are regarded as a powerful and efficient tool for boundary detection and image segmentation due to its global optimality and the well-established numerical solutions such as fast marching method. In this paper, we introduce a flexible interactive image segmentation model based on the Eikonal partial differential equation (PDE) framework in conjunction with region-based homogeneity enhancement. A key ingredient in the introduced model is the construction of local geodesic metrics, which are capable of integrating anisotropic and asymmetric edge features, implicit region-based homogeneity features and/or curvature regularization. The incorporation of the region-based homogeneity features into the metrics considered relies on an implicit representation of these features, which is one of the contributions of this work. Moreover, we also introduce a way to build simple closed contours as the concatenation of two disjoint open curves. Experimental results prove that the proposed model indeed outperforms state-of-the-art minimal paths-based image segmentation approaches.",0
"Due to their global optimality and well-established numerical solutions like the fast marching method, minimal paths are widely recognized as an effective and efficient tool for image segmentation and boundary detection. This study presents a flexible interactive image segmentation model that utilizes the Eikonal partial differential equation (PDE) framework and region-based homogeneity enhancement. The model's key component is the construction of local geodesic metrics that can incorporate anisotropic and asymmetric edge features, implicit region-based homogeneity features, and/or curvature regularization. The integration of region-based homogeneity features into the metrics involves an implicit representation of these features, which is a significant contribution of this work. Additionally, the study introduces a method for constructing simple closed contours by concatenating two disjoint open curves. Experimental results demonstrate that the proposed model performs better than existing minimal paths-based image segmentation approaches.",1
"While multiple studies have explored the relation between inter-rater variability and deep learning model uncertainty in medical segmentation tasks, little is known about the impact of individual rater style. This study quantifies rater style in the form of bias and consistency and explores their impacts when used to train deep learning models. Two multi-rater public datasets were used, consisting of brain multiple sclerosis lesion and spinal cord grey matter segmentation. On both datasets, results show a correlation ($R^2 = 0.60$ and $0.93$) between rater bias and deep learning uncertainty. The impact of label fusion between raters' annotations on this relationship is also explored, and we show that multi-center consensuses are more effective than single-center consensuses to reduce uncertainty, since rater style is mostly center-specific.",0
"Although previous studies have investigated the connection between inter-rater variability and deep learning model uncertainty within medical segmentation tasks, the effect of individual rater style remains largely unknown. This research evaluates rater style by measuring bias and consistency and examines their influence on deep learning model training. Two publicly available datasets containing brain multiple sclerosis lesion and spinal cord grey matter segmentation were utilized. Results indicate a correlation ($R^2 = 0.60$ and $0.93$) between rater bias and deep learning uncertainty for both datasets. Additionally, the study analyzes the impact of label fusion between raters' annotations on this relationship and demonstrates that multi-center agreements are more effective than single-center agreements in reducing uncertainty due to rater style being primarily center-specific.",1
"Incorporating shape information is essential for the delineation of many organs and anatomical structures in medical images. While previous work has mainly focused on parametric spatial transformations applied on reference template shapes, in this paper, we address the Bayesian inference of parametric shape models for segmenting medical images with the objective to provide interpretable results. The proposed framework defines a likelihood appearance probability and a prior label probability based on a generic shape function through a logistic function. A reference length parameter defined in the sigmoid controls the trade-off between shape and appearance information. The inference of shape parameters is performed within an Expectation-Maximisation approach where a Gauss-Newton optimization stage allows to provide an approximation of the posterior probability of shape parameters. This framework is applied to the segmentation of cochlea structures from clinical CT images constrained by a 10 parameter shape model. It is evaluated on three different datasets, one of which includes more than 200 patient images. The results show performances comparable to supervised methods and better than previously proposed unsupervised ones. It also enables an analysis of parameter distributions and the quantification of segmentation uncertainty including the effect of the shape model.",0
"The utilization of shape information plays a critical role in identifying various organs and anatomical structures in medical images. Although previous efforts have primarily concentrated on spatial transformations using reference template shapes, this study focuses on Bayesian inference of parametric shape models for medical image segmentation to produce easily understandable outcomes. The proposed method establishes a likelihood appearance probability and a prior label probability based on a generic shape function that employs a logistic function. A sigmoid reference length parameter controls the balance between appearance and shape information. The shape parameters are inferred using an Expectation-Maximization approach, and a Gauss-Newton optimization stage provides an approximation of the posterior probability of shape parameters. The framework is applied to segment cochlea structures from clinical CT images constrained by a 10 parameter shape model and evaluated on three datasets, including over 200 patient images. The results demonstrate comparable performance to supervised methods and better than prior unsupervised approaches. It also allows for an examination of parameter distributions and the quantification of segmentation uncertainty, including the impact of the shape model.",1
"Recently, referring image segmentation has aroused widespread interest. Previous methods perform the multi-modal fusion between language and vision at the decoding side of the network. And, linguistic feature interacts with visual feature of each scale separately, which ignores the continuous guidance of language to multi-scale visual features. In this work, we propose an encoder fusion network (EFN), which transforms the visual encoder into a multi-modal feature learning network, and uses language to refine the multi-modal features progressively. Moreover, a co-attention mechanism is embedded in the EFN to realize the parallel update of multi-modal features, which can promote the consistent of the cross-modal information representation in the semantic space. Finally, we propose a boundary enhancement module (BEM) to make the network pay more attention to the fine structure. The experiment results on four benchmark datasets demonstrate that the proposed approach achieves the state-of-the-art performance under different evaluation metrics without any post-processing.",0
"The concept of referring image segmentation has recently become popular. Previous approaches have focused on combining language and vision in a decoding network, but this ignores the influence of language on multi-scale visual features. Our proposed encoder fusion network (EFN) transforms the visual encoder into a multi-modal feature learning network, and progressively refines these features using language. The EFN also includes a co-attention mechanism to update multi-modal features in parallel, promoting consistency in cross-modal information representation. Additionally, we introduce a boundary enhancement module (BEM) to enhance fine structure attention. Our experiments on four benchmark datasets show that our approach achieves state-of-the-art results without requiring post-processing.",1
"Citrus segmentation is a key step of automatic citrus picking. While most current image segmentation approaches achieve good segmentation results by pixel-wise segmentation, these supervised learning-based methods require a large amount of annotated data, and do not consider the continuous temporal changes of citrus position in real-world applications. In this paper, we first train a simple CNN with a small number of labelled citrus images in a supervised manner, which can roughly predict the citrus location from each frame. Then, we extend a state-of-the-art unsupervised learning approach to pre-learn the citrus's potential movements between frames from unlabelled citrus's videos. To take advantages of both networks, we employ the multimodal transformer to combine supervised learned static information and unsupervised learned movement information. The experimental results show that combing both network allows the prediction accuracy reached at 88.3$\%$ IOU and 93.6$\%$ precision, outperforming the original supervised baseline 1.2$\%$ and 2.4$\%$. Compared with most of the existing citrus segmentation methods, our method uses a small amount of supervised data and a large number of unsupervised data, while learning the pixel level location information and the temporal information of citrus changes to enhance the segmentation effect.",0
"The automatic picking of citrus requires proper segmentation of the fruit, which is a challenging task. While current pixel-wise segmentation techniques achieve satisfactory results, they require a vast amount of annotated data and do not account for the continuous temporal changes in citrus position in practical scenarios. In this study, we propose a method that combines supervised and unsupervised learning to improve citrus segmentation accuracy. Firstly, we train a simple CNN with a small number of labelled images to predict the location of the fruit in each frame. Then, we use an unsupervised learning approach to pre-learn the potential movements of the citrus between frames from unlabelled videos. Finally, we employ a multimodal transformer to merge the information from both networks. Our approach achieves an accuracy of 88.3% IOU and 93.6% precision, outperforming the supervised baseline by 1.2% and 2.4%. Moreover, our method utilizes a small amount of supervised data and a large number of unsupervised data to enhance both the spatial and temporal information of citrus changes, resulting in better segmentation performance than most existing methods.",1
"This work explores the use of computer vision for image segmentation and classification of medical fluid samples in transparent containers (for example, tubes, syringes, infusion bags). Handling fluids such as infusion fluids, blood, and urine samples is a significant part of the work carried out in medical labs and hospitals. The ability to accurately identify and segment the liquids and the vessels that contain them from images can help in automating such processes. Modern computer vision typically involves training deep neural nets on large datasets of annotated images. This work presents a new dataset containing 1,300 annotated images of medical samples involving vessels containing liquids and solid material. The images are annotated with the type of liquid (e.g., blood, urine), the phase of the material (e.g., liquid, solid, foam, suspension), the type of vessel (e.g., syringe, tube, cup, infusion bottle/bag), and the properties of the vessel (transparent, opaque). In addition, vessel parts such as corks, labels, spikes, and valves are annotated. Relations and hierarchies between vessels and materials are also annotated, such as which vessel contains which material or which vessels are linked or contain each other. Three neural networks are trained on the dataset: One network learns to detect vessels, a second net detects the materials and parts inside each vessel, and a third net identifies relationships and connectivity between vessels.",0
"The focus of this study is to investigate the potential of computer vision in the segmentation and classification of medical fluid samples held in clear containers (such as tubes, syringes, and infusion bags). The handling of fluids, such as blood, urine, and infusion fluids, is an integral aspect of medical laboratories and hospitals. The accuracy in identifying and segmenting both the liquids and their containers from images can aid in the automation of such processes. Contemporary computer vision techniques commonly rely on the training of deep neural networks on large sets of annotated images. This research introduces a novel dataset of 1,300 annotated images of medical samples that feature vessels containing both liquids and solids. The annotations detail the type of material, the phase of the material, the type of container, and its properties. Additionally, parts of the containers (such as corks, labels, spikes, and valves) are annotated, as are the relationships and hierarchies between vessels and materials. The dataset is used to train three neural networks: one to detect vessels, another to detect materials and parts within each vessel, and a third to identify connections and relationships between vessels.",1
"The Voronoi diagram-based dual-front active contour models are known as a powerful and efficient way for addressing the image segmentation and domain partitioning problems. In the basic formulation of the dual-front models, the evolving contours can be considered as the interfaces of adjacent Voronoi regions. Among these dual-front models, a crucial ingredient is regarded as the geodesic metrics by which the geodesic distances and the corresponding Voronoi diagram can be estimated. In this paper, we introduce a type of asymmetric quadratic metrics dual-front model. The metrics considered are built by the integration of the image features and a vector field derived from the evolving contours. The use of the asymmetry enhancement can reduce the risk of contour shortcut or leakage problems especially when the initial contours are far away from the target boundaries or the images have complicated intensity distributions. Moreover, the proposed dual-front model can be applied for image segmentation in conjunction with various region-based homogeneity terms. The numerical experiments on both synthetic and real images show that the proposed dual-front model indeed achieves encouraging results.",0
"The dual-front active contour models based on Voronoi diagrams are recognized as a potent and effective approach to tackle image segmentation and domain partitioning issues. In the fundamental design of the dual-front models, the evolving contours act as interfaces between neighboring Voronoi regions. The geodesic metrics, which can estimate the geodesic distances and corresponding Voronoi diagram, are considered a vital component of these models. In this study, we present a new version of the dual-front model that uses asymmetric quadratic metrics. These metrics are created by combining image features and a vector field obtained from the evolving contours. The incorporation of asymmetry enhancement helps to reduce the risk of contour shortcut or leakage problems, especially when the initial contours are far from the target boundaries or images have complex intensity distributions. Furthermore, the proposed dual-front model can be combined with various region-based homogeneity terms to perform image segmentation. The results of numerical experiments on synthetic and real images demonstrate that the proposed dual-front model performs well.",1
"Standard losses for training deep segmentation networks could be seen as individual classifications of pixels, instead of supervising the global shape of the predicted segmentations. While effective, they require exact knowledge of the label of each pixel in an image.   This study investigates how effective global geometric shape descriptors could be, when used on their own as segmentation losses for training deep networks. Not only interesting theoretically, there exist deeper motivations to posing segmentation problems as a reconstruction of shape descriptors: Annotations to obtain approximations of low-order shape moments could be much less cumbersome than their full-mask counterparts, and anatomical priors could be readily encoded into invariant shape descriptions, which might alleviate the annotation burden. Also, and most importantly, we hypothesize that, given a task, certain shape descriptions might be invariant across image acquisition protocols/modalities and subject populations, which might open interesting research avenues for generalization in medical image segmentation.   We introduce and formulate a few shape descriptors in the context of deep segmentation, and evaluate their potential as standalone losses on two different challenging tasks. Inspired by recent works in constrained optimization for deep networks, we propose a way to use those descriptors to supervise segmentation, without any pixel-level label. Very surprisingly, as little as 4 descriptors values per class can approach the performance of a segmentation mask with 65k individual discrete labels. We also found that shape descriptors can be a valid way to encode anatomical priors about the task, enabling to leverage expert knowledge without additional annotations. Our implementation is publicly available and can be easily extended to other tasks and descriptors: https://github.com/hkervadec/shape_descriptors",0
"Instead of supervising the global shape of predicted segmentations, standard losses for training deep segmentation networks classify individual pixels, which requires exact knowledge of each pixel's label in an image. This study explores the effectiveness of using global geometric shape descriptors as standalone losses for training deep networks. Using shape descriptors to pose segmentation problems as a reconstruction of shape descriptors has practical benefits, such as reducing the annotation burden and encoding anatomical priors into invariant shape descriptions. Furthermore, certain shape descriptions may be invariant across image acquisition protocols/modalities and subject populations, which could lead to interesting research avenues for generalization in medical image segmentation. The study introduces and formulates several shape descriptors for deep segmentation and evaluates their potential as standalone losses on two different challenging tasks. The study proposes a way to use these descriptors to supervise segmentation without any pixel-level label, which surprisingly can approach the performance of a segmentation mask with 65k individual discrete labels with as little as four descriptor values per class. The study also found that shape descriptors can be a valid way to encode anatomical priors about the task, leveraging expert knowledge without additional annotations. The implementation is publicly available and can be easily extended to other tasks and descriptors at https://github.com/hkervadec/shape_descriptors.",1
"The field of view (FOV) of convolutional neural networks is highly related to the accuracy of inference. Dilated convolutions are known as an effective solution to the problems which require large FOVs. However, for general-purpose hardware or dedicated hardware, it usually takes extra time to handle dilated convolutions compared with standard convolutions. In this paper, we propose a network module, Cascaded and Separable Structure of Dilated (CASSOD) Convolution, and a special hardware system to handle the CASSOD networks efficiently. A CASSOD-Net includes multiple cascaded $2 \times 2$ dilated filters, which can be used to replace the traditional $3 \times 3$ dilated filters without decreasing the accuracy of inference. Two example applications, face detection and image segmentation, are tested with dilated convolutions and the proposed CASSOD modules. The new network for face detection achieves higher accuracy than the previous work with only 47% of filter weights in the dilated convolution layers of the context module. Moreover, the proposed hardware system can accelerate the computations of dilated convolutions, and it is 2.78 times faster than traditional hardware systems when the filter size is $3 \times 3$.",0
"Convolutional neural networks' (CNNs) accuracy of inference is closely tied to the field of view (FOV). Dilated convolutions are effective in addressing large FOV problems, but they require extra time to handle on general-purpose or dedicated hardware compared to standard convolutions. This paper presents a network module and a special hardware system, Cascaded and Separable Structure of Dilated (CASSOD) Convolution, for efficient handling of CASSOD networks. CASSOD-Net contains multiple cascaded $2 \times 2$ dilated filters that can replace traditional $3 \times 3$ dilated filters while maintaining inference accuracy. The proposed CASSOD modules are tested on two applications, face detection and image segmentation, and outperform dilated convolutions. The face detection network achieves higher accuracy with only 47% of filter weights in the dilated convolution layers of the context module. Additionally, the proposed hardware system accelerates dilated convolution computations and is 2.78 times faster than traditional hardware systems for a $3 \times 3$ filter size.",1
"We propose a parameter efficient Bayesian layer for hierarchical convolutional Gaussian Processes that incorporates Gaussian Processes operating in Wasserstein-2 space to reliably propagate uncertainty. This directly replaces convolving Gaussian Processes with a distance-preserving affine operator on distributions. Our experiments on brain tissue-segmentation show that the resulting architecture approaches the performance of well-established deterministic segmentation algorithms (U-Net), which has never been achieved with previous hierarchical Gaussian Processes. Moreover, by applying the same segmentation model to out-of-distribution data (i.e., images with pathology such as brain tumors), we show that our uncertainty estimates result in out-of-distribution detection that outperforms the capabilities of previous Bayesian networks and reconstruction-based approaches that learn normative distributions.",0
"Our proposal involves a parameter-efficient Bayesian layer for hierarchical convolutional Gaussian Processes. It utilizes Gaussian Processes operating in Wasserstein-2 space to propagate uncertainty effectively. This method replaces convolving Gaussian Processes with an affine operator that preserves distance on distributions. Our experiments on brain tissue-segmentation demonstrate that the resulting architecture performs similarly to established deterministic segmentation algorithms (U-Net). This achievement was not possible with previous hierarchical Gaussian Processes. Additionally, we applied the same segmentation model to out-of-distribution data, such as brain tumors, and found our uncertainty estimates to be superior to previous Bayesian networks and reconstruction-based approaches that learned normative distributions.",1
"Siamese-based trackers have achived promising performance on visual object tracking tasks. Most existing Siamese-based trackers contain two separate branches for tracking, including classification branch and bounding box regression branch. In addition, image segmentation provides an alternative way to obetain the more accurate target region. In this paper, we propose a novel tracker with two-stages: detection and segmentation. The detection stage is capable of locating the target by Siamese networks. Then more accurate tracking results are obtained by segmentation module given the coarse state estimation in the first stage. We conduct experiments on four benchmarks. Our approach achieves state-of-the-art results, with the EAO of 52.6$\%$ on VOT2016, 51.3$\%$ on VOT2018, and 39.0$\%$ on VOT2019 datasets, respectively.",0
"The performance of Siamese-based trackers in visual object tracking tasks has shown promise. These trackers typically have two separate branches for classification and bounding box regression. Another method for obtaining more accurate target regions is through image segmentation. In this study, we introduce a new two-stage tracker that includes a detection stage using Siamese networks to locate the target, followed by a segmentation module to improve tracking accuracy based on the coarse state estimation from the first stage. Our approach was tested on four benchmarks and achieved state-of-the-art results, including an EAO of 52.6%, 51.3%, and 39.0% on the VOT2016, VOT2018, and VOT2019 datasets, respectively.",1
"Pixel-wise segmentation is one of the most data and annotation hungry tasks in our field. Providing representative and accurate annotations is often mission-critical especially for challenging medical applications. In this paper, we propose a semi-weakly supervised segmentation algorithm to overcome this barrier. Our approach is based on a new formulation of deep supervision and student-teacher model and allows for easy integration of different supervision signals. In contrast to previous work, we show that care has to be taken how deep supervision is integrated in lower layers and we present multi-label deep supervision as the most important secret ingredient for success. With our novel training regime for segmentation that flexibly makes use of images that are either fully labeled, marked with bounding boxes, just global labels, or not at all, we are able to cut the requirement for expensive labels by 94.22% - narrowing the gap to the best fully supervised baseline to only 5% mean IoU. Our approach is validated by extensive experiments on retinal fluid segmentation and we provide an in-depth analysis of the anticipated effect each annotation type can have in boosting segmentation performance.",0
"In our field, pixel-wise segmentation is a highly demanding task that requires significant amounts of data and annotations. Accurate and representative annotations are particularly crucial for challenging medical applications. To address this issue, we propose a semi-weakly supervised segmentation algorithm in this paper. Our approach utilizes a new formulation of deep supervision and student-teacher models to integrate various supervision signals easily. We demonstrate that integrating deep supervision in lower layers requires careful consideration, and we highlight the crucial role of multi-label deep supervision. Our novel training regime for segmentation uses images that are fully labeled, marked with bounding boxes, labeled globally, or not labeled at all, reducing the need for expensive labels by 94.22%. Our approach achieves a mean IoU of only 5% lower than the best fully supervised baseline. We validate our approach through extensive experiments on retinal fluid segmentation and provide an in-depth analysis of the effect of each annotation type on segmentation performance.",1
"BiSeNet has been proved to be a popular two-stream network for real-time segmentation. However, its principle of adding an extra path to encode spatial information is time-consuming, and the backbones borrowed from pretrained tasks, e.g., image classification, may be inefficient for image segmentation due to the deficiency of task-specific design. To handle these problems, we propose a novel and efficient structure named Short-Term Dense Concatenate network (STDC network) by removing structure redundancy. Specifically, we gradually reduce the dimension of feature maps and use the aggregation of them for image representation, which forms the basic module of STDC network. In the decoder, we propose a Detail Aggregation module by integrating the learning of spatial information into low-level layers in single-stream manner. Finally, the low-level features and deep features are fused to predict the final segmentation results. Extensive experiments on Cityscapes and CamVid dataset demonstrate the effectiveness of our method by achieving promising trade-off between segmentation accuracy and inference speed. On Cityscapes, we achieve 71.9% mIoU on the test set with a speed of 250.4 FPS on NVIDIA GTX 1080Ti, which is 45.2% faster than the latest methods, and achieve 76.8% mIoU with 97.0 FPS while inferring on higher resolution images.",0
"Although BiSeNet is a popular two-stream network for real-time segmentation, its approach of adding an extra path to encode spatial information can be time-consuming and the borrowed backbones from pretrained tasks may not be efficient for image segmentation due to a lack of task-specific design. To address these issues, we present a new and efficient structure called the Short-Term Dense Concatenate network (STDC network) by eliminating structure redundancy. Our approach involves gradually reducing the dimension of feature maps and aggregating them for image representation, which forms the basis of the STDC network's basic module. In the decoder, we propose a Detail Aggregation module by integrating spatial information learning into low-level layers in a single-stream manner. Finally, low-level features and deep features are combined to predict the final segmentation results. Our method achieves promising trade-offs between segmentation accuracy and inference speed, as demonstrated in extensive experiments on both the Cityscapes and CamVid datasets. Specifically, on the Cityscapes dataset, we achieve 71.9% mIoU on the test set with a speed of 250.4 FPS on NVIDIA GTX 1080Ti, which is 45.2% faster than the latest methods. Our approach also achieves 76.8% mIoU with 97.0 FPS while inferring on higher resolution images.",1
"Medical images are often accompanied by metadata describing the image (vendor, acquisition parameters) and the patient (disease type or severity, demographics, genomics). This metadata is usually disregarded by image segmentation methods. In this work, we adapt a linear conditioning method called FiLM (Feature-wise Linear Modulation) for image segmentation tasks. This FiLM adaptation enables integrating metadata into segmentation models for better performance. We observed an average Dice score increase of 5.1% on spinal cord tumor segmentation when incorporating the tumor type with FiLM. The metadata modulates the segmentation process through low-cost affine transformations applied on feature maps which can be included in any neural network's architecture. Additionally, we assess the relevance of segmentation FiLM layers for tackling common challenges in medical imaging: multi-class training with missing segmentations, model adaptation to multiple tasks, and training with a limited or unbalanced number of annotated data. Our results demonstrated the following benefits of FiLM for segmentation: FiLMed U-Net was robust to missing labels and reached higher Dice scores with few labels (up to 16.7%) compared to single-task U-Net. The code is open-source and available at www.ivadomed.org.",0
"Medical images often contain metadata that describes both the image (such as the vendor and acquisition parameters) and the patient (including disease type and severity, demographics, and genomics). Unfortunately, this metadata is typically ignored by image segmentation methods. In this study, we utilized a linear conditioning technique called FiLM (Feature-wise Linear Modulation) to improve the performance of image segmentation models by incorporating relevant metadata. By applying low-cost affine transformations to feature maps, we were able to integrate metadata into any neural network architecture. Our results showed that spinal cord tumor segmentation improved by an average of 5.1% when using FiLM to incorporate tumor type. Additionally, we found that segmentation FiLM layers were effective for addressing common challenges in medical imaging, such as multi-class training with missing segmentations, model adaptation to multiple tasks, and training with limited or unbalanced annotated data. Our open-source code is available at www.ivadomed.org.",1
"Segmentation of organs or lesions from medical images plays an essential role in many clinical applications such as diagnosis and treatment planning. Though Convolutional Neural Networks (CNN) have achieved the state-of-the-art performance for automatic segmentation, they are often limited by the lack of clinically acceptable accuracy and robustness in complex cases. Therefore, interactive segmentation is a practical alternative to these methods. However, traditional interactive segmentation methods require a large amount of user interactions, and recently proposed CNN-based interactive segmentation methods are limited by poor performance on previously unseen objects. To solve these problems, we propose a novel deep learning-based interactive segmentation method that not only has high efficiency due to only requiring clicks as user inputs but also generalizes well to a range of previously unseen objects. Specifically, we first encode user-provided interior margin points via our proposed exponentialized geodesic distance that enables a CNN to achieve a good initial segmentation result of both previously seen and unseen objects, then we use a novel information fusion method that combines the initial segmentation with only few additional user clicks to efficiently obtain a refined segmentation. We validated our proposed framework through extensive experiments on 2D and 3D medical image segmentation tasks with a wide range of previous unseen objects that were not present in the training set. Experimental results showed that our proposed framework 1) achieves accurate results with fewer user interactions and less time compared with state-of-the-art interactive frameworks and 2) generalizes well to previously unseen objects.",0
"The segmentation of organs and lesions from medical images is crucial for various clinical applications, including diagnosis and treatment planning. Despite Convolutional Neural Networks (CNN) being the preferred method for automatic segmentation, they often lack clinical accuracy and robustness in complex cases. Interactive segmentation is a viable alternative, but traditional methods require excessive user interactions, and CNN-based interactive segmentation methods have limited performance on previously unseen objects. To address these issues, we propose a novel deep learning-based interactive segmentation approach that efficiently uses only clicks as user inputs and generalizes well to a wide range of previously unseen objects. Our method encodes user-provided interior margin points using an exponentialized geodesic distance, enabling a CNN to achieve a good initial segmentation of both previously seen and unseen objects. We then fuse the initial segmentation with only a few additional user clicks using a novel information fusion method to obtain a refined segmentation. Our extensive experiments on 2D and 3D medical image segmentation tasks with a variety of previously unseen objects demonstrate that our approach achieves accurate results with fewer user interactions and less time than state-of-the-art interactive frameworks and generalizes well to previously unseen objects.",1
"Deep neural networks (DNNs) have demonstrated their great potential in recent years, exceeding the per-formance of human experts in a wide range of applications. Due to their large sizes, however, compressiontechniques such as weight quantization and pruning are usually applied before they can be accommodated onthe edge. It is generally believed that quantization leads to performance degradation, and plenty of existingworks have explored quantization strategies aiming at minimum accuracy loss. In this paper, we argue thatquantization, which essentially imposes regularization on weight representations, can sometimes help toimprove accuracy. We conduct comprehensive experiments on three widely used applications: fully con-nected network (FCN) for biomedical image segmentation, convolutional neural network (CNN) for imageclassification on ImageNet, and recurrent neural network (RNN) for automatic speech recognition, and experi-mental results show that quantization can improve the accuracy by 1%, 1.95%, 4.23% on the three applicationsrespectively with 3.5x-6.4x memory reduction.",0
"In recent years, Deep Neural Networks (DNNs) have displayed immense potential, outperforming human experts in various applications. However, their large sizes require compression techniques such as weight quantization and pruning before they can be used on edge devices. While quantization is believed to cause a decline in performance, existing studies have explored quantization strategies that minimize accuracy loss. In this article, we argue that quantization, which acts as regularization on weight representations, can enhance accuracy. We conducted extensive experiments on three commonly used applications: biomedical image segmentation using a fully connected network (FCN), image classification on ImageNet using a Convolutional Neural Network (CNN), and automatic speech recognition using a Recurrent Neural Network (RNN). The results show that quantization can improve accuracy by 1%, 1.95%, and 4.23% on the three applications, respectively, with a memory reduction of 3.5x-6.4x.",1
"Advances in object-centric generative models (OCGMs) have culminated in the development of a broad range of methods for unsupervised object segmentation and interpretable object-centric scene generation. These methods, however, are limited to simulated and real-world datasets with limited visual complexity. Moreover, object representations are often inferred using RNNs which do not scale well to large images or iterative refinement which avoids imposing an unnatural ordering on objects in an image but requires the a priori initialisation of a fixed number of object representations. In contrast to established paradigms, this work proposes an embedding-based approach in which embeddings of pixels are clustered in a differentiable fashion using a stochastic, non-parametric stick-breaking process. Similar to iterative refinement, this clustering procedure also leads to randomly ordered object representations, but without the need of initialising a fixed number of clusters a priori. This is used to develop a new model, GENESIS-V2, which can infer a variable number of object representations without using RNNs or iterative refinement. We show that GENESIS-V2 outperforms previous methods for unsupervised image segmentation and object-centric scene generation on established synthetic datasets as well as more complex real-world datasets.",0
"The development of object-centric generative models (OCGMs) has resulted in a wide range of techniques for unsupervised object segmentation and interpretable object-centric scene generation. However, these methods are only effective on datasets with limited visual complexity, both in simulated and real-world scenarios. Additionally, RNNs are often used to infer object representations, but they do not scale well to large images. Iterative refinement is another option, but it requires the a priori initialization of a fixed number of object representations and imposes an unnatural order on objects. In contrast, this study proposes an embedding-based approach that uses a stochastic, non-parametric stick-breaking process to differentiably cluster pixel embeddings. This clustering process generates randomly ordered object representations without the need for a priori initialization of a fixed number of clusters. This approach leads to the development of a new model, GENESIS-V2, which can infer a variable number of object representations without RNNs or iterative refinement. Our results show that GENESIS-V2 outperforms previous methods in unsupervised image segmentation and object-centric scene generation on established synthetic datasets and more complex real-world datasets.",1
"Semantic image segmentation aims to obtain object labels with precise boundaries, which usually suffers from overfitting. Recently, various data augmentation strategies like regional dropout and mix strategies have been proposed to address the problem. These strategies have proved to be effective for guiding the model to attend on less discriminative parts. However, current strategies operate at the image level, and objects and the background are coupled. Thus, the boundaries are not well augmented due to the fixed semantic scenario. In this paper, we propose ObjectAug to perform object-level augmentation for semantic image segmentation. ObjectAug first decouples the image into individual objects and the background using the semantic labels. Next, each object is augmented individually with commonly used augmentation methods (e.g., scaling, shifting, and rotation). Then, the black area brought by object augmentation is further restored using image inpainting. Finally, the augmented objects and background are assembled as an augmented image. In this way, the boundaries can be fully explored in the various semantic scenarios. In addition, ObjectAug can support category-aware augmentation that gives various possibilities to objects in each category, and can be easily combined with existing image-level augmentation methods to further boost performance. Comprehensive experiments are conducted on both natural image and medical image datasets. Experiment results demonstrate that our ObjectAug can evidently improve segmentation performance.",0
"Semantic image segmentation is a process that aims to identify the labels of objects with precise boundaries. However, this process often results in overfitting. To address this issue, various data augmentation strategies have been proposed, such as regional dropout and mix strategies, which have been effective in guiding the model to focus on less discriminative parts. However, current strategies operate at the image level, which limits their ability to augment boundaries due to the fixed semantic scenario. In our paper, we introduce ObjectAug, a new approach that performs object-level augmentation for semantic image segmentation. ObjectAug first separates the image into individual objects and the background using semantic labels, and then each object is individually augmented using common methods such as scaling, shifting, and rotation. The black areas that result from object augmentation are then restored using image inpainting, and the augmented objects and background are assembled into an augmented image. This approach allows for exploration of boundaries in various semantic scenarios. Furthermore, ObjectAug can support category-aware augmentation, which provides various possibilities for objects in each category, and can also be easily combined with existing image-level augmentation methods to improve performance. Our experiments on natural and medical image datasets show that ObjectAug can significantly enhance segmentation performance.",1
"Video segmentation for the human head and shoulders is essential in creating elegant media for videoconferencing and virtual reality applications. The main challenge is to process high-quality background subtraction in a real-time manner and address the segmentation issues under motion blurs, e.g., shaking the head or waving hands during conference video. To overcome the motion blur problem in video segmentation, we propose a novel flow-based encoder-decoder network (FUNet) that combines both traditional Horn-Schunck optical-flow estimation technique and convolutional neural networks to perform robust real-time video segmentation. We also introduce a video and image segmentation dataset: ConferenceVideoSegmentationDataset. Code and pre-trained models are available on our GitHub repository: \url{https://github.com/kuangzijian/Flow-Based-Video-Matting}.",0
"Creating sophisticated media for videoconferencing and virtual reality applications requires video segmentation of the human head and shoulders. The major difficulty in achieving this is processing high-quality background subtraction in real-time while addressing segmentation issues caused by motion blur, such as head shaking or hand waving during a conference. To tackle the motion blur problem in video segmentation, we have introduced a novel flow-based encoder-decoder network (FUNet) that combines Horn-Schunck optical-flow estimation with convolutional neural networks to ensure strong and efficient real-time video segmentation. Additionally, we have developed a video and image segmentation dataset called ConferenceVideoSegmentationDataset, and our GitHub repository, \url{https://github.com/kuangzijian/Flow-Based-Video-Matting}, includes pre-trained models and code.",1
"We introduce DatasetGAN: an automatic procedure to generate massive datasets of high-quality semantically segmented images requiring minimal human effort. Current deep networks are extremely data-hungry, benefiting from training on large-scale datasets, which are time consuming to annotate. Our method relies on the power of recent GANs to generate realistic images. We show how the GAN latent code can be decoded to produce a semantic segmentation of the image. Training the decoder only needs a few labeled examples to generalize to the rest of the latent space, resulting in an infinite annotated dataset generator! These generated datasets can then be used for training any computer vision architecture just as real datasets are. As only a few images need to be manually segmented, it becomes possible to annotate images in extreme detail and generate datasets with rich object and part segmentations. To showcase the power of our approach, we generated datasets for 7 image segmentation tasks which include pixel-level labels for 34 human face parts, and 32 car parts. Our approach outperforms all semi-supervised baselines significantly and is on par with fully supervised methods, which in some cases require as much as 100x more annotated data as our method.",0
"We have developed DatasetGAN, an automated method of creating vast collections of high-quality semantically segmented images with minimal human input. Deep networks rely heavily on large datasets for training, but annotating these datasets is a time-consuming task. Our method utilizes the capabilities of recent GANs to produce realistic images, with the GAN latent code used to decode semantic segmentation. The decoder requires only a few labeled examples to generalize to the rest of the latent space, resulting in an unlimited annotated dataset generator. These generated datasets can be used to train computer vision architectures just like real datasets. With only a few images requiring manual segmentation, it is possible to annotate images in great detail and create datasets with rich object and part segmentations. To demonstrate the effectiveness of our approach, we generated datasets for 7 image segmentation tasks, including pixel-level labels for 34 human face parts and 32 car parts. Our method surpassed all semi-supervised baselines and was on par with fully supervised methods, which often require 100 times more annotated data than our method.",1
"In supervised learning for medical image analysis, sample selection methodologies are fundamental to attain optimum system performance promptly and with minimal expert interactions (e.g. label querying in an active learning setup). In this paper we propose a novel sample selection methodology based on deep features leveraging information contained in interpretability saliency maps. In the absence of ground truth labels for informative samples, we use a novel self supervised learning based approach for training a classifier that learns to identify the most informative sample in a given batch of images. We demonstrate the benefits of the proposed approach, termed Interpretability-Driven Sample Selection (IDEAL), in an active learning setup aimed at lung disease classification and histopathology image segmentation. We analyze three different approaches to determine sample informativeness from interpretability saliency maps: (i) an observational model stemming from findings on previous uncertainty-based sample selection approaches, (ii) a radiomics-based model, and (iii) a novel data-driven self-supervised approach. We compare IDEAL to other baselines using the publicly available NIH chest X-ray dataset for lung disease classification, and a public histopathology segmentation dataset (GLaS), demonstrating the potential of using interpretability information for sample selection in active learning systems. Results show our proposed self supervised approach outperforms other approaches in selecting informative samples leading to state of the art performance with fewer samples.",0
"The selection of samples is crucial in achieving optimal system performance in supervised learning for medical image analysis, while minimizing expert interactions. Our paper proposes a new sample selection method that employs deep features and interpretability saliency maps. To train a classifier that identifies informative samples in a batch of images, we use a self-supervised learning approach when ground truth labels are unavailable. The proposed approach, known as Interpretability-Driven Sample Selection (IDEAL), is tested in an active learning setup for lung disease classification and histopathology image segmentation. Three approaches are used to determine sample informativeness: (i) an observational model based on uncertainty-based sample selection methods, (ii) a radiomics-based model, and (iii) a novel data-driven self-supervised approach. Using publicly available datasets, we compare IDEAL to other baselines and show that our self-supervised approach outperforms other methods in selecting informative samples, resulting in state-of-the-art performance with fewer samples. The study demonstrates the potential of using interpretability information for sample selection in active learning systems.",1
"Training deep networks with limited labeled data while achieving a strong generalization ability is key in the quest to reduce human annotation efforts. This is the goal of semi-supervised learning, which exploits more widely available unlabeled data to complement small labeled data sets. In this paper, we propose a novel framework for discriminative pixel-level tasks using a generative model of both images and labels. Concretely, we learn a generative adversarial network that captures the joint image-label distribution and is trained efficiently using a large set of unlabeled images supplemented with only few labeled ones. We build our architecture on top of StyleGAN2, augmented with a label synthesis branch. Image labeling at test time is achieved by first embedding the target image into the joint latent space via an encoder network and test-time optimization, and then generating the label from the inferred embedding. We evaluate our approach in two important domains: medical image segmentation and part-based face segmentation. We demonstrate strong in-domain performance compared to several baselines, and are the first to showcase extreme out-of-domain generalization, such as transferring from CT to MRI in medical imaging, and photographs of real faces to paintings, sculptures, and even cartoons and animal faces. Project Page: \url{https://nv-tlabs.github.io/semanticGAN/}",0
"The objective of reducing human annotation efforts is achieved by training deep networks with limited labeled data to possess a strong generalization ability. Semi-supervised learning is employed to supplement small labeled data sets with widely available unlabeled data. This paper introduces a new framework for discriminative pixel-level tasks that utilizes a generative model of both images and labels. A generative adversarial network is learned to capture the joint image-label distribution with the aid of a large set of unlabeled images and a few labeled ones. The proposed architecture is based on StyleGAN2, with a label synthesis branch added. At test time, image labeling is accomplished by first embedding the target image into the joint latent space using an encoder network and test-time optimization, and then generating the label from the inferred embedding. The approach is evaluated in two domains: medical image segmentation and part-based face segmentation. Strong in-domain performance is demonstrated, along with extreme out-of-domain generalization, such as transferring from CT to MRI in medical imaging, and from photographs of real faces to paintings, sculptures, cartoons, and animal faces. The project page can be found at \url{https://nv-tlabs.github.io/semanticGAN/}.",1
"The task of image segmentation is inherently noisy due to ambiguities regarding the exact location of boundaries between anatomical structures. We argue that this information can be extracted from the expert annotations at no extra cost, and when integrated into state-of-the-art neural networks, it can lead to improved calibration between soft probabilistic predictions and the underlying uncertainty. We built upon label smoothing (LS) where a network is trained on 'blurred' versions of the ground truth labels which has been shown to be effective for calibrating output predictions. However, LS is not taking the local structure into account and results in overly smoothed predictions with low confidence even for non-ambiguous regions. Here, we propose Spatially Varying Label Smoothing (SVLS), a soft labeling technique that captures the structural uncertainty in semantic segmentation. SVLS also naturally lends itself to incorporate inter-rater uncertainty when multiple labelmaps are available. The proposed approach is extensively validated on four clinical segmentation tasks with different imaging modalities, number of classes and single and multi-rater expert annotations. The results demonstrate that SVLS, despite its simplicity, obtains superior boundary prediction with improved uncertainty and model calibration.",0
"Image segmentation is challenging due to uncertainties in identifying the boundaries of anatomical structures. However, we suggest that expert annotations can provide valuable information without additional costs. By integrating this information into neural networks, we can improve the calibration of soft probabilistic predictions and underlying uncertainties. We expanded on the label smoothing (LS) technique, which uses blurred ground truth labels to improve predictions. However, LS does not account for local structure and can result in overly smoothed predictions. Our proposed Spatially Varying Label Smoothing (SVLS) technique addresses this issue by capturing structural uncertainty in semantic segmentation. Additionally, SVLS can incorporate inter-rater uncertainty when multiple labelmaps are available. We validated SVLS on four clinical segmentation tasks using various imaging modalities, classes, and expert annotations. Our results show that SVLS outperforms LS, achieving superior boundary predictions, improved uncertainty, and model calibration.",1
"While convolutional neural networks (CNNs) trained by back-propagation have seen unprecedented success at semantic segmentation tasks, they are known to struggle on out-of-distribution data. Markov random fields (MRFs) on the other hand, encode simpler distributions over labels that, although less flexible than UNets, are less prone to over-fitting. In this paper, we propose to fuse both strategies by computing the product of distributions of a UNet and an MRF. As this product is intractable, we solve for an approximate distribution using an iterative mean-field approach. The resulting MRF-UNet is trained jointly by back-propagation. Compared to other works using conditional random fields (CRFs), the MRF has no dependency on the imaging data, which should allow for less over-fitting. We show on 3D neuroimaging data that this novel network improves generalisation to out-of-distribution samples. Furthermore, it allows the overall number of parameters to be reduced while preserving high accuracy. These results suggest that a classic MRF smoothness prior can allow for less over-fitting when principally integrated into a CNN model. Our implementation is available at https://github.com/balbasty/nitorch.",0
"Semantic segmentation tasks have seen great success with convolutional neural networks (CNNs) trained by back-propagation. However, CNNs have difficulty with out-of-distribution data. On the other hand, Markov random fields (MRFs) encode simpler label distributions that are less flexible but less prone to over-fitting than UNets. This paper proposes a fusion of both strategies by computing the product of distributions of a UNet and an MRF. Due to the intractability of this product, an iterative mean-field approach is used to solve for an approximate distribution. The resulting MRF-UNet is trained jointly by back-propagation. Unlike other works using conditional random fields (CRFs), the MRF has no dependence on imaging data, allowing for less over-fitting. The network improves generalisation to out-of-distribution samples and reduces the overall number of parameters while maintaining high accuracy. These findings suggest that integrating a classic MRF smoothness prior into a CNN model can reduce over-fitting. The implementation is available at https://github.com/balbasty/nitorch and was tested on 3D neuroimaging data.",1
"We propose to adapt segmentation networks with a constrained formulation, which embeds domain-invariant prior knowledge about the segmentation regions. Such knowledge may take the form of simple anatomical information, e.g., structure size or shape, estimated from source samples or known a priori. Our method imposes domain-invariant inequality constraints on the network outputs of unlabeled target samples. It implicitly matches prediction statistics between target and source domains with permitted uncertainty of prior knowledge. We address our constrained problem with a differentiable penalty, fully suited for standard stochastic gradient descent approaches, removing the need for computationally expensive Lagrangian optimization with dual projections. Unlike current two-step adversarial training, our formulation is based on a single loss in a single network, which simplifies adaptation by avoiding extra adversarial steps, while improving convergence and quality of training.   The comparison of our approach with state-of-the-art adversarial methods reveals substantially better performance on the challenging task of adapting spine segmentation across different MRI modalities. Our results also show a robustness to imprecision of size priors, approaching the accuracy of a fully supervised model trained directly in a target domain.Our method can be readily used for various constraints and segmentation problems.",0
"Our proposal is to modify segmentation networks through a constrained formulation that incorporates domain-invariant prior knowledge regarding the segmentation regions. This knowledge can be anatomical information, such as the size or shape of a structure, which is either estimated from source samples or known beforehand. To achieve this, our method applies domain-invariant inequality constraints to the network outputs of unlabeled target samples, which matches prediction statistics between target and source domains while allowing for prior knowledge uncertainty. We solve this constrained problem using a differentiable penalty that is compatible with standard stochastic gradient descent approaches, eliminating the need for computationally expensive dual projections with Lagrangian optimization. Unlike current two-step adversarial training, our approach employs a single loss in a single network, simplifying adaptation by avoiding additional adversarial steps while enhancing convergence and training quality. Our method outperforms state-of-the-art adversarial methods when adapting spine segmentation across various MRI modalities, and it also demonstrates robustness to imprecise size priors, approaching the accuracy of a fully supervised model trained directly in a target domain. Our technique can be applied to diverse constraints and segmentation problems with ease.",1
"Colorectal cancer (CRC) is the first cause of death in many countries. CRC originates from a small clump of cells on the lining of the colon called polyps, which over time might grow and become malignant. Early detection and removal of polyps are therefore necessary for the prevention of colon cancer. In this paper, we introduce an ensemble of medical polyp segmentation algorithms. Based on an observation that different segmentation algorithms will perform well on different subsets of examples because of the nature and size of training sets they have been exposed to and because of method-intrinsic factors, we propose to measure the confidence in the prediction of each algorithm and then use an associate threshold to determine whether the confidence is acceptable or not. An algorithm is selected for the ensemble if the confidence is below its associate threshold. The optimal threshold for each segmentation algorithm is found by using Comprehensive Learning Particle Swarm Optimization (CLPSO), a swarm intelligence algorithm. The Dice coefficient, a popular performance metric for image segmentation, is used as the fitness criteria. Experimental results on two polyp segmentation datasets MICCAI2015 and Kvasir-SEG confirm that our ensemble achieves better results compared to some well-known segmentation algorithms.",0
"Many countries have identified colorectal cancer (CRC) as the leading cause of death. Polyps, which are small groups of cells on the colon lining, can develop into malignant growths over time, making early detection and removal necessary for colon cancer prevention. To address this issue, we present a collection of medical polyp segmentation algorithms. We recognize that different algorithms excel in different scenarios due to varying training sets and method-specific factors. Consequently, we suggest measuring each algorithm's prediction confidence and applying a corresponding threshold to determine its acceptability. We include an algorithm in the ensemble if its confidence falls below the relevant threshold. We use the Comprehensive Learning Particle Swarm Optimization (CLPSO) as a swarm intelligence algorithm to determine the optimal threshold for each segmentation algorithm, using the Dice coefficient as the performance metric. Our experimental results on the MICCAI2015 and Kvasir-SEG datasets show that our ensemble outperforms some well-known segmentation algorithms.",1
"In recent years, deep learning has rapidly become a method of choice for the segmentation of medical images. Deep Neural Network (DNN) architectures such as UNet have achieved state-of-the-art results on many medical datasets. To further improve the performance in the segmentation task, we develop an ensemble system which combines various deep learning architectures. We propose a two-layer ensemble of deep learning models for the segmentation of medical images. The prediction for each training image pixel made by each model in the first layer is used as the augmented data of the training image for the second layer of the ensemble. The prediction of the second layer is then combined by using a weights-based scheme in which each model contributes differently to the combined result. The weights are found by solving linear regression problems. Experiments conducted on two popular medical datasets namely CAMUS and Kvasir-SEG show that the proposed method achieves better results concerning two performance metrics (Dice Coefficient and Hausdorff distance) compared to some well-known benchmark algorithms.",0
"In recent times, the utilization of deep learning for medical image segmentation has surged. Deep Neural Network (DNN) models like UNet have attained state-of-the-art outcomes on numerous medical datasets. To enhance segmentation performance, we have devised an ensemble system that incorporates multiple deep learning architectures. Our two-layer ensemble model utilizes predictions from the first layer as augmented data for the second layer. A weights-based scheme is used to combine the predictions from the second layer, with each model's contribution determined by solving linear regression problems to find the optimal weights. Our proposed method outperforms several benchmark algorithms on CAMUS and Kvasir-SEG datasets in terms of two performance metrics (Dice Coefficient and Hausdorff distance).",1
"Semantic segmentation has a wide array of applications ranging from medical-image analysis, scene understanding, autonomous driving and robotic navigation. This work deals with medical image segmentation and in particular with accurate polyp detection and segmentation during colonoscopy examinations. Several convolutional neural network architectures have been proposed to effectively deal with this task and with the problem of segmenting objects at different scale input. The basic architecture in image segmentation consists of an encoder and a decoder: the first uses convolutional filters to extract features from the image, the second is responsible for generating the final output. In this work, we compare some variant of the DeepLab architecture obtained by varying the decoder backbone. We compare several decoder architectures, including ResNet, Xception, EfficentNet, MobileNet and we perturb their layers by substituting ReLU activation layers with other functions. The resulting methods are used to create deep ensembles which are shown to be very effective. Our experimental evaluations show that our best ensemble produces good segmentation results by achieving high evaluation scores with a dice coefficient of 0.884, and a mean Intersection over Union (mIoU) of 0.818 for the Kvasir-SEG dataset. To improve reproducibility and research efficiency the MATLAB source code used for this research is available at GitHub: https://github.com/LorisNanni.",0
"Semantic segmentation finds widespread use in various fields, such as medical-image analysis, autonomous driving, scene understanding, and robotic navigation. The present study focuses on accurate polyp detection and segmentation during colonoscopy examinations in medical image segmentation. Different convolutional neural network architectures have been proposed to solve this task effectively, including the encoder and decoder architecture. The encoder uses convolutional filters to extract features from the image, whereas the decoder generates the final output. This study compares several decoder architectures, such as ResNet, Xception, EfficentNet, MobileNet, by perturbing their layers using functions other than ReLU activation layers to create deep ensembles, which are proven to be highly effective. The best ensemble achieved a dice coefficient of 0.884 and a mean Intersection over Union (mIoU) of 0.818 for the Kvasir-SEG dataset. To promote research efficiency and reproducibility, the MATLAB source code used in this study is available at GitHub: https://github.com/LorisNanni.",1
"Domain adaptation (DA) has drawn high interests for its capacity to adapt a model trained on labeled source data to perform well on unlabeled or weakly labeled target data from a different domain. Most common DA techniques require the concurrent access to the input images of both the source and target domains. However, in practice, it is common that the source images are not available in the adaptation phase. This is a very frequent DA scenario in medical imaging, for instance, when the source and target images come from different clinical sites. We propose a novel formulation for adapting segmentation networks, which relaxes such a constraint. Our formulation is based on minimizing a label-free entropy loss defined over target-domain data, which we further guide with a domain invariant prior on the segmentation regions. Many priors can be used, derived from anatomical information. Here, a class-ratio prior is learned via an auxiliary network and integrated in the form of a Kullback-Leibler (KL) divergence in our overall loss function. We show the effectiveness of our prior-aware entropy minimization in adapting spine segmentation across different MRI modalities. Our method yields comparable results to several state-of-the-art adaptation techniques, even though is has access to less information, the source images being absent in the adaptation phase. Our straight-forward adaptation strategy only uses one network, contrary to popular adversarial techniques, which cannot perform without the presence of the source images. Our framework can be readily used with various priors and segmentation problems.",0
"The ability of Domain adaptation (DA) to adapt models trained on labeled source data to perform well on unlabeled or weakly labeled target data from a different domain has generated significant interest. However, most common DA techniques require access to input images from both source and target domains simultaneously. This constraint is often not met in medical imaging, where source and target images may come from different clinical sites. In this context, we propose a novel formulation for adapting segmentation networks that relaxes this constraint. Our approach minimizes a label-free entropy loss defined over target-domain data and guides it with a domain invariant prior on segmentation regions, which can be derived from anatomical information. To do this, we learn a class-ratio prior via an auxiliary network and integrate it in the form of a Kullback-Leibler (KL) divergence in our overall loss function. We demonstrate the effectiveness of our approach in adapting spine segmentation across different MRI modalities, where it yields comparable results to several state-of-the-art adaptation techniques despite having access to less information, as the source images are absent in the adaptation phase. Our approach uses only one network and does not require the presence of source images, unlike popular adversarial techniques. Furthermore, our framework can be used readily with various priors and segmentation problems.",1
"Computer vision has shown promising results in medical image processing. Pneumothorax is a deadly condition and if not diagnosed and treated at time then it causes death. It can be diagnosed with chest X-ray images. We need an expert and experienced radiologist to predict whether a person is suffering from pneumothorax or not by looking at the chest X-ray images. Everyone does not have access to such a facility. Moreover, in some cases, we need quick diagnoses. So we propose an image segmentation model to predict and give the output a mask that will assist the doctor in taking this crucial decision. Deep Learning has proved their worth in many areas and outperformed man state-of-the-art models. We want to use the power of these deep learning model to solve this problem. We have used U-net [13] architecture with ResNet [17] as a backbone and achieved promising results. U-net [13] performs very well in medical image processing and semantic segmentation. Our problem falls in the semantic segmentation category.",0
"Medical image processing using computer vision has demonstrated encouraging outcomes, particularly in identifying pneumothorax, a life-threatening condition that can result in death if not diagnosed and treated promptly. Chest X-ray images can aid in diagnosing pneumothorax, but an experienced radiologist is required to determine whether a person is suffering from the disease by analyzing the images. This facility is not available to everyone, and urgent diagnoses are sometimes required. We propose an image segmentation model that predicts and produces a mask as an output, which can aid the doctor in making this critical decision. Deep Learning has proven to be a valuable tool in various fields, surpassing numerous state-of-the-art models. To address this issue, we aim to employ the power of these deep learning models. We utilized the U-net [13] architecture with ResNet [17] as a backbone and attained encouraging results. U-net [13] is highly effective in medical image processing and semantic segmentation, and our problem falls under the semantic segmentation category.",1
"Understanding the structure of Earth's polar ice sheets is important for modeling how global warming will impact polar ice and, in turn, the Earth's climate. Ground-penetrating radar is able to collect observations of the internal structure of snow and ice, but the process of manually labeling these observations is slow and laborious. Recent work has developed automatic techniques for finding the boundaries between the ice and the bedrock, but finding internal layers - the subtle boundaries that indicate where one year's ice accumulation ended and the next began - is much more challenging because the number of layers varies and the boundaries often merge and split. In this paper, we propose a novel deep neural network for solving a general class of tiered segmentation problems. We then apply it to detecting internal layers in polar ice, evaluating on a large-scale dataset of polar ice radar data with human-labeled annotations as ground truth.",0
"It is crucial to comprehend the configuration of the polar ice sheets on Earth to anticipate how global warming will influence polar ice and ultimately, the Earth's climate. Ground-penetrating radar can gather data on the internal structure of snow and ice; however, the manual labeling of observations is slow and arduous. Recently, automatic methods have emerged to locate boundaries between ice and bedrock. Yet, identifying internal layers that indicate the end of one year's ice accumulation and the start of the next is more convoluted as the number of layers varies, and the boundaries often merge and split. This article introduces a new deep neural network for solving tiered segmentation issues and applies it to detect internal layers in polar ice. The research evaluates the model's performance on a vast dataset of polar ice radar data, using human-labeled annotations as a reference.",1
"The importance of hierarchical image organization has been witnessed by a wide spectrum of applications in computer vision and graphics. Different from image segmentation with the spatial whole-part consideration, this work designs a modern framework for disassembling an image into a family of derived signals from a scale-space perspective. Specifically, we first offer a formal definition of image disassembly. Then, by concerning desired properties, such as peeling hierarchy and structure preservation, we convert the original complex problem into a series of two-component separation sub-problems, significantly reducing the complexity. The proposed framework is flexible to both supervised and unsupervised settings. A compact recurrent network, namely hierarchical image peeling net, is customized to efficiently and effectively fulfill the task, which is about 3.5Mb in size, and can handle 1080p images in more than 60 fps per recurrence on a GTX 2080Ti GPU, making it attractive for practical use. Both theoretical findings and experimental results are provided to demonstrate the efficacy of the proposed framework, reveal its superiority over other state-of-the-art alternatives, and show its potential to various applicable scenarios. Our code is available at \url{https://github.com/ForawardStar/HIPe}.",0
"A wide range of applications in computer vision and graphics have demonstrated the significance of hierarchical image organization. This study proposes a novel approach to disassembling an image into a set of derived signals from a scale-space viewpoint, which differs from spatial whole-part consideration in image segmentation. The original complicated problem is transformed into a sequence of two-component separation sub-problems, resulting in a substantial reduction in complexity while preserving desired features such as peeling hierarchy and structure. The proposed model is adaptable to both supervised and unsupervised settings, and a compact recurrent network called Hierarchical Image Peeling Net (HIPe) is developed to efficiently and effectively accomplish the task. With a size of around 3.5Mb, HIPe can handle 1080p images at a rate of over 60 fps per recurrence on a GTX 2080Ti GPU, making it ideal for practical applications. Theoretical findings and experimental results are presented to demonstrate the effectiveness of the proposed framework, as well as its superiority over other state-of-the-art approaches, and its potential for a variety of applicable situations. The code is available at \url{https://github.com/ForawardStar/HIPe}.",1
"We present ObSuRF, a method which turns a single image of a scene into a 3D model represented as a set of Neural Radiance Fields (NeRFs), with each NeRF corresponding to a different object. A single forward pass of an encoder network outputs a set of latent vectors describing the objects in the scene. These vectors are used independently to condition a NeRF decoder, defining the geometry and appearance of each object. We make learning more computationally efficient by deriving a novel loss, which allows training NeRFs on RGB-D inputs without explicit ray marching. After confirming that the model performs equal or better than state of the art on three 2D image segmentation benchmarks, we apply it to two multi-object 3D datasets: A multiview version of CLEVR, and a novel dataset in which scenes are populated by ShapeNet models. We find that after training ObSuRF on RGB-D views of training scenes, it is capable of not only recovering the 3D geometry of a scene depicted in a single input image, but also to segment it into objects, despite receiving no supervision in that regard.",0
"ObSuRF is a technique that transforms a single image of a scene into a 3D model comprising Neural Radiance Fields (NeRFs), each representing a distinct object. Using an encoder network, latent vectors describing the objects in the scene are generated, which are then employed independently to condition a NeRF decoder, determining the geometry and appearance of each object. To enhance learning efficiency, we introduce a new loss that enables NeRFs to be trained on RGB-D inputs without explicit ray marching. We validate the model's performance on three 2D image segmentation benchmarks, demonstrating its superiority to state-of-the-art techniques. Additionally, we apply ObSuRF to two multi-object 3D datasets: a multiview version of CLEVR and a new dataset featuring ShapeNet models. We discovered that after training ObSuRF on RGB-D views of training scenes, it can not only discover the 3D geometry of a scene depicted in a single input image but also segment it into objects without any supervision.",1
"Deep Neural Networks (DNNs) have become ubiquitous in medical image processing and analysis. Among them, U-Nets are very popular in various image segmentation tasks. Yet, little is known about how information flows through these networks and whether they are indeed properly designed for the tasks they are being proposed for. In this paper, we employ information-theoretic tools in order to gain insight into information flow through U-Nets. In particular, we show how mutual information between input/output and an intermediate layer can be a useful tool to understand information flow through various portions of a U-Net, assess its architectural efficiency, and even propose more efficient designs.",0
"The use of Deep Neural Networks (DNNs) has become widespread in medical image processing and analysis, with U-Nets being a popular choice for image segmentation tasks. However, it is not well understood how information is processed through these networks or if their design is appropriate for the tasks they are intended for. This study employs information-theoretic methods to investigate the flow of information in U-Nets. Specifically, we demonstrate how measuring the mutual information between input/output and an intermediate layer can provide insight into the information flow in different parts of the U-Net, evaluate its effectiveness, and suggest more efficient designs.",1
"MeanShift is a popular mode-seeking clustering algorithm used in a wide range of applications in machine learning. However, it is known to be prohibitively slow, with quadratic runtime per iteration. We propose MeanShift++, an extremely fast mode-seeking algorithm based on MeanShift that uses a grid-based approach to speed up the mean shift step, replacing the computationally expensive neighbors search with a density-weighted mean of adjacent grid cells. In addition, we show that this grid-based technique for density estimation comes with theoretical guarantees. The runtime is linear in the number of points and exponential in dimension, which makes MeanShift++ ideal on low-dimensional applications such as image segmentation and object tracking. We provide extensive experimental analysis showing that MeanShift++ can be more than 10,000x faster than MeanShift with competitive clustering results on benchmark datasets and nearly identical image segmentations as MeanShift. Finally, we show promising results for object tracking.",0
"MeanShift is a well-known clustering algorithm that is commonly used in machine learning applications. However, it has a significant drawback of being too slow, with a quadratic runtime per iteration. To address this issue, we introduce MeanShift++, which is a mode-seeking algorithm that is based on MeanShift but uses a grid-based approach to speed up the mean shift step. In this approach, the computationally demanding neighbors search is replaced with a density-weighted mean of adjacent grid cells. Moreover, we demonstrate that this grid-based technique for density estimation has theoretical guarantees. The runtime of MeanShift++ is linear in the number of points and exponential in dimension, making it ideal for low-dimensional applications such as image segmentation and object tracking. Our experimental analysis indicates that MeanShift++ can be more than 10,000 times faster than MeanShift, while still achieving competitive clustering results on benchmark datasets and producing nearly identical image segmentations as MeanShift. Finally, we present promising results for object tracking.",1
"With the increase in available large clinical and experimental datasets, there has been substantial amount of work being done on addressing the challenges in the area of biomedical image analysis. Image segmentation, which is crucial for any quantitative analysis, has especially attracted attention. Recent hardware advancement has led to the success of deep learning approaches. However, although deep learning models are being trained on large datasets, existing methods do not use the information from different learning epochs effectively. In this work, we leverage the information of each training epoch to prune the prediction maps of the subsequent epochs. We propose a novel architecture called feedback attention network (FANet) that unifies the previous epoch mask with the feature map of the current training epoch. The previous epoch mask is then used to provide a hard attention to the learnt feature maps at different convolutional layers. The network also allows to rectify the predictions in an iterative fashion during the test time. We show that our proposed feedback attention model provides a substantial improvement on most segmentation metrics tested on seven publicly available biomedical imaging datasets demonstrating the effectiveness of the proposed FANet.",0
"The field of biomedical image analysis has seen significant progress due to the increase in large clinical and experimental datasets. Image segmentation, a crucial aspect of quantitative analysis, has garnered particular attention. Advances in hardware have led to the success of deep learning techniques, which are trained on large datasets. However, current methods do not effectively use information from different learning epochs. This study proposes a new approach, called feedback attention network (FANet), that combines the previous epoch mask with the feature map of the current epoch to prune subsequent prediction maps. The FANet architecture employs hard attention to rectify predictions iteratively during test time. Results show that FANet significantly improves segmentation metrics on seven publicly available biomedical imaging datasets, highlighting its effectiveness.",1
"While state of the art image segmentation models typically output segmentations in raster format, applications in geographic information systems often require vector polygons. To help bridge the gap between deep network output and the format used in downstream tasks, we add a frame field output to a deep segmentation model for extracting buildings from remote sensing images. We train a deep neural network that aligns a predicted frame field to ground truth contours. This additional objective improves segmentation quality by leveraging multi-task learning and provides structural information that later facilitates polygonization; we also introduce a polygonization algorithm that utilizes the frame field along with the raster segmentation. Our code is available at https://github.com/Lydorn/Polygonization-by-Frame-Field-Learning.",0
"Current image segmentation models produce raster format segmentations, but vector polygons are often required in geographic information systems applications. To address this issue, we incorporated a frame field output into a deep segmentation model for extracting buildings from remote sensing images. Our deep neural network aligns predicted frame fields to ground truth contours, improving segmentation quality and providing structural information for polygonization. We also developed a polygonization algorithm that uses both the frame field and raster segmentation. Our code can be found at https://github.com/Lydorn/Polygonization-by-Frame-Field-Learning.",1
"Image segmentation is to extract meaningful objects from a given image. For degraded images due to occlusions, obscurities or noises, the accuracy of the segmentation result can be severely affected. To alleviate this problem, prior information about the target object is usually introduced. In [10], a topology-preserving registration-based segmentation model was proposed, which is restricted to segment 2D images only. In this paper, we propose a novel 3D topology-preserving registration-based segmentation model with the hyperelastic regularization, which can handle both 2D and 3D images. The existence of the solution of the proposed model is established. We also propose a converging iterative scheme to solve the proposed model. Numerical experiments have been carried out on the synthetic and real images, which demonstrate the effectiveness of our proposed model.",0
"The process of image segmentation involves the extraction of significant objects from an image. However, the accuracy of this process can be greatly impacted by occlusions, obscurities, or noise, especially in degraded images. To address this issue, previous knowledge about the target object is often utilized. In a previous study, a segmentation model was introduced that preserved topology through registration, but was limited to 2D images. In this paper, we present a new topology-preserving registration-based segmentation model with hyperelastic regularization capable of handling both 2D and 3D images. We establish the existence of a solution for our proposed model and offer an iterative scheme for convergence. Numerical experiments conducted using synthetic and real images demonstrate the effectiveness of our proposed model.",1
"In the recent years, researchers proposed a number of successful methods to perform out-of-distribution (OOD) detection in deep neural networks (DNNs). So far the scope of the highly accurate methods has been limited to image level classification tasks. However, attempts for generally applicable methods beyond classification did not attain similar performance. In this paper, we address this limitation by proposing a simple yet effective task-agnostic OOD detection method. We estimate the probability density functions (pdfs) of intermediate features of a pre-trained DNN by performing kernel density estimation (KDE) on the training dataset. As direct application of KDE to feature maps is hindered by their high dimensionality, we use a set of lower-dimensional marginalized KDE models instead of a single high-dimensional one. At test time, we evaluate the pdfs on a test sample and produce a confidence score that indicates the sample is OOD. The use of KDE eliminates the need for making simplifying assumptions about the underlying feature pdfs and makes the proposed method task-agnostic. We perform extensive experiments on classification tasks using benchmark datasets for OOD detection. Additionally, we perform experiments on medical image segmentation tasks using brain MRI datasets. The results demonstrate that the proposed method consistently achieves high OOD detection performance in both classification and segmentation tasks and improves state-of-the-art in almost all cases. Code is available at \url{https://github.com/eerdil/task_agnostic_ood}",0
"Several successful techniques have been developed by researchers in recent years for detecting out-of-distribution (OOD) in deep neural networks (DNNs). However, these methods have mainly been limited to image classification tasks, and attempts to create generally applicable techniques beyond classification have not been as successful. This paper proposes a task-agnostic OOD detection method that is both simple and effective. The method involves using kernel density estimation (KDE) to estimate the probability density functions (pdfs) of intermediate features of a pre-trained DNN. This is done by using a set of lower-dimensional marginalized KDE models instead of a single high-dimensional one, as the latter is hindered by the high dimensionality of feature maps. At test time, the pdfs are evaluated on a test sample to produce a confidence score indicating whether the sample is OOD. The proposed method eliminates the need for making simplifying assumptions about the underlying feature pdfs and is task-agnostic. The effectiveness of the method is demonstrated through extensive experiments on benchmark datasets for OOD detection in classification tasks and medical image segmentation tasks using brain MRI datasets. The proposed method consistently achieves high OOD detection performance in both classification and segmentation tasks and improves state-of-the-art in almost all cases. The code for the method is available at \url{https://github.com/eerdil/task_agnostic_ood}.",1
"We present Boundary IoU (Intersection-over-Union), a new segmentation evaluation measure focused on boundary quality. We perform an extensive analysis across different error types and object sizes and show that Boundary IoU is significantly more sensitive than the standard Mask IoU measure to boundary errors for large objects and does not over-penalize errors on smaller objects. The new quality measure displays several desirable characteristics like symmetry w.r.t. prediction/ground truth pairs and balanced responsiveness across scales, which makes it more suitable for segmentation evaluation than other boundary-focused measures like Trimap IoU and F-measure. Based on Boundary IoU, we update the standard evaluation protocols for instance and panoptic segmentation tasks by proposing the Boundary AP (Average Precision) and Boundary PQ (Panoptic Quality) metrics, respectively. Our experiments show that the new evaluation metrics track boundary quality improvements that are generally overlooked by current Mask IoU-based evaluation metrics. We hope that the adoption of the new boundary-sensitive evaluation metrics will lead to rapid progress in segmentation methods that improve boundary quality.",0
"Boundary IoU, a novel segmentation evaluation metric that emphasizes boundary quality, is introduced in this study. Through extensive analysis across various error types and object sizes, we demonstrate that Boundary IoU is more sensitive to boundary errors for large objects than the conventional Mask IoU measure and does not unfairly penalize errors on smaller objects. The new metric is symmetrical with respect to prediction/ground truth pairs and has balanced responsiveness across scales, making it more suitable for segmentation evaluation than other boundary-focused measures such as Trimap IoU and F-measure. We propose the Boundary AP (Average Precision) and Boundary PQ (Panoptic Quality) metrics for instance and panoptic segmentation tasks, respectively, based on Boundary IoU. Our experiments demonstrate that these new evaluation metrics capture improvements in boundary quality that are often overlooked by current Mask IoU-based metrics. We anticipate that the adoption of these boundary-sensitive evaluation metrics will facilitate the development of segmentation methods that enhance boundary quality.",1
"Referring image segmentation aims to segment the objects referred by a natural language expression. Previous methods usually focus on designing an implicit and recurrent feature interaction mechanism to fuse the visual-linguistic features to directly generate the final segmentation mask without explicitly modeling the localization information of the referent instances. To tackle these problems, we view this task from another perspective by decoupling it into a ""Locate-Then-Segment"" (LTS) scheme. Given a language expression, people generally first perform attention to the corresponding target image regions, then generate a fine segmentation mask about the object based on its context. The LTS first extracts and fuses both visual and textual features to get a cross-modal representation, then applies a cross-model interaction on the visual-textual features to locate the referred object with position prior, and finally generates the segmentation result with a light-weight segmentation network. Our LTS is simple but surprisingly effective. On three popular benchmark datasets, the LTS outperforms all the previous state-of-the-art methods by a large margin (e.g., +3.2% on RefCOCO+ and +3.4% on RefCOCOg). In addition, our model is more interpretable with explicitly locating the object, which is also proved by visualization experiments. We believe this framework is promising to serve as a strong baseline for referring image segmentation.",0
"The goal of image segmentation in reference to natural language is to divide the objects mentioned in the language expression. Past approaches have focused on an implicit and recurrent mechanism to merge the visual-linguistic features to create the final segmentation mask without explicitly taking into account the localization information of the referred instances. To address these issues, we propose a new method called ""Locate-Then-Segment"" (LTS), which breaks down the task into two steps. Firstly, the attention is directed towards the corresponding regions in the target image, and secondly, a fine segmentation mask is created based on the object's context. Our LTS approach first merges both visual and textual features to create a cross-modal representation, then uses a cross-model interaction to locate the object based on position prior, and finally generates the segmentation result using a lightweight segmentation network. Our LTS method outperforms all previous state-of-the-art approaches by a significant margin on three popular benchmark datasets (e.g., +3.2% on RefCOCO+ and +3.4% on RefCOCOg). Moreover, our model is more interpretable as it explicitly locates the object, which is also supported by visualization experiments. We believe that our framework can serve as a strong baseline for referring image segmentation.",1
"Probabilistic image segmentation encodes varying prediction confidence and inherent ambiguity in the segmentation problem. While different probabilistic segmentation models are designed to capture different aspects of segmentation uncertainty and ambiguity, these modelling differences are rarely discussed in the context of applications of uncertainty. We consider two common use cases of segmentation uncertainty, namely assessment of segmentation quality and active learning. We consider four established strategies for probabilistic segmentation, discuss their modelling capabilities, and investigate their performance in these two tasks. We find that for all models and both tasks, returned uncertainty correlates positively with segmentation error, but does not prove to be useful for active learning.",0
"The use of probabilistic image segmentation allows for the representation of varied prediction confidence and inherent ambiguity in the segmentation task. Despite different models being created to capture different aspects of segmentation uncertainty, there is a lack of discussion regarding their practical application. This study examines two key uses of segmentation uncertainty, namely evaluating segmentation quality and active learning. Four established strategies for probabilistic segmentation are examined, with their modelling capabilities and performance in these two tasks being evaluated. Results indicate that all models and tasks show a positive correlation between returned uncertainty and segmentation error, but uncertainty is not found to be helpful for active learning.",1
"Few-shot segmentation has been attracting a lot of attention due to its effectiveness to segment unseen object classes with a few annotated samples. Most existing approaches use masked Global Average Pooling (GAP) to encode an annotated support image to a feature vector to facilitate query image segmentation. However, this pipeline unavoidably loses some discriminative information due to the average operation. In this paper, we propose a simple but effective self-guided learning approach, where the lost critical information is mined. Specifically, through making an initial prediction for the annotated support image, the covered and uncovered foreground regions are encoded to the primary and auxiliary support vectors using masked GAP, respectively. By aggregating both primary and auxiliary support vectors, better segmentation performances are obtained on query images. Enlightened by our self-guided module for 1-shot segmentation, we propose a cross-guided module for multiple shot segmentation, where the final mask is fused using predictions from multiple annotated samples with high-quality support vectors contributing more and vice versa. This module improves the final prediction in the inference stage without re-training. Extensive experiments show that our approach achieves new state-of-the-art performances on both PASCAL-5i and COCO-20i datasets.",0
"Many researchers have shown interest in few-shot segmentation due to its success in segmenting new object classes with only a few annotated samples. Most current methods use masked Global Average Pooling (GAP) to encode the annotated support image into a feature vector for query image segmentation. However, this process can result in a loss of discriminative information due to the average operation. To address this issue, we propose a self-guided learning method that mines this critical information. Our approach involves making an initial prediction for the annotated support image and encoding the covered and uncovered foreground regions into primary and auxiliary support vectors, respectively, using masked GAP. By combining both primary and auxiliary support vectors, we achieve improved segmentation performance on query images. Building on this method, we introduce a cross-guided module for multiple shot segmentation that fuses the final mask using predictions from multiple annotated samples. High-quality support vectors contribute more to the final prediction, and vice versa. This module enhances the final prediction in the inference stage without re-training. Our experiments demonstrate that our approach achieves new state-of-the-art performances on both PASCAL-5i and COCO-20i datasets.",1
"Recently, neural architecture search (NAS) has been applied to automatically search high-performance networks for medical image segmentation. The NAS search space usually contains a network topology level (controlling connections among cells with different spatial scales) and a cell level (operations within each cell). Existing methods either require long searching time for large-scale 3D image datasets, or are limited to pre-defined topologies (such as U-shaped or single-path). In this work, we focus on three important aspects of NAS in 3D medical image segmentation: flexible multi-path network topology, high search efficiency, and budgeted GPU memory usage. A novel differentiable search framework is proposed to support fast gradient-based search within a highly flexible network topology search space. The discretization of the searched optimal continuous model in differentiable scheme may produce a sub-optimal final discrete model (discretization gap). Therefore, we propose a topology loss to alleviate this problem. In addition, the GPU memory usage for the searched 3D model is limited with budget constraints during search. Our Differentiable Network Topology Search scheme (DiNTS) is evaluated on the Medical Segmentation Decathlon (MSD) challenge, which contains ten challenging segmentation tasks. Our method achieves the state-of-the-art performance and the top ranking on the MSD challenge leaderboard.",0
"Neural architecture search (NAS) has recently been utilized to automatically discover high-performance networks for medical image segmentation. The NAS search space includes a network topology level and a cell level, but current methods either necessitate lengthy search times for large-scale 3D image datasets or are restricted to predefined topologies such as U-shaped or single-path. In this study, we concentrate on three essential aspects of NAS in 3D medical image segmentation: a flexible multi-path network topology, high search efficiency, and budgeted GPU memory usage. We propose a novel differentiable search framework that supports rapid gradient-based search within a highly adaptable network topology search space. However, the discretization of the optimal continuous model may result in a sub-optimal final discrete model, so we introduce a topology loss to mitigate this issue. Furthermore, GPU memory usage for the searched 3D model is limited by budget constraints during search. Our Differentiable Network Topology Search scheme (DiNTS) is evaluated on the Medical Segmentation Decathlon (MSD) challenge, which includes ten challenging segmentation tasks. Our approach achieves state-of-the-art performance and is ranked first on the MSD challenge leaderboard.",1
"Transformers are increasingly dominating multi-modal reasoning tasks, such as visual question answering, achieving state-of-the-art results thanks to their ability to contextualize information using the self-attention and co-attention mechanisms. These attention modules also play a role in other computer vision tasks including object detection and image segmentation. Unlike Transformers that only use self-attention, Transformers with co-attention require to consider multiple attention maps in parallel in order to highlight the information that is relevant to the prediction in the model's input. In this work, we propose the first method to explain prediction by any Transformer-based architecture, including bi-modal Transformers and Transformers with co-attentions. We provide generic solutions and apply these to the three most commonly used of these architectures: (i) pure self-attention, (ii) self-attention combined with co-attention, and (iii) encoder-decoder attention. We show that our method is superior to all existing methods which are adapted from single modality explainability.",0
"Multi-modal reasoning tasks, such as visual question answering, are increasingly being dominated by Transformers. This is due to their ability to contextualize information using the self-attention and co-attention mechanisms, resulting in state-of-the-art results. These attention modules are also useful in other computer vision tasks, such as object detection and image segmentation. Transformers with co-attention require considering multiple attention maps in parallel to highlight relevant information for predictions in the model's input. In this study, we introduce a novel method to explain prediction for any Transformer-based architecture, including bi-modal Transformers and Transformers with co-attentions. We provide generic solutions and apply them to the three most commonly used architectures. Our method outperforms all existing methods adapted from single modality explainability.",1
"Neural Architecture Search (NAS) has shown great potentials in automatically designing scalable network architectures for dense image predictions. However, existing NAS algorithms usually compromise on restricted search space and search on proxy task to meet the achievable computational demands. To allow as wide as possible network architectures and avoid the gap between target and proxy dataset, we propose a Densely Connected NAS (DCNAS) framework, which directly searches the optimal network structures for the multi-scale representations of visual information, over a large-scale target dataset. Specifically, by connecting cells with each other using learnable weights, we introduce a densely connected search space to cover an abundance of mainstream network designs. Moreover, by combining both path-level and channel-level sampling strategies, we design a fusion module to reduce the memory consumption of ample search space. We demonstrate that the architecture obtained from our DCNAS algorithm achieves state-of-the-art performances on public semantic image segmentation benchmarks, including 84.3% on Cityscapes, and 86.9% on PASCAL VOC 2012. We also retain leading performances when evaluating the architecture on the more challenging ADE20K and Pascal Context dataset.",0
"Automatically designing scalable network architectures for dense image predictions has been made possible by Neural Architecture Search (NAS). However, existing NAS algorithms usually have limited search space and search on proxy tasks to meet computational demands. To overcome this and allow for a wide range of network architectures to be explored, while avoiding the gap between target and proxy datasets, we propose a Densely Connected NAS (DCNAS) framework that directly searches for optimal network structures for multi-scale visual representations on a large-scale target dataset. Our approach introduces a densely connected search space by connecting cells with learnable weights to cover a range of mainstream network designs. We also incorporate path-level and channel-level sampling strategies in a fusion module to reduce memory consumption. The architecture obtained from our DCNAS algorithm achieves state-of-the-art performance on public semantic image segmentation benchmarks, including 84.3% on Cityscapes and 86.9% on PASCAL VOC 2012. We also retain leading performance when evaluating the architecture on more challenging datasets such as ADE20K and Pascal Context.",1
"Semantic and instance segmentation algorithms are two general yet distinct image segmentation solutions powered by Convolution Neural Network. While semantic segmentation benefits extensively from the end-to-end training strategy, instance segmentation is frequently framed as a multi-stage task, supported by learning-based discrimination and post-process clustering. Independent optimizations on substages instigate the accumulation of segmentation errors. In this work, we propose to embed prior clustering information into an embedding learning framework FCRNet, stimulating the one-stage instance segmentation. FCRNet relieves the complexity of post process by incorporating the number of clustering groups into the embedding space. The superior performance of FCRNet is verified and compared with other methods on the nucleus dataset BBBC006.",0
"Convolution Neural Network powers both semantic and instance segmentation algorithms, which are two distinct image segmentation solutions. While semantic segmentation benefits from end-to-end training, instance segmentation is often a multi-stage task that utilizes learning-based discrimination and post-process clustering. However, independent optimizations on substages can lead to segmentation errors. This paper proposes embedding prior clustering information into an embedding learning framework called FCRNet to facilitate one-stage instance segmentation. FCRNet incorporates the number of clustering groups into the embedding space, reducing post-process complexity. The superior performance of FCRNet is demonstrated and compared with other methods on the nucleus dataset BBBC006.",1
"Large, fine-grained image segmentation datasets, annotated at pixel-level, are difficult to obtain, particularly in medical imaging, where annotations also require expert knowledge. Weakly-supervised learning can train models by relying on weaker forms of annotation, such as scribbles. Here, we learn to segment using scribble annotations in an adversarial game. With unpaired segmentation masks, we train a multi-scale GAN to generate realistic segmentation masks at multiple resolutions, while we use scribbles to learn their correct position in the image. Central to the model's success is a novel attention gating mechanism, which we condition with adversarial signals to act as a shape prior, resulting in better object localization at multiple scales. Subject to adversarial conditioning, the segmentor learns attention maps that are semantic, suppress the noisy activations outside the objects, and reduce the vanishing gradient problem in the deeper layers of the segmentor. We evaluated our model on several medical (ACDC, LVSC, CHAOS) and non-medical (PPSS) datasets, and we report performance levels matching those achieved by models trained with fully annotated segmentation masks. We also demonstrate extensions in a variety of settings: semi-supervised learning; combining multiple scribble sources (a crowdsourcing scenario) and multi-task learning (combining scribble and mask supervision). We release expert-made scribble annotations for the ACDC dataset, and the code used for the experiments, at https://vios-s.github.io/multiscale-adversarial-attention-gates",0
"It is challenging to obtain large, pixel-level annotated datasets for fine-grained image segmentation, especially in medical imaging, which requires expert knowledge. Weakly-supervised learning can train models using weaker forms of annotation, such as scribbles. In this study, we developed a method to segment using scribble annotations in an adversarial game. Our approach involves training a multi-scale GAN with unpaired segmentation masks to generate realistic masks at various resolutions. We then use scribbles to learn the correct position of the masks in the image. Our model's success relies on a novel attention gating mechanism that acts as a shape prior, resulting in better object localization at multiple scales. The segmentor learns semantic attention maps that suppress noisy activations outside objects and reduce the vanishing gradient problem in deeper layers. We evaluated our model on various medical and non-medical datasets and achieved performance levels comparable to models trained with fully annotated masks. We also demonstrated extensions in semi-supervised learning, combining multiple scribble sources, and multi-task learning. We have released expert-made scribble annotations for the ACDC dataset and the code used for the experiments. More information can be found at https://vios-s.github.io/multiscale-adversarial-attention-gates.",1
"Conventional deformable registration methods aim at solving an optimization model carefully designed on image pairs and their computational costs are exceptionally high. In contrast, recent deep learning based approaches can provide fast deformation estimation. These heuristic network architectures are fully data-driven and thus lack explicit geometric constraints, e.g., topology-preserving, which are indispensable to generate plausible deformations. We design a new deep learning based framework to optimize a diffeomorphic model via multi-scale propagation in order to integrate advantages and avoid limitations of these two categories of approaches. Specifically, we introduce a generic optimization model to formulate diffeomorphic registration and develop a series of learnable architectures to obtain propagative updating in the coarse-to-fine feature space. Moreover, we propose a novel bilevel self-tuned training strategy, allowing efficient search of task-specific hyper-parameters. This training strategy increases the flexibility to various types of data while reduces computational and human burdens. We conduct two groups of image registration experiments on 3D volume datasets including image-to-atlas registration on brain MRI data and image-to-image registration on liver CT data. Extensive results demonstrate the state-of-the-art performance of the proposed method with diffeomorphic guarantee and extreme efficiency. We also apply our framework to challenging multi-modal image registration, and investigate how our registration to support the down-streaming tasks for medical image analysis including multi-modal fusion and image segmentation.",0
"Conventional methods for deformable registration involve solving optimization models that are complex and computationally expensive when dealing with image pairs. In contrast, recent deep learning approaches offer faster deformation estimation. However, these data-driven methods lack explicit geometric constraints such as topology preservation, which are necessary for generating plausible deformations. To address this limitation, we propose a new deep learning-based framework that integrates the advantages of both conventional and deep learning methods. We introduce a diffeomorphic model that is optimized through multi-scale propagation using a series of learnable architectures. Additionally, we propose a bilevel self-tuned training strategy that enables efficient search of task-specific hyper-parameters while reducing computational and human burdens. We evaluated our method on 3D volume datasets for image-to-atlas registration on brain MRI data and image-to-image registration on liver CT data. Our results demonstrate state-of-the-art performance with diffeomorphic guarantee and extreme efficiency. We also applied our framework to multi-modal image registration and explored downstream tasks such as multi-modal fusion and image segmentation for medical image analysis.",1
"Registration is a fundamental task in medical robotics and is often a crucial step for many downstream tasks such as motion analysis, intra-operative tracking and image segmentation. Popular registration methods such as ANTs and NiftyReg optimize objective functions for each pair of images from scratch, which are time-consuming for 3D and sequential images with complex deformations. Recently, deep learning-based registration approaches such as VoxelMorph have been emerging and achieve competitive performance. In this work, we construct a test-time training for deep deformable image registration to improve the generalization ability of conventional learning-based registration model. We design multi-scale deep networks to consecutively model the residual deformations, which is effective for high variational deformations. Extensive experiments validate the effectiveness of multi-scale deep registration with test-time training based on Dice coefficient for image segmentation and mean square error (MSE), normalized local cross-correlation (NLCC) for tissue dense tracking tasks. Two videos are in https://www.youtube.com/watch?v=NvLrCaqCiAE and https://www.youtube.com/watch?v=pEA6ZmtTNuQ",0
"Medical robotics relies heavily on registration, which is a crucial step for various downstream tasks such as motion analysis, intra-operative tracking, and image segmentation. However, popular registration methods like ANTs and NiftyReg require significant time and effort for 3D and sequential images with complex deformations, as they optimize objective functions for each pair of images from scratch. Recently, deep learning-based registration approaches like VoxelMorph have emerged as competitive alternatives. This study introduces a test-time training approach for deep deformable image registration, which improves the generalization ability of conventional learning-based models. The researchers design multi-scale deep networks to model residual deformations consecutively, which is effective for high variational deformations. The study's experiments validate the effectiveness of multi-scale deep registration with test-time training based on Dice coefficient for image segmentation and mean square error (MSE), normalized local cross-correlation (NLCC) for tissue dense tracking tasks. Two videos demonstrating the approach are available on YouTube.",1
"This work explores how to design a single neural network that is capable of adapting to multiple heterogeneous tasks of computer vision, such as image segmentation, 3D detection, and video recognition. This goal is challenging because network architecture designs in different tasks are inconsistent. We solve this challenge by proposing Network Coding Propagation (NCP), a novel ""neural predictor"", which is able to predict an architecture's performance in multiple datasets and tasks. Unlike prior arts of neural architecture search (NAS) that typically focus on a single task, NCP has several unique benefits. (1) NCP can be trained on different NAS benchmarks, such as NAS-Bench-201 and NAS-Bench-MR, which contains a novel network space designed by us for jointly searching an architecture among multiple tasks, including ImageNet, Cityscapes, KITTI, and HMDB51. (2) NCP learns from network codes but not original data, enabling it to update the architecture efficiently across datasets. (3) Extensive experiments evaluate NCP on object classification, detection, segmentation, and video recognition. For example, with 17\% fewer FLOPs, a single architecture returned by NCP achieves 86\% and 77.16\% on ImageNet-50-1000 and Cityscapes respectively, outperforming its counterparts. More interestingly, NCP enables a single architecture applicable to both image segmentation and video recognition, which achieves competitive performance on both HMDB51 and ADE20K compared to the singular counterparts. Code is available at https://github.com/dingmyu/NCP}{https://github.com/dingmyu/NCP.",0
"The aim of this study is to create a neural network that can adapt to multiple computer vision tasks, such as image segmentation, 3D detection, and video recognition. This is difficult because different tasks require different network architecture designs. However, the researchers have developed a solution called Network Coding Propagation (NCP), which is a ""neural predictor"" that can predict the performance of an architecture in multiple datasets and tasks. NCP has several advantages over other neural architecture search methods, including the ability to be trained on different NAS benchmarks, learn from network codes rather than original data, and achieve competitive performance on various tasks such as object classification, detection, segmentation, and video recognition. The code for NCP is available on GitHub.",1
"Fluorescence microscopy images play the critical role of capturing spatial or spatiotemporal information of biomedical processes in life sciences. Their simple structures and semantics provide unique advantages in elucidating learning behavior of deep neural networks (DNNs). It is generally assumed that accurate image annotation is required to train DNNs for accurate image segmentation. In this study, however, we find that DNNs trained by label images in which nearly half (49%) of the binary pixel labels are randomly flipped provide largely the same segmentation performance. This suggests that DNNs learn high-level structures rather than pixel-level labels per se to segment fluorescence microscopy images. We refer to these structures as meta-structures. In support of the existence of the meta-structures, when DNNs are trained by a series of label images with progressively less meta-structure information, we find progressive degradation in their segmentation performance. Motivated by the learning behavior of DNNs trained by random labels and the characteristics of meta-structures, we propose an unsupervised segmentation model. Experiments show that it achieves remarkably competitive performance in comparison to supervised segmentation models.",0
"The spatial or spatiotemporal information of biomedical processes in life sciences is captured by fluorescence microscopy images, which play a critical role. Due to their simple structures and semantics, they provide unique benefits in understanding the learning behavior of deep neural networks (DNNs). It is commonly believed that accurate image annotation is necessary to train DNNs for precise image segmentation. However, our study reveals that DNNs trained using label images with nearly half (49%) of binary pixel labels randomly flipped still achieve similar segmentation performance. This suggests that DNNs learn high-level structures rather than pixel-level labels to segment fluorescence microscopy images, which we call meta-structures. We provide evidence for the existence of these meta-structures by showing that the segmentation performance of DNNs decreases as we provide progressively less meta-structure information through label images. Inspired by the learning behavior of DNNs trained by random labels and the characteristics of meta-structures, we propose an unsupervised segmentation model that achieves highly competitive performance compared to supervised segmentation models.",1
"Deep Metric Learning (DML) is helpful in computer vision tasks. In this paper, we firstly introduce DML into image co-segmentation. We propose a novel Triplet loss for Image Segmentation, called IS-Triplet loss for short, and combine it with traditional image segmentation loss. Different from the general DML task which learns the metric between pictures, we treat each pixel as a sample, and use their embedded features in high-dimensional space to form triples, then we tend to force the distance between pixels of different categories greater than of the same category by optimizing IS-Triplet loss so that the pixels from different categories are easier to be distinguished in the high-dimensional feature space. We further present an efficient triple sampling strategy to make a feasible computation of IS-Triplet loss. Finally, the IS-Triplet loss is combined with 3 traditional image segmentation losses to perform image segmentation. We apply the proposed approach to image co-segmentation and test it on the SBCoseg dataset and the Internet dataset. The experimental result shows that our approach can effectively improve the discrimination of pixels' categories in high-dimensional space and thus help traditional loss achieve better performance of image segmentation with fewer training epochs.",0
"Computer vision tasks can benefit from Deep Metric Learning (DML). In this study, DML is integrated into image co-segmentation using a novel Triplet loss for Image Segmentation (IS-Triplet loss) in combination with traditional image segmentation loss. Unlike the typical DML task that focuses on learning the metric between images, each pixel is treated as a sample and their embedded features in high-dimensional space are used to form triples. The optimization of IS-Triplet loss aims to increase the distance between pixels of different categories and decrease the distance between pixels of the same category. An efficient triple sampling strategy is also introduced to enable feasible computation of IS-Triplet loss. The combined approach of IS-Triplet loss and three traditional image segmentation losses is applied to image co-segmentation and evaluated on the SBCoseg dataset and the Internet dataset. The results indicate that the proposed approach effectively improves the discrimination of pixel categories in high-dimensional space, leading to better performance of image segmentation with fewer training epochs.",1
"Confused about renovating your space? Choosing the perfect color for your walls is always a challenging task. One does rounds of color consultation and several patch tests. This paper proposes an AI tool to pitch paint based on attributes of your room and other furniture, and visualize it on your walls. It makes the color selection process easy. It takes in images of a room, detects furniture objects using YOLO object detection. Once these objects have been detected, the tool picks out color of the object. Later this object specific information gets appended to the room attributes (room_type, room_size, preferred_tone, etc) and a deep neural net is trained to make predictions for color/texture/wallpaper for the walls. Finally, these predictions are visualized on the walls from the images provided. The idea is to take the knowledge of a color consultant and pitch colors that suit the walls and provide a good contrast with the furniture and harmonize with different colors in the room. Transfer learning for YOLO object detection from the COCO dataset was used as a starting point and the weights were later fine-tuned by training on additional images. The model was trained on 1000 records listing the room and furniture attributes, to predict colors. Given the room image, this method finds the best color scheme for the walls. These predictions are then visualized on the walls in the image using image segmentation. The results are visually appealing and automatically enhance the color look-and-feel.",0
"If you're struggling with how to renovate your space, picking the right color for your walls can be a daunting task. Many people seek out color consultations and perform patch tests to find the perfect shade. However, this paper suggests an AI tool that can help you choose the right paint color based on your room's attributes and existing furniture, and then visualize it on your walls. This tool simplifies the color selection process by taking images of your room and identifying furniture objects using YOLO object detection. The tool then selects the color of each object and combines this information with the room's attributes, such as its size and preferred tone, to train a deep neural network to predict the best color, texture, or wallpaper for your walls. The tool then visualizes these predictions on your walls, taking into account your furniture and other colors in the room to create a harmonious look. The YOLO object detection uses transfer learning from the COCO dataset and fine-tunes its weights using additional images. The model was trained on 1000 records of room and furniture attributes to predict colors. By using this method, you can find the best color scheme for your walls automatically and enhance the overall look-and-feel of your space.",1
"Despite the tremendous success of deep neural networks in medical image segmentation, they typically require a large amount of costly, expert-level annotated data. Few-shot segmentation approaches address this issue by learning to transfer knowledge from limited quantities of labeled examples. Incorporating appropriate prior knowledge is critical in designing high-performance few-shot segmentation algorithms. Since strong spatial priors exist in many medical imaging modalities, we propose a prototype-based method -- namely, the location-sensitive local prototype network -- that leverages spatial priors to perform few-shot medical image segmentation. Our approach divides the difficult problem of segmenting the entire image with global prototypes into easily solvable subproblems of local region segmentation with local prototypes. For organ segmentation experiments on the VISCERAL CT image dataset, our method outperforms the state-of-the-art approaches by 10% in the mean Dice coefficient. Extensive ablation studies demonstrate the substantial benefits of incorporating spatial information and confirm the effectiveness of our approach.",0
"Even though deep neural networks have shown great success in medical image segmentation, they typically require a large amount of costly, expert-level annotated data. To address this issue, few-shot segmentation approaches have been developed, which learn to transfer knowledge from a limited number of labeled examples. To design high-performance few-shot segmentation algorithms, it is critical to incorporate appropriate prior knowledge. Since many medical imaging modalities have strong spatial priors, we propose a prototype-based method called the location-sensitive local prototype network. This leverages spatial priors to perform few-shot medical image segmentation. Our approach breaks down the complex task of segmenting the entire image with global prototypes into easily manageable subproblems of local region segmentation with local prototypes. In organ segmentation experiments using the VISCERAL CT image dataset, our method outperformed state-of-the-art approaches by 10% in the mean Dice coefficient. Extensive ablation studies confirmed the effectiveness of our approach, highlighting the substantial benefits of incorporating spatial information.",1
"In the segmentation of fine-scale structures from natural and biomedical images, per-pixel accuracy is not the only metric of concern. Topological correctness, such as vessel connectivity and membrane closure, is crucial for downstream analysis tasks. In this paper, we propose a new approach to train deep image segmentation networks for better topological accuracy. In particular, leveraging the power of discrete Morse theory (DMT), we identify global structures, including 1D skeletons and 2D patches, which are important for topological accuracy. Trained with a novel loss based on these global structures, the network performance is significantly improved especially near topologically challenging locations (such as weak spots of connections and membranes). On diverse datasets, our method achieves superior performance on both the DICE score and topological metrics.",0
"In the process of identifying fine-scale structures from natural and biomedical images, achieving per-pixel accuracy alone is insufficient. It is essential to ensure topological correctness, which involves factors such as vessel connectivity and membrane closure, for downstream analysis tasks. This study proposes a new method for training deep image segmentation networks to attain better topological accuracy. By utilizing the power of discrete Morse theory (DMT), we can identify global structures, such as 1D skeletons and 2D patches, that are critical for topological accuracy. With the aid of a novel loss function based on these global structures, the network performance improves significantly, particularly in topologically challenging areas (e.g., weak spots of connections and membranes). Our approach achieves superior performance on both the DICE score and topological metrics for diverse datasets.",1
"Medical image segmentation is a relevant task as it serves as the first step for several diagnosis processes, thus it is indispensable in clinical usage. Whilst major success has been reported using supervised techniques, they assume a large and well-representative labelled set. This is a strong assumption in the medical domain where annotations are expensive, time-consuming, and inherent to human bias. To address this problem, unsupervised techniques have been proposed in the literature yet it is still an open problem due to the difficulty of learning any transformation pattern. In this work, we present a novel optimisation model framed into a new CNN-based contrastive registration architecture for unsupervised medical image segmentation. The core of our approach is to exploit image-level registration and feature-level from a contrastive learning mechanism, to perform registration-based segmentation. Firstly, we propose an architecture to capture the image-to-image transformation pattern via registration for unsupervised medical image segmentation. Secondly, we embed a contrastive learning mechanism into the registration architecture to enhance the discriminating capacity of the network in the feature-level. We show that our proposed technique mitigates the major drawbacks of existing unsupervised techniques. We demonstrate, through numerical and visual experiments, that our technique substantially outperforms the current state-of-the-art unsupervised segmentation methods on two major medical image datasets.",0
"Medical image segmentation is a crucial component of diagnostic processes in clinical settings and is therefore indispensable. While supervised techniques have shown considerable success, they require a large and representative labelled set, which is often expensive, time-consuming, and subject to human bias in the medical domain. Unsupervised techniques have been proposed to address this issue, but their efficacy is limited due to the difficulty of learning transformation patterns. In this study, we propose a new CNN-based contrastive registration architecture that combines image-level registration and feature-level contrastive learning to perform registration-based segmentation for unsupervised medical image segmentation. Our approach captures image-to-image transformation patterns and enhances the network's discriminating capacity through contrastive learning. Our proposed technique outperforms existing unsupervised segmentation methods on two major medical image datasets, as demonstrated through numerical and visual experiments.",1
"Recent advances in appearance-based models have shown improved eye tracking performance in difficult scenarios like occlusion due to eyelashes, eyelids or camera placement, and environmental reflections on the cornea and glasses. The key reason for the improvement is the accurate and robust identification of eye parts (pupil, iris, and sclera regions). The improved accuracy often comes at the cost of labeling an enormous dataset, which is complex and time-consuming. This work presents two semi-supervised learning frameworks to identify eye-parts by taking advantage of unlabeled images where labeled datasets are scarce. With these frameworks, leveraging the domain-specific augmentation and novel spatially varying transformations for image segmentation, we show improved performance on various test cases. For instance, for a model trained on just 48 labeled images, these frameworks achieved an improvement of 0.38% and 0.65% in segmentation performance over the baseline model, which is trained only with the labeled dataset.",0
"Advancements in appearance-based models have resulted in enhanced eye tracking capabilities, even in challenging situations such as eyelid or eyelash occlusion, cornea and glasses reflections, and camera placement. This improvement is due to the precise and resilient identification of eye components, specifically the pupil, iris, and sclera regions. However, this accuracy often requires labeling a vast and intricate dataset, which can be time-consuming. This study introduces two semi-supervised learning frameworks that utilize unlabeled images to identify eye parts, especially when labeled data is scarce. By utilizing domain-specific augmentation and novel spatially varying transformations for image segmentation, these frameworks show improved performance in various test cases. For example, when trained on just 48 labeled images, these frameworks achieved 0.38% and 0.65% increases in segmentation performance compared to the baseline model trained solely with the labeled dataset.",1
"To bridge the gap between the source and target domains in unsupervised domain adaptation (UDA), the most common strategy puts focus on matching the marginal distributions in the feature space through adversarial learning. However, such category-agnostic global alignment lacks of exploiting the class-level joint distributions, causing the aligned distribution less discriminative. To address this issue, we propose in this paper a novel margin preserving self-paced contrastive Learning (MPSCL) model for cross-modal medical image segmentation. Unlike the conventional construction of contrastive pairs in contrastive learning, the domain-adaptive category prototypes are utilized to constitute the positive and negative sample pairs. With the guidance of progressively refined semantic prototypes, a novel margin preserving contrastive loss is proposed to boost the discriminability of embedded representation space. To enhance the supervision for contrastive learning, more informative pseudo-labels are generated in target domain in a self-paced way, thus benefiting the category-aware distribution alignment for UDA. Furthermore, the domain-invariant representations are learned through joint contrastive learning between the two domains. Extensive experiments on cross-modal cardiac segmentation tasks demonstrate that MPSCL significantly improves semantic segmentation performance, and outperforms a wide variety of state-of-the-art methods by a large margin.",0
"The common approach in unsupervised domain adaptation (UDA) is to match the marginal distributions in the feature space through adversarial learning, which does not take into account the class-level joint distributions. This results in a less discriminative aligned distribution. To tackle this issue, we propose a novel model called Margin Preserving Self-Paced Contrastive Learning (MPSCL) for cross-modal medical image segmentation. MPSCL uses domain-adaptive category prototypes to form positive and negative sample pairs, and a margin preserving contrastive loss is introduced to enhance the discriminability of the embedded representation space. To improve the supervision for contrastive learning, informative pseudo-labels are generated in a self-paced manner, which benefits the category-aware distribution alignment for UDA. Additionally, domain-invariant representations are learned through joint contrastive learning between the two domains. Our experiments on cross-modal cardiac segmentation tasks demonstrate that MPSCL outperforms a wide range of state-of-the-art methods by a significant margin, and significantly improves semantic segmentation performance.",1
"Deep learning models are sensitive to domain shift phenomena. A model trained on images from one domain cannot generalise well when tested on images from a different domain, despite capturing similar anatomical structures. It is mainly because the data distribution between the two domains is different. Moreover, creating annotation for every new modality is a tedious and time-consuming task, which also suffers from high inter- and intra- observer variability. Unsupervised domain adaptation (UDA) methods intend to reduce the gap between source and target domains by leveraging source domain labelled data to generate labels for the target domain. However, current state-of-the-art (SOTA) UDA methods demonstrate degraded performance when there is insufficient data in source and target domains. In this paper, we present a novel UDA method for multi-modal cardiac image segmentation. The proposed method is based on adversarial learning and adapts network features between source and target domain in different spaces. The paper introduces an end-to-end framework that integrates: a) entropy minimisation, b) output feature space alignment and c) a novel point-cloud shape adaptation based on the latent features learned by the segmentation model. We validated our method on two cardiac datasets by adapting from the annotated source domain, bSSFP-MRI (balanced Steady-State Free Procession-MRI), to the unannotated target domain, LGE-MRI (Late-gadolinium enhance-MRI), for the multi-sequence dataset; and from MRI (source) to CT (target) for the cross-modality dataset. The results highlighted that by enforcing adversarial learning in different parts of the network, the proposed method delivered promising performance, compared to other SOTA methods.",0
"Domain shift phenomena can affect the sensitivity of deep learning models. When a model is trained on images from one domain, it may not perform well when tested on images from a different domain, even if the images contain similar anatomical structures. The issue arises because the data distribution between the two domains is different. Additionally, the creation of annotations for new modalities is a time-consuming and laborious task, which also suffers from variance between different observers. Unsupervised domain adaptation (UDA) methods aim to reduce the gap between the source and target domains by utilizing labelled data from the source domain to generate labels for the target domain. However, current UDA methods experience reduced performance when there is insufficient data in both the source and target domains. In this study, we introduce a novel UDA method for multi-modal cardiac image segmentation that uses adversarial learning to adapt network features between the source and target domains in different spaces. The method integrates entropy minimisation, output feature space alignment, and a new point-cloud shape adaptation based on the latent features learned by the segmentation model. The proposed method was validated on two cardiac datasets, one multi-sequence dataset consisting of bSSFP-MRI and LGE-MRI, and one cross-modality dataset consisting of MRI and CT. The results demonstrated that the proposed method delivered promising performance, compared to other state-of-the-art UDA methods, by enforcing adversarial learning in different parts of the network.",1
"In this paper, we present new image segmentation methods based on hidden Markov random fields (HMRFs) and cuckoo search (CS) variants. HMRFs model the segmentation problem as a minimization of an energy function. CS algorithm is one of the recent powerful optimization techniques. Therefore, five variants of the CS algorithm are used to compute a solution. Through tests, we conduct a study to choose the CS variant with parameters that give good results (execution time and quality of segmentation). CS variants are evaluated and compared with non-destructive testing (NDT) images using a misclassification error (ME) criterion.",0
"New image segmentation techniques utilizing hidden Markov random fields (HMRFs) and various versions of the cuckoo search (CS) algorithm are presented in this paper. The segmentation problem is modeled as an energy function minimization using HMRFs, while CS is employed as a powerful optimization technique. Five CS variants are utilized to determine the best solution via a study that assesses their execution time and segmentation quality. The selected CS variant's parameters are determined to yield good results. The CS variants are evaluated using non-destructive testing (NDT) images and compared using the misclassification error (ME) criterion.",1
"We aim to estimate food portion size, a property that is strongly related to the presence of food object in 3D space, from single monocular images under real life setting. Specifically, we are interested in end-to-end estimation of food portion size, which has great potential in the field of personal health management. Unlike image segmentation or object recognition where annotation can be obtained through large scale crowd sourcing, it is much more challenging to collect datasets for portion size estimation since human cannot accurately estimate the size of an object in an arbitrary 2D image without expert knowledge. To address such challenge, we introduce a real life food image dataset collected from a nutrition study where the groundtruth food energy (calorie) is provided by registered dietitians, and will be made available to the research community. We propose a deep regression process for portion size estimation by combining features estimated from both RGB and learned energy distribution domains. Our estimates of food energy achieved state-of-the-art with a MAPE of 11.47%, significantly outperforms non-expert human estimates by 27.56%.",0
"Our goal is to determine the size of food portions using single monocular images in real-life situations, which is closely linked to the objects' presence in 3D space. Our primary focus is on achieving end-to-end food portion size estimation, which has enormous potential for personal health management. Unlike image segmentation or object recognition, obtaining annotations for portion size estimation is more difficult since humans lack the expertise to accurately estimate an object's size in a 2D image. To overcome this challenge, we have created a real-life food image dataset based on a nutrition study. Registered dietitians have provided the groundtruth food energy (calorie), and we will make the dataset available to the research community. We propose a deep regression process that combines features estimated from both RGB and learned energy distribution domains for portion size estimation. We have achieved state-of-the-art food energy estimates with a MAPE of 11.47%, significantly outperforming non-expert human estimates by 27.56%.",1
"We generalize a graph-based multiclass semi-supervised classification technique based on diffuse interface methods to multilayer graphs. Besides the treatment of various applications with an inherent multilayer structure, we present a very flexible approach that interprets high-dimensional data in a low-dimensional multilayer graph representation. Highly efficient numerical methods involving the spectral decomposition of the corresponding differential graph operators as well as fast matrix-vector products based on the nonequispaced fast Fourier transform (NFFT) enable the rapid treatment of large and high-dimensional data sets. We perform various numerical tests putting a special focus on image segmentation. In particular, we test the performance of our method on data sets with up to 10 million nodes per layer as well as up to 104 dimensions resulting in graphs with up to 52 layers. While all presented numerical experiments can be run on an average laptop computer, the linear dependence per iteration step of the runtime on the network size in all stages of our algorithm makes it scalable to even larger and higher-dimensional problems.",0
"Our approach extends a diffuse interface method for graph-based multiclass semi-supervised classification to multilayer graphs, providing a flexible way to represent high-dimensional data in a low-dimensional multilayer graph. This method efficiently handles large and complex data sets, utilizing spectral decomposition of differential graph operators and fast matrix-vector products based on the nonequispaced fast Fourier transform (NFFT). Our numerical tests focus on image segmentation, demonstrating the method's effectiveness on data sets with up to 10 million nodes per layer and up to 104 dimensions, resulting in graphs with up to 52 layers. Despite the linear dependence per iteration step of the runtime on the network size in all stages of our algorithm, it remains scalable to even larger and higher-dimensional problems and can be run on an average laptop computer.",1
"Aerial Image Segmentation is a particular semantic segmentation problem and has several challenging characteristics that general semantic segmentation does not have. There are two critical issues: The one is an extremely foreground-background imbalanced distribution, and the other is multiple small objects along with the complex background. Such problems make the recent dense affinity context modeling perform poorly even compared with baselines due to over-introduced background context. To handle these problems, we propose a point-wise affinity propagation module based on the Feature Pyramid Network (FPN) framework, named PointFlow. Rather than dense affinity learning, a sparse affinity map is generated upon selected points between the adjacent features, which reduces the noise introduced by the background while keeping efficiency. In particular, we design a dual point matcher to select points from the salient area and object boundaries, respectively. Experimental results on three different aerial segmentation datasets suggest that the proposed method is more effective and efficient than state-of-the-art general semantic segmentation methods. Especially, our methods achieve the best speed and accuracy trade-off on three aerial benchmarks. Further experiments on three general semantic segmentation datasets prove the generality of our method. Code will be provided in (https: //github.com/lxtGH/PFSegNets).",0
"Aerial Image Segmentation presents unique challenges that differ from general semantic segmentation. Two critical issues are the imbalanced distribution of foreground and background and the presence of numerous small objects amidst a complex background. These difficulties cause dense affinity context modeling to perform poorly compared to baselines due to an over-introduction of background context. To address these challenges, we introduce PointFlow, a point-wise affinity propagation module based on the Feature Pyramid Network (FPN) framework. PointFlow generates a sparse affinity map on selected points between adjacent features, reducing noise from the background while maintaining efficiency. We employ a dual point matcher to select points from the salient area and object boundaries. Our approach outperforms state-of-the-art general semantic segmentation methods on three aerial segmentation datasets in terms of both speed and accuracy. Additionally, experiments on three general semantic segmentation datasets confirm the effectiveness and generality of our method. Code is available at (https://github.com/lxtGH/PFSegNets).",1
"Image segmentation, one of the most critical vision tasks, has been studied for many years. Most of the early algorithms are unsupervised methods, which use hand-crafted features to divide the image into many regions. Recently, owing to the great success of deep learning technology, CNNs based methods show superior performance in image segmentation. However, these methods rely on a large number of human annotations, which are expensive to collect. In this paper, we propose a deep unsupervised method for image segmentation, which contains the following two stages. First, a Superpixelwise Autoencoder (SuperAE) is designed to learn the deep embedding and reconstruct a smoothed image, then the smoothed image is passed to generate superpixels. Second, we present a novel clustering algorithm called Deep Superpixel Cut (DSC), which measures the deep similarity between superpixels and formulates image segmentation as a soft partitioning problem. Via backpropagation, DSC adaptively partitions the superpixels into perceptual regions. Experimental results on the BSDS500 dataset demonstrate the effectiveness of the proposed method.",0
"The task of image segmentation has been a crucial area of study for many years. Initially, unsupervised methods that utilized manually crafted features were employed to divide the image into various regions. However, with the emergence of deep learning technology, CNN-based methods have shown better performance in image segmentation. These methods, however, require a large number of costly human annotations. This paper presents an alternative deep unsupervised method for image segmentation that involves two stages. Firstly, a Superpixelwise Autoencoder (SuperAE) is utilized to learn the deep embedding and reconstruct a smoothed image, which is then used to generate superpixels. Secondly, a new clustering algorithm named Deep Superpixel Cut (DSC) is introduced, which measures deep similarity between superpixels and formulates image segmentation as a soft partitioning problem. By using backpropagation, DSC can adaptively partition superpixels into perceptual regions. The proposed method's effectiveness is demonstrated through experimental results on the BSDS500 dataset.",1
"Federated learning allows distributed medical institutions to collaboratively learn a shared prediction model with privacy protection. While at clinical deployment, the models trained in federated learning can still suffer from performance drop when applied to completely unseen hospitals outside the federation. In this paper, we point out and solve a novel problem setting of federated domain generalization (FedDG), which aims to learn a federated model from multiple distributed source domains such that it can directly generalize to unseen target domains. We present a novel approach, named as Episodic Learning in Continuous Frequency Space (ELCFS), for this problem by enabling each client to exploit multi-source data distributions under the challenging constraint of data decentralization. Our approach transmits the distribution information across clients in a privacy-protecting way through an effective continuous frequency space interpolation mechanism. With the transferred multi-source distributions, we further carefully design a boundary-oriented episodic learning paradigm to expose the local learning to domain distribution shifts and particularly meet the challenges of model generalization in medical image segmentation scenario. The effectiveness of our method is demonstrated with superior performance over state-of-the-arts and in-depth ablation experiments on two medical image segmentation tasks. The code is available at ""https://github.com/liuquande/FedDG-ELCFS"".",0
"Federated learning is a technique that enables multiple medical institutions to collaboratively create a prediction model while maintaining privacy. However, when these models are applied to hospitals outside the federation, they can suffer from a decrease in performance. This paper addresses this issue by introducing a new approach called Federated Domain Generalization (FedDG), which aims to create a model that can be applied to unseen target domains. The approach, Episodic Learning in Continuous Frequency Space (ELCFS), allows each client to use multi-source data distributions while maintaining data decentralization. The approach uses an interpolation mechanism to transmit distribution information in a privacy-protecting way. Additionally, a boundary-oriented episodic learning paradigm is used to address challenges in model generalization for medical image segmentation scenarios. The effectiveness of the approach is demonstrated through experiments on two medical image segmentation tasks, with superior performance over existing techniques. The code for the approach is available at ""https://github.com/liuquande/FedDG-ELCFS"".",1
"The in vitro clonogenic assay is a technique to study the ability of a cell to form a colony in a culture dish. By optical imaging, dishes with stained colonies can be scanned and assessed digitally. Identification, segmentation and counting of stained colonies play a vital part in high-throughput screening and quantitative assessment of biological assays. Image processing of such pictured/scanned assays can be affected by image/scan acquisition artifacts like background noise and spatially varying illumination, and contaminants in the suspension medium. Although existing approaches tackle these issues, the segmentation quality requires further improvement, particularly on noisy and low contrast images. In this work, we present an objective and versatile machine learning procedure to amend these issues by characterizing, extracting and segmenting inquired colonies using principal component analysis, k-means clustering and a modified watershed segmentation algorithm. The intention is to automatically identify visible colonies through spatial texture assessment and accordingly discriminate them from background in preparation for successive segmentation. The proposed segmentation algorithm yielded a similar quality as manual counting by human observers. High F1 scores (>0.9) and low root-mean-square errors (around 14%) underlined good agreement with ground truth data. Moreover, it outperformed a recent state-of-the-art method. The methodology will be an important tool in future cancer research applications.",0
"The in vitro clonogenic assay is a method for investigating a cell's ability to generate a colony in a culture dish. Optical imaging is employed to scan and digitally evaluate dishes with stained colonies. Identification, segmentation, and counting of stained colonies are essential for high-throughput screening and quantitative analysis of biological assays. Image processing may be compromised by image acquisition artifacts such as background noise, spatially varying illumination, and contaminants in the suspension medium. While current approaches address these concerns, segmentation quality still needs improvement, especially in noisy and low contrast images. This study introduces a machine learning procedure that utilizes principal component analysis, k-means clustering, and a modified watershed segmentation algorithm for objective and versatile characterization, extraction, and segmentation of colonies. The goal is to automatically differentiate visible colonies from the background through spatial texture evaluation before segmentation. The proposed segmentation algorithm performs similarly to manual counting by human observers, with high F1 scores (>0.9) and low root-mean-square errors (around 14%) indicating good agreement with ground truth data. Additionally, it outperforms a recent state-of-the-art technique. This methodology will be a valuable tool for future cancer research applications.",1
"Convolutional Networks (ConvNets) excel at semantic segmentation and have become a vital component for perception in autonomous driving. Enabling an all-encompassing view of street-scenes, omnidirectional cameras present themselves as a perfect fit in such systems. Most segmentation models for parsing urban environments operate on common, narrow Field of View (FoV) images. Transferring these models from the domain they were designed for to 360-degree perception, their performance drops dramatically, e.g., by an absolute 30.0% (mIoU) on established test-beds. To bridge the gap in terms of FoV and structural distribution between the imaging domains, we introduce Efficient Concurrent Attention Networks (ECANets), directly capturing the inherent long-range dependencies in omnidirectional imagery. In addition to the learned attention-based contextual priors that can stretch across 360-degree images, we upgrade model training by leveraging multi-source and omni-supervised learning, taking advantage of both: Densely labeled and unlabeled data originating from multiple datasets. To foster progress in panoramic image segmentation, we put forward and extensively evaluate models on Wild PAnoramic Semantic Segmentation (WildPASS), a dataset designed to capture diverse scenes from all around the globe. Our novel model, training regimen and multi-source prediction fusion elevate the performance (mIoU) to new state-of-the-art results on the public PASS (60.2%) and the fresh WildPASS (69.0%) benchmarks.",0
"Convolutional Networks (ConvNets) are highly effective in semantic segmentation and are essential for autonomous driving perception. Omnidirectional cameras are a perfect fit for such systems as they provide a comprehensive view of street-scenes. However, most segmentation models for urban environments operate on narrow Field of View (FoV) images, which do not perform well when transferred to 360-degree perception. The performance of these models drops by 30.0% (mIoU) on established test-beds. To address this issue, we introduce Efficient Concurrent Attention Networks (ECANets) that capture long-range dependencies in omnidirectional imagery. Our model uses attention-based contextual priors that can stretch across 360-degree images. We also upgrade model training by leveraging multi-source and omni-supervised learning, which takes advantage of densely labeled and unlabeled data from multiple datasets. To evaluate our approach, we use the Wild PAnoramic Semantic Segmentation (WildPASS) dataset, which captures diverse scenes from around the world. Our novel model, training regimen, and multi-source prediction fusion achieve state-of-the-art results on both the public PASS (60.2%) and the fresh WildPASS (69.0%) benchmarks, advancing progress in panoramic image segmentation.",1
"Synthetic Aperture Sonar (SAS) surveys produce imagery with large regions of transition between seabed types. Due to these regions, it is difficult to label and segment the imagery and, furthermore, challenging to score the image segmentations appropriately. While there are many approaches to quantify performance in standard crisp segmentation schemes, drawing hard boundaries in remote sensing imagery where gradients and regions of uncertainty exist is inappropriate. These cases warrant weak labels and an associated appropriate scoring approach. In this paper, a labeling approach and associated modified version of the Rand index for weakly-labeled data is introduced to address these issues. Results are evaluated with the new index and compared to traditional segmentation evaluation methods. Experimental results on a SAS data set containing must-link and cannot-link labels show that our Weakly-Labeled Rand index scores segmentations appropriately in reference to qualitative performance and is more suitable than traditional quantitative metrics for scoring weakly-labeled data.",0
"The use of Synthetic Aperture Sonar (SAS) surveys often generates images that contain large transitional areas between different seabed types. These regions pose difficulties in terms of accurate labeling and segmentation of the imagery, as well as challenges in appropriately scoring the resulting image segmentations. While there are various methods available for quantifying performance in standard crisp segmentation schemes, these methods are not suitable for drawing hard boundaries in remote sensing imagery where gradients and regions of uncertainty exist. Thus, weak labeling and an appropriate scoring approach are necessary in such cases. This paper presents a labeling approach and a modified version of the Rand index specifically designed for weakly-labeled data to address these issues. The results of the new index are compared to traditional segmentation evaluation methods, and experimental results on a SAS data set containing must-link and cannot-link labels demonstrate that the Weakly-Labeled Rand index is more appropriate for accurately scoring weakly-labeled data than traditional quantitative metrics.",1
"Deep learning-based semi-supervised learning (SSL) algorithms have led to promising results in medical images segmentation and can alleviate doctors' expensive annotations by leveraging unlabeled data. However, most of the existing SSL algorithms in literature tend to regularize the model training by perturbing networks and/or data. Observing that multi/dual-task learning attends to various levels of information which have inherent prediction perturbation, we ask the question in this work: can we explicitly build task-level regularization rather than implicitly constructing networks- and/or data-level perturbation-and-transformation for SSL? To answer this question, we propose a novel dual-task-consistency semi-supervised framework for the first time. Concretely, we use a dual-task deep network that jointly predicts a pixel-wise segmentation map and a geometry-aware level set representation of the target. The level set representation is converted to an approximated segmentation map through a differentiable task transform layer. Simultaneously, we introduce a dual-task consistency regularization between the level set-derived segmentation maps and directly predicted segmentation maps for both labeled and unlabeled data. Extensive experiments on two public datasets show that our method can largely improve the performance by incorporating the unlabeled data. Meanwhile, our framework outperforms the state-of-the-art semi-supervised medical image segmentation methods. Code is available at: https://github.com/Luoxd1996/DTC",0
"The use of deep learning-based semi-supervised learning (SSL) algorithms has shown promise in the segmentation of medical images. These algorithms can decrease the need for costly annotations by leveraging unlabeled data. However, existing SSL algorithms tend to regulate model training by perturbing networks and/or data. To address this issue, we propose a new approach that explicitly builds task-level regularization instead of implicitly constructing networks or data-level perturbations. Specifically, we introduce a dual-task-consistency semi-supervised framework that utilizes a dual-task deep network to predict both a pixel-wise segmentation map and a geometry-aware level set representation of the target. We incorporate a dual-task consistency regularization between the level set-derived segmentation maps and directly predicted segmentation maps for both labeled and unlabeled data. Our method outperforms existing semi-supervised medical image segmentation methods and significantly improves performance by incorporating unlabeled data. The code for our approach is available at https://github.com/Luoxd1996/DTC.",1
"The shapes and morphology of the organs and tissues are important prior knowledge in medical imaging recognition and segmentation. The morphological operation is a well-known method for morphological feature extraction. As the morphological operation is performed well in hand-crafted image segmentation techniques, it is also promising to design an approach to approximate morphological operation in the convolutional networks. However, using the traditional convolutional neural network as a black-box is usually hard to specify the morphological operation action. Here, we introduced a 3D morphological operation residual block to extract morphological features in end-to-end deep learning models for semantic segmentation. This study proposed a novel network block architecture that embedded the morphological operation as an infinitely strong prior in the convolutional neural network. Several 3D deep learning models with the proposed morphological operation block were built and compared in different medical imaging segmentation tasks. Experimental results showed the proposed network achieved a relatively higher performance in the segmentation tasks comparing with the conventional approach. In conclusion, the novel network block could be easily embedded in traditional networks and efficiently reinforce the deep learning models for medical imaging segmentation.",0
"Prior knowledge about the shapes and morphology of organs and tissues is crucial in medical imaging recognition and segmentation. Morphological operation is a well-established technique for feature extraction. Although it works well in hand-crafted image segmentation, incorporating it into convolutional networks is challenging. This is because using traditional convolutional neural networks as a black-box makes it hard to specify the morphological operation action. To overcome this, we introduced a 3D morphological operation residual block in end-to-end deep learning models for semantic segmentation. The block is designed to embed the morphological operation as an infinitely strong prior in the convolutional neural network. We built several 3D deep learning models with the proposed morphological operation block and compared them in different medical imaging segmentation tasks. The experimental results showed that the proposed network achieved higher performance in the segmentation tasks than the conventional approach. In conclusion, the novel network block can be easily incorporated into traditional networks and efficiently reinforce deep learning models for medical imaging segmentation.",1
"Convolutional neural networks (CNNs) have been the de facto standard for nowadays 3D medical image segmentation. The convolutional operations used in these networks, however, inevitably have limitations in modeling the long-range dependency due to their inductive bias of locality and weight sharing. Although Transformer was born to address this issue, it suffers from extreme computational and spatial complexities in processing high-resolution 3D feature maps. In this paper, we propose a novel framework that efficiently bridges a {\bf Co}nvolutional neural network and a {\bf Tr}ansformer {\bf (CoTr)} for accurate 3D medical image segmentation. Under this framework, the CNN is constructed to extract feature representations and an efficient deformable Transformer (DeTrans) is built to model the long-range dependency on the extracted feature maps. Different from the vanilla Transformer which treats all image positions equally, our DeTrans pays attention only to a small set of key positions by introducing the deformable self-attention mechanism. Thus, the computational and spatial complexities of DeTrans have been greatly reduced, making it possible to process the multi-scale and high-resolution feature maps, which are usually of paramount importance for image segmentation. We conduct an extensive evaluation on the Multi-Atlas Labeling Beyond the Cranial Vault (BCV) dataset that covers 11 major human organs. The results indicate that our CoTr leads to a substantial performance improvement over other CNN-based, transformer-based, and hybrid methods on the 3D multi-organ segmentation task. Code is available at \def\UrlFont{\rm\small\ttfamily} \url{https://github.com/YtongXie/CoTr}",0
"Nowadays, Convolutional Neural Networks (CNNs) are commonly used for 3D medical image segmentation. However, due to their reliance on locality and weight sharing, these networks have limitations in modeling long-range dependencies. Although the Transformer was created to address this issue, it struggles with the computational and spatial complexities of processing high-resolution 3D feature maps. This paper proposes a new framework, called CoTr, which bridges the CNN and Transformer for precise 3D medical image segmentation. The CNN extracts feature representations while the Deformable Transformer (DeTrans) efficiently models long-range dependencies on the extracted feature maps. Unlike the vanilla Transformer, which treats all image positions equally, DeTrans focuses on a small set of key positions through the deformable self-attention mechanism, significantly reducing computational and spatial complexities. This enables the processing of multi-scale and high-resolution feature maps, which are crucial for image segmentation. The CoTr framework is evaluated on the Multi-Atlas Labeling Beyond the Cranial Vault (BCV) dataset, covering 11 main human organs, and outperforms other CNN-based, Transformer-based, and hybrid methods for 3D multi-organ segmentation. Code is available at \def\UrlFont{\rm\small\ttfamily} \url{https://github.com/YtongXie/CoTr}.",1
"The hatching process also influences the success of hatching eggs beside the initial egg factor. So that the results have a large percentage of hatching, it is necessary to check the development of the embryo at the beginning of the hatching. This process aims to sort eggs that have embryos to remain hatched until the end. Maximum checking is done the first week in the hatching period. This study aims to detect the presence of embryos in eggs. Detection of the existence of embryos is processed using segmentation. Egg images are segmented using the K-means algorithm based on Lab color images. The results of the images acquisition are converted into Lab color space images. The results of Lab color space images are processed using K-means for each color. The K-means process uses cluster k=3, where this cluster divided the image into three parts, namely background, eggs, and yolk eggs. Yolk eggs are part of eggs that have embryonic characteristics. This study applies the concept of color in the initial segmentation and grayscale in the final stages. The results of the initial phase show that the image segmentation results using k-means clustering based on Lab color space provide a grouping of three parts. At the grayscale image processing stage, the results of color image segmentation are processed with grayscaling, image enhancement, and morphology. Thus, it seems clear that the yolk segmented shows the presence of egg embryos. Based on this process and results, K-means segmentation based on Lab color space can be used for the initial stages of the embryo detection process. The evaluation uses MSE and MSSIM, with values of 0.0486 and 0.9979; this can be used as a reference that the results obtained can indicate the detection of embryos in egg yolk.",0
"Aside from the quality of the eggs, the success of hatching is also influenced by the hatching process itself. To increase the likelihood of successful hatching, it is necessary to monitor the embryo's development early on in the process so that only eggs with viable embryos are selected for hatching. The first week of the hatching period is particularly important for this purpose. This study aimed to detect the presence of embryos in eggs using segmentation techniques. The K-means algorithm was applied to Lab color images to segment egg images and identify the presence of embryos based on yolk characteristics. The initial segmentation results showed that K-means clustering based on Lab color space successfully divided the image into three parts: background, eggs, and yolk eggs. In the final stages, grayscaling, image enhancement, and morphology were employed to process the results of color image segmentation. The evaluation of this process using MSE and MSSIM yielded values of 0.0486 and 0.9979, respectively, indicating that K-means segmentation based on Lab color space can be used as a reliable method for detecting embryos in egg yolks.",1
"With the widespread success of deep learning in biomedical image segmentation, domain shift becomes a critical and challenging problem, as the gap between two domains can severely affect model performance when deployed to unseen data with heterogeneous features. To alleviate this problem, we present a novel unsupervised domain adaptation network, for generalizing models learned from the labeled source domain to the unlabeled target domain for cross-modality biomedical image segmentation. Specifically, our approach consists of two key modules, a conditional domain discriminator~(CDD) and a category-centric prototype aligner~(CCPA). The CDD, extended from conditional domain adversarial networks in classifier tasks, is effective and robust in handling complex cross-modality biomedical images. The CCPA, improved from the graph-induced prototype alignment mechanism in cross-domain object detection, can exploit precise instance-level features through an elaborate prototype representation. In addition, it can address the negative effect of class imbalance via entropy-based loss. Extensive experiments on a public benchmark for the cardiac substructure segmentation task demonstrate that our method significantly improves performance on the target domain.",0
"The success of deep learning in biomedical image segmentation has led to a significant problem of domain shift, where the gap between two domains can adversely affect model performance when applied to unseen data with different features. To combat this, we propose an innovative unsupervised domain adaptation network that can generalize models learned from labeled source domains to unlabeled target domains for cross-modality biomedical image segmentation. Our approach comprises two main modules - a conditional domain discriminator (CDD) and a category-centric prototype aligner (CCPA). The CDD is an extension of conditional domain adversarial networks used in classifier tasks and is effective in handling complex cross-modality biomedical images. The CCPA is an improvement on the graph-induced prototype alignment mechanism used in cross-domain object detection and can leverage precise instance-level features through an elaborate prototype representation. Additionally, it can mitigate the negative impact of class imbalance using an entropy-based loss. Our experiments on a public benchmark for cardiac substructure segmentation show that our method significantly enhances performance on the target domain.",1
"Deep convolutional neural networks have shown outstanding performance in medical image segmentation tasks. The usual problem when training supervised deep learning methods is the lack of labeled data which is time-consuming and costly to obtain. In this paper, we propose a novel uncertainty-guided semi-supervised learning based on a student-teacher approach for training the segmentation network using limited labeled samples and a large number of unlabeled images. First, a teacher segmentation model is trained from the labeled samples using Bayesian deep learning. The trained model is used to generate soft segmentation labels and uncertainty maps for the unlabeled set. The student model is then updated using the softly segmented samples and the corresponding pixel-wise confidence of the segmentation quality estimated from the uncertainty of the teacher model using a newly designed loss function. Experimental results on a retinal layer segmentation task show that the proposed method improves the segmentation performance in comparison to the fully supervised approach and is on par with the expert annotator. The proposed semi-supervised segmentation framework is a key contribution and applicable for biomedical image segmentation across various imaging modalities where access to annotated medical images is challenging",0
"Medical image segmentation tasks have seen remarkable results with deep convolutional neural networks. However, supervised deep learning methods often suffer from the issue of insufficient labeled data, which can be expensive and time-consuming to obtain. To tackle this problem, this study proposes a novel semi-supervised learning approach that utilizes a teacher-student model to train the segmentation network with limited labeled data and an abundance of unlabeled images. The teacher model is first trained using Bayesian deep learning on the labeled samples to generate soft segmentation labels and uncertainty maps for the unlabeled set. The student model is then updated using the softly segmented samples and the corresponding pixel-wise confidence of the segmentation quality estimated from the uncertainty of the teacher model using a newly designed loss function. The proposed method has been tested on a retinal layer segmentation task and has shown significant improvement compared to the fully supervised approach, and is on par with the expert annotator. This semi-supervised segmentation framework is a crucial contribution and can be applied to biomedical image segmentation across various imaging modalities where access to annotated medical images is a challenge.",1
"In medical image diagnosis, pathology image analysis using semantic segmentation becomes important for efficient screening as a field of digital pathology. The spatial augmentation is ordinary used for semantic segmentation. Tumor images under malignant are rare and to annotate the labels of nuclei region takes much time-consuming. We require an effective use of dataset to maximize the segmentation accuracy. It is expected that some augmentation to transform generalized images influence the segmentation performance. We propose a synthetic augmentation using label-to-image translation, mapping from a semantic label with the edge structure to a real image. Exactly this paper deal with stain slides of nuclei in tumor. Actually, we demonstrate several segmentation algorithms applied to the initial dataset that contains real images and labels using synthetic augmentation in order to add their generalized images. We computes and reports that a proposed synthetic augmentation procedure improve their accuracy.",0
"Efficient screening in medical image diagnosis requires the use of semantic segmentation for pathology image analysis in the field of digital pathology. Spatial augmentation is commonly utilized for this purpose. However, labeling nuclei regions in rare malignant tumor images can be time-consuming. Therefore, maximizing segmentation accuracy through effective dataset usage is crucial. To improve segmentation performance, we propose a synthetic augmentation technique using label-to-image translation that maps a semantic label with edge structure to a real image. Our focus is on stain slides of nuclei in tumors. We apply several segmentation algorithms to the initial dataset, which includes real images and labels, and use synthetic augmentation to add generalized images. Our results demonstrate that the proposed synthetic augmentation procedure enhances accuracy.",1
"Time-series remote sensing data offer a rich source of information that can be used in a wide range of applications, from monitoring changes in land cover to surveilling crops, coastal changes, flood risk assessment, and urban sprawl. This paper addresses the challenge of using time-series satellite images to predict urban expansion. Building upon previous work, we propose a novel two-step approach based on semantic image segmentation in order to predict urban expansion. The first step aims to extract information about urban regions at different time scales and prepare them for use in the training step. The second step combines Convolutional Neural Networks (CNN) with Long Short Term Memory (LSTM) methods in order to learn temporal features and thus predict urban expansion. In this paper, experimental results are conducted using several multi-date satellite images representing the three largest cities in Saudi Arabia, namely: Riyadh, Jeddah, and Dammam. We empirically evaluated our proposed technique, and examined its results by comparing them with state-of-the-art approaches. Following this evaluation, we determined that our results reveal improved performance for the new-coupled CNN-LSTM approach, particularly in terms of assessments based on Mean Square Error, Root Mean Square Error, Peak Signal to Noise Ratio, Structural Similarity Index, and overall classification accuracy.",0
"The utilization of time-series remote sensing data provides a vast amount of information that can be applied in various fields such as land cover monitoring, crop surveillance, flood risk assessment, coastal changes, and urban sprawl. This research paper focuses on the challenge of predicting urban expansion using time-series satellite images. By building on previous research, a unique two-step approach based on semantic image segmentation is proposed. The first step involves gathering data on urban regions across different time periods and preparing them for the training stage. The second step combines Convolutional Neural Networks (CNN) with Long Short Term Memory (LSTM) techniques to learn temporal features and predict urban expansion. The proposed technique was tested on multi-date satellite images of the three largest cities in Saudi Arabia, Riyadh, Jeddah, and Dammam. Results were evaluated empirically and compared with existing approaches, and it was found that the coupled CNN-LSTM approach showed improved performance in various assessments such as Mean Square Error, Root Mean Square Error, Peak Signal to Noise Ratio, Structural Similarity Index, and overall classification accuracy.",1
"Despite the remarkable performance of deep learning methods on various tasks, most cutting-edge models rely heavily on large-scale annotated training examples, which are often unavailable for clinical and health care tasks. The labeling costs for medical images are very high, especially in medical image segmentation, which typically requires intensive pixel/voxel-wise labeling. Therefore, the strong capability of learning and generalizing from limited supervision, including a limited amount of annotations, sparse annotations, and inaccurate annotations, is crucial for the successful application of deep learning models in medical image segmentation. However, due to its intrinsic difficulty, segmentation with limited supervision is challenging and specific model design and/or learning strategies are needed. In this paper, we provide a systematic and up-to-date review of the solutions above, with summaries and comments about the methodologies. We also highlight several problems in this field, discussed future directions observing further investigations.",0
"Although deep learning methods have shown impressive performance in various tasks, most state-of-the-art models heavily rely on large-scale annotated training examples, which are often unavailable in clinical and health care settings. The high labeling costs associated with medical images, particularly in medical image segmentation, which requires intensive pixel/voxel-wise labeling, make it even more challenging. Hence, it is essential to have the ability to learn and generalize from limited supervision, such as a limited amount of annotations, sparse annotations, and inaccurate annotations, to successfully apply deep learning models in medical image segmentation. However, segmentation with limited supervision is intrinsically difficult, requiring specific model design and/or learning strategies. This paper reviews the current solutions for these challenges, including methodologies, summaries, and comments, while also highlighting several issues in this field and discussing future directions for further investigations.",1
"Inspired by the recent development of deep network-based methods in semantic image segmentation, we introduce an end-to-end trainable model for face mask extraction in video sequence. Comparing to landmark-based sparse face shape representation, our method can produce the segmentation masks of individual facial components, which can better reflect their detailed shape variations. By integrating Convolutional LSTM (ConvLSTM) algorithm with Fully Convolutional Networks (FCN), our new ConvLSTM-FCN model works on a per-sequence basis and takes advantage of the temporal correlation in video clips. In addition, we also propose a novel loss function, called Segmentation Loss, to directly optimise the Intersection over Union (IoU) performances. In practice, to further increase segmentation accuracy, one primary model and two additional models were trained to focus on the face, eyes, and mouth regions, respectively. Our experiment shows the proposed method has achieved a 16.99% relative improvement (from 54.50% to 63.76% mean IoU) over the baseline FCN model on the 300 Videos in the Wild (300VW) dataset.",0
"Our model for face mask extraction in video sequences is based on deep network-based methods in semantic image segmentation. Unlike sparse face shape representation, our approach produces segmentation masks for individual facial components, capturing their detailed shape variations. We combine Convolutional LSTM (ConvLSTM) and Fully Convolutional Networks (FCN) to create an end-to-end trainable model that uses temporal correlation in video clips. We introduce a new loss function, the Segmentation Loss, which optimizes Intersection over Union (IoU) performance. To increase segmentation accuracy, we trained one primary model and two additional models that focus on the face, eyes, and mouth regions. Our experiment shows a 16.99% relative improvement (from 54.50% to 63.76% mean IoU) over the baseline FCN model on the 300VW dataset.",1
"Considering the scarcity of medical data, most datasets in medical image analysis are an order of magnitude smaller than those of natural images. However, most Network Architecture Search (NAS) approaches in medical images focused on specific datasets and did not take into account the generalization ability of the learned architectures on unseen datasets as well as different domains. In this paper, we address this point by proposing to search for generalizable U-shape architectures on a composited dataset that mixes medical images from multiple segmentation tasks and domains creatively, which is named MixSearch. Specifically, we propose a novel approach to mix multiple small-scale datasets from multiple domains and segmentation tasks to produce a large-scale dataset. Then, a novel weaved encoder-decoder structure is designed to search for a generalized segmentation network in both cell-level and network-level. The network produced by the proposed MixSearch framework achieves state-of-the-art results compared with advanced encoder-decoder networks across various datasets.",0
"Due to the limited availability of medical data, most datasets used for medical image analysis are significantly smaller in size than those for natural images. However, Network Architecture Search (NAS) approaches for medical images have typically been tailored to specific datasets and have disregarded the ability of the learned architectures to generalize to unseen datasets and domains. This paper addresses this issue by proposing the MixSearch method, which searches for generalizable U-shape architectures on a composite dataset that creatively mixes medical images from multiple segmentation tasks and domains. This involves using a unique approach to combine multiple small-scale datasets from various domains and segmentation tasks to create a large-scale dataset. A novel weaved encoder-decoder structure is then employed to search for a generalized segmentation network at both the cell-level and network-level. The resulting network produced by the MixSearch framework outperforms advanced encoder-decoder networks across a range of datasets, achieving state-of-the-art results.",1
"One-shot semantic image segmentation aims to segment the object regions for the novel class with only one annotated image. Recent works adopt the episodic training strategy to mimic the expected situation at testing time. However, these existing approaches simulate the test conditions too strictly during the training process, and thus cannot make full use of the given label information. Besides, these approaches mainly focus on the foreground-background target class segmentation setting. They only utilize binary mask labels for training. In this paper, we propose to leverage the multi-class label information during the episodic training. It will encourage the network to generate more semantically meaningful features for each category. After integrating the target class cues into the query features, we then propose a pyramid feature fusion module to mine the fused features for the final classifier. Furthermore, to take more advantage of the support image-mask pair, we propose a self-prototype guidance branch to support image segmentation. It can constrain the network for generating more compact features and a robust prototype for each semantic class. For inference, we propose a fused prototype guidance branch for the segmentation of the query image. Specifically, we leverage the prediction of the query image to extract the pseudo-prototype and combine it with the initial prototype. Then we utilize the fused prototype to guide the final segmentation of the query image. Extensive experiments demonstrate the superiority of our proposed approach.",0
"The objective of one-shot semantic image segmentation is to segment object regions for a new class using only one annotated image. Current methods use episodic training to mimic testing conditions, but they follow strict simulation guidelines during training, which limits their ability to use label information. Additionally, these methods focus mainly on foreground-background segmentation with binary mask labels. This paper proposes using multi-class label information during episodic training to encourage the network to generate semantically meaningful features for each category. A pyramid feature fusion module is also proposed to mine fused features for the final classifier. To further take advantage of support image-mask pairs, a self-prototype guidance branch is introduced to generate compact features and a robust prototype for each semantic class. At inference, a fused prototype guidance branch is used to segment the query image by combining the initial prototype with a pseudo-prototype generated from the query image prediction. Our proposed approach is demonstrated to outperform existing methods through extensive experiments.",1
"Environmental Microorganism Data Set Fifth Version (EMDS-5) is a microscopic image dataset including original Environmental Microorganism (EM) images and two sets of Ground Truth (GT) images. The GT image sets include a single-object GT image set and a multi-object GT image set. The EMDS-5 dataset has 21 types of EMs, each of which contains 20 original EM images, 20 single-object GT images and 20 multi-object GT images. EMDS-5 can realize to evaluate image preprocessing, image segmentation, feature extraction, image classification and image retrieval functions. In order to prove the effectiveness of EMDS-5, for each function, we select the most representative algorithms and price indicators for testing and evaluation. The image preprocessing functions contain two parts: image denoising and image edge detection. Image denoising uses nine kinds of filters to denoise 13 kinds of noises, respectively. In the aspect of edge detection, six edge detection operators are used to detect the edges of the images, and two evaluation indicators, peak-signal to noise ratio and mean structural similarity, are used for evaluation. Image segmentation includes single-object image segmentation and multi-object image segmentation. Six methods are used for single-object image segmentation, while k-means and U-net are used for multi-object segmentation.We extract nine features from the images in EMDS-5 and use the Support Vector Machine classifier for testing. In terms of image classification, we select the VGG16 feature to test different classifiers. We test two types of retrieval approaches: texture feature retrieval and deep learning feature retrieval. We select the last layer of features of these two deep learning networks as feature vectors. We use mean average precision as the evaluation index for retrieval.",0
"The Environmental Microorganism Data Set Fifth Version (EMDS-5) is a dataset of microscopic images that includes original Environmental Microorganism (EM) images and two sets of Ground Truth (GT) images - a single-object and a multi-object GT image set. EMDS-5 comprises 21 types of EMs, each with 20 original EM images as well as 20 single-object and 20 multi-object GT images. It can be used to evaluate image preprocessing, segmentation, feature extraction, classification, and retrieval functions. To test and evaluate its efficacy, we use representative algorithms and price indicators for each function. For image preprocessing, we use nine filters to denoise 13 types of noises, and six edge detection operators with two evaluation indicators to detect edges. Single-object and multi-object image segmentation are performed using six and two methods, respectively. Feature extraction involves the extraction of nine features, which are tested using the Support Vector Machine classifier. For image classification, we use the VGG16 feature to test various classifiers. Two retrieval approaches are tested: texture feature retrieval and deep learning feature retrieval. The last layer of the deep learning networks is used to generate feature vectors, and mean average precision is used as the evaluation index for retrieval.",1
"Class imbalance poses a challenge for developing unbiased, accurate predictive models. In particular, in image segmentation neural networks may overfit to the foreground samples from small structures, which are often heavily under-represented in the training set, leading to poor generalization. In this study, we provide new insights on the problem of overfitting under class imbalance by inspecting the network behavior. We find empirically that when training with limited data and strong class imbalance, at test time the distribution of logit activations may shift across the decision boundary, while samples of the well-represented class seem unaffected. This bias leads to a systematic under-segmentation of small structures. This phenomenon is consistently observed for different databases, tasks and network architectures. To tackle this problem, we introduce new asymmetric variants of popular loss functions and regularization techniques including a large margin loss, focal loss, adversarial training, mixup and data augmentation, which are explicitly designed to counter logit shift of the under-represented classes. Extensive experiments are conducted on several challenging segmentation tasks. Our results demonstrate that the proposed modifications to the objective function can lead to significantly improved segmentation accuracy compared to baselines and alternative approaches.",0
"Developing accurate predictive models is a challenge due to class imbalance, particularly in image segmentation neural networks. These networks may overfit to foreground samples from small structures that are under-represented in the training set, leading to poor generalization. This study examines network behavior and finds that limited data and strong class imbalance cause a shift in the distribution of logit activations across the decision boundary at test time, which affects small structures. To address this issue, new asymmetric variants of popular loss functions and regularization techniques are introduced, including a large margin loss, focal loss, adversarial training, mixup, and data augmentation. These modifications counter logit shift of the under-represented classes and improve segmentation accuracy compared to baselines and alternative approaches in challenging segmentation tasks.",1
"Preserving contour topology during image segmentation is useful in many practical scenarios. By keeping the contours isomorphic, it is possible to prevent over-segmentation and under-segmentation, as well as to adhere to given topologies. The Self-repelling Snake model (SR) is a variational model that preserves contour topology by combining a non-local repulsion term with the geodesic active contour model (GAC). The SR is traditionally solved using the additive operator splitting (AOS) scheme. In our paper, we propose an alternative solution to the SR using the Split Bregman method. Our algorithm breaks the problem down into simpler sub-problems to use lower-order evolution equations and a simple projection scheme rather than re-initialization. The sub-problems can be solved via fast Fourier transform (FFT) or an approximate soft thresholding formula which maintains stability, shortening the convergence time, and reduces the memory requirement. The Split Bregman and AOS algorithms are compared theoretically and experimentally.",0
"Many practical scenarios benefit from the preservation of contour topology during image segmentation. This technique prevents both over-segmentation and under-segmentation, while adhering to prescribed topologies. The Self-repelling Snake model (SR) achieves this by combining a non-local repulsion term with the geodesic active contour model (GAC). The traditional method of solving the SR involves the additive operator splitting (AOS) scheme. However, our paper proposes a new approach using the Split Bregman method. By breaking down the problem into simpler sub-problems, our algorithm utilizes lower-order evolution equations and a simple projection scheme instead of re-initialization. This technique can be solved via fast Fourier transform (FFT) or an approximate soft thresholding formula, which reduces memory requirements and shortens convergence time while maintaining stability. The theoretical and experimental comparison of Split Bregman and AOS algorithms is presented in our paper.",1
"Producing manual, pixel-accurate, image segmentation labels is tedious and time-consuming. This is often a rate-limiting factor when large amounts of labeled images are required, such as for training deep convolutional networks for instrument-background segmentation in surgical scenes. No large datasets comparable to industry standards in the computer vision community are available for this task. To circumvent this problem, we propose to automate the creation of a realistic training dataset by exploiting techniques stemming from special effects and harnessing them to target training performance rather than visual appeal. Foreground data is captured by placing sample surgical instruments over a chroma key (a.k.a. green screen) in a controlled environment, thereby making extraction of the relevant image segment straightforward. Multiple lighting conditions and viewpoints can be captured and introduced in the simulation by moving the instruments and camera and modulating the light source. Background data is captured by collecting videos that do not contain instruments. In the absence of pre-existing instrument-free background videos, minimal labeling effort is required, just to select frames that do not contain surgical instruments from videos of surgical interventions freely available online. We compare different methods to blend instruments over tissue and propose a novel data augmentation approach that takes advantage of the plurality of options. We show that by training a vanilla U-Net on semi-synthetic data only and applying a simple post-processing, we are able to match the results of the same network trained on a publicly available manually labeled real dataset.",0
"The process of creating segmentation labels for images that are precise and manual is time-consuming and tiresome. This can pose a challenge when large quantities of labeled images are needed, particularly for training deep convolutional networks that can perform instrument-background segmentation in surgical scenes. Unfortunately, there are no significant datasets available for this task that match industry standards in the computer vision community. To overcome this obstacle, we suggest automating the creation of a realistic training dataset using techniques that are typically used for special effects but are geared towards optimizing training performance rather than visual appeal. We capture foreground data by placing surgical instruments on a controlled chroma key (also known as a green screen), making the extraction of the relevant image segment easy. We can also capture and simulate multiple lighting conditions and viewpoints by moving the instruments and camera while modulating the light source. Additionally, we collect videos that do not contain instruments to serve as background data. If there are no pre-existing instrument-free background videos, we only need to select frames that do not feature surgical instruments from freely available videos of surgical interventions and label them minimally. We compare different techniques for blending instruments over tissue and propose a novel data augmentation approach that takes advantage of the multitude of options available. We demonstrate that by training a vanilla U-Net solely on semi-synthetic data and applying a simple post-processing technique, we can achieve results that match those obtained from training the same network on a publicly available manually labeled real dataset.",1
"The success of modern deep learning algorithms for image segmentation heavily depends on the availability of large datasets with clean pixel-level annotations (masks), where the objects of interest are accurately delineated. Lack of time and expertise during data annotation leads to incorrect boundaries and label noise. It is known that deep convolutional neural networks (DCNNs) can memorize even completely random labels, resulting in poor accuracy. We propose a framework to train binary segmentation DCNNs using sets of unreliable pixel-level annotations. Erroneously labeled pixels are identified based on the estimated aleatoric uncertainty of the segmentation and are relabeled to the true value.",0
"The efficacy of contemporary deep learning algorithms for image segmentation is largely reliant on the existence of extensive datasets containing precise pixel-level annotations or masks, which accurately identify the objects of interest. However, a lack of time and expertise during the annotation process can lead to incorrect labeling and boundary issues. It is a known fact that deep convolutional neural networks (DCNNs) can remember even random labels, which can result in poor accuracy. To address this issue, we propose a framework that trains binary segmentation DCNNs using unreliable pixel-level annotations. We identify mislabeled pixels based on the estimated aleatoric uncertainty of the segmentation, and re-label them to their accurate value.",1
"Advances in image-based dietary assessment methods have allowed nutrition professionals and researchers to improve the accuracy of dietary assessment, where images of food consumed are captured using smartphones or wearable devices. These images are then analyzed using computer vision methods to estimate energy and nutrition content of the foods. Food image segmentation, which determines the regions in an image where foods are located, plays an important role in this process. Current methods are data dependent, thus cannot generalize well for different food types. To address this problem, we propose a class-agnostic food image segmentation method. Our method uses a pair of eating scene images, one before start eating and one after eating is completed. Using information from both the before and after eating images, we can segment food images by finding the salient missing objects without any prior information about the food class. We model a paradigm of top down saliency which guides the attention of the human visual system (HVS) based on a task to find the salient missing objects in a pair of images. Our method is validated on food images collected from a dietary study which showed promising results.",0
"The accuracy of dietary assessments has been improved by advancements in image-based methods, which involve capturing pictures of food consumed using smartphones or wearable devices and analyzing them with computer vision techniques to estimate energy and nutrition content. Food image segmentation, determining where food is located in the image, is an essential part of this process. However, current methods are dependent on data and cannot be generalized for different food types. To address this issue, a class-agnostic food image segmentation method is proposed, which uses a pair of images taken before and after eating. By finding the salient missing objects in both images, food images can be segmented without prior knowledge of the food class. The method is based on a top-down saliency paradigm that guides the human visual system's attention to locate the missing objects. The method has been tested on food images collected from a dietary study, and the results are promising.",1
"Coarse-to-fine models and cascade segmentation architectures are widely adopted to solve the problem of large scale variations in medical image segmentation. However, those methods have two primary limitations: the first-stage segmentation becomes a performance bottleneck; the lack of overall differentiability makes the training process of two stages asynchronous and inconsistent. In this paper, we propose a differentiable two-stage network architecture to tackle these problems. In the first stage, a localization network (L-Net) locates Regions of Interest (RoIs) in a detection fashion; in the second stage, a segmentation network (S-Net) performs fine segmentation on the recalibrated RoIs; a RoI recalibration module between L-Net and S-Net eliminating the inconsistencies. Experimental results on the public dataset show that our method outperforms state-of-the-art coarse-to-fine models with negligible computation overheads.",0
"The issue of large scale variations in medical image segmentation is often addressed through the use of coarse-to-fine models and cascade segmentation architectures. However, these methods are limited by two main factors: the initial segmentation stage can hinder performance, and the lack of overall differentiability leads to asynchronous and inconsistent training. In this study, we propose a two-stage network architecture that is fully differentiable and solves these issues. The first stage uses a localization network (L-Net) to detect Regions of Interest (RoIs), while the second stage employs a segmentation network (S-Net) to perform fine segmentation on recalibrated RoIs. A RoI recalibration module between L-Net and S-Net eliminates inconsistencies. Our method outperforms state-of-the-art coarse-to-fine models with minimal computation overheads, as demonstrated by experimental results on a public dataset.",1
"Deep co-training has recently been proposed as an effective approach for image segmentation when annotated data is scarce. In this paper, we improve existing approaches for semi-supervised segmentation with a self-paced and self-consistent co-training method. To help distillate information from unlabeled images, we first design a self-paced learning strategy for co-training that lets jointly-trained neural networks focus on easier-to-segment regions first, and then gradually consider harder ones.This is achieved via an end-to-end differentiable loss inthe form of a generalized Jensen Shannon Divergence(JSD). Moreover, to encourage predictions from different networks to be both consistent and confident, we enhance this generalized JSD loss with an uncertainty regularizer based on entropy. The robustness of individual models is further improved using a self-ensembling loss that enforces their prediction to be consistent across different training iterations. We demonstrate the potential of our method on three challenging image segmentation problems with different image modalities, using small fraction of labeled data. Results show clear advantages in terms of performance compared to the standard co-training baselines and recently proposed state-of-the-art approaches for semi-supervised segmentation",0
"Recently, there has been a proposal to use deep co-training as an effective method for image segmentation in situations where annotated data is limited. In this study, we have improved upon existing semi-supervised segmentation approaches by developing a self-paced and self-consistent co-training technique. Our approach involves a self-paced learning strategy that allows neural networks to focus on easier-to-segment regions before gradually tackling harder ones, achieved through an end-to-end differentiable loss in the form of a generalized Jensen Shannon Divergence (JSD). To further encourage consistent and confident predictions, we have enhanced this loss with an uncertainty regularizer based on entropy. We have also utilized a self-ensembling loss to improve the robustness of individual models by enforcing consistency across different training iterations. Our method has been tested on three challenging image segmentation problems with different image modalities, using only a small fraction of labeled data. The results demonstrate clear advantages in terms of performance compared to standard co-training baselines and recently proposed state-of-the-art approaches for semi-supervised segmentation.",1
"Medical image segmentation is an essential prerequisite for developing healthcare systems, especially for disease diagnosis and treatment planning. On various medical image segmentation tasks, the u-shaped architecture, also known as U-Net, has become the de-facto standard and achieved tremendous success. However, due to the intrinsic locality of convolution operations, U-Net generally demonstrates limitations in explicitly modeling long-range dependency. Transformers, designed for sequence-to-sequence prediction, have emerged as alternative architectures with innate global self-attention mechanisms, but can result in limited localization abilities due to insufficient low-level details. In this paper, we propose TransUNet, which merits both Transformers and U-Net, as a strong alternative for medical image segmentation. On one hand, the Transformer encodes tokenized image patches from a convolution neural network (CNN) feature map as the input sequence for extracting global contexts. On the other hand, the decoder upsamples the encoded features which are then combined with the high-resolution CNN feature maps to enable precise localization.   We argue that Transformers can serve as strong encoders for medical image segmentation tasks, with the combination of U-Net to enhance finer details by recovering localized spatial information. TransUNet achieves superior performances to various competing methods on different medical applications including multi-organ segmentation and cardiac segmentation. Code and models are available at https://github.com/Beckschen/TransUNet.",0
"Developing healthcare systems requires medical image segmentation, which is crucial for disease diagnosis and treatment planning. U-Net, also known as the u-shaped architecture, has become the standard for various medical image segmentation tasks and has been highly successful. However, U-Net has limitations in modeling long-range dependency due to the locality of convolution operations. Transformers, which possess innate global self-attention mechanisms designed for sequence-to-sequence prediction, have emerged as an alternative architecture. However, Transformers can lack localization abilities because of insufficient low-level details. To address these issues, this paper introduces TransUNet, which combines both Transformers and U-Net. TransUNet utilizes the Transformer to encode tokenized image patches from a convolution neural network (CNN) feature map as the input sequence to extract global contexts. The decoder upsamples the encoded features and combines them with the high-resolution CNN feature maps to enable precise localization. TransUNet achieves superior performances on multi-organ segmentation and cardiac segmentation compared to various competing methods. Code and models are available at https://github.com/Beckschen/TransUNet.",1
"Segmentation and analysis of individual pores and grains of mudrocks from scanning electron microscope images is non-trivial because of noise, imaging artifacts, variation in pixel grayscale values across images, and overlaps in grayscale values among different physical features such as silt grains, clay grains, and pores in an image, which make their identification difficult. Moreover, because grains and pores often have overlapping grayscale values, direct application of threshold-based segmentation techniques is not sufficient. Recent advances in the field of computer vision have made it easier and faster to segment images and identify multiple occurrences of such features in an image, provided that ground-truth data for training the algorithm is available. Here, we propose a deep learning SEM image segmentation model, MudrockNet based on Google's DeepLab-v3+ architecture implemented with the TensorFlow library. The ground-truth data was obtained from an image-processing workflow applied to scanning electron microscope images of uncemented muds from the Kumano Basin offshore Japan at depths < 1.1 km. The trained deep learning model obtained a pixel-accuracy about 90%, and predictions for the test data obtained a mean intersection over union (IoU) of 0.6591 for silt grains and 0.6642 for pores. We also compared our model with the random forest classifier using trainable Weka segmentation in ImageJ, and it was observed that MudrockNet gave better predictions for both silt grains and pores. The size, concentration, and spatial arrangement of the silt and clay grains can affect the petrophysical properties of a mudrock, and an automated method to accurately identify the different grains and pores in mudrocks can help improve reservoir and seal characterization for petroleum exploration and anthropogenic waste sequestration.",0
"The identification and analysis of individual pores and grains in mudrocks from scanning electron microscope images is a complex task due to various challenges. These include imaging artifacts, noise, variability in pixel grayscale values, and overlaps in grayscale values among different physical features. Direct application of threshold-based segmentation techniques is not sufficient as grains and pores often have overlapping grayscale values. Recent advances in computer vision have made it easier to segment images and identify multiple occurrences of features in an image, provided that ground-truth data is available for training the algorithm. We propose a deep learning model, MudrockNet, based on Google's DeepLab-v3+ architecture and implemented with the TensorFlow library. The ground-truth data was obtained from an image-processing workflow applied to scanning electron microscope images of uncemented muds from the Kumano Basin offshore Japan. The trained model achieved a pixel accuracy of about 90%, and predictions for the test data had a mean intersection over union of 0.6591 for silt grains and 0.6642 for pores. MudrockNet outperformed the random forest classifier using trainable Weka segmentation in ImageJ. An automated method to accurately identify different grains and pores in mudrocks can help improve reservoir and seal characterization for petroleum exploration and anthropogenic waste sequestration.",1
"Supervised deep learning performance is heavily tied to the availability of high-quality labels for training. Neural networks can gradually overfit corrupted labels if directly trained on noisy datasets, leading to severe performance degradation at test time. In this paper, we propose a novel deep learning framework, namely Co-Seg, to collaboratively train segmentation networks on datasets which include low-quality noisy labels. Our approach first trains two networks simultaneously to sift through all samples and obtain a subset with reliable labels. Then, an efficient yet easily-implemented label correction strategy is applied to enrich the reliable subset. Finally, using the updated dataset, we retrain the segmentation network to finalize its parameters. Experiments in two noisy labels scenarios demonstrate that our proposed model can achieve results comparable to those obtained from supervised learning trained on the noise-free labels. In addition, our framework can be easily implemented in any segmentation algorithm to increase its robustness to noisy labels.",0
"The success of supervised deep learning depends heavily on the availability of high-quality labels during training. If neural networks are trained directly on noisy datasets, they can gradually overfit corrupted labels, which can lead to significant performance degradation during testing. This paper introduces a new deep learning framework called Co-Seg, which can collaboratively train segmentation networks on datasets that contain low-quality, noisy labels. Our approach involves training two networks simultaneously to identify samples with reliable labels, followed by an efficient label correction strategy to enhance the reliable subset. Finally, we retrain the segmentation network using the updated dataset to finalize its parameters. Our experiments demonstrate that Co-Seg can achieve results similar to those obtained from supervised learning trained on noise-free labels in two noisy label scenarios. Furthermore, our framework can be easily implemented in any segmentation algorithm to enhance its robustness to noisy labels.",1
"We apply generative adversarial convolutional neural networks to the problem of style transfer to underdrawings and ghost-images in x-rays of fine art paintings with a special focus on enhancing their spatial resolution. We build upon a neural architecture developed for the related problem of synthesizing high-resolution photo-realistic image from semantic label maps. Our neural architecture achieves high resolution through a hierarchy of generators and discriminator sub-networks, working throughout a range of spatial resolutions. This coarse-to-fine generator architecture can increase the effective resolution by a factor of eight in each spatial direction, or an overall increase in number of pixels by a factor of 64. We also show that even just a few examples of human-generated image segmentations can greatly improve -- qualitatively and quantitatively -- the generated images. We demonstrate our method on works such as Leonardo's Madonna of the carnation and the underdrawing in his Virgin of the rocks, which pose several special problems in style transfer, including the paucity of representative works from which to learn and transfer style information.",0
"Our focus is on using generative adversarial convolutional neural networks to improve the spatial resolution of underdrawings and ghost-images in x-rays of fine art paintings through style transfer. Our approach is based on a neural architecture that was originally developed for synthesizing high-resolution photo-realistic images from semantic label maps. We achieve high resolution by using a hierarchy of generators and discriminator sub-networks that work across various spatial resolutions. This generator architecture increases effective resolution by a factor of eight in each spatial direction, resulting in an overall increase in the number of pixels by a factor of 64. We also demonstrate that using even a small number of human-generated image segmentations can significantly improve the quality of the generated images. Our method is applied to works such as Leonardo's Madonna of the Carnation and the underdrawing in his Virgin of the Rocks, which present unique challenges in style transfer due to limited available style information.",1
"Fluorescence microscopy images contain several channels, each indicating a marker staining the sample. Since many different marker combinations are utilized in practice, it has been challenging to apply deep learning based segmentation models, which expect a predefined channel combination for all training samples as well as at inference for future application. Recent work circumvents this problem using a modality attention approach to be effective across any possible marker combination. However, for combinations that do not exist in a labeled training dataset, one cannot have any estimation of potential segmentation quality if that combination is encountered during inference. Without this, not only one lacks quality assurance but one also does not know where to put any additional imaging and labeling effort. We herein propose a method to estimate segmentation quality on unlabeled images by (i) estimating both aleatoric and epistemic uncertainties of convolutional neural networks for image segmentation, and (ii) training a Random Forest model for the interpretation of uncertainty features via regression to their corresponding segmentation metrics. Additionally, we demonstrate that including these uncertainty measures during training can provide an improvement on segmentation performance.",0
"Fluorescence microscopy images are comprised of various channels that represent different markers used to stain the sample. This poses a challenge for deep learning-based segmentation models, as they require a predefined channel combination for all training samples and future applications. To tackle this issue, a modality attention approach has been implemented, enabling the models to be effective across any marker combination. However, this approach falls short when encountering a marker combination not seen in the labeled training dataset, as there is no estimation of potential segmentation quality, leading to a lack of quality assurance and uncertainty regarding additional imaging and labeling efforts. We propose a method to estimate segmentation quality on unlabeled images by (i) estimating the aleatoric and epistemic uncertainties of convolutional neural networks for image segmentation and (ii) training a Random Forest model to interpret uncertainty features through regression to their corresponding segmentation metrics. Furthermore, we show that including these uncertainty measures during training can enhance segmentation performance.",1
"Semantic segmentation using convolutional neural networks (CNN) is a crucial component in image analysis. Training a CNN to perform semantic segmentation requires a large amount of labeled data, where the production of such labeled data is both costly and labor intensive. Semi-supervised learning algorithms address this issue by utilizing unlabeled data and so reduce the amount of labeled data needed for training. In particular, data augmentation techniques such as CutMix and ClassMix generate additional training data from existing labeled data. In this paper we propose a new approach for data augmentation, termed ComplexMix, which incorporates aspects of CutMix and ClassMix with improved performance. The proposed approach has the ability to control the complexity of the augmented data while attempting to be semantically-correct and address the tradeoff between complexity and correctness. The proposed ComplexMix approach is evaluated on a standard dataset for semantic segmentation and compared to other state-of-the-art techniques. Experimental results show that our method yields improvement over state-of-the-art methods on standard datasets for semantic image segmentation.",0
"Convolutional neural networks (CNN) are a crucial element in analyzing images through semantic segmentation. However, training a CNN to perform semantic segmentation requires a large amount of labeled data, which is both costly and labor-intensive to produce. To address this issue, semi-supervised learning algorithms make use of unlabeled data, reducing the amount of labeled data needed for training. Data augmentation techniques, such as CutMix and ClassMix, generate additional training data from existing labeled data. This paper introduces a new approach to data augmentation called ComplexMix, which combines aspects of CutMix and ClassMix to improve performance. The proposed method can control the complexity of the augmented data while maintaining semantic correctness and addressing the tradeoff between complexity and correctness. The effectiveness of the ComplexMix approach is evaluated on a standard dataset for semantic segmentation and compared to other state-of-the-art techniques. The experimental results demonstrate that our method outperforms state-of-the-art methods on standard datasets for semantic image segmentation.",1
"Conventional transfer learning leverages weights of pre-trained networks, but mandates the need for similar neural architectures. Alternatively, knowledge distillation can transfer knowledge between heterogeneous networks but often requires access to the original training data or additional generative networks. Knowledge transfer between networks can be improved by being agnostic to the choice of network architecture and reducing the dependence on original training data. We propose a knowledge transfer approach from a teacher to a student network wherein we train the student on an independent transferal dataset, whose annotations are generated by the teacher. Experiments were conducted on five state-of-the-art networks for semantic segmentation and seven datasets across three imaging modalities. We studied knowledge transfer from a single teacher, combination of knowledge transfer and fine-tuning, and knowledge transfer from multiple teachers. The student model with a single teacher achieved similar performance as the teacher; and the student model with multiple teachers achieved better performance than the teachers. The salient features of our algorithm include: 1)no need for original training data or generative networks, 2) knowledge transfer between different architectures, 3) ease of implementation for downstream tasks by using the downstream task dataset as the transferal dataset, 4) knowledge transfer of an ensemble of models, trained independently, into one student model. Extensive experiments demonstrate that the proposed algorithm is effective for knowledge transfer and easily tunable.",0
"The conventional method of transfer learning utilizes pre-trained network weights, but requires similar neural architectures. On the other hand, knowledge distillation can transfer knowledge between different networks, but often necessitates access to the original training data or additional generative networks. To enhance knowledge transfer between networks, it is essential to be independent of the choice of network architecture and reduce reliance on original training data. In this study, we introduce a knowledge transfer technique from a teacher to a student network by training the student on a separate transferal dataset, whose annotations are generated by the teacher. We conducted experiments on seven datasets across three imaging modalities using five state-of-the-art networks for semantic segmentation. We examined knowledge transfer from a single teacher, a combination of knowledge transfer and fine-tuning, and knowledge transfer from multiple teachers. The student model with a single teacher performed similarly to the teacher, while the student model with multiple teachers outperformed the teachers. Our algorithm has several significant features, including not requiring original training data or generative networks, knowledge transfer between different architectures, ease of implementation for downstream tasks using the downstream task dataset as the transferal dataset, and knowledge transfer of an ensemble of models trained independently into one student model. Extensive experiments validate the effectiveness and ease of tuning of our proposed algorithm for knowledge transfer.",1
"Image segmentation is one of the most essential biomedical image processing problems for different imaging modalities, including microscopy and X-ray in the Internet-of-Medical-Things (IoMT) domain. However, annotating biomedical images is knowledge-driven, time-consuming, and labor-intensive, making it difficult to obtain abundant labels with limited costs. Active learning strategies come into ease the burden of human annotation, which queries only a subset of training data for annotation. Despite receiving attention, most of active learning methods generally still require huge computational costs and utilize unlabeled data inefficiently. They also tend to ignore the intermediate knowledge within networks. In this work, we propose a deep active semi-supervised learning framework, DSAL, combining active learning and semi-supervised learning strategies. In DSAL, a new criterion based on deep supervision mechanism is proposed to select informative samples with high uncertainties and low uncertainties for strong labelers and weak labelers respectively. The internal criterion leverages the disagreement of intermediate features within the deep learning network for active sample selection, which subsequently reduces the computational costs. We use the proposed criteria to select samples for strong and weak labelers to produce oracle labels and pseudo labels simultaneously at each active learning iteration in an ensemble learning manner, which can be examined with IoMT Platform. Extensive experiments on multiple medical image datasets demonstrate the superiority of the proposed method over state-of-the-art active learning methods.",0
"Biomedical image processing is crucial for various imaging modalities in the IoMT field, but annotating these images is difficult and time-consuming. Active learning strategies have been developed to reduce the burden of human annotation, but they are often computationally expensive and inefficient in utilizing unlabeled data. The proposed DSAL framework combines active and semi-supervised learning methods to select informative samples with high uncertainties and low uncertainties for strong and weak labelers, respectively. The framework leverages the disagreement of intermediate features within the deep learning network to reduce computational costs and produce oracle and pseudo labels simultaneously. The proposed method outperforms state-of-the-art active learning methods on multiple medical image datasets.",1
"As a natural way for human-computer interaction, fixation provides a promising solution for interactive image segmentation. In this paper, we focus on Personal Fixations-based Object Segmentation (PFOS) to address issues in previous studies, such as the lack of appropriate dataset and the ambiguity in fixations-based interaction. In particular, we first construct a new PFOS dataset by carefully collecting pixel-level binary annotation data over an existing fixation prediction dataset, such dataset is expected to greatly facilitate the study along the line. Then, considering characteristics of personal fixations, we propose a novel network based on Object Localization and Boundary Preservation (OLBP) to segment the gazed objects. Specifically, the OLBP network utilizes an Object Localization Module (OLM) to analyze personal fixations and locates the gazed objects based on the interpretation. Then, a Boundary Preservation Module (BPM) is designed to introduce additional boundary information to guard the completeness of the gazed objects. Moreover, OLBP is organized in the mixed bottom-up and top-down manner with multiple types of deep supervision. Extensive experiments on the constructed PFOS dataset show the superiority of the proposed OLBP network over 17 state-of-the-art methods, and demonstrate the effectiveness of the proposed OLM and BPM components. The constructed PFOS dataset and the proposed OLBP network are available at https://github.com/MathLee/OLBPNet4PFOS.",0
Fixation is a natural way for humans to interact with computers and shows promise for interactive image segmentation. This study focuses on Personal Fixations-based Object Segmentation (PFOS) and addresses previous issues related to the lack of appropriate datasets and ambiguity in fixations-based interaction. The authors constructed a new PFOS dataset by collecting pixel-level binary annotation data over an existing fixation prediction dataset. The dataset is expected to facilitate future studies in this area. The authors propose a novel network called Object Localization and Boundary Preservation (OLBP) that considers personal fixations' characteristics to segment gazed objects. OLBP utilizes an Object Localization Module (OLM) to analyze personal fixations and locate the gazed objects based on interpretation. A Boundary Preservation Module (BPM) is designed to introduce additional boundary information to ensure the completeness of the gazed objects. OLBP is organized in a mixed bottom-up and top-down manner with multiple types of deep supervision. The authors conducted extensive experiments on the constructed PFOS dataset and showed the superiority of the proposed OLBP network over 17 state-of-the-art methods. The effectiveness of the proposed OLM and BPM components was also demonstrated. The constructed PFOS dataset and proposed OLBP network are available at https://github.com/MathLee/OLBPNet4PFOS.,1
"Finger vein recognition has drawn increasing attention as one of the most popular and promising biometrics due to its high distinguishes ability, security and non-invasive procedure. The main idea of traditional schemes is to directly extract features from finger vein images or patterns and then compare features to find the best match. However, the features extracted from images contain much redundant data, while the features extracted from patterns are greatly influenced by image segmentation methods. To tack these problems, this paper proposes a new finger vein recognition by generating code. The proposed method does not require an image segmentation algorithm, is simple to calculate and has a small amount of data. Firstly, the finger vein images were divided into blocks to calculate the mean value. Then the centrosymmetric coding is performed by using the generated eigenmatrix. The obtained codewords are concatenated as the feature codewords of the image. The similarity between vein codes is measured by the ratio of minimum Hamming distance to codeword length. Extensive experiments on two public finger vein databases verify the effectiveness of the proposed method. The results indicate that our method outperforms the state-of-theart methods and has competitive potential in performing the matching task.",0
"Finger vein recognition is becoming increasingly popular as a biometric due to its high level of accuracy, security, and non-invasive nature. Traditional methods involve extracting features directly from finger vein images or patterns and comparing them to find a match. However, this approach often results in redundant data and is influenced by image segmentation techniques. To address these issues, a new finger vein recognition method is proposed in this paper. It involves generating a code without the need for image segmentation, making it simple to calculate and requiring minimal data. The method involves dividing finger vein images into blocks to calculate the mean value, performing centrosymmetric coding using the generated eigenmatrix, and concatenating the obtained codewords as feature codewords. The similarity between vein codes is measured by the ratio of minimum Hamming distance to codeword length. Experiments on two public finger vein databases confirm the effectiveness of the proposed method, which outperforms state-of-the-art methods and has significant potential in matching tasks.",1
"Image segmentation aims at identifying regions of interest within an image, by grouping pixels according to their properties. This task resembles the statistical one of clustering, yet many standard clustering methods fail to meet the basic requirements of image segmentation: segment shapes are often biased toward predetermined shapes and their number is rarely determined automatically. Nonparametric clustering is, in principle, free from these limitations and turns out to be particularly suitable for the task of image segmentation. This is also witnessed by several operational analogies, as, for instance, the resort to topological data analysis and spatial tessellation in both the frameworks. We discuss the application of nonparametric clustering to image segmentation and provide an algorithm specific for this task. Pixel similarity is evaluated in terms of density of the color representation and the adjacency structure of the pixels is exploited to introduce a simple, yet effective method to identify image segments as disconnected high-density regions. The proposed method works both to segment an image and to detect its boundaries and can be seen as a generalization to color images of the class of thresholding methods.",0
"The goal of image segmentation is to detect areas of interest within an image by grouping pixels based on their attributes. Although similar to statistical clustering, standard clustering methods are often inadequate for image segmentation as they favor predetermined shapes and do not automatically determine the number of segments. Nonparametric clustering is a better fit for image segmentation as it is not limited by these constraints. There are operational similarities between the two frameworks, such as the use of topological data analysis and spatial tessellation. We present an algorithm specific to nonparametric clustering for image segmentation. The method utilizes pixel color density for similarity evaluation and the adjacency structure of the pixels to identify high-density, disconnected segments. The proposed method is effective for both segmenting an image and detecting its boundaries and can be considered a generalization of thresholding methods for color images.",1
"Deep Neural Networks (DNNs) are widely used for decision making in a myriad of critical applications, ranging from medical to societal and even judicial. Given the importance of these decisions, it is crucial for us to be able to interpret these models. We introduce a new method for interpreting image segmentation models by learning regions of images in which noise can be applied without hindering downstream model performance. We apply this method to segmentation of the pancreas in CT scans, and qualitatively compare the quality of the method to existing explainability techniques, such as Grad-CAM and occlusion sensitivity. Additionally we show that, unlike other methods, our interpretability model can be quantitatively evaluated based on the downstream performance over obscured images.",0
"Decision making in critical applications, including medical, societal, and judicial, commonly relies on Deep Neural Networks (DNNs). It is crucial to interpret these models due to the significance of their decisions. A new approach is proposed to interpret image segmentation models by identifying regions of images where noise can be added without affecting downstream model performance. The effectiveness of this method is evaluated through segmentation of the pancreas in CT scans and compared to existing techniques like Grad-CAM and occlusion sensitivity. Furthermore, our interpretability model can be quantitatively assessed based on downstream performance on obscured images, unlike other methods.",1
"Image Segmentation plays an essential role in computer vision and image processing with various applications from medical diagnosis to autonomous car driving. A lot of segmentation algorithms have been proposed for addressing specific problems. In recent years, the success of deep learning techniques has tremendously influenced a wide range of computer vision areas, and the modern approaches of image segmentation based on deep learning are becoming prevalent. In this article, we introduce a high-efficient development toolkit for image segmentation, named PaddleSeg. The toolkit aims to help both developers and researchers in the whole process of designing segmentation models, training models, optimizing performance and inference speed, and deploying models. Currently, PaddleSeg supports around 20 popular segmentation models and more than 50 pre-trained models from real-time and high-accuracy levels. With modular components and backbone networks, users can easily build over one hundred models for different requirements. Furthermore, we provide comprehensive benchmarks and evaluations to show that these segmentation algorithms trained on our toolkit have more competitive accuracy. Also, we provide various real industrial applications and practical cases based on PaddleSeg. All codes and examples of PaddleSeg are available at https://github.com/PaddlePaddle/PaddleSeg.",0
"Computer vision and image processing rely heavily on Image Segmentation, which has numerous applications ranging from medical diagnosis to autonomous car driving. Several segmentation algorithms have been suggested to address specific problems, but the advent of deep learning techniques has led to the emergence of modern approaches based on deep learning that are gaining more ground. This article introduces a high-efficient development toolkit, PaddleSeg, for image segmentation. The toolkit is designed to enable developers and researchers to design segmentation models, train, optimize, and deploy them easily. PaddleSeg supports nearly 20 popular segmentation models and over 50 pre-trained models with real-time and high-accuracy levels. Its modular components and backbone networks make it possible to create over one hundred models to meet various requirements. Comprehensive benchmarks and evaluations demonstrate the competitive accuracy of segmentation algorithms trained with PaddleSeg. Various real industrial applications and practical cases based on PaddleSeg are also available. All codes and examples of PaddleSeg can be found at https://github.com/PaddlePaddle/PaddleSeg.",1
"This paper proposes an affinity fusion graph framework to effectively connect different graphs with highly discriminating power and nonlinearity for natural image segmentation. The proposed framework combines adjacency-graphs and kernel spectral clustering based graphs (KSC-graphs) according to a new definition named affinity nodes of multi-scale superpixels. These affinity nodes are selected based on a better affiliation of superpixels, namely subspace-preserving representation which is generated by sparse subspace clustering based on subspace pursuit. Then a KSC-graph is built via a novel kernel spectral clustering to explore the nonlinear relationships among these affinity nodes. Moreover, an adjacency-graph at each scale is constructed, which is further used to update the proposed KSC-graph at affinity nodes. The fusion graph is built across different scales, and it is partitioned to obtain final segmentation result. Experimental results on the Berkeley segmentation dataset and Microsoft Research Cambridge dataset show the superiority of our framework in comparison with the state-of-the-art methods. The code is available at https://github.com/Yangzhangcst/AF-graph.",0
"In this paper, a novel framework called the affinity fusion graph is proposed to enhance the natural image segmentation process. The framework combines adjacency-graphs with kernel spectral clustering based graphs (KSC-graphs) by introducing a new concept known as affinity nodes of multi-scale superpixels. These nodes are selected based on a better affiliation of superpixels, which is generated through sparse subspace clustering based on subspace pursuit. The KSC-graph is built using a kernel spectral clustering approach to identify the nonlinear relationships among these affinity nodes. Additionally, an adjacency-graph is constructed at each scale to update the proposed KSC-graph at affinity nodes. Finally, the fusion graph is built across different scales, and the partitioned result is obtained for the final segmentation. Experimental results on the Berkeley segmentation dataset and Microsoft Research Cambridge dataset demonstrate the superiority of this framework over the existing methods. The code for the proposed framework is available at https://github.com/Yangzhangcst/AF-graph.",1
"Despite the progress of interactive image segmentation methods, high-quality pixel-level annotation is still time-consuming and laborious -- a bottleneck for several deep learning applications. We take a step back to propose interactive and simultaneous segment annotation from multiple images guided by feature space projection and optimized by metric learning as the labeling progresses. This strategy is in stark contrast to existing interactive segmentation methodologies, which perform annotation in the image domain. We show that our approach can surpass the accuracy of state-of-the-art methods in foreground segmentation datasets: iCoSeg, DAVIS, and Rooftop. Moreover, it achieves 91.5\% accuracy in a known semantic segmentation dataset, Cityscapes, being 74.75 times faster than the original annotation procedure. The appendix presents additional qualitative results. Code and video demonstration will be released upon publication.",0
"Although interactive image segmentation methods have progressed, the process of high-quality pixel-level annotation remains arduous and time-consuming, which has become a bottleneck for deep learning applications. Our approach proposes interactive and simultaneous segment annotation from multiple images guided by feature space projection and optimized by metric learning to streamline the labeling process. This differs from existing interactive segmentation methodologies that conduct annotation in the image domain. Our results demonstrate that our approach outperforms state-of-the-art methods in foreground segmentation datasets, including iCoSeg, DAVIS, and Rooftop. In addition, it achieves 91.5\% accuracy in the Cityscapes known semantic segmentation dataset while being 74.75 times faster than the original annotation procedure. The appendix provides further qualitative results, and we will release the code and video demonstration upon publication.",1
"We address the problem of semantic nighttime image segmentation and improve the state-of-the-art, by adapting daytime models to nighttime without using nighttime annotations. Moreover, we design a new evaluation framework to address the substantial uncertainty of semantics in nighttime images. Our central contributions are: 1) a curriculum framework to gradually adapt semantic segmentation models from day to night through progressively darker times of day, exploiting cross-time-of-day correspondences between daytime images from a reference map and dark images to guide the label inference in the dark domains; 2) a novel uncertainty-aware annotation and evaluation framework and metric for semantic segmentation, including image regions beyond human recognition capability in the evaluation in a principled fashion; 3) the Dark Zurich dataset, comprising 2416 unlabeled nighttime and 2920 unlabeled twilight images with correspondences to their daytime counterparts plus a set of 201 nighttime images with fine pixel-level annotations created with our protocol, which serves as a first benchmark for our novel evaluation. Experiments show that our map-guided curriculum adaptation significantly outperforms state-of-the-art methods on nighttime sets both for standard metrics and our uncertainty-aware metric. Furthermore, our uncertainty-aware evaluation reveals that selective invalidation of predictions can improve results on data with ambiguous content such as our benchmark and profit safety-oriented applications involving invalid inputs.",0
"Our focus is on improving semantic nighttime image segmentation without using nighttime annotations. We achieve this by adapting daytime models to nighttime and introducing a new evaluation framework that takes into account the uncertainty of semantics in nighttime images. Our contributions include: 1) a curriculum framework that gradually adapts semantic segmentation models from day to night, using cross-time-of-day correspondences between daytime images from a reference map and dark images to guide the label inference; 2) an uncertainty-aware annotation and evaluation framework and metric that includes image regions beyond human recognition capability in the evaluation; and 3) the Dark Zurich dataset, comprising unlabeled nighttime and twilight images with correspondences to their daytime counterparts, and a set of nighttime images with fine pixel-level annotations. Our experiments show that our curriculum adaptation outperforms state-of-the-art methods for both standard metrics and our uncertainty-aware metric. Additionally, our uncertainty-aware evaluation reveals that selective invalidation of predictions can improve results on data with ambiguous content, benefiting safety-oriented applications.",1
"Boundary information plays a significant role in 2D image segmentation, while usually being ignored in 3D point cloud segmentation where ambiguous features might be generated in feature extraction, leading to misclassification in the transition area between two objects. In this paper, firstly, we propose a Boundary Prediction Module (BPM) to predict boundary points. Based on the predicted boundary, a boundary-aware Geometric Encoding Module (GEM) is designed to encode geometric information and aggregate features with discrimination in a neighborhood, so that the local features belonging to different categories will not be polluted by each other. To provide extra geometric information for boundary-aware GEM, we also propose a light-weight Geometric Convolution Operation (GCO), making the extracted features more distinguishing. Built upon the boundary-aware GEM, we build our network and test it on benchmarks like ScanNet v2, S3DIS. Results show our methods can significantly improve the baseline and achieve state-of-the-art performance. Code is available at https://github.com/JchenXu/BoundaryAwareGEM.",0
"The role of boundary information differs in 2D image segmentation and 3D point cloud segmentation. In the latter, ignoring boundary information can result in ambiguous features during feature extraction, which can lead to misclassification between two objects. This paper introduces the Boundary Prediction Module (BPM) to predict boundary points and the boundary-aware Geometric Encoding Module (GEM) to encode geometric information and aggregate features. The GEM ensures that local features belonging to different categories do not interfere with each other. Additionally, a Geometric Convolution Operation (GCO) is proposed to provide extra geometric information for the GEM. The network is evaluated on benchmarks like ScanNet v2 and S3DIS, and the results show a significant improvement over the baseline and achieve state-of-the-art performance. The code for this method is available at https://github.com/JchenXu/BoundaryAwareGEM.",1
"Active learning is a unique abstraction of machine learning techniques where the model/algorithm could guide users for annotation of a set of data points that would be beneficial to the model, unlike passive machine learning. The primary advantage being that active learning frameworks select data points that can accelerate the learning process of a model and can reduce the amount of data needed to achieve full accuracy as compared to a model trained on a randomly acquired data set. Multiple frameworks for active learning combined with deep learning have been proposed, and the majority of them are dedicated to classification tasks. Herein, we explore active learning for the task of segmentation of medical imaging data sets. We investigate our proposed framework using two datasets: 1.) MRI scans of the hippocampus, 2.) CT scans of pancreas and tumors. This work presents a query-by-committee approach for active learning where a joint optimizer is used for the committee. At the same time, we propose three new strategies for active learning: 1.) increasing frequency of uncertain data to bias the training data set; 2.) Using mutual information among the input images as a regularizer for acquisition to ensure diversity in the training dataset; 3.) adaptation of Dice log-likelihood for Stein variational gradient descent (SVGD). The results indicate an improvement in terms of data reduction by achieving full accuracy while only using 22.69 % and 48.85 % of the available data for each dataset, respectively.",0
"Active learning is a distinct form of machine learning that involves models or algorithms guiding users in annotating data points that can benefit the model. This approach differs from passive machine learning and has the primary advantage of selecting data points that can expedite the learning process while reducing the amount of data required to achieve full accuracy, compared to a model trained on randomly obtained data. Many active learning frameworks have been proposed, mainly for classification tasks. In this study, we explore active learning for medical imaging data set segmentation, using MRI scans of the hippocampus and CT scans of pancreas and tumors. We introduce a query-by-committee approach for active learning, using a joint optimizer for the committee, alongside three new strategies: increasing the frequency of uncertain data to bias the training data set, using mutual information among input images as a regularizer for acquisition to ensure diversity in the training dataset, and adapting Dice log-likelihood for Stein variational gradient descent (SVGD). Our findings show that this approach can achieve full accuracy while using only 22.69% and 48.85% of the available data for each dataset, respectively, indicating a significant reduction in the amount of data required.",1
"Multi-modal medical image segmentation plays an essential role in clinical diagnosis. It remains challenging as the input modalities are often not well-aligned spatially. Existing learning-based methods mainly consider sharing trainable layers across modalities and minimizing visual feature discrepancies. While the problem is often formulated as joint supervised feature learning, multiple-scale features and class-specific representation have not yet been explored. In this paper, we propose an affinity-guided fully convolutional network for multimodal image segmentation. To learn effective representations, we design class-specific affinity matrices to encode the knowledge of hierarchical feature reasoning, together with the shared convolutional layers to ensure the cross-modality generalization. Our affinity matrix does not depend on spatial alignments of the visual features and thus allows us to train with unpaired, multimodal inputs. We extensively evaluated our method on two public multimodal benchmark datasets and outperform state-of-the-art methods.",0
"Clinical diagnosis heavily relies on multi-modal medical image segmentation. However, it is a challenging task due to the lack of spatial alignment between input modalities. Current learning-based methods focus on sharing trainable layers and minimizing visual feature discrepancies. Although the problem is approached through joint supervised feature learning, class-specific representation and multiple-scale features have not been explored. This study proposes a fully convolutional network guided by affinity for multimodal image segmentation. To achieve effective representations, class-specific affinity matrices are designed to encode hierarchical feature reasoning. This is combined with shared convolutional layers to ensure cross-modality generalization. The proposed affinity matrix does not require spatial alignment of visual features, allowing training with unpaired, multimodal inputs. The method was evaluated on two public multimodal benchmark datasets, and it outperformed state-of-the-art methods.",1
"We present a fully convolutional neural network (ConvNet), named RatLesNetv2, for segmenting lesions in rodent magnetic resonance (MR) brain images. RatLesNetv2 architecture resembles an autoencoder and it incorporates residual blocks that facilitate its optimization. RatLesNetv2 is trained end to end on three-dimensional images and it requires no preprocessing. We evaluated RatLesNetv2 on an exceptionally large dataset composed of 916 T2-weighted rat brain MRI scans of 671 rats at nine different lesion stages that were used to study focal cerebral ischemia for drug development. In addition, we compared its performance with three other ConvNets specifically designed for medical image segmentation. RatLesNetv2 obtained similar to higher Dice coefficient values than the other ConvNets and it produced much more realistic and compact segmentations with notably fewer holes and lower Hausdorff distance. The Dice scores of RatLesNetv2 segmentations also exceeded inter-rater agreement of manual segmentations. In conclusion, RatLesNetv2 could be used for automated lesion segmentation, reducing human workload and improving reproducibility. RatLesNetv2 is publicly available at https://github.com/jmlipman/RatLesNetv2.",0
"Our study introduces RatLesNetv2, a fully convolutional neural network that can effectively segment lesions in rodent MR brain images. This network is designed with residual blocks to optimize its performance and resembles an autoencoder. Unlike other medical image segmentation ConvNets, RatLesNetv2 does not require preprocessing and is trained end to end on three-dimensional images. We tested RatLesNetv2 on a large dataset containing 916 T2-weighted rat brain MRI scans of 671 rats across nine different lesion stages. The results show that RatLesNetv2 achieves similar to higher Dice coefficient scores than other ConvNets and generates more realistic and compact segmentations with fewer holes and lower Hausdorff distance. Moreover, the Dice scores of RatLesNetv2 segmentations surpass the inter-rater agreement of manual segmentations. Hence, RatLesNetv2 could be used for automated lesion segmentation, reducing human workload, and enhancing reproducibility. The network is publicly available at https://github.com/jmlipman/RatLesNetv2.",1
"Unsupervised domain adaptation (UDA) for cross-modality medical image segmentation has shown great progress by domain-invariant feature learning or image appearance translation. Adapted feature learning usually cannot detect domain shifts at the pixel level and is not able to achieve good results in dense semantic segmentation tasks. Image appearance translation, e.g. CycleGAN, translates images into different styles with good appearance, despite its population, its semantic consistency is hardly to maintain and results in poor cross-modality segmentation. In this paper, we propose intra- and cross-modality semantic consistency (ICMSC) for UDA and our key insight is that the segmentation of synthesised images in different styles should be consistent. Specifically, our model consists of an image translation module and a domain-specific segmentation module. The image translation module is a standard CycleGAN, while the segmentation module contains two domain-specific segmentation networks. The intra-modality semantic consistency (IMSC) forces the reconstructed image after a cycle to be segmented in the same way as the original input image, while the cross-modality semantic consistency (CMSC) encourages the synthesized images after translation to be segmented exactly the same as before translation. Comprehensive experimental results on cross-modality hip joint bone segmentation show the effectiveness of our proposed method, which achieves an average DICE of 81.61% on the acetabulum and 88.16% on the proximal femur, outperforming other state-of-the-art methods. It is worth to note that without UDA, a model trained on CT for hip joint bone segmentation is non-transferable to MRI and has almost zero-DICE segmentation.",0
"The progress of unsupervised domain adaptation (UDA) for cross-modality medical image segmentation has been demonstrated through domain-invariant feature learning or image appearance translation. However, adapted feature learning is unable to detect domain shifts at the pixel level and does not perform well in dense semantic segmentation tasks. While image appearance translation such as CycleGAN can translate images into different styles with good appearance, it struggles to maintain semantic consistency and results in poor cross-modality segmentation. To address these limitations, we propose the use of intra- and cross-modality semantic consistency (ICMSC) for UDA, which emphasizes the importance of consistent segmentation in synthesised images with various styles. Our model includes an image translation module and a domain-specific segmentation module, where the image translation module uses a standard CycleGAN and the segmentation module includes two domain-specific segmentation networks. Our approach utilizes intra-modality semantic consistency (IMSC) to ensure that the reconstructed image after a cycle is segmented in the same way as the original input image, and cross-modality semantic consistency (CMSC) to encourage the synthesized images after translation to be segmented in the same way as before translation. The effectiveness of our proposed method is demonstrated through comprehensive experimental results on cross-modality hip joint bone segmentation, where our model achieves an average DICE of 81.61% on the acetabulum and 88.16% on the proximal femur, outperforming other state-of-the-art methods. It is noteworthy that without UDA, a model trained on CT for hip joint bone segmentation is non-transferable to MRI and produces almost zero-DICE segmentation.",1
"In image segmentation, there is often more than one plausible solution for a given input. In medical imaging, for example, experts will often disagree about the exact location of object boundaries. Estimating this inherent uncertainty and predicting multiple plausible hypotheses is of great interest in many applications, yet this ability is lacking in most current deep learning methods. In this paper, we introduce stochastic segmentation networks (SSNs), an efficient probabilistic method for modelling aleatoric uncertainty with any image segmentation network architecture. In contrast to approaches that produce pixel-wise estimates, SSNs model joint distributions over entire label maps and thus can generate multiple spatially coherent hypotheses for a single image. By using a low-rank multivariate normal distribution over the logit space to model the probability of the label map given the image, we obtain a spatially consistent probability distribution that can be efficiently computed by a neural network without any changes to the underlying architecture. We tested our method on the segmentation of real-world medical data, including lung nodules in 2D CT and brain tumours in 3D multimodal MRI scans. SSNs outperform state-of-the-art for modelling correlated uncertainty in ambiguous images while being much simpler, more flexible, and more efficient.",0
"There are often multiple possible solutions in image segmentation, particularly in medical imaging where experts may disagree on object boundaries. It is important to estimate this uncertainty and predict multiple hypotheses, but most deep learning methods are not capable of doing so. This paper introduces stochastic segmentation networks (SSNs), which are probabilistic models that efficiently handle aleatoric uncertainty with any image segmentation network architecture. Unlike other methods that estimate pixel-wise probabilities, SSNs model joint distributions over entire label maps, allowing for multiple coherent hypotheses to be generated for a single image. By using a low-rank multivariate normal distribution to model the probability of the label map given the image, SSNs produce a spatially consistent probability distribution that can be efficiently computed by a neural network without altering the underlying architecture. The method was tested on real-world medical data, including lung nodules in 2D CT and brain tumors in 3D multimodal MRI scans, and outperformed state-of-the-art approaches for modelling correlated uncertainty in ambiguous images, while being simpler, more flexible, and more efficient.",1
"Superpixel algorithms, which group pixels similar in color and other low-level properties, are increasingly used for pre-processing in image segmentation. Commonly important criteria for the computation of superpixels are boundary adherence, speed, and regularity.   Boundary adherence and regularity are typically contradictory goals. Most recent algorithms have focused on improving boundary adherence. Motivated by improving superpixel regularity, we propose a diagram-based superpixel generation method called Power-SLIC.   On the BSDS500 data set, Power-SLIC outperforms other state-of-the-art algorithms in terms of compactness and boundary precision, and its boundary adherence is the most robust against varying levels of Gaussian noise. In terms of speed, Power-SLIC is competitive with SLIC.",0
"The use of superpixel algorithms for image segmentation pre-processing is on the rise, with these algorithms grouping pixels based on similar low-level properties, such as color. When computing superpixels, important factors to consider include regularity, speed, and boundary adherence. However, achieving both boundary adherence and regularity can be difficult, as they are often contradictory goals. While most recent algorithms have focused on improving boundary adherence, we propose a diagram-based method called Power-SLIC to enhance superpixel regularity. Our method outperforms other state-of-the-art algorithms in terms of compactness and boundary precision on the BSDS500 data set. Additionally, Power-SLIC's boundary adherence is more robust against varying levels of Gaussian noise. Finally, our method is competitive in terms of speed with SLIC.",1
"Nowcasting is a field of meteorology which aims at forecasting weather on a short term of up to a few hours. In the meteorology landscape, this field is rather specific as it requires particular techniques, such as data extrapolation, where conventional meteorology is generally based on physical modeling. In this paper, we focus on cloud cover nowcasting, which has various application areas such as satellite shots optimisation and photovoltaic energy production forecast.   Following recent deep learning successes on multiple imagery tasks, we applied deep convolutionnal neural networks on Meteosat satellite images for cloud cover nowcasting. We present the results of several architectures specialized in image segmentation and time series prediction. We selected the best models according to machine learning metrics as well as meteorological metrics. All selected architectures showed significant improvements over persistence and the well-known U-Net surpasses AROME physical model.",0
"The field of meteorology known as nowcasting involves predicting weather conditions for short periods, typically ranging from a few hours. This area of study is unique within meteorology due to its requirement for specific techniques, like data extrapolation, which contrasts with the physical modeling often used in conventional meteorology. This article concentrates on cloud cover nowcasting, which has a range of applications, including optimizing satellite shots and forecasting photovoltaic energy production. In light of recent successes in deep learning for imagery tasks, we applied deep convolutional neural networks to Meteosat satellite images to predict cloud cover. We evaluated several architectures specialized in image segmentation and time series prediction, selecting the most successful models based on both machine learning and meteorological metrics. All selected models demonstrated a significant improvement over existing methods, with the U-Net architecture surpassing the AROME physical model.",1
"As an important component of autonomous systems, autonomous car perception has had a big leap with recent advances in parallel computing architectures. With the use of tiny but full-feature embedded supercomputers, computer stereo vision has been prevalently applied in autonomous cars for depth perception. The two key aspects of computer stereo vision are speed and accuracy. They are both desirable but conflicting properties, as the algorithms with better disparity accuracy usually have higher computational complexity. Therefore, the main aim of developing a computer stereo vision algorithm for resource-limited hardware is to improve the trade-off between speed and accuracy. In this chapter, we introduce both the hardware and software aspects of computer stereo vision for autonomous car systems. Then, we discuss four autonomous car perception tasks, including 1) visual feature detection, description and matching, 2) 3D information acquisition, 3) object detection/recognition and 4) semantic image segmentation. The principles of computer stereo vision and parallel computing on multi-threading CPU and GPU architectures are then detailed.",0
"Recent advancements in parallel computing architectures have significantly improved autonomous car perception, which is a crucial component of autonomous systems. Computer stereo vision, facilitated by tiny yet full-featured embedded supercomputers, has become increasingly popular in autonomous cars for depth perception. The speed and accuracy of computer stereo vision are both desirable but conflicting properties, as algorithms with better disparity accuracy typically have higher computational complexity. Therefore, the primary objective of developing a computer stereo vision algorithm for resource-limited hardware is to optimize the trade-off between speed and accuracy. This chapter provides an overview of the hardware and software aspects of computer stereo vision for autonomous car systems. Additionally, it examines four autonomous car perception tasks, including visual feature detection, description and matching, 3D information acquisition, object detection/recognition, and semantic image segmentation. The principles of computer stereo vision and parallel computing on multi-threading CPU and GPU architectures are also thoroughly explained.",1
"Automatic medical image segmentation has wide applications for disease diagnosing. However, it is much more challenging than natural optical image segmentation due to the high-resolution of medical images and the corresponding huge computation cost. The sliding window is a commonly used technique for whole slide image (WSI) segmentation, however, for these methods based on the sliding window, the main drawback is lacking global contextual information for supervision. In this paper, we propose a dual-inputs attention network (denoted as DA-RefineNet) for WSI segmentation, where both local fine-grained information and global coarse information can be efficiently utilized. Sufficient comparative experiments are conducted to evaluate the effectiveness of the proposed method, the results prove that the proposed method can achieve better performance on WSI segmentation compared to methods relying on single-input.",0
"Medical image segmentation is essential for diagnosing diseases, and automated methods have numerous applications. However, it is complicated due to the high-resolution of medical images and the enormous computation cost. The sliding window is a widely used technique for whole slide image segmentation, but it lacks global contextual information for supervision. This paper introduces the DA-RefineNet, a dual-inputs attention network for WSI segmentation that efficiently utilizes both local fine-grained information and global coarse information. Comparative experiments are conducted to evaluate the effectiveness of the proposed method, which outperforms single-input methods on WSI segmentation.",1
"Automatic histopathology image segmentation is crucial to disease analysis. Limited available labeled data hinders the generalizability of trained models under the fully supervised setting. Semi-supervised learning (SSL) based on generative methods has been proven to be effective in utilizing diverse image characteristics. However, it has not been well explored what kinds of generated images would be more useful for model training and how to use such images. In this paper, we propose a new data guided generative method for histopathology image segmentation by leveraging the unlabeled data distributions. First, we design an image generation module. Image content and style are disentangled and embedded in a clustering-friendly space to utilize their distributions. New images are synthesized by sampling and cross-combining contents and styles. Second, we devise an effective data selection policy for judiciously sampling the generated images: (1) to make the generated training set better cover the dataset, the clusters that are underrepresented in the original training set are covered more; (2) to make the training process more effective, we identify and oversample the images of ""hard cases"" in the data for which annotated training data may be scarce. Our method is evaluated on glands and nuclei datasets. We show that under both the inductive and transductive settings, our SSL method consistently boosts the performance of common segmentation models and attains state-of-the-art results.",0
"The segmentation of histopathology images is essential for analyzing diseases, but the lack of labeled data limits the effectiveness of fully supervised models. Generative methods using semi-supervised learning have been successful in utilizing various image characteristics. However, little research has been done on the types of generated images that would be most helpful for training models and how to use them. To address this issue, we propose a new data-guided generative method for histopathology image segmentation that leverages unlabeled data distributions. We create an image generation module that disentangles image content and style and embeds them in a clustering-friendly space for sampling and cross-combining. We also devise a data selection policy that oversamples underrepresented clusters and ""hard cases"" to improve the training process. Our method is evaluated on glands and nuclei datasets and consistently improves the performance of common segmentation models, achieving state-of-the-art results under both inductive and transductive settings.",1
"3D Convolution Neural Networks (CNNs) have been widely applied to 3D scene understanding, such as video analysis and volumetric image recognition. However, 3D networks can easily lead to over-parameterization which incurs expensive computation cost. In this paper, we propose Channel-wise Automatic KErnel Shrinking (CAKES), to enable efficient 3D learning by shrinking standard 3D convolutions into a set of economic operations e.g., 1D, 2D convolutions. Unlike previous methods, CAKES performs channel-wise kernel shrinkage, which enjoys the following benefits: 1) enabling operations deployed in every layer to be heterogeneous, so that they can extract diverse and complementary information to benefit the learning process; and 2) allowing for an efficient and flexible replacement design, which can be generalized to both spatial-temporal and volumetric data. Further, we propose a new search space based on CAKES, so that the replacement configuration can be determined automatically for simplifying 3D networks. CAKES shows superior performance to other methods with similar model size, and it also achieves comparable performance to state-of-the-art with much fewer parameters and computational costs on tasks including 3D medical imaging segmentation and video action recognition. Codes and models are available at https://github.com/yucornetto/CAKES",0
"The use of 3D Convolution Neural Networks (CNNs) has become widespread in 3D scene understanding, particularly in video analysis and volumetric image recognition. However, the over-parameterization of 3D networks can result in costly computations. To address this issue, we introduce Channel-wise Automatic KErnel Shrinking (CAKES), which reduces standard 3D convolutions to a series of economical operations, such as 1D and 2D convolutions, allowing for more efficient 3D learning. Unlike previous methods, CAKES performs channel-wise kernel shrinkage, which offers two main advantages: Firstly, it allows for the use of heterogeneous operations in each layer, enabling the extraction of diverse and complementary information that benefits the learning process. Secondly, it provides a flexible and efficient replacement design that can be applied to spatial-temporal and volumetric data. Additionally, we propose a new search space based on CAKES, which automates the replacement configuration process, making 3D networks less complicated. Our results show that CAKES outperforms other comparable methods in terms of model size, while achieving comparable performance to state-of-the-art models with fewer parameters and computational costs. The codes and models used for this research are available at https://github.com/yucornetto/CAKES.",1
"Unsupervised image segmentation aims at assigning the pixels with similar feature into a same cluster without annotation, which is an important task in computer vision. Due to lack of prior knowledge, most of existing model usually need to be trained several times to obtain suitable results. To address this problem, we propose an unsupervised image segmentation model based on the Mutual Mean-Teaching (MMT) framework to produce more stable results. In addition, since the labels of pixels from two model are not matched, a label alignment algorithm based on the Hungarian algorithm is proposed to match the cluster labels. Experimental results demonstrate that the proposed model is able to segment various types of images and achieves better performance than the existing methods.",0
"The objective of unsupervised image segmentation is to cluster pixels with similar attributes into the same group without any annotation. This is an essential task in computer vision, but existing models require multiple training sessions to generate satisfactory outcomes due to a lack of prior knowledge. To solve this issue, we propose an unsupervised image segmentation model that utilizes the Mutual Mean-Teaching (MMT) framework to produce more consistent results. Furthermore, since the labels of pixels from two models do not correspond, we introduce a label alignment algorithm that utilizes the Hungarian algorithm to match the cluster labels. Experimental findings reveal that our model can segment various image types and outperforms current techniques.",1
"Segmentation of findings in the gastrointestinal tract is a challenging but also an important task which is an important building stone for sufficient automatic decision support systems. In this work, we present our solution for the Medico 2020 task, which focused on the problem of colon polyp segmentation. We present our simple but efficient idea of using an augmentation method that uses grids in a pyramid-like manner (large to small) for segmentation. Our results show that the proposed methods work as indented and can also lead to comparable results when competing with other methods.",0
"The segmentation of gastrointestinal tract findings is a crucial yet complex duty that serves as a vital foundation for effective automated decision-making systems. In this study, we introduce our approach to the Medico 2020 challenge, which addressed the issue of colon polyp segmentation. Our technique involves a straightforward yet effective augmentation strategy that employs pyramidal grids of varying sizes to facilitate segmentation. Our findings demonstrate that our proposed method performs as intended and can yield results that are comparable to those obtained through other methods.",1
"Compared with common image segmentation tasks targeted at low-resolution images, higher resolution detailed image segmentation receives much less attention. In this paper, we propose and study a task named Meticulous Object Segmentation (MOS), which is focused on segmenting well-defined foreground objects with elaborate shapes in high resolution images (e.g. 2k - 4k). To this end, we propose the MeticulousNet which leverages a dedicated decoder to capture the object boundary details. Specifically, we design a Hierarchical Point-wise Refining (HierPR) block to better delineate object boundaries, and reformulate the decoding process as a recursive coarse to fine refinement of the object mask. To evaluate segmentation quality near object boundaries, we propose the Meticulosity Quality (MQ) score considering both the mask coverage and boundary precision. In addition, we collect a MOS benchmark dataset including 600 high quality images with complex objects. We provide comprehensive empirical evidence showing that MeticulousNet can reveal pixel-accurate segmentation boundaries and is superior to state-of-the-art methods for high resolution object segmentation tasks.",0
"In contrast to image segmentation tasks that deal with low-resolution images, there is limited focus on segmentation of intricate, well-defined foreground objects in high-resolution images. This paper introduces a new task called Meticulous Object Segmentation (MOS) that aims to address this issue. The proposed MeticulousNet utilizes a specialized decoder that captures object boundary details through a Hierarchical Point-wise Refining (HierPR) block, which enhances object boundary delineation. The decoding process is reformulated as a recursive coarse to fine refinement of the object mask. To assess segmentation quality near object boundaries, the paper introduces a Meticulosity Quality (MQ) score that considers both mask coverage and boundary precision. Further, a MOS benchmark dataset comprising of 600 high-quality images is collected. Empirical evidence suggests that MeticulousNet can accurately segment object boundaries at the pixel level and outperforms state-of-the-art methods for high-resolution object segmentation tasks.",1
"Semantic segmentation has achieved significant advances in recent years. While deep neural networks perform semantic segmentation well, their success rely on pixel level supervision which is expensive and time-consuming. Further, training using data from one domain may not generalize well to data from a new domain due to a domain gap between data distributions in the different domains. This domain gap is particularly evident in aerial images where visual appearance depends on the type of environment imaged, season, weather, and time of day when the environment is imaged. Subsequently, this distribution gap leads to severe accuracy loss when using a pretrained segmentation model to analyze new data with different characteristics. In this paper, we propose a novel unsupervised domain adaptation framework to address domain shift in the context of aerial semantic image segmentation. To this end, we solve the problem of domain shift by learn the soft label distribution difference between the source and target domains. Further, we also apply entropy minimization on the target domain to produce high-confident prediction rather than using high-confident prediction by pseudo-labeling. We demonstrate the effectiveness of our domain adaptation framework using the challenge image segmentation dataset of ISPRS, and show improvement over state-of-the-art methods in terms of various metrics.",0
"Recent years have seen significant progress in semantic segmentation. Although deep neural networks perform well in this area, they rely on pixel-level supervision, which can be costly and time-consuming. Moreover, training with data from one domain may not generalize to data from a different domain due to a distribution gap between the two. This gap is particularly apparent in aerial images, where visual appearance is influenced by factors such as environment type, season, weather, and time of day. As a result, using a pretrained segmentation model on new data with different characteristics can lead to significant accuracy loss. This paper proposes an innovative unsupervised domain adaptation framework to tackle domain shift in aerial semantic image segmentation. The framework addresses the problem of domain shift by learning the difference in soft label distribution between the source and target domains. Additionally, it applies entropy minimization to the target domain to produce high-confidence predictions rather than relying on high-confidence predictions through pseudo-labeling. The proposed framework is demonstrated on the challenge image segmentation dataset of ISPRS, and it is shown to outperform state-of-the-art methods in terms of various metrics.",1
"Despite deep convolutional neural networks achieved impressive progress in medical image computing and analysis, its paradigm of supervised learning demands a large number of annotations for training to avoid overfitting and achieving promising results. In clinical practices, massive semantic annotations are difficult to acquire in some conditions where specialized biomedical expert knowledge is required, and it is also a common condition where only few annotated classes are available. In this work, we proposed a novel method for few-shot medical image segmentation, which enables a segmentation model to fast generalize to an unseen class with few training images. We construct our few-shot image segmentor using a deep convolutional network trained episodically. Motivated by the spatial consistency and regularity in medical images, we developed an efficient global correlation module to capture the correlation between a support and query image and incorporate it into the deep network called global correlation network. Moreover, we enhance discriminability of deep embedding to encourage clustering of the feature domains of the same class while keep the feature domains of different organs far apart. Ablation Study proved the effectiveness of the proposed global correlation module and discriminative embedding loss. Extensive experiments on anatomical abdomen images on both CT and MRI modalities are performed to demonstrate the state-of-the-art performance of our proposed model.",0
"Although deep convolutional neural networks have made significant strides in medical image computing and analysis, their supervised learning approach requires a large number of annotations for effective training. Obtaining these annotations can be challenging in clinical settings, where specialized biomedical expertise is often required, and only a limited number of annotated classes may be available. To address these issues, we propose a novel few-shot medical image segmentation method that enables a segmentation model to quickly generalize to an unseen class with minimal training images. Our approach involves training a deep convolutional network episodically and incorporating an efficient global correlation module to capture correlations between support and query images. We also enhance the discriminability of deep embedding by encouraging clustering of feature domains of the same class while keeping those of different organs separate. Ablation study confirms the effectiveness of our proposed global correlation module and discriminative embedding loss, and extensive experiments on anatomical abdomen images on both CT and MRI modalities demonstrate the state-of-the-art performance of our model.",1
"We present CROP (Central Roundish Object Painter), which identifies and paints the object at the center of an RGB image. Primarily CROP works for roundish fruits in various illumination conditions, but surprisingly, it could also deal with images of other organic or inorganic materials, or ones by optical and electron microscopes, although CROP was trained solely by 172 images of fruits. The method involves image segmentation by deep learning, and the architecture of the neural network is a deeper version of the original U-Net. This technique could provide us with a means of automatically collecting statistical data of fruit growth in farms. As an example, we describe our experiment of processing 510 time series photos automatically to collect the data on the size and the position of the target fruit. Our trained neural network CROP and the above automatic programs are available on GitHub with user-friendly interface programs.",0
"Introducing CROP (Central Roundish Object Painter), a program designed to identify and paint the central object in an RGB image. While primarily intended for round fruits in varying lighting conditions, CROP has also proven effective for images of other organic or inorganic materials, as well as those captured through optical and electron microscopes. Despite being trained on just 172 fruit images, the method employs deep learning image segmentation and utilizes a more complex version of the original U-Net neural network architecture. This technology could revolutionize the collection of statistical data on fruit growth in farms, as demonstrated by our experiment of automatically processing 510 time series photos to collect data on the size and position of the target fruit. CROP and the associated automatic programs are readily available on GitHub, complete with user-friendly interfaces.",1
"Artist, year and style classification of fine-art paintings are generally achieved using standard image classification methods, image segmentation, or more recently, convolutional neural networks (CNNs). This works aims to use newly developed face recognition methods such as FaceNet that use CNNs to cluster fine-art paintings using the extracted faces in the paintings, which are found abundantly. A dataset consisting of over 80,000 paintings from over 1000 artists is chosen, and three separate face recognition and clustering tasks are performed. The produced clusters are analyzed by the file names of the paintings and the clusters are named by their majority artist, year range, and style. The clusters are further analyzed and their performance metrics are calculated. The study shows promising results as the artist, year, and styles are clustered with an accuracy of 58.8, 63.7, and 81.3 percent, while the clusters have an average purity of 63.1, 72.4, and 85.9 percent.",0
"The typical methods for determining the artist, year, and style of fine-art paintings include using standard image classification techniques, image segmentation, and convolutional neural networks. However, this study proposes a novel approach utilizing face recognition methods like FaceNet. By extracting the faces present in fine-art paintings, which are abundant, the paintings can be clustered using CNNs. The study uses a dataset comprising over 80,000 paintings from more than 1000 artists and conducts three separate face recognition and clustering tasks. The resulting clusters are named according to their majority artist, year range, and style based on the file names of the paintings. The clusters are then analyzed, and performance metrics are calculated. The results are promising, with accuracy rates of 58.8%, 63.7%, and 81.3% for clustering artist, year, and style, respectively, and an average purity of 63.1%, 72.4%, and 85.9% for the clusters.",1
"In recent years, the idea of using morphological operations as networks has received much attention. Mathematical morphology provides very efficient and useful image processing and image analysis tools based on basic operators like dilation and erosion, defined in terms of kernels. Many other morphological operations are built up using the dilation and erosion operations. Although the learning of structuring elements such as dilation or erosion using the backpropagation algorithm is not new, the order and the way these morphological operations are used is not standard. In this paper, we have theoretically analyzed the use of morphological operations for processing 1D feature vectors and shown that this gets extended to the 2D case in a simple manner. Our theoretical results show that a morphological block represents a sum of hinge functions. Hinge functions are used in many places for classification and regression tasks (Breiman (1993)). We have also proved a universal approximation theorem -- a stack of two morphological blocks can approximate any continuous function over arbitrary compact sets. To experimentally validate the efficacy of this network in real-life applications, we have evaluated its performance on satellite image classification datasets since morphological operations are very sensitive to geometrical shapes and structures. We have also shown results on a few tasks like segmentation of blood vessels from fundus images, segmentation of lungs from chest x-ray and image dehazing. The results are encouraging and further establishes the potential of morphological networks.",0
"The concept of utilizing morphological operations as networks has gained considerable attention in recent times. These operations, based on fundamental operators such as dilation and erosion defined using kernels, provide efficient and valuable tools for image analysis and processing. Various other morphological operations are constructed by incorporating dilation and erosion. Though the use of backpropagation algorithm for learning structuring elements like dilation and erosion is not new, the way these morphological operations are utilized is not uniform. This research paper analyzes the application of morphological operations for processing 1D feature vectors and demonstrates that it can be extended easily to the 2D case. The study reveals that a morphological block is a collection of hinge functions, which are extensively employed for classification and regression tasks. Additionally, the paper proves a universal approximation theorem, suggesting that two morphological blocks can approximate any continuous function. To validate the effectiveness of this network in real-world scenarios, the researchers evaluate its performance on satellite image classification datasets, highlighting the sensitivity of morphological operations towards geometric shapes and structures. The article presents the results of various tasks, including segmentation of blood vessels from fundus images, segmentation of lungs from chest x-rays, and image dehazing, which indicate the potential of morphological networks.",1
"The data-driven nature of deep learning models for semantic segmentation requires a large number of pixel-level annotations. However, large-scale and fully labeled medical datasets are often unavailable for practical tasks. Recently, partially supervised methods have been proposed to utilize images with incomplete labels to mitigate the data scarcity problem in the medical domain. As an emerging research area, the breakthroughs made by existing methods rely on either large-scale data or complex model design, which makes them 1) less practical for certain real-life tasks and 2) less robust for small-scale data. It is time to step back and think about the robustness of partially supervised methods and how to maximally utilize small-scale and partially labeled data for medical image segmentation tasks. To bridge the methodological gaps in label-efficient deep learning with partial supervision, we propose RAMP, a simple yet efficient data augmentation framework for partially supervised medical image segmentation by exploiting the assumption that patients share anatomical similarities. We systematically evaluate RAMP and the previous methods in various controlled multi-structure segmentation tasks. Compared to the mainstream approaches, RAMP consistently improves the performance of traditional segmentation networks on small-scale partially labeled data and utilize additional image-wise weak annotations.",0
"Deep learning models for semantic segmentation rely heavily on pixel-level annotations, but obtaining large-scale and fully labeled medical datasets is often impractical. To address this issue, researchers have proposed partially supervised methods that use images with incomplete labels. However, these methods have limitations, such as relying on either large-scale data or complex model design, which makes them less practical and robust for certain real-life tasks and small-scale data. Therefore, it is necessary to reconsider the robustness of partially supervised methods and how to effectively utilize small-scale and partially labeled data for medical image segmentation. To fill the gaps in label-efficient deep learning with partial supervision, we propose RAMP, a data augmentation framework that exploits the assumption of anatomical similarities between patients. Through a systematic evaluation in various controlled multi-structure segmentation tasks, we demonstrate that RAMP consistently outperforms mainstream approaches and enables the use of image-wise weak annotations on small-scale partially labeled data.",1
"Gliomas are the most common primary brain malignancies, with different degrees of aggressiveness, variable prognosis and various heterogeneous histological sub-regions, i.e., peritumoral edema, necrotic core, enhancing and non-enhancing tumour core. Although brain tumours can easily be detected using multi-modal MRI, accurate tumor segmentation is a challenging task. Hence, using the data provided by the BraTS Challenge 2020, we propose a 3D volume-to-volume Generative Adversarial Network for segmentation of brain tumours. The model, called Vox2Vox, generates realistic segmentation outputs from multi-channel 3D MR images, segmenting the whole, core and enhancing tumor with mean values of 87.20%, 81.14%, and 78.67% as dice scores and 6.44mm, 24.36mm, and 18.95mm for Hausdorff distance 95 percentile for the BraTS testing set after ensembling 10 Vox2Vox models obtained with a 10-fold cross-validation.",0
"Gliomas, which are primary brain malignancies, come in varying degrees of aggressiveness and have different prognoses and histological sub-regions such as peritumoral edema, necrotic core, enhancing and non-enhancing tumour core. Although it is easy to identify brain tumours using multi-modal MRI, accurately segmenting them is a challenging task. Therefore, we propose a 3D volume-to-volume Generative Adversarial Network known as Vox2Vox, which uses data from the BraTS Challenge 2020 to segment brain tumours. Vox2Vox generates realistic segmentation outputs from multi-channel 3D MR images, segmenting the whole, core, and enhancing tumour with dice scores of 87.20%, 81.14%, and 78.67% and Hausdorff distance 95 percentile values of 6.44mm, 24.36mm, and 18.95mm for the BraTS testing set after ensembling 10 Vox2Vox models obtained with a 10-fold cross-validation.",1
"It has been widely recognized that the success of deep learning in image segmentation relies overwhelmingly on a myriad amount of densely annotated training data, which, however, are difficult to obtain due to the tremendous labor and expertise required, particularly for annotating 3D medical images. Although self-supervised learning (SSL) has shown great potential to address this issue, most SSL approaches focus only on image-level global consistency, but ignore the local consistency which plays a pivotal role in capturing structural information for dense prediction tasks such as segmentation. In this paper, we propose a PriorGuided Local (PGL) self-supervised model that learns the region-wise local consistency in the latent feature space. Specifically, we use the spatial transformations, which produce different augmented views of the same image, as a prior to deduce the location relation between two views, which is then used to align the feature maps of the same local region but being extracted on two views. Next, we construct a local consistency loss to minimize the voxel-wise discrepancy between the aligned feature maps. Thus, our PGL model learns the distinctive representations of local regions, and hence is able to retain structural information. This ability is conducive to downstream segmentation tasks. We conducted an extensive evaluation on four public computerized tomography (CT) datasets that cover 11 kinds of major human organs and two tumors. The results indicate that using pre-trained PGL model to initialize a downstream network leads to a substantial performance improvement over both random initialization and the initialization with global consistency-based models. Code and pre-trained weights will be made available at: https://git.io/PGL.",0
"The success of deep learning in image segmentation is heavily dependent on densely annotated training data, which is difficult to obtain because of the labor and expertise required, especially for 3D medical images. While self-supervised learning (SSL) has potential to address this issue, most SSL approaches focus on global consistency at the image level, ignoring the crucial role of local consistency in capturing structural information for dense prediction tasks like segmentation. In this paper, we propose a PriorGuided Local (PGL) self-supervised model that learns local consistency in the latent feature space. We use spatial transformations as a prior to determine the location relation between two views, aligning the feature maps of the same local region extracted from two views. We then construct a local consistency loss to minimize the voxel-wise discrepancy between the aligned feature maps. Our PGL model learns distinctive representations of local regions, retaining structural information that is beneficial for downstream segmentation tasks. We evaluated our model on four public CT datasets covering 11 major human organs and two tumors, demonstrating that using pre-trained PGL model for downstream network initialization leads to substantial performance improvements over both random initialization and global consistency-based models. The code and pre-trained weights will be available at: https://git.io/PGL.",1
"Infrared (IR) image segmentation is essential in many urban defence applications, such as pedestrian surveillance, vehicle counting, security monitoring, etc. Active contour model (ACM) is one of the most widely used image segmentation tools at present, but the existing methods only utilize the local or global single feature information of image to minimize the energy function, which is easy to cause false segmentations in IR images. In this paper, we propose a multi-feature driven active contour segmentation model to handle IR images with intensity inhomogeneity. Firstly, an especially-designed signed pressure force (SPF) function is constructed by combining the global information calculated by global average gray information and the local multi-feature information calculated by local entropy, local standard deviation and gradient information. Then, we draw upon adaptive weight coefficient calculated by local range to adjust the afore-mentioned global term and local term. Next, the SPF function is substituted into the level set formulation (LSF) for further evolution. Finally, the LSF converges after a finite number of iterations, and the IR image segmentation result is obtained from the corresponding convergence result. Experimental results demonstrate that the presented method outperforms the state-of-the-art models in terms of precision rate and overlapping rate in IR test images.",0
"Segmenting infrared (IR) images is crucial in various urban defence applications such as security monitoring, pedestrian surveillance, vehicle counting, etc. Although the active contour model (ACM) is a widely used image segmentation tool, current methods only utilize local or global single feature information to minimize the energy function, resulting in false segmentation in IR images. This paper proposes a multi-feature driven active contour segmentation model that can handle IR images with intensity inhomogeneity. To achieve this, a signed pressure force (SPF) function is constructed by combining global and local multi-feature information. An adaptive weight coefficient calculated by local range is then applied to adjust the global and local terms of the SPF function. The SPF function is integrated into the level set formulation (LSF) for further evolution, and the LSF converges after a finite number of iterations to obtain the segmentation result. The presented method outperforms state-of-the-art models in terms of precision rate and overlapping rate in IR test images, as demonstrated by experimental results.",1
"In recent years, Convolutional Neural Networks (CNNs) have become the state-of-the-art method for biomedical image analysis. However, these networks are usually trained in a supervised manner, requiring large amounts of labelled training data. These labelled data sets are often difficult to acquire in the biomedical domain. In this work, we validate alternative ways to train CNNs with fewer labels for biomedical image segmentation using. We adapt two semi- and self-supervised image classification methods and analyse their performance for semantic segmentation of biomedical microscopy images.",0
"Biomedical image analysis has seen a rise in the use of Convolutional Neural Networks (CNNs) as the most advanced method. Nonetheless, these networks require supervised training, which demands vast amounts of labelled data that are often scarce in the biomedical field. This study examines alternative methods to train CNNs with fewer labels for biomedical image segmentation. Two semi- and self-supervised image classification techniques are adapted and their efficiency is analyzed for semantic segmentation of biomedical microscopy images.",1
"Today, deep convolutional neural networks (CNNs) have demonstrated state of the art performance for supervised medical image segmentation, across various imaging modalities and tasks. Despite early success, segmentation networks may still generate anatomically aberrant segmentations, with holes or inaccuracies near the object boundaries. To mitigate this effect, recent research works have focused on incorporating spatial information or prior knowledge to enforce anatomically plausible segmentation. If the integration of prior knowledge in image segmentation is not a new topic in classical optimization approaches, it is today an increasing trend in CNN based image segmentation, as shown by the growing literature on the topic. In this survey, we focus on high level prior, embedded at the loss function level. We categorize the articles according to the nature of the prior: the object shape, size, topology, and the inter-regions constraints. We highlight strengths and limitations of current approaches, discuss the challenge related to the design and the integration of prior-based losses, and the optimization strategies, and draw future research directions.",0
"Supervised medical image segmentation has been shown to achieve top-notch results using deep convolutional neural networks (CNNs) in various imaging modalities and tasks. However, anatomically incorrect segmentations may still occur, such as holes or inaccuracies near object boundaries. Recent studies have focused on incorporating spatial information or prior knowledge to ensure realistic segmentation. While classical optimization approaches have explored this topic, it is now increasingly prevalent in CNN-based image segmentation, with growing literature in this area. This survey specifically examines high-level prior knowledge embedded at the loss function level, categorized by object shape, size, topology, and inter-regions constraints. We discuss the strengths and limitations of current approaches, the challenges related to designing and integrating prior-based losses, optimization strategies, and suggest future research directions.",1
"Ferrograph image segmentation is of significance for obtaining features of wear particles. However, wear particles are usually overlapped in the form of debris chains, which makes challenges to segment wear debris. An overlapping wear particle segmentation network (OWPSNet) is proposed in this study to segment the overlapped debris chains. The proposed deep learning model includes three parts: a region segmentation network, an edge detection network and a feature refine module. The region segmentation network is an improved U shape network, and it is applied to separate the wear debris form background of ferrograph image. The edge detection network is used to detect the edges of wear particles. Then, the feature refine module combines low-level features and high-level semantic features to obtain the final results. In order to solve the problem of sample imbalance, we proposed a square dice loss function to optimize the model. Finally, extensive experiments have been carried out on a ferrograph image dataset. Results show that the proposed model is capable of separating overlapping wear particles. Moreover, the proposed square dice loss function can improve the segmentation results, especially for the segmentation results of wear particle edge.",0
"Segmenting wear particles in Ferrograph images is crucial for analyzing their features. However, wear particles are often intertwined in the form of debris chains, which poses a challenge in their segmentation. This study introduces the Overlapping Wear Particle Segmentation Network (OWPSNet) to address this issue. The deep learning model comprises three components: a region segmentation network, an edge detection network, and a feature refine module. The improved U-shape network, used as the region segmentation network, helps segregate wear debris from the Ferrograph image's background. The edge detection network identifies wear particle edges, followed by the feature refine module, which combines low-level and high-level semantic features to produce accurate results. To address sample imbalance, the study proposes a square dice loss function to optimize the model. Experiments on a Ferrograph image dataset demonstrate that the proposed model can accurately segment overlapping wear particles, and the square dice loss function can enhance segmentation results, particularly for wear particle edge segmentation.",1
"Due to the intensive cost of labor and expertise in annotating 3D medical images at a voxel level, most benchmark datasets are equipped with the annotations of only one type of organs and/or tumors, resulting in the so-called partially labeling issue. To address this, we propose a dynamic on-demand network (DoDNet) that learns to segment multiple organs and tumors on partially labeled datasets. DoDNet consists of a shared encoder-decoder architecture, a task encoding module, a controller for generating dynamic convolution filters, and a single but dynamic segmentation head. The information of the current segmentation task is encoded as a task-aware prior to tell the model what the task is expected to solve. Different from existing approaches which fix kernels after training, the kernels in dynamic head are generated adaptively by the controller, conditioned on both input image and assigned task. Thus, DoDNet is able to segment multiple organs and tumors, as done by multiple networks or a multi-head network, in a much efficient and flexible manner. We have created a large-scale partially labeled dataset, termed MOTS, and demonstrated the superior performance of our DoDNet over other competitors on seven organ and tumor segmentation tasks. We also transferred the weights pre-trained on MOTS to a downstream multi-organ segmentation task and achieved state-of-the-art performance. This study provides a general 3D medical image segmentation model that has been pre-trained on a large-scale partially labelled dataset and can be extended (after fine-tuning) to downstream volumetric medical data segmentation tasks. The dataset and code areavailableat: https://git.io/DoDNet",0
"The partially labeling issue in benchmark datasets arises from the high cost of labor and expertise required to annotate 3D medical images at a voxel level. Consequently, these datasets are only equipped with annotations for one type of organ or tumor. To overcome this limitation, we propose a dynamic on-demand network called DoDNet, which can learn to segment multiple organs and tumors on partially labeled datasets. DoDNet comprises a shared encoder-decoder architecture, a task encoding module, a controller for generating dynamic convolution filters, and a single but dynamic segmentation head. To inform the model of the current segmentation task, we encode its information as a task-aware prior. Unlike existing approaches that use fixed kernels, the kernels in DoDNet's dynamic head are generated adaptively by the controller, based on both input image and assigned task. As a result, DoDNet can segment multiple organs and tumors more efficiently and flexibly than multiple networks or a multi-head network. We have created a large-scale partially labeled dataset called MOTS and demonstrated the superior performance of DoDNet over other competitors on seven organ and tumor segmentation tasks. We have also transferred the weights pre-trained on MOTS to a downstream multi-organ segmentation task, achieving state-of-the-art performance. This study presents a general 3D medical image segmentation model, pre-trained on a large-scale partially labeled dataset, that can be extended to downstream volumetric medical data segmentation tasks after fine-tuning. The dataset and code are available at: https://git.io/DoDNet.",1
"Segmentation of organs of interest in 3D medical images is necessary for accurate diagnosis and longitudinal studies. Though recent advances using deep learning have shown success for many segmentation tasks, large datasets are required for high performance and the annotation process is both time consuming and labor intensive. In this paper, we propose a 3D few shot segmentation framework for accurate organ segmentation using limited training samples of the target organ annotation. To achieve this, a U-Net like network is designed to predict segmentation by learning the relationship between 2D slices of support data and a query image, including a bidirectional gated recurrent unit (GRU) that learns consistency of encoded features between adjacent slices. Also, we introduce a transfer learning method to adapt the characteristics of the target image and organ by updating the model before testing with arbitrary support and query data sampled from the support data. We evaluate our proposed model using three 3D CT datasets with annotations of different organs. Our model yielded significantly improved performance over state-of-the-art few shot segmentation models and was comparable to a fully supervised model trained with more target training data.",0
"For accurate diagnosis and longitudinal studies, it is necessary to segment organs of interest in 3D medical images. Despite recent success using deep learning for segmentation tasks, high performance requires large datasets, and annotations are time-consuming and labor-intensive. This paper proposes a 3D few-shot segmentation framework for accurate organ segmentation using limited training samples of the target organ annotation. To achieve this, a U-Net-like network is designed that predicts segmentation by learning the relationship between 2D slices of support data and a query image, with a bidirectional gated recurrent unit (GRU) learning consistency of encoded features between adjacent slices. Additionally, a transfer learning method is introduced to adapt the characteristics of the target image and organ by updating the model before testing with arbitrary support and query data sampled from the support data. The proposed model is evaluated using three 3D CT datasets with annotations of different organs, showing significantly improved performance over state-of-the-art few-shot segmentation models and comparable performance to a fully supervised model trained with more target training data.",1
"Dilated convolutions are widely used in deep semantic segmentation models as they can enlarge the filters' receptive field without adding additional weights nor sacrificing spatial resolution. However, as dilated convolutional filters do not possess positional knowledge about the pixels on semantically meaningful contours, they could lead to ambiguous predictions on object boundaries. In addition, although dilating the filter can expand its receptive field, the total number of sampled pixels remains unchanged, which usually comprises a small fraction of the receptive field's total area. Inspired by the Lateral Inhibition (LI) mechanisms in human visual systems, we propose the dilated convolution with lateral inhibitions (LI-Convs) to overcome these limitations. Introducing LI mechanisms improves the convolutional filter's sensitivity to semantic object boundaries. Moreover, since LI-Convs also implicitly take the pixels from the laterally inhibited zones into consideration, they can also extract features at a denser scale. By integrating LI-Convs into the Deeplabv3+ architecture, we propose the Lateral Inhibited Atrous Spatial Pyramid Pooling (LI-ASPP), the Lateral Inhibited MobileNet-V2 (LI-MNV2) and the Lateral Inhibited ResNet (LI-ResNet). Experimental results on three benchmark datasets (PASCAL VOC 2012, CelebAMask-HQ and ADE20K) show that our LI-based segmentation models outperform the baseline on all of them, thus verify the effectiveness and generality of the proposed LI-Convs.",0
"Dilated convolutions are a popular technique in deep semantic segmentation models because they can increase the receptive field of filters without adding more weights or reducing spatial resolution. However, these filters lack positional knowledge of pixels on semantically significant contours, which can lead to ambiguous predictions on object boundaries. Additionally, while dilating filters can expand their receptive field, the total number of sampled pixels remains small compared to the total area. To address these issues, we propose using dilated convolutions with lateral inhibitions (LI-Convs), which are inspired by the Lateral Inhibition mechanisms of human visual systems. These LI-Convs improve filter sensitivity to semantic object boundaries and also extract features at a denser scale by taking pixels from the laterally inhibited zones into consideration. We integrate LI-Convs into the Deeplabv3+ architecture to create the Lateral Inhibited Atrous Spatial Pyramid Pooling (LI-ASPP), the Lateral Inhibited MobileNet-V2 (LI-MNV2), and the Lateral Inhibited ResNet (LI-ResNet). Our experimental results on three benchmark datasets (PASCAL VOC 2012, CelebAMask-HQ, and ADE20K) show that our LI-based segmentation models outperform the baseline on all of them, demonstrating the effectiveness and generality of LI-Convs.",1
"In recent years there has been a growing interest in image generation through deep learning. While an important part of the evaluation of the generated images usually involves visual inspection, the inclusion of human perception as a factor in the training process is often overlooked. In this paper we propose an alternative perceptual regulariser for image-to-image translation using conditional generative adversarial networks (cGANs). To do so automatically (avoiding visual inspection), we use the Normalised Laplacian Pyramid Distance (NLPD) to measure the perceptual similarity between the generated image and the original image. The NLPD is based on the principle of normalising the value of coefficients with respect to a local estimate of mean energy at different scales and has already been successfully tested in different experiments involving human perception. We compare this regulariser with the originally proposed L1 distance and note that when using NLPD the generated images contain more realistic values for both local and global contrast. We found that using NLPD as a regulariser improves image segmentation accuracy on generated images as well as improving two no-reference image quality metrics.",0
"Lately, there has been a growing interest in creating images using deep learning. While visual inspection is typically used to evaluate the quality of generated images, the importance of considering human perception during the training process is often overlooked. This paper presents an alternative approach to image-to-image translation using conditional generative adversarial networks (cGANs) that incorporates a perceptual regularizer. To avoid visual inspection, the Normalised Laplacian Pyramid Distance (NLPD) is used to measure the perceptual similarity between the generated and original images. NLPD has been successfully tested in previous experiments involving human perception and is based on normalizing coefficient values with respect to a local estimate of mean energy at different scales. By comparing the NLPD regularizer to the originally proposed L1 distance, it is noted that generated images using NLPD have more realistic values for both local and global contrast. The regularizer also improves image segmentation accuracy and two no-reference image quality metrics.",1
"Medical image segmentation is one of the major challenges addressed by machine learning methods. Yet, deep learning methods profoundly depend on a large amount of annotated data, which is time-consuming and costly. Though, semi-supervised learning methods approach this problem by leveraging an abundant amount of unlabeled data along with a small amount of labeled data in the training process. Recently, MixUp regularizer has been successfully introduced to semi-supervised learning methods showing superior performance. MixUp augments the model with new data points through linear interpolation of the data at the input space. We argue that this option is limited. Instead, we propose ROAM, a RandOm lAyer Mixup, which encourages the network to be less confident for interpolated data points at randomly selected space. ROAM generates more data points that have never seen before, and hence it avoids over-fitting and enhances the generalization ability. We conduct extensive experiments to validate our method on three publicly available datasets on whole-brain image segmentation. ROAM achieves state-of-the-art (SOTA) results in fully supervised (89.5%) and semi-supervised (87.0%) settings with a relative improvement of up to 2.40% and 16.50%, respectively for the whole-brain segmentation.",0
"One of the main challenges tackled by machine learning is the segmentation of medical images. However, deep learning methods heavily rely on annotated data, which is both time-consuming and expensive. Semi-supervised learning overcomes this challenge by utilizing a large amount of unlabeled data in addition to a small amount of labeled data during training. The MixUp regularizer has recently been introduced to semi-supervised learning, which has demonstrated exceptional performance. However, this method has limitations. In its place, we present ROAM, a RandOm lAyer Mixup that encourages the network to be less certain for interpolated data points at randomly selected spaces. ROAM generates new data points that have not been seen before, preventing over-fitting and improving generalization ability. We conducted extensive experiments on three publicly available whole-brain image segmentation datasets, and ROAM achieved state-of-the-art results in fully supervised (89.5%) and semi-supervised (87.0%) settings, with relative improvements of up to 2.40% and 16.50%, respectively, for whole-brain segmentation.",1
"Deep learning-based medical image segmentation technology aims at automatic recognizing and annotating objects on the medical image. Non-local attention and feature learning by multi-scale methods are widely used to model network, which drives progress in medical image segmentation. However, those attention mechanism methods have weakly non-local receptive fields' strengthened connection for small objects in medical images. Then, the features of important small objects in abstract or coarse feature maps may be deserted, which leads to unsatisfactory performance. Moreover, the existing multi-scale methods only simply focus on different sizes of view, whose sparse multi-scale features collected are not abundant enough for small objects segmentation. In this work, a multi-dimensional attention segmentation model with cascade multi-scale convolution is proposed to predict accurate segmentation for small objects in medical images. As the weight function, multi-dimensional attention modules provide coefficient modification for significant/informative small objects features. Furthermore, The cascade multi-scale convolution modules in each skip-connection path are exploited to capture multi-scale features in different semantic depth. The proposed method is evaluated on three datasets: KiTS19, Pancreas CT of Decathlon-10, and MICCAI 2018 LiTS Challenge, demonstrating better segmentation performances than the state-of-the-art baselines.",0
"The goal of deep learning-based medical image segmentation technology is to automatically recognize and annotate objects in medical images. To achieve this, non-local attention and multi-scale feature learning methods are commonly used to model the network. However, these attention mechanisms are not effective for small objects in medical images, which can lead to unsatisfactory results. Additionally, current multi-scale methods do not provide enough coverage for small objects. To address these issues, this work proposes a multi-dimensional attention segmentation model with cascade multi-scale convolution to accurately segment small objects in medical images. This model uses attention modules to modify the coefficient of small object features and cascade multi-scale convolution modules to capture multi-scale features. The proposed method is evaluated on three datasets and outperforms existing baselines.",1
"Image segmentation is a key topic in image processing and computer vision with applications such as scene understanding, medical image analysis, robotic perception, video surveillance, augmented reality, and image compression, among many others. Various algorithms for image segmentation have been developed in the literature. Recently, due to the success of deep learning models in a wide range of vision applications, there has been a substantial amount of works aimed at developing image segmentation approaches using deep learning models. In this survey, we provide a comprehensive review of the literature at the time of this writing, covering a broad spectrum of pioneering works for semantic and instance-level segmentation, including fully convolutional pixel-labeling networks, encoder-decoder architectures, multi-scale and pyramid based approaches, recurrent networks, visual attention models, and generative models in adversarial settings. We investigate the similarity, strengths and challenges of these deep learning models, examine the most widely used datasets, report performances, and discuss promising future research directions in this area.",0
"The segmentation of images is a significant area of interest in computer vision and image processing. It has numerous applications, such as medical image analysis, scene understanding, video surveillance, robotic perception, augmented reality, and image compression. Over time, several algorithms for image segmentation have been developed and documented. With the increasing success of deep learning models in various vision applications, many researchers have focused on developing image segmentation methods using deep learning models. This survey provides a comprehensive review of the pioneering works in semantic and instance-level segmentation, covering a wide range of approaches, including fully convolutional pixel-labeling networks, encoder-decoder architectures, multi-scale and pyramid based methods, recurrent networks, visual attention models, and generative models in adversarial settings. We analyze the similarities and challenges of these deep learning models, evaluate their performances on the most widely used datasets, and discuss future research directions in this area.",1
"Datasets with noisy labels are a common occurrence in practical applications of classification methods. We propose a simple probabilistic method for training deep classifiers under input-dependent (heteroscedastic) label noise. We assume an underlying heteroscedastic generative process for noisy labels. To make gradient based training feasible we use a temperature parameterized softmax as a smooth approximation to the assumed generative process. We illustrate that the softmax temperature controls a bias-variance trade-off for the approximation. By tuning the softmax temperature, we improve accuracy, log-likelihood and calibration on both image classification benchmarks with controlled label noise as well as Imagenet-21k which has naturally occurring label noise. For image segmentation, our method increases the mean IoU on the PASCAL VOC and Cityscapes datasets by more than 1% over the state-of-the-art model.",0
"In practical applications of classification methods, it is common to encounter datasets with labels that contain noise. Our proposal is a straightforward probabilistic approach to train deep classifiers while taking into account input-dependent (heteroscedastic) label noise. We operate under the assumption that there is a heteroscedastic generative process at play when it comes to noisy labels. To make use of gradient-based training, we introduce a temperature parameterized softmax that serves as a smooth approximation of the assumed generative process. We demonstrate that the softmax temperature can be used to manage the trade-off between bias and variance in the approximation. By adjusting the softmax temperature, we have been able to improve accuracy, log-likelihood, and calibration in benchmarks for image classification with controlled label noise, as well as Imagenet-21k, which has naturally occurring label noise. Our method has achieved a mean IoU increase of more than 1% over the state-of-the-art model for image segmentation on the PASCAL VOC and Cityscapes datasets.",1
"Video semantic segmentation is active in recent years benefited from the great progress of image semantic segmentation. For such a task, the per-frame image segmentation is generally unacceptable in practice due to high computation cost. To tackle this issue, many works use the flow-based feature propagation to reuse the features of previous frames. However, the optical flow estimation inevitably suffers inaccuracy and then causes the propagated features distorted. In this paper, we propose distortion-aware feature correction to alleviate the issue, which improves video segmentation performance by correcting distorted propagated features. To be specific, we firstly propose to transfer distortion patterns from feature into image space and conduct effective distortion map prediction. Benefited from the guidance of distortion maps, we proposed Feature Correction Module (FCM) to rectify propagated features in the distorted areas. Our proposed method can significantly boost the accuracy of video semantic segmentation at a low price. The extensive experimental results on Cityscapes and CamVid show that our method outperforms the recent state-of-the-art methods.",0
"In recent years, video semantic segmentation has seen significant advancements due to the progress made in image semantic segmentation. However, per-frame image segmentation is generally not practical due to high computation costs. To address this issue, many researchers have used flow-based feature propagation to reuse features from previous frames. Unfortunately, optical flow estimation can be inaccurate and cause distortion in the propagated features. In this study, we propose a distortion-aware feature correction method to improve video segmentation performance by correcting distorted propagated features. Specifically, we transfer distortion patterns from features to image space and predict distortion maps. With the guidance of these maps, we use our Feature Correction Module (FCM) to rectify distorted features. Our approach significantly boosts segmentation accuracy at a low cost. Experimental results on Cityscapes and CamVid datasets demonstrate that our method outperforms the recent state-of-the-art methods.",1
"Deep learning (DL) models for disease classification or segmentation from medical images are increasingly trained using transfer learning (TL) from unrelated natural world images. However, shortcomings and utility of TL for specialized tasks in the medical imaging domain remain unknown and are based on assumptions that increasing training data will improve performance. We report detailed comparisons, rigorous statistical analysis and comparisons of widely used DL architecture for binary segmentation after TL with ImageNet initialization (TII-models) with supervised learning with only medical images(LMI-models) of macroscopic optical skin cancer, microscopic prostate core biopsy and Computed Tomography (CT) DICOM images. Through visual inspection of TII and LMI model outputs and their Grad-CAM counterparts, our results identify several counter intuitive scenarios where automated segmentation of one tumor by both models or the use of individual segmentation output masks in various combinations from individual models leads to 10% increase in performance. We also report sophisticated ensemble DL strategies for achieving clinical grade medical image segmentation and model explanations under low data regimes. For example; estimating performance, explanations and replicability of LMI and TII models described by us can be used for situations in which sparsity promotes better learning. A free GitHub repository of TII and LMI models, code and more than 10,000 medical images and their Grad-CAM output from this study can be used as starting points for advanced computational medicine and DL research for biomedical discovery and applications.",0
"DL models used for classifying or segmenting diseases in medical images are increasingly being trained using TL from unrelated natural world images. However, the effectiveness of TL for specialized tasks in medical imaging is still unclear and assumptions have been made that increasing training data will improve performance. This study compares and analyzes TII-models that use TL with ImageNet initialization and LMI-models that only use medical images for binary segmentation of macroscopic optical skin cancer, microscopic prostate core biopsy, and CT DICOM images. The results show that there are counter intuitive scenarios where automated segmentation by both models or the use of individual segmentation output masks from individual models leads to a 10% increase in performance. The study also reports sophisticated ensemble DL strategies for achieving clinical grade medical image segmentation and model explanations under low data regimes. The free GitHub repository of TII and LMI models, code, and more than 10,000 medical images and their Grad-CAM output can be used for advanced computational medicine and DL research for biomedical discovery and applications.",1
"Magnetic resonance (MR) protocols rely on several sequences to assess pathology and organ status properly. Despite advances in image analysis, we tend to treat each sequence, here termed modality, in isolation. Taking advantage of the common information shared between modalities (an organ's anatomy) is beneficial for multi-modality processing and learning. However, we must overcome inherent anatomical misregistrations and disparities in signal intensity across the modalities to obtain this benefit. We present a method that offers improved segmentation accuracy of the modality of interest (over a single input model), by learning to leverage information present in other modalities, even if few (semi-supervised) or no (unsupervised) annotations are available for this specific modality. Core to our method is learning a disentangled decomposition into anatomical and imaging factors. Shared anatomical factors from the different inputs are jointly processed and fused to extract more accurate segmentation masks. Image misregistrations are corrected with a Spatial Transformer Network, which non-linearly aligns the anatomical factors. The imaging factor captures signal intensity characteristics across different modality data and is used for image reconstruction, enabling semi-supervised learning. Temporal and slice pairing between inputs are learned dynamically. We demonstrate applications in Late Gadolinium Enhanced (LGE) and Blood Oxygenation Level Dependent (BOLD) cardiac segmentation, as well as in T2 abdominal segmentation. Code is available at https://github.com/vios-s/multimodal_segmentation.",0
"To properly evaluate organ status and pathology, Magnetic Resonance (MR) protocols use various sequences referred to as modalities. Despite advancements in image analysis, these modalities are often treated in isolation from one another. Taking advantage of the common anatomical information shared between modalities can improve multi-modality processing and learning. However, obstacles such as anatomical misregistrations and signal intensity differences across modalities must be overcome to reap these benefits. Our proposed method improves segmentation accuracy of the targeted modality by leveraging information from other modalities, even if annotations are limited or unavailable. This is achieved by disentangling anatomical and imaging factors, processing shared anatomical factors from various inputs, and correcting image misregistrations with a Spatial Transformer Network. Our approach allows for semi-supervised learning through the use of the imaging factor for image reconstruction. Dynamic learning of temporal and slice pairing between inputs is also employed. Our method is demonstrated in Late Gadolinium Enhanced (LGE) and Blood Oxygenation Level Dependent (BOLD) cardiac segmentation, as well as in T2 abdominal segmentation. Code for our method is available at https://github.com/vios-s/multimodal_segmentation.",1
"In autonomous Vehicles technology Image segmentation was a major problem in visual perception. This image segmentation process is mainly used in medical applications. Here we adopted an image segmentation process to visual perception tasks for predicting the agents on the surrounding environment, identifying the road boundaries and tracking the line markings. Main objective of the paper is to divide the input images using the image segmentation process and Convolution Neural Network method for efficient results of visual perception. For Sampling assume a local city data-set samples and validation process done in Jupyter Notebook using Python language. We proposed this image segmentation method planning to standard and further the development of state-of-the art methods for visual inspection system understanding. The experimental results achieves 73% mean IOU. Our method also achieves 90 FPS inference speed and using a NVDIA GeForce GTX 1050 GPU.",0
"The problem of image segmentation in visual perception has been a significant challenge in the development of autonomous vehicle technology. While image segmentation is commonly used in medical applications, we have applied this process to predict the agents in the surrounding environment, identify road boundaries, and track line markings. Our paper aims to utilize image segmentation and Convolution Neural Network methods to efficiently divide input images and improve visual perception. We utilized a local city dataset for sampling and validation in Jupyter Notebook using Python. Our proposed image segmentation method is intended to standardize and advance state-of-the-art methods for visual inspection systems. Through experimentation, we achieved a mean IOU of 73% and an inference speed of 90 FPS using an NVDIA GeForce GTX 1050 GPU.",1
"The Jaccard index, also known as Intersection-over-Union (IoU score), is one of the most critical evaluation metrics in medical image segmentation. However, directly optimizing the mean IoU (mIoU) score over multiple objective classes is an open problem. Although some algorithms have been proposed to optimize its surrogates, there is no guarantee provided for their generalization ability. In this paper, we present a novel data-distribution-aware margin calibration method for a better generalization of the mIoU over the whole data-distribution, underpinned by a rigid lower bound. This scheme ensures a better segmentation performance in terms of IoU scores in practice. We evaluate the effectiveness of the proposed margin calibration method on two medical image segmentation datasets, showing substantial improvements of IoU scores over other learning schemes using deep segmentation models.",0
"Medical image segmentation heavily relies on the Jaccard index, also known as Intersection-over-Union (IoU score), which is a crucial evaluation metric. However, optimizing the mean IoU (mIoU) score directly for multiple objective classes remains a challenge. Despite proposed algorithms to optimize its surrogates, their generalization ability is not guaranteed. This paper proposes a novel data-distribution-aware margin calibration method that ensures better generalization of the mIoU over the entire data-distribution, with a rigid lower bound. This method leads to better segmentation performance in terms of IoU scores. By evaluating on two medical image segmentation datasets, we demonstrate significant improvements in IoU scores compared to other learning schemes using deep segmentation models.",1
"Waste recycling is an important way of saving energy and materials in the production process. In general cases recyclable objects are mixed with unrecyclable objects, which raises a need for identification and classification. This paper proposes a convolutional neural network (CNN) model to complete both tasks. The model uses transfer learning from a pretrained Resnet-50 CNN to complete feature extraction. A subsequent fully connected layer for classification was trained on the augmented TrashNet dataset [1]. In the application, sliding-window is used for image segmentation in the pre-classification stage. In the post-classification stage, the labelled sample points are integrated with Gaussian Clustering to locate the object. The resulting model has achieved an overall detection rate of 48.4% in simulation and final classification accuracy of 92.4%.",0
"Recycling waste is a crucial method for conserving energy and materials during production. Typically, recyclable items are mixed with non-recyclable ones, necessitating identification and classification. This article proposes a convolutional neural network (CNN) model that performs both functions. The model employs transfer learning from a pre-existing Resnet-50 CNN for feature extraction. A fully connected layer for classification was then trained on the augmented TrashNet dataset [1]. In the pre-classification stage, sliding-window segmentation is employed on images. In the post-classification stage, labelled sample points are combined with Gaussian Clustering to locate objects. The resulting model boasts a 48.4% detection rate in simulation and a final classification accuracy of 92.4%.",1
"Working with images, one often faces problems with incomplete or unclear information. Image inpainting can be used to restore missing image regions but focuses, however, on low-level image features such as pixel intensity, pixel gradient orientation, and color. This paper aims to recover semantic image features (objects and positions) in images. Based on published gated PixelCNNs, we demonstrate a new approach referred to as quadro-directional PixelCNN to recover missing objects and return probable positions for objects based on the context. We call this approach context-based image segment labeling (CBISL). The results suggest that our four-directional model outperforms one-directional models (gated PixelCNN) and returns a human-comparable performance.",0
"Incomplete or unclear information often presents challenges when working with images. Image inpainting is a method used to restore missing regions of an image, but it only considers low-level features such as pixel intensity, gradient orientation, and color. In this paper, we propose a new approach called quadro-directional PixelCNN that focuses on recovering semantic image features like objects and positions. Our method, called context-based image segment labeling (CBISL), is based on published gated PixelCNNs. By analyzing the context, our model can identify missing objects and predict their probable positions. Our results demonstrate that the four-directional model outperforms the one-directional models (gated PixelCNN) and achieves performance comparable to that of a human.",1
"Scene understanding is an essential technique in semantic segmentation. Although there exist several datasets that can be used for semantic segmentation, they are mainly focused on semantic image segmentation with large deep neural networks. Therefore, these networks are not useful for real time applications, especially in autonomous driving systems. In order to solve this problem, we make two contributions to semantic segmentation task. The first contribution is that we introduce the semantic video dataset, the Highway Driving dataset, which is a densely annotated benchmark for a semantic video segmentation task. The Highway Driving dataset consists of 20 video sequences having a 30Hz frame rate, and every frame is densely annotated. Secondly, we propose a baseline algorithm that utilizes a temporal correlation. Together with our attempt to analyze the temporal correlation, we expect the Highway Driving dataset to encourage research on semantic video segmentation.",0
"Semantic segmentation relies heavily on scene understanding, but current datasets are mainly geared towards semantic image segmentation using deep neural networks, which are not ideal for real-time applications such as autonomous driving. To address this issue, we offer two contributions to the semantic segmentation task. Firstly, we introduce the Highway Driving dataset, a densely annotated benchmark containing 20 video sequences with a 30Hz frame rate. Secondly, we propose a baseline algorithm that utilizes temporal correlation. By analyzing this correlation and utilizing the Highway Driving dataset, we hope to inspire further research into semantic video segmentation.",1
"A key requirement for the success of supervised deep learning is a large labeled dataset - a condition that is difficult to meet in medical image analysis. Self-supervised learning (SSL) can help in this regard by providing a strategy to pre-train a neural network with unlabeled data, followed by fine-tuning for a downstream task with limited annotations. Contrastive learning, a particular variant of SSL, is a powerful technique for learning image-level representations. In this work, we propose strategies for extending the contrastive learning framework for segmentation of volumetric medical images in the semi-supervised setting with limited annotations, by leveraging domain-specific and problem-specific cues. Specifically, we propose (1) novel contrasting strategies that leverage structural similarity across volumetric medical images (domain-specific cue) and (2) a local version of the contrastive loss to learn distinctive representations of local regions that are useful for per-pixel segmentation (problem-specific cue). We carry out an extensive evaluation on three Magnetic Resonance Imaging (MRI) datasets. In the limited annotation setting, the proposed method yields substantial improvements compared to other self-supervision and semi-supervised learning techniques. When combined with a simple data augmentation technique, the proposed method reaches within 8% of benchmark performance using only two labeled MRI volumes for training, corresponding to only 4% (for ACDC) of the training data used to train the benchmark. The code is made public at https://github.com/krishnabits001/domain_specific_cl.",0
"Medical image analysis poses a challenge for supervised deep learning as it requires a significant amount of labeled data, which is difficult to obtain. Self-supervised learning (SSL) is a potential solution that involves pre-training a neural network with unlabeled data, followed by fine-tuning with limited annotations for a downstream task. Within SSL, contrastive learning is a powerful technique for learning image-level representations. This paper proposes strategies to extend the contrastive learning framework for segmenting volumetric medical images in the semi-supervised setting with limited annotations, by utilizing domain-specific and problem-specific cues. The proposed methods include novel contrasting strategies that leverage structural similarity across volumetric medical images and a local version of the contrastive loss to learn distinctive representations of local regions for per-pixel segmentation. The proposed method is evaluated on three Magnetic Resonance Imaging (MRI) datasets and outperforms other self-supervision and semi-supervised learning techniques in the limited annotation setting. When combined with a simple data augmentation technique, the proposed method yields performance close to the benchmark using only two labeled MRI volumes for training, corresponding to 4% of the training data used to train the benchmark. The code is publicly available at https://github.com/krishnabits001/domain_specific_cl.",1
"Although deep neural networks have been a dominant method for many 2D vision tasks, it is still challenging to apply them to 3D tasks, such as medical image segmentation, due to the limited amount of annotated 3D data and limited computational resources. In this chapter, by rethinking the strategy to apply 3D Convolutional Neural Networks to segment medical images, we propose a novel 3D-based coarse-to-fine framework to efficiently tackle these challenges. The proposed 3D-based framework outperforms their 2D counterparts by a large margin since it can leverage the rich spatial information along all three axes. We further analyze the threat of adversarial attacks on the proposed framework and show how to defense against the attack. We conduct experiments on three datasets, the NIH pancreas dataset, the JHMI pancreas dataset and the JHMI pathological cyst dataset, where the first two and the last one contain healthy and pathological pancreases respectively, and achieve the current state-of-the-art in terms of Dice-Sorensen Coefficient (DSC) on all of them. Especially, on the NIH pancreas segmentation dataset, we outperform the previous best by an average of over $2\%$, and the worst case is improved by $7\%$ to reach almost $70\%$, which indicates the reliability of our framework in clinical applications.",0
"Despite being a widely used method for 2D vision tasks, deep neural networks face difficulties when applied to 3D tasks like medical image segmentation. This is due to the limited availability of annotated 3D data and computational resources. In this chapter, we present a new approach to segment medical images using a 3D-based coarse-to-fine framework that outperforms 2D counterparts by leveraging spatial information along all three axes. We also address the threat of adversarial attacks and demonstrate the effectiveness of our defense strategy. Our experiments on three datasets, including healthy and pathological pancreases, show that our framework achieves state-of-the-art results in terms of Dice-Sorensen Coefficient (DSC). Notably, we improve the previous best results on the NIH pancreas segmentation dataset by over 2%, with the worst-case performance improving by 7% to nearly 70%, demonstrating the reliability of our framework for clinical applications.",1
"Recent years have seen increasing use of supervised learning methods for segmentation tasks. However, the predictive performance of these algorithms depends on the quality of labels. This problem is particularly pertinent in the medical image domain, where both the annotation cost and inter-observer variability are high. In a typical label acquisition process, different human experts provide their estimates of the ""true"" segmentation labels under the influence of their own biases and competence levels. Treating these noisy labels blindly as the ground truth limits the performance that automatic segmentation algorithms can achieve. In this work, we present a method for jointly learning, from purely noisy observations alone, the reliability of individual annotators and the true segmentation label distributions, using two coupled CNNs. The separation of the two is achieved by encouraging the estimated annotators to be maximally unreliable while achieving high fidelity with the noisy training data. We first define a toy segmentation dataset based on MNIST and study the properties of the proposed algorithm. We then demonstrate the utility of the method on three public medical imaging segmentation datasets with simulated (when necessary) and real diverse annotations: 1) MSLSC (multiple-sclerosis lesions); 2) BraTS (brain tumours); 3) LIDC-IDRI (lung abnormalities). In all cases, our method outperforms competing methods and relevant baselines particularly in cases where the number of annotations is small and the amount of disagreement is large. The experiments also show strong ability to capture the complex spatial characteristics of annotators' mistakes.",0
"Supervised learning methods have become increasingly popular for segmentation tasks in recent years. However, the accuracy of these algorithms relies heavily on the quality of labels, which is a major issue in the medical image field due to high annotation costs and inter-observer variability. The traditional label acquisition process involves multiple experts providing their estimates of the ""true"" segmentation labels, which can be influenced by their own biases and competence levels. Blindly treating these noisy labels as the ground truth limits the performance of automatic segmentation algorithms. This study presents a method for jointly learning the reliability of individual annotators and the true segmentation label distributions using two coupled CNNs, which are separated by encouraging the estimated annotators to be maximally unreliable while achieving high fidelity with the noisy training data. The proposed algorithm is tested on a toy segmentation dataset based on MNIST and three public medical imaging segmentation datasets with simulated and real diverse annotations: MSLSC, BraTS, and LIDC-IDRI. The results show that the proposed method outperforms competing methods and relevant baselines, particularly in cases where the number of annotations is small and the amount of disagreement is large. The experiments also demonstrate strong ability to capture the complex spatial characteristics of annotators' mistakes.",1
"Standard segmentation of medical images based on full-supervised convolutional networks demands accurate dense annotations. Such learning framework is built on laborious manual annotation with restrict demands for expertise, leading to insufficient high-quality labels. To overcome such limitation and exploit massive weakly labeled data, we relaxed the rigid labeling requirement and developed a semi-supervised learning framework based on a teacher-student fashion for organ and lesion segmentation with partial dense-labeled supervision and supplementary loose bounding-box supervision which are easier to acquire. Observing the geometrical relation of an organ and its inner lesions in most cases, we propose a hierarchical organ-to-lesion (O2L) attention module in a teacher segmentor to produce pseudo-labels. Then a student segmentor is trained with combinations of manual-labeled and pseudo-labeled annotations. We further proposed a localization branch realized via an aggregation of high-level features in a deep decoder to predict locations of organ and lesion, which enriches student segmentor with precise localization information. We validated each design in our model on LiTS challenge datasets by ablation study and showed its state-of-the-art performance compared with recent methods. We show our model is robust to the quality of bounding box and achieves comparable performance compared with full-supervised learning methods.",0
"Medical image segmentation using fully-supervised convolutional networks requires accurate dense annotations, which are difficult and time-consuming to obtain. This results in a shortage of high-quality labels, limiting the effectiveness of the learning framework. In order to overcome this issue and make use of weakly-labeled data, we developed a semi-supervised learning framework for organ and lesion segmentation using a teacher-student approach. This involves partial dense-labeled supervision and loose bounding-box supervision, which are easier to acquire. Our approach makes use of the geometrical relationship between organs and their lesions and includes a hierarchical organ-to-lesion attention module in the teacher segmentor to generate pseudo-labels. The student segmentor is then trained using a combination of manual and pseudo-labeled annotations. Additionally, we proposed a localization branch to predict the locations of the organs and lesions with high precision. Our approach was validated on LiTS challenge datasets and showed state-of-the-art performance compared to recent methods. We demonstrated that our model is robust to the quality of the bounding box and achieves comparable performance to fully-supervised learning methods.",1
"Continual learning protocols are attracting increasing attention from the medical imaging community. In a continual setup, data from different sources arrives sequentially and each batch is only available for a limited period. Given the inherent privacy risks associated with medical data, this setup reflects the reality of deployment for deep learning diagnostic radiology systems. Many techniques exist to learn continuously for classification tasks, and several have been adapted to semantic segmentation. Yet most have at least one of the following flaws: a) they rely too heavily on domain identity information during inference, or b) data as seen in early training stages does not profit from training with later data. In this work, we propose an evaluation framework that addresses both concerns, and introduce a fair multi-model benchmark. We show that the benchmark outperforms two popular continual learning methods for the task of T2-weighted MR prostate segmentation.",0
"The medical imaging community is increasingly interested in continual learning protocols. In this type of learning, data from various sources is received sequentially and is only accessible for a limited time. Due to the risk of privacy breaches in medical data, this type of setup is typical for deep learning diagnostic radiology systems. There are various techniques available for continuous learning for classification tasks, and some of them have been adapted for semantic segmentation. However, most of them have flaws, such as relying too much on domain identity information during inference or not benefiting from later data. In this study, we introduce an evaluation framework that addresses both flaws and a fair multi-model benchmark. We demonstrate that the benchmark outperforms two popular continual learning methods for T2-weighted MR prostate segmentation.",1
"An automatic image segmentation procedure is an inevitable part of many image analyses and computer vision which deeply affect the rest of the system; therefore, a set of interactive segmentation evaluation methods can substantially simplify the system development process. This entry presents the state of the art of quantitative evaluation metrics for color image segmentation methods by performing an analytical and comparative review of the measures. The decision-making process in selecting a suitable evaluation metric is still very serious because each metric tends to favor a different segmentation method for each benchmark dataset. Furthermore, a conceptual comparison of these metrics is provided at a high level of abstraction and is discussed for understanding the quantitative changes in different image segmentation results.",0
"Many image analyses and computer vision rely on automatic image segmentation procedures, which have a significant impact on the overall system. To simplify the system development process, interactive segmentation evaluation methods are essential. This article provides a comprehensive review of the current quantitative evaluation metrics for color image segmentation methods. However, selecting an appropriate evaluation metric remains a crucial decision-making process, as each metric tends to favor a different segmentation method for each benchmark dataset. Additionally, a high-level conceptual comparison of these metrics is discussed to aid in understanding the quantitative changes in various image segmentation results.",1
"For the Convolutional Neural Networks (CNNs) applied in the intelligent diagnosis of gastric cancer, existing methods mostly focus on individual characteristics or network frameworks without a policy to depict the integral information. Mainly, Conditional Random Field (CRF), an efficient and stable algorithm for analyzing images containing complicated contents, can characterize spatial relation in images. In this paper, a novel Hierarchical Conditional Random Field (HCRF) based Gastric Histopathology Image Segmentation (GHIS) method is proposed, which can automatically localize abnormal (cancer) regions in gastric histopathology images obtained by an optical microscope to assist histopathologists in medical work. This HCRF model is built up with higher order potentials, including pixel-level and patch-level potentials, and graph-based post-processing is applied to further improve its segmentation performance. Especially, a CNN is trained to build up the pixel-level potentials and another three CNNs are fine-tuned to build up the patch-level potentials for sufficient spatial segmentation information. In the experiment, a hematoxylin and eosin (H&E) stained gastric histopathological dataset with 560 abnormal images are divided into training, validation and test sets with a ratio of 1 : 1 : 2. Finally, segmentation accuracy, recall and specificity of 78.91%, 65.59%, and 81.33% are achieved on the test set. Our HCRF model demonstrates high segmentation performance and shows its effectiveness and future potential in the GHIS field.",0
"Current methods for using Convolutional Neural Networks (CNNs) to diagnose gastric cancer focus on individual characteristics or network frameworks, rather than providing a holistic view. Conditional Random Field (CRF) is an algorithm that can analyze complex images and characterize spatial relations. This paper proposes a novel Hierarchical Conditional Random Field (HCRF)-based Gastric Histopathology Image Segmentation (GHIS) method, which automatically locates abnormal regions in gastric histopathology images obtained by an optical microscope. The HCRF model uses higher order potentials, including pixel-level and patch-level potentials, and graph-based post-processing to improve segmentation performance. The model is trained using a CNN for pixel-level potentials and three fine-tuned CNNs for patch-level potentials. The experiment uses a hematoxylin and eosin (H&E) stained gastric histopathological dataset and achieves segmentation accuracy, recall, and specificity of 78.91%, 65.59%, and 81.33% on the test set. The HCRF model demonstrates high segmentation performance and potential for future use in GHIS.",1
"Accurate and efficient catheter segmentation in 3D ultrasound (US) is essential for cardiac intervention. Currently, the state-of-the-art segmentation algorithms are based on convolutional neural networks (CNNs), which achieved remarkable performances in a standard Cartesian volumetric data. Nevertheless, these approaches suffer the challenges of low efficiency and GPU unfriendly image size. Therefore, such difficulties and expensive hardware requirements become a bottleneck to build accurate and efficient segmentation models for real clinical application. In this paper, we propose a novel Frustum ultrasound based catheter segmentation method. Specifically, Frustum ultrasound is a polar coordinate based image, which includes same information of standard Cartesian image but has much smaller size, which overcomes the bottleneck of efficiency than conventional Cartesian images. Nevertheless, the irregular and deformed Frustum images lead to more efforts for accurate voxel-level annotation. To address this limitation, a weakly supervised learning framework is proposed, which only needs 3D bounding box annotations overlaying the region-of-interest to training the CNNs. Although the bounding box annotation includes noise and inaccurate annotation to mislead to model, it is addressed by the proposed pseudo label generated scheme. The labels of training voxels are generated by incorporating class activation maps with line filtering, which is iteratively updated during the training. Our experimental results show the proposed method achieved the state-of-the-art performance with an efficiency of 0.25 second per volume. More crucially, the Frustum image segmentation provides a much faster and cheaper solution for segmentation in 3D US image, which meet the demands of clinical applications.",0
"In order to perform cardiac intervention, accurate and efficient catheter segmentation in 3D ultrasound (US) is crucial. Currently, convolutional neural networks (CNNs) are the state-of-the-art algorithms for segmentation, achieving impressive results with standard Cartesian volumetric data. However, these methods are challenged by low efficiency and GPU-unfriendly image sizes, which makes building accurate and efficient segmentation models difficult for real clinical application. To address these issues, a new Frustum ultrasound based catheter segmentation method is proposed. Frustum ultrasound is a polar coordinate based image that includes the same information as standard Cartesian images but with a much smaller size, making it more efficient. However, the irregular and deformed Frustum images require more effort for accurate voxel-level annotation. To solve this problem, a weakly supervised learning framework is proposed that only requires 3D bounding box annotations for training. Although these annotations may include noise and inaccurate annotation, a pseudo label generated scheme is employed to address this issue. The proposed method achieved state-of-the-art performance with an efficiency of 0.25 seconds per volume. The Frustum image segmentation provides a faster and cheaper solution for segmentation in 3D US images that meets the demands of clinical applications.",1
"Computer vision technology is widely used in biological and medical data analysis and understanding. However, there are still two major bottlenecks in the field of cell membrane segmentation, which seriously hinder further research: lack of sufficient high-quality data and lack of suitable evaluation criteria. In order to solve these two problems, this paper first proposes an Ultra-high Resolution Image Segmentation dataset for the Cell membrane, called U-RISC, the largest annotated Electron Microscopy (EM) dataset for the Cell membrane with multiple iterative annotations and uncompressed high-resolution raw data. During the analysis process of the U-RISC, we found that the current popular segmentation evaluation criteria are inconsistent with human perception. This interesting phenomenon is confirmed by a subjective experiment involving twenty people. Furthermore, to resolve this inconsistency, we propose a new evaluation criterion called Perceptual Hausdorff Distance (PHD) to measure the quality of cell membrane segmentation results. Detailed performance comparison and discussion of classic segmentation methods along with two iterative manual annotation results under existing evaluation criteria and PHD is given.",0
"The utilization of computer vision technology has proliferated in the analysis and comprehension of biological and medical data. Nonetheless, the field of cell membrane segmentation faces two primary obstructions that impede further research: the lack of adequate high-quality data and the absence of appropriate assessment standards. To tackle these challenges, this article introduces a new Ultra-high Resolution Image Segmentation dataset for the Cell membrane, called U-RISC, which constitutes the most significant annotated Electron Microscopy (EM) dataset for the Cell membrane, featuring numerous iterative annotations and uncompressed high-resolution raw data. During the analysis of the U-RISC, it became apparent that the presently prevalent segmentation assessment standards do not align with human perception. This intriguing phenomenon was confirmed via a subjective experiment involving twenty individuals. Moreover, to address this inconsistency, we propose a novel evaluation standard known as Perceptual Hausdorff Distance (PHD) to gauge the quality of cell membrane segmentation outcomes. The article provides a detailed comparison and discussion of the performance of classic segmentation techniques, along with two iterative manual annotation outcomes, under both the existing evaluation criteria and PHD.",1
"This paper addresses representational block named Hierarchical-Split Block, which can be taken as a plug-and-play block to upgrade existing convolutional neural networks, improves model performance significantly in a network. Hierarchical-Split Block contains many hierarchical split and concatenate connections within one single residual block. We find multi-scale features is of great importance for numerous vision tasks. Moreover, Hierarchical-Split block is very flexible and efficient, which provides a large space of potential network architectures for different applications. In this work, we present a common backbone based on Hierarchical-Split block for tasks: image classification, object detection, instance segmentation and semantic image segmentation/parsing. Our approach shows significant improvements over all these core tasks in comparison with the baseline. As shown in Figure1, for image classification, our 50-layers network(HS-ResNet50) achieves 81.28% top-1 accuracy with competitive latency on ImageNet-1k dataset. It also outperforms most state-of-the-art models. The source code and models will be available on: https://github.com/PaddlePaddle/PaddleClas",0
"The Hierarchical-Split Block is a representational block discussed in this paper. It can be used as a plug-and-play block to enhance the performance of existing convolutional neural networks. The block comprises multiple hierarchical split and concatenate connections within a single residual block. We have observed that multi-scale features are crucial for various vision tasks. The Hierarchical-Split Block is highly flexible and efficient, allowing for the creation of diverse network architectures for different applications. In this study, we propose a common backbone based on the Hierarchical-Split Block for tasks such as image classification, object detection, instance segmentation, and semantic image segmentation/parsing. Our approach outperforms the baseline in all these core tasks as demonstrated in Figure1. For instance, our 50-layers network (HS-ResNet50) achieves a top-1 accuracy of 81.28% on the ImageNet-1k dataset with competitive latency, surpassing most state-of-the-art models. The source code and models are available on https://github.com/PaddlePaddle/PaddleClas.",1
"Road network and building footprint extraction is essential for many applications such as updating maps, traffic regulations, city planning, ride-hailing, disaster response \textit{etc}. Mapping road networks is currently both expensive and labor-intensive. Recently, improvements in image segmentation through the application of deep neural networks has shown promising results in extracting road segments from large scale, high resolution satellite imagery. However, significant challenges remain due to lack of enough labeled training data needed to build models for industry grade applications. In this paper, we propose a two-stage transfer learning technique to improve robustness of semantic segmentation for satellite images that leverages noisy pseudo ground truth masks obtained automatically (without human labor) from crowd-sourced OpenStreetMap (OSM) data. We further propose Pyramid Pooling-LinkNet (PP-LinkNet), an improved deep neural network for segmentation that uses focal loss, poly learning rate, and context module. We demonstrate the strengths of our approach through evaluations done on three popular datasets over two tasks, namely, road extraction and building foot-print detection. Specifically, we obtain 78.19\% meanIoU on SpaceNet building footprint dataset, 67.03\% and 77.11\% on the road topology metric on SpaceNet and DeepGlobe road extraction dataset, respectively.",0
"The extraction of road networks and building footprints is crucial for various applications, including city planning, traffic regulations, disaster response, ride-hailing, updating maps, among others. However, this process is currently expensive and requires a lot of labor. Recent advancements in deep neural networks have shown promising results in extracting road segments from high-resolution satellite images through image segmentation. Nonetheless, there are still significant challenges due to limited labeled training data for industry-grade applications. This paper presents a two-stage transfer learning technique that uses noisy pseudo ground truth masks from crowd-sourced OpenStreetMap data to improve semantic segmentation for satellite images. Additionally, we introduce a better deep neural network for segmentation, PP-LinkNet, which employs focal loss, poly learning rate, and a context module. We evaluate our approach on three popular datasets for two tasks: road extraction and building foot-print detection, achieving a meanIoU of 78.19% on the SpaceNet building footprint dataset, and 67.03% and 77.11% on the SpaceNet and DeepGlobe road extraction datasets, respectively.",1
"Deep convolutional neural networks have significantly boosted the performance of fundus image segmentation when test datasets have the same distribution as the training datasets. However, in clinical practice, medical images often exhibit variations in appearance for various reasons, e.g., different scanner vendors and image quality. These distribution discrepancies could lead the deep networks to over-fit on the training datasets and lack generalization ability on the unseen test datasets. To alleviate this issue, we present a novel Domain-oriented Feature Embedding (DoFE) framework to improve the generalization ability of CNNs on unseen target domains by exploring the knowledge from multiple source domains. Our DoFE framework dynamically enriches the image features with additional domain prior knowledge learned from multi-source domains to make the semantic features more discriminative. Specifically, we introduce a Domain Knowledge Pool to learn and memorize the prior information extracted from multi-source domains. Then the original image features are augmented with domain-oriented aggregated features, which are induced from the knowledge pool based on the similarity between the input image and multi-source domain images. We further design a novel domain code prediction branch to infer this similarity and employ an attention-guided mechanism to dynamically combine the aggregated features with the semantic features. We comprehensively evaluate our DoFE framework on two fundus image segmentation tasks, including the optic cup and disc segmentation and vessel segmentation. Our DoFE framework generates satisfying segmentation results on unseen datasets and surpasses other domain generalization and network regularization methods.",0
"The use of deep convolutional neural networks has greatly improved the accuracy of fundus image segmentation, but only when the testing data matches the training data. In reality, medical images can vary in appearance due to factors such as different scanners or varying image quality. This can cause over-fitting on the training data and poor performance on new test data. To address this issue, a new Domain-oriented Feature Embedding (DoFE) framework has been developed to improve the generalization ability of CNNs by incorporating knowledge from multiple source domains. The DoFE framework utilizes a Domain Knowledge Pool to extract information from multiple domains and enriches the image features to make them more discriminative. Additionally, a domain code prediction branch is employed to assess the similarity between the input image and the multi-source domain images, and an attention-guided mechanism is used to combine the augmented features with the semantic features. The DoFE framework has been successfully tested on optic cup and disc segmentation and vessel segmentation, outperforming other domain generalization and network regularization methods.",1
"Few-shot semantic segmentation (FSS) has great potential for medical imaging applications. Most of the existing FSS techniques require abundant annotated semantic classes for training. However, these methods may not be applicable for medical images due to the lack of annotations. To address this problem we make several contributions: (1) A novel self-supervised FSS framework for medical images in order to eliminate the requirement for annotations during training. Additionally, superpixel-based pseudo-labels are generated to provide supervision; (2) An adaptive local prototype pooling module plugged into prototypical networks, to solve the common challenging foreground-background imbalance problem in medical image segmentation; (3) We demonstrate the general applicability of the proposed approach for medical images using three different tasks: abdominal organ segmentation for CT and MRI, as well as cardiac segmentation for MRI. Our results show that, for medical image segmentation, the proposed method outperforms conventional FSS methods which require manual annotations for training.",0
"The potential of few-shot semantic segmentation (FSS) in medical imaging applications is significant. However, most existing FSS techniques rely on abundant annotated semantic classes for training, which is not feasible for medical images due to the lack of annotations. To address this issue, we present several contributions: (1) We propose a novel self-supervised FSS framework for medical images that eliminates the need for annotations during training. We generate superpixel-based pseudo-labels to provide supervision. (2) We introduce an adaptive local prototype pooling module integrated into prototypical networks to overcome the foreground-background imbalance problem common in medical image segmentation. (3) We demonstrate the versatility of our approach for medical images through three different tasks: abdominal organ segmentation for CT and MRI, as well as cardiac segmentation for MRI. Our findings indicate that our proposed method surpasses conventional FSS methods that require manual annotations for training in medical image segmentation.",1
"We present a novel region based active learning method for semantic image segmentation, called MetaBox+. For acquisition, we train a meta regression model to estimate the segment-wise Intersection over Union (IoU) of each predicted segment of unlabeled images. This can be understood as an estimation of segment-wise prediction quality. Queried regions are supposed to minimize to competing targets, i.e., low predicted IoU values / segmentation quality and low estimated annotation costs. For estimating the latter we propose a simple but practical method for annotation cost estimation. We compare our method to entropy based methods, where we consider the entropy as uncertainty of the prediction. The comparison and analysis of the results provide insights into annotation costs as well as robustness and variance of the methods. Numerical experiments conducted with two different networks on the Cityscapes dataset clearly demonstrate a reduction of annotation effort compared to random acquisition. Noteworthily, we achieve 95%of the mean Intersection over Union (mIoU), using MetaBox+ compared to when training with the full dataset, with only 10.47% / 32.01% annotation effort for the two networks, respectively.",0
"Our study introduces a new approach to active learning called MetaBox+ which is designed for semantic image segmentation. Our method involves training a meta regression model to predict the segment-wise Intersection over Union (IoU) for unlabeled images, indicating the quality of segmentation prediction. Our goal is to select regions with low predicted IoU values and annotation costs. To estimate annotation costs, we propose a practical method. This approach is compared with entropy-based methods, which consider the entropy as a measure of prediction uncertainty. The results of our analysis provide insights into the methods' robustness, variance, and annotation costs. We conducted experiments on the Cityscapes dataset with two different networks, and our approach significantly reduced the annotation effort compared to random acquisition. Impressively, we achieved 95% of the mean Intersection over Union (mIoU) with MetaBox+ compared to full dataset training, with only 10.47% / 32.01% annotation effort for the two networks, respectively.",1
"Referring image segmentation aims to predict the foreground mask of the object referred by a natural language sentence. Multimodal context of the sentence is crucial to distinguish the referent from the background. Existing methods either insufficiently or redundantly model the multimodal context. To tackle this problem, we propose a ""gather-propagate-distribute"" scheme to model multimodal context by cross-modal interaction and implement this scheme as a novel Linguistic Structure guided Context Modeling (LSCM) module. Our LSCM module builds a Dependency Parsing Tree suppressed Word Graph (DPT-WG) which guides all the words to include valid multimodal context of the sentence while excluding disturbing ones through three steps over the multimodal feature, i.e., gathering, constrained propagation and distributing. Extensive experiments on four benchmarks demonstrate that our method outperforms all the previous state-of-the-arts.",0
"The goal of image segmentation in reference is to predict the foreground mask of an object mentioned in a natural language sentence. The context of the sentence is important in distinguishing the referent from the background. However, current methods either fail to fully consider or redundantly model the multimodal context. To address this issue, we propose a ""gather-propagate-distribute"" approach that utilizes cross-modal interaction to model the multimodal context. Our novel Linguistic Structure guided Context Modeling (LSCM) module implements this approach. The LSCM module constructs a Dependency Parsing Tree suppressed Word Graph (DPT-WG) that guides all words to incorporate valid multimodal context while filtering out irrelevant context. This is done through three steps: gathering, constrained propagation, and distributing. Our experiments on four benchmarks demonstrate that our method outperforms all previous state-of-the-art techniques.",1
"Image segmentation has long been a basic problem in computer vision. Depth-wise Layering is a kind of segmentation that slices an image in a depth-wise sequence unlike the conventional image segmentation problems dealing with surface-wise decomposition. The proposed Depth-wise Layering technique uses a single depth image of a static scene to slice it into multiple layers. The technique employs a thresholding approach to segment rows of the dense depth map into smaller partitions called Line-Segments in this paper. Then, it uses the line-segment labelling method to identify number of objects and layers of the scene independently. The final stage is to link objects of the scene to their respective object-layers. We evaluate the efficiency of the proposed technique by applying that on many images along with their dense depth maps. The experiments have shown promising results of layering.",0
"For a while now, computer vision has faced the challenge of image segmentation. However, Depth-wise Layering presents a new type of segmentation that differs from the conventional approach of surface-wise decomposition. This technique involves using a single depth image of a stationary scene and segmenting it into multiple layers in a depth-wise sequence. To achieve this, the technique uses a thresholding approach to partition rows of the dense depth map into smaller segments referred to as Line-Segments. Additionally, the line-segment labeling method is utilized to identify the number of objects and layers in the scene independently. The final step is to link each object to its respective object-layer. We tested the effectiveness of this technique by applying it to various images along with their dense depth maps. The results of the experiments were promising in terms of layering accuracy.",1
"Image normalization is a building block in medical image analysis. Conventional approaches are customarily utilized on a per-dataset basis. This strategy, however, prevents the current normalization algorithms from fully exploiting the complex joint information available across multiple datasets. Consequently, ignoring such joint information has a direct impact on the performance of segmentation algorithms. This paper proposes to revisit the conventional image normalization approach by instead learning a common normalizing function across multiple datasets. Jointly normalizing multiple datasets is shown to yield consistent normalized images as well as an improved image segmentation. To do so, a fully automated adversarial and task-driven normalization approach is employed as it facilitates the training of realistic and interpretable images while keeping performance on-par with the state-of-the-art. The adversarial training of our network aims at finding the optimal transfer function to improve both the segmentation accuracy and the generation of realistic images. We evaluated the performance of our normalizer on both infant and adult brains images from the iSEG, MRBrainS and ABIDE datasets. Results reveal the potential of our normalization approach for segmentation, with Dice improvements of up to 57.5% over our baseline. Our method can also enhance data availability by increasing the number of samples available when learning from multiple imaging domains.",0
"Medical image analysis relies heavily on image normalization, which is typically performed on a per-dataset basis using conventional approaches. However, this strategy fails to leverage the joint information that exists across multiple datasets, leading to suboptimal performance in segmentation algorithms. To overcome this limitation, this paper proposes a novel approach that involves learning a common normalizing function across multiple datasets. By jointly normalizing multiple datasets, this method yields consistent normalized images and improves image segmentation. The proposed approach involves using a fully automated adversarial and task-driven normalization approach that facilitates the training of realistic and interpretable images while maintaining state-of-the-art performance. Our network is trained using an adversarial approach to find the optimal transfer function for improving both segmentation accuracy and the generation of realistic images. Our approach was evaluated using infant and adult brain images from the iSEG, MRBrainS, and ABIDE datasets, and results show that our normalization approach can significantly improve segmentation performance, with Dice improvements of up to 57.5% over our baseline. Additionally, our method has the potential to increase data availability by increasing the number of samples available for learning from multiple imaging domains.",1
"In recent years, deep learning techniques (e.g., U-Net, DeepLab) have achieved tremendous success in image segmentation. The performance of these models heavily relies on high-quality ground truth segment labels. Unfortunately, in many real-world problems, ground truth segment labels often have geometric annotation errors due to manual annotation mistakes, GPS errors, or visually interpreting background imagery at a coarse resolution. Such location errors will significantly impact the training performance of existing deep learning algorithms. Existing research on label errors either models ground truth errors in label semantics (assuming label locations to be correct) or models label location errors with simple square patch shifting. These methods cannot fully incorporate the geometric properties of label location errors. To fill the gap, this paper proposes a generic learning framework based on the EM algorithm to update deep learning model parameters and infer hidden true label locations simultaneously. Evaluations on a real-world hydrological dataset in the streamline refinement application show that the proposed framework outperforms baseline methods in classification accuracy (reducing the number of false positives by 67% and reducing the number of false negatives by 55%).",0
"In recent times, image segmentation has seen remarkable success through the use of deep learning techniques such as U-Net and DeepLab. However, the performance of such models heavily relies on the accuracy of ground truth segment labels. In real-world scenarios, geometric annotation errors are common due to errors in manual annotation, GPS, or interpreting background imagery at a coarse resolution. These location errors can have a significant impact on the performance of deep learning algorithms. Current research in label errors either assumes label locations to be correct or models label location errors with simple square patch shifting, without fully considering the geometric properties of these errors. This paper proposes a learning framework based on the EM algorithm to update deep learning model parameters and infer hidden true label locations simultaneously, bridging this gap. Evaluations on a real-world hydrological dataset in the streamline refinement application show that the proposed framework outperforms baseline methods in classification accuracy, reducing the number of false positives by 67% and the number of false negatives by 55%.",1
"Referring image segmentation aims at segmenting the foreground masks of the entities that can well match the description given in the natural language expression. Previous approaches tackle this problem using implicit feature interaction and fusion between visual and linguistic modalities, but usually fail to explore informative words of the expression to well align features from the two modalities for accurately identifying the referred entity. In this paper, we propose a Cross-Modal Progressive Comprehension (CMPC) module and a Text-Guided Feature Exchange (TGFE) module to effectively address the challenging task. Concretely, the CMPC module first employs entity and attribute words to perceive all the related entities that might be considered by the expression. Then, the relational words are adopted to highlight the correct entity as well as suppress other irrelevant ones by multimodal graph reasoning. In addition to the CMPC module, we further leverage a simple yet effective TGFE module to integrate the reasoned multimodal features from different levels with the guidance of textual information. In this way, features from multi-levels could communicate with each other and be refined based on the textual context. We conduct extensive experiments on four popular referring segmentation benchmarks and achieve new state-of-the-art performances.",0
"The goal of referring image segmentation is to segment the foreground masks of entities that match the natural language description. Previous methods relied on implicit feature interaction and fusion between visual and linguistic modalities, but failed to utilize informative words in the expression to accurately identify the referred entity. To address this challenge, we propose the Cross-Modal Progressive Comprehension (CMPC) and Text-Guided Feature Exchange (TGFE) modules. The CMPC module uses entity and attribute words to perceive related entities, and relational words to highlight the correct entity and suppress irrelevant ones. The TGFE module integrates multimodal features from different levels with textual guidance, allowing for refinement based on the contextual information. Our approach achieves state-of-the-art performance on four popular referring segmentation benchmarks following extensive experiments.",1
"The task of video object segmentation with referring expressions (language-guided VOS) is to, given a linguistic phrase and a video, generate binary masks for the object to which the phrase refers. Our work argues that existing benchmarks used for this task are mainly composed of trivial cases, in which referents can be identified with simple phrases. Our analysis relies on a new categorization of the phrases in the DAVIS-2017 and Actor-Action datasets into trivial and non-trivial REs, with the non-trivial REs annotated with seven RE semantic categories. We leverage this data to analyze the results of RefVOS, a novel neural network that obtains competitive results for the task of language-guided image segmentation and state of the art results for language-guided VOS. Our study indicates that the major challenges for the task are related to understanding motion and static actions.",0
"The aim of language-guided VOS is to produce binary masks for the object referred to in a given linguistic phrase and video. However, we argue that current benchmarks for this task mostly contain easy cases, where simple phrases can identify the object. To support our claim, we categorize phrases in the DAVIS-2017 and Actor-Action datasets as trivial or non-trivial REs, with the latter annotated with seven RE semantic categories. This categorization helps us analyze the performance of RefVOS, a new neural network that achieves competitive results for language-guided image segmentation and state-of-the-art results for language-guided VOS. Our research shows that the primary difficulties of the task entail comprehending motion and static actions.",1
"In this paper, we present a novel neural network using multi scale feature fusion at various scales for accurate and efficient semantic image segmentation. We used ResNet based feature extractor, dilated convolutional layers in downsampling part, atrous convolutional layers in the upsampling part and used concat operation to merge them. A new attention module is proposed to encode more contextual information and enhance the receptive field of the network. We present an in depth theoretical analysis of our network with training and optimization details. Our network was trained and tested on the Camvid dataset and Cityscapes dataset using mean accuracy per class and Intersection Over Union (IOU) as the evaluation metrics. Our model outperforms previous state of the art methods on semantic segmentation achieving mean IOU value of 74.12 while running at >100 FPS.",0
"This paper introduces a unique neural network that utilizes multi-scale feature fusion at various levels to achieve precise and efficient semantic image segmentation. To accomplish this, we employed a ResNet-based feature extractor, dilated convolutional layers in the downsampling phase, atrous convolutional layers in the upsampling phase, and concatenation operation to merge them. Additionally, we developed an attention module that encodes more contextual information and enhances the network's receptive field. We provide a comprehensive theoretical analysis of the network, including training and optimization details. We evaluated our network's performance using the Camvid and Cityscapes datasets, using mean accuracy per class and Intersection Over Union (IOU) as metrics. Our model achieved a mean IOU value of 74.12, surpassing previous state-of-the-art methods in semantic segmentation, while operating at over 100 frames per second.",1
"Efficient and easy segmentation of images and volumes is of great practical importance. Segmentation problems that motivate our approach originate from microscopy imaging commonly used in materials science, medicine, and biology. We formulate image segmentation as a probabilistic pixel classification problem, and we apply segmentation as a step towards characterising image content. Our method allows the user to define structures of interest by interactively marking a subset of pixels. Thanks to the real-time feedback, the user can place new markings strategically, depending on the current outcome. The final pixel classification may be obtained from a very modest user input. An important ingredient of our method is a graph that encodes image content. This graph is built in an unsupervised manner during initialisation and is based on clustering of image features. Since we combine a limited amount of user-labelled data with the clustering information obtained from the unlabelled parts of the image, our method fits in the general framework of semi-supervised learning. We demonstrate how this can be a very efficient approach to segmentation through pixel classification.",0
"The practical significance of efficient and simple segmentation of images and volumes cannot be overstated. Our approach to segmentation is motivated by the challenges presented in microscopy imaging, which is commonly used in fields such as materials science, medicine, and biology. We view image segmentation as a problem of probabilistic pixel classification, and we use it as a tool to understand image content. Our method empowers users to identify areas of interest by manually marking a subset of pixels. With real-time feedback, users can strategically add new markings based on the current results. By combining user input with clustering information from unlabelled parts of the image, our method is an example of semi-supervised learning. Our technique's essential component is a graph that encodes image content, which is created in an unsupervised way during initialization based on clustering image features. We demonstrate how this can efficiently approach segmentation through pixel classification.",1
"Semantic image segmentation is one of fastest growing areas in computer vision with a variety of applications. In many areas, such as robotics and autonomous vehicles, semantic image segmentation is crucial, since it provides the necessary context for actions to be taken based on a scene understanding at the pixel level. Moreover, the success of medical diagnosis and treatment relies on the extremely accurate understanding of the data under consideration and semantic image segmentation is one of the important tools in many cases. Recent developments in deep learning have provided a host of tools to tackle this problem efficiently and with increased accuracy. This work provides a comprehensive analysis of state-of-the-art deep learning architectures in image segmentation and, more importantly, an extensive list of techniques to achieve fast inference and computational efficiency. The origins of these techniques as well as their strengths and trade-offs are discussed with an in-depth analysis of their impact in the area. The best-performing architectures are summarized with a list of methods used to achieve these state-of-the-art results.",0
"Semantic image segmentation has become a rapidly growing field in computer vision with a wide range of applications. Its significance cannot be overlooked in many domains like robotics and self-driving cars, as it plays a crucial role in comprehending scenes at the pixel level, thereby assisting in decision-making and actions. Furthermore, the precise understanding of data is paramount in medical diagnosis and treatment, and semantic image segmentation is an indispensable tool in this regard. The advent of deep learning has revolutionized this field, providing efficient and accurate solutions to the problem. This study encompasses a comprehensive overview of the latest deep learning architectures used in image segmentation, along with an exhaustive list of techniques to achieve fast inference and computational efficiency. The paper delves into the origins of these techniques and critically analyzes their strengths and weaknesses and their impact on the field. The top-performing architectures are summarized, and the methods employed to achieve these remarkable results are listed.",1
"Medical image annotation is a major hurdle for developing precise and robust machine learning models. Annotation is expensive, time-consuming, and often requires expert knowledge, particularly in the medical field. Here, we suggest using minimal user interaction in the form of extreme point clicks to train a segmentation model which, in effect, can be used to speed up medical image annotation. An initial segmentation is generated based on the extreme points utilizing the random walker algorithm. This initial segmentation is then used as a noisy supervision signal to train a fully convolutional network that can segment the organ of interest, based on the provided user clicks. Through experimentation on several medical imaging datasets, we show that the predictions of the network can be refined using several rounds of training with the prediction from the same weakly annotated data. Further improvements are shown utilizing the clicked points within a custom-designed loss and attention mechanism. Our approach has the potential to speed up the process of generating new training datasets for the development of new machine learning and deep learning-based models for, but not exclusively, medical image analysis.",0
"Developing accurate and robust machine learning models for medical image annotation is a difficult task due to its high cost, time consumption, and requirement of expert knowledge. To overcome these challenges, we propose a method that utilizes minimal user interaction in the form of extreme point clicks to train a segmentation model. The random walker algorithm generates an initial segmentation based on the extreme points, which acts as a noisy supervision signal to train a fully convolutional network that can segment the organ of interest using the provided user clicks. Our experiments on various medical imaging datasets demonstrate that the network predictions can be refined through multiple rounds of training with the same weakly annotated data. Additionally, we have designed a custom loss and attention mechanism that utilizes clicked points to further improve the approach. By speeding up the process of generating new training datasets, our method has the potential to develop new and advanced machine learning and deep learning-based models for medical image analysis and beyond.",1
"Dense pixel-wise classification maps output by deep neural networks are of extreme importance for scene understanding. However, these maps are often partially inaccurate due to a variety of possible factors. Therefore, we propose to interactively refine them within a framework named DISCA (Deep Image Segmentation with Continual Adaptation). It consists of continually adapting a neural network to a target image using an interactive learning process with sparse user annotations as ground-truth. We show through experiments on three datasets using synthesized annotations the benefits of the approach, reaching an IoU improvement up to 4.7% for ten sampled clicks. Finally, we exhibit that our approach can be particularly rewarding when it is faced to additional issues such as domain adaptation.",0
"The precise classification maps produced by deep neural networks are crucial for comprehending a scene. However, these maps can be somewhat inaccurate due to various factors. To address this issue, we propose DISCA (Deep Image Segmentation with Continual Adaptation), a framework that enables interactive refinement of the maps. Our approach involves continually adapting a neural network to a target image, using sparse user annotations as ground-truth. We conducted experiments on three datasets, using synthesized annotations, and observed significant benefits from our approach, including an improvement in IoU up to 4.7% with ten sampled clicks. Furthermore, we demonstrate that our approach is particularly useful in dealing with additional issues, such as domain adaptation.",1
"Today's success of state of the art methods for semantic segmentation is driven by large datasets. Data is considered an important asset that needs to be protected, as the collection and annotation of such datasets comes at significant efforts and associated costs. In addition, visual data might contain private or sensitive information, that makes it equally unsuited for public release. Unfortunately, recent work on membership inference in the broader area of adversarial machine learning and inference attacks on machine learning models has shown that even black box classifiers leak information on the dataset that they were trained on. We show that such membership inference attacks can be successfully carried out on complex, state of the art models for semantic segmentation. In order to mitigate the associated risks, we also study a series of defenses against such membership inference attacks and find effective counter measures against the existing risks with little effect on the utility of the segmentation method. Finally, we extensively evaluate our attacks and defenses on a range of relevant real-world datasets: Cityscapes, BDD100K, and Mapillary Vistas.",0
"Large datasets are the driving force behind the success of modern semantic segmentation methods. Assembling and annotating such datasets requires significant effort and cost, making data a valuable asset that must be safeguarded. Furthermore, visual data may contain sensitive or private information, making it unsuitable for public release. However, recent studies on adversarial machine learning and inference attacks have revealed that even black box classifiers can divulge information about their training datasets. Our research demonstrates that such attacks can be conducted on sophisticated state-of-the-art semantic segmentation models. To mitigate the associated risks, we investigate several defenses against membership inference attacks and identify effective countermeasures that have minimal impact on segmentation performance. Finally, we extensively evaluate our attacks and defenses on real-world datasets such as Cityscapes, BDD100K, and Mapillary Vistas.",1
"We introduce a method for training neural networks to perform image or volume segmentation in which prior knowledge about the topology of the segmented object can be explicitly provided and then incorporated into the training process. By using the differentiable properties of persistent homology, a concept used in topological data analysis, we can specify the desired topology of segmented objects in terms of their Betti numbers and then drive the proposed segmentations to contain the specified topological features. Importantly this process does not require any ground-truth labels, just prior knowledge of the topology of the structure being segmented. We demonstrate our approach in three experiments. Firstly we create a synthetic task in which handwritten MNIST digits are de-noised, and show that using this kind of topological prior knowledge in the training of the network significantly improves the quality of the de-noised digits. Secondly we perform an experiment in which the task is segmenting the myocardium of the left ventricle from cardiac magnetic resonance images. We show that the incorporation of the prior knowledge of the topology of this anatomy improves the resulting segmentations in terms of both the topological accuracy and the Dice coefficient. Thirdly, we extend the method to 3D volumes and demonstrate its performance on the task of segmenting the placenta from ultrasound data, again showing that incorporating topological priors improves performance on this challenging task. We find that embedding explicit prior knowledge in neural network segmentation tasks is most beneficial when the segmentation task is especially challenging and that it can be used in either a semi-supervised or post-processing context to extract a useful training gradient from images without pixelwise labels.",0
"Our method trains neural networks for image or volume segmentation by incorporating prior knowledge about the topology of the segmented object. We use persistent homology, a concept from topological data analysis, to specify the desired topology in terms of Betti numbers and include it in the training process. This approach does not require ground-truth labels, but instead relies on prior knowledge of the structure being segmented. We conduct three experiments to demonstrate the effectiveness of our approach. The first experiment involves de-noising handwritten MNIST digits, where incorporating topological prior knowledge significantly improves the quality of the output. In the second experiment, we segment the myocardium of the left ventricle from cardiac magnetic resonance images and show that our method improves both the topological accuracy and the Dice coefficient. Finally, we extend our method to 3D volumes and perform segmentation of the placenta from ultrasound data, achieving better results with the inclusion of topological priors. We find that embedding prior knowledge in neural network segmentation tasks is particularly useful for challenging tasks and can be applied in a semi-supervised or post-processing context to obtain a useful training gradient without pixelwise labels.",1
"Aggregating multi-level feature representation plays a critical role in achieving robust volumetric medical image segmentation, which is important for the auxiliary diagnosis and treatment. Unlike the recent neural architecture search (NAS) methods that typically searched the optimal operators in each network layer, but missed a good strategy to search for feature aggregations, this paper proposes a novel NAS method for 3D medical image segmentation, named UXNet, which searches both the scale-wise feature aggregation strategies as well as the block-wise operators in the encoder-decoder network. UXNet has several appealing benefits. (1) It significantly improves flexibility of the classical UNet architecture, which only aggregates feature representations of encoder and decoder in equivalent resolution. (2) A continuous relaxation of UXNet is carefully designed, enabling its searching scheme performed in an efficient differentiable manner. (3) Extensive experiments demonstrate the effectiveness of UXNet compared with recent NAS methods for medical image segmentation. The architecture discovered by UXNet outperforms existing state-of-the-art models in terms of Dice on several public 3D medical image segmentation benchmarks, especially for the boundary locations and tiny tissues. The searching computational complexity of UXNet is cheap, enabling to search a network with the best performance less than 1.5 days on two TitanXP GPUs.",0
"To achieve robust volumetric medical image segmentation, aggregating multi-level feature representation is crucial for auxiliary diagnosis and treatment. Recent neural architecture search (NAS) methods have focused on searching for optimal operators in each network layer, but have neglected the importance of searching for feature aggregations. This paper proposes a new NAS method called UXNet for 3D medical image segmentation that searches for both scale-wise feature aggregation strategies and block-wise operators in the encoder-decoder network. UXNet offers several benefits, including increased flexibility compared to the classical UNet architecture, a carefully designed continuous relaxation for efficient differentiable searching, and improved effectiveness compared to recent NAS methods for medical image segmentation. UXNet outperforms existing state-of-the-art models in terms of Dice on several public 3D medical image segmentation benchmarks, particularly for boundary locations and tiny tissues. Additionally, UXNet's searching computational complexity is low, requiring less than 1.5 days on two TitanXP GPUs to search for a network with the best performance.",1
"Deep Learning (DL) models are becoming larger, because the increase in model size might offer significant accuracy gain. To enable the training of large deep networks, data parallelism and model parallelism are two well-known approaches for parallel training. However, data parallelism does not help reduce memory footprint per device. In this work, we introduce Large deep 3D ConvNets with Automated Model Parallelism (LAMP) and investigate the impact of both input's and deep 3D ConvNets' size on segmentation accuracy. Through automated model parallelism, it is feasible to train large deep 3D ConvNets with a large input patch, even the whole image. Extensive experiments demonstrate that, facilitated by the automated model parallelism, the segmentation accuracy can be improved through increasing model size and input context size, and large input yields significant inference speedup compared with sliding window of small patches in the inference. Code is available\footnote{https://monai.io/research/lamp-automated-model-parallelism}.",0
"The accuracy of Deep Learning (DL) models can be significantly improved by increasing their size, resulting in larger models. However, traditional approaches such as data parallelism and model parallelism are not effective in reducing memory footprint per device. To address this, we propose the use of Large deep 3D ConvNets with Automated Model Parallelism (LAMP), which enables the training of large deep networks with a large input patch or even the whole image. Our experiments show that automated model parallelism can improve segmentation accuracy by increasing both model and input context size. Additionally, using large input leads to faster inference compared to using small patches in a sliding window fashion. Our code is available at https://monai.io/research/lamp-automated-model-parallelism.",1
"Games such as go, chess and checkers have multiple equivalent game states, i.e. multiple board positions where symmetrical and opposite moves should be made. These equivalences are not exploited by current state of the art neural agents which instead must relearn similar information, thereby wasting computing time. Group equivariant CNNs in existing work create networks which can exploit symmetries to improve learning, however, they lack the expressiveness to correctly reflect the move embeddings necessary for games. We introduce Finite Group Neural Networks (FGNNs), a method for creating agents with an innate understanding of these board positions. FGNNs are shown to improve the performance of networks playing checkers (draughts), and can be easily adapted to other games and learning problems. Additionally, FGNNs can be created from existing network architectures. These include, for the first time, those with skip connections and arbitrary layer types. We demonstrate that an equivariant version of U-Net (FGNN-U-Net) outperforms the unmodified network in image segmentation.",0
"Current state of the art neural agents do not take advantage of the multiple equivalent game states present in games like go, chess, and checkers. These equivalent board positions require symmetrical and opposite moves, which are ignored by existing group equivariant CNNs that lack the expressiveness to reflect the necessary move embeddings for these games. This results in wasted computing time as the agents must relearn similar information. To address this issue, we propose Finite Group Neural Networks (FGNNs) that possess an innate understanding of these board positions. FGNNs improve the performance of networks playing checkers and can be easily adapted to other games and learning problems. Furthermore, FGNNs can be created from existing network architectures, including those with skip connections and arbitrary layer types. We demonstrate that an equivariant version of U-Net (FGNN-U-Net) performs better than the unmodified network in image segmentation.",1
"The need for labour intensive pixel-wise annotation is a major limitation of many fully supervised learning methods for segmenting bioimages that can contain numerous object instances with thin separations. In this paper, we introduce a deep convolutional neural network for microscopy image segmentation. Annotation issues are circumvented by letting the network being trainable on coarse labels combined with only a very small number of images with pixel-wise annotations. We call this new labelling strategy `lazy' labels. Image segmentation is stratified into three connected tasks: rough inner region detection, object separation and pixel-wise segmentation. These tasks are learned in an end-to-end multi-task learning framework. The method is demonstrated on two microscopy datasets, where we show that the model gives accurate segmentation results even if exact boundary labels are missing for a majority of annotated data. It brings more flexibility and efficiency for training deep neural networks that are data hungry and is applicable to biomedical images with poor contrast at the object boundaries or with diverse textures and repeated patterns.",0
"Fully supervised learning methods for segmenting bioimages can be limited due to the need for labour intensive pixel-wise annotation, especially when dealing with images that contain multiple object instances with thin separations. To address this issue, a deep convolutional neural network is introduced in this paper for microscopy image segmentation. The new labelling strategy, called `lazy' labels, allows the network to be trained on coarse labels combined with only a few images that have pixel-wise annotations, thus bypassing annotation issues. The image segmentation process is divided into three tasks: rough inner region detection, object separation, and pixel-wise segmentation, all of which are learned in an end-to-end multi-task learning framework. The model is demonstrated to produce accurate segmentation results on two microscopy datasets, even when exact boundary labels are missing for the majority of annotated data. This approach offers greater flexibility and efficiency for training data-hungry deep neural networks and is suitable for biomedical images with poor contrast at object boundaries, diverse textures, and repeated patterns.",1
"Deep learning (DL)-based models have demonstrated good performance in medical image segmentation. However, the models trained on a known dataset often fail when performed on an unseen dataset collected from different centers, vendors and disease populations. In this work, we present a random style transfer network to tackle the domain generalization problem for multi-vendor and center cardiac image segmentation. Style transfer is used to generate training data with a wider distribution/ heterogeneity, namely domain augmentation. As the target domain could be unknown, we randomly generate a modality vector for the target modality in the style transfer stage, to simulate the domain shift for unknown domains. The model can be trained in a semi-supervised manner by simultaneously optimizing a supervised segmentation and an unsupervised style translation objective. Besides, the framework incorporates the spatial information and shape prior of the target by introducing two regularization terms. We evaluated the proposed framework on 40 subjects from the M\&Ms challenge2020, and obtained promising performance in the segmentation for data from unknown vendors and centers.",0
"Medical image segmentation has been successful using Deep learning (DL)-based models. However, these models are limited when applied to an unknown dataset collected from different centers, vendors, and disease populations. This paper presents a solution to this domain generalization problem for multi-vendor and center cardiac image segmentation through a random style transfer network. The network generates training data with a wider distribution/heterogeneity using style transfer, called domain augmentation. To account for unknown domains, a modality vector is randomly generated during the style transfer stage. The model is trained in a semi-supervised manner by optimizing a supervised segmentation and an unsupervised style translation objective. Additionally, the framework includes spatial information and shape prior of the target through two regularization terms. The proposed framework was evaluated on 40 subjects from the M\&Ms challenge2020, and showed promising results in segmenting data from unknown vendors and centers.",1
"Slope difference distribution (SDD) is computed for the one-dimensional curve. It is not only robust to calculate the partitioning point to separate the curve logically, but also robust to calculate the clustering center of each part of the separated curve. SDD has been proposed for image segmentation and it outperforms all existing image segmentation methods. For verification purpose, we have made the Matlab codes of comparing SDD method with existing image segmentation methods freely available at Matlab Central. The contour of the object is similar to the histogram of the image. Thus, feature detection by SDD from the contour of the object is also feasible. In this letter, SDD features are defined and they form the sparse representation of the object contour. The reference model of each object is built based on the SDD features and then model matching is used for on line object recognition. The experimental results are very encouraging. For the gesture recognition, SDD achieved 100% accuracy for two public datasets: the NUS dataset and the near-infrared dataset. For the object recognition, SDD achieved 100% accuracy for the Kimia 99 dataset.",0
"The computation of Slope Difference Distribution (SDD) is carried out on a one-dimensional curve. The computation method not only provides a robust approach for logically separating the curve into parts, but also for determining the clustering center of each of these parts. SDD has been proposed as a superior image segmentation method compared to all existing techniques. To verify this, we have made the Matlab codes for comparing SDD method with existing image segmentation methods freely available at Matlab Central. The object's contour is similar to the histogram of the image, making it feasible to detect features using SDD. In this letter, SDD features are defined and they form the sparse representation of the object contour. The reference model for each object is built based on the SDD features, and model matching is then used for online object recognition. The experimental results are highly encouraging. SDD achieved 100% accuracy for two public datasets, namely the NUS dataset and the near-infrared dataset, for gesture recognition. For object recognition, SDD achieved 100% accuracy for the Kimia 99 dataset.",1
"Given a 3D surface defined by an elevation function on a 2D grid as well as non-spatial features observed at each pixel, the problem of surface segmentation aims to classify pixels into contiguous classes based on both non-spatial features and surface topology. The problem has important applications in hydrology, planetary science, and biochemistry but is uniquely challenging for several reasons. First, the spatial extent of class segments follows surface contours in the topological space, regardless of their spatial shapes and directions. Second, the topological structure exists in multiple spatial scales based on different surface resolutions. Existing widely successful deep learning models for image segmentation are often not applicable due to their reliance on convolution and pooling operations to learn regular structural patterns on a grid. In contrast, we propose to represent surface topological structure by a contour tree skeleton, which is a polytree capturing the evolution of surface contours at different elevation levels. We further design a graph neural network based on the contour tree hierarchy to model surface topological structure at different spatial scales. Experimental evaluations based on real-world hydrological datasets show that our model outperforms several baseline methods in classification accuracy.",0
"The task of surface segmentation involves categorizing pixels on a 2D grid based on their non-spatial features and surface topology. This problem is crucial in hydrology, planetary science, and biochemistry; however, it is particularly challenging due to two main reasons. Firstly, the spatial extent of class segments follows surface contours in the topological space, regardless of their spatial shapes and directions. Secondly, the topological structure exists in multiple spatial scales based on different surface resolutions. Existing deep learning models for image segmentation are not suitable as they rely on convolution and pooling operations to learn regular structural patterns on a grid. In contrast, we propose utilizing a contour tree skeleton to represent surface topological structure, which captures the evolution of surface contours at different elevation levels. We have designed a graph neural network based on the contour tree hierarchy to model surface topological structure at different spatial scales. Our experimental results using real-world hydrological datasets demonstrate that our model outperforms several baseline methods in classification accuracy.",1
"Image segmentation methods are usually trained with pixel-level annotations, which require significant human effort to collect. The most common solution to address this constraint is to implement weakly-supervised pipelines trained with lower forms of supervision, such as bounding boxes or scribbles. Another option are semi-supervised methods, which leverage a large amount of unlabeled data and a limited number of strongly-labeled samples. In this second setup, samples to be strongly-annotated can be selected randomly or with an active learning mechanism that chooses the ones that will maximize the model performance. In this work, we propose a sample selection approach to decide which samples to annotate for semi-supervised instance segmentation. Our method consists in first predicting pseudo-masks for the unlabeled pool of samples, together with a score predicting the quality of the mask. This score is an estimate of the Intersection Over Union (IoU) of the segment with the ground truth mask. We study which samples are better to annotate given the quality score, and show how our approach outperforms a random selection, leading to improved performance for semi-supervised instance segmentation with low annotation budgets.",0
"Typically, image segmentation techniques necessitate pixel-level annotations, which involve a significant amount of manual labour to gather. To tackle this limitation, weakly-supervised approaches employing lower levels of supervision such as bounding boxes or scribbles are commonly used. Alternatively, semi-supervised methods can leverage plentiful unlabeled data and a restricted number of strongly-labeled examples. In this scenario, samples requiring strong annotation can be chosen randomly or using an active learning mechanism that maximizes model performance. Our study introduces a sample selection technique for semi-supervised instance segmentation by first predicting pseudo-masks and a score indicating mask quality for the unlabeled dataset. This score approximates the Intersection Over Union (IoU) of the segment with the ground truth mask. We investigate which samples are best to annotate based on the quality score and demonstrate that our technique outperforms random selection, resulting in improved semi-supervised instance segmentation performance on a low annotation budget.",1
"Incorporating a human-in-the-loop system when deploying automated decision support is critical in healthcare contexts to create trust, as well as provide reliable performance on a patient-to-patient basis. Deep learning methods while having high performance, do not allow for this patient-centered approach due to the lack of uncertainty representation. Thus, we present a framework of uncertainty representation evaluated for medical image segmentation, using MCU-Net which combines a U-Net with Monte Carlo Dropout, evaluated with four different uncertainty metrics. The framework augments this by adding a human-in-the-loop aspect based on an uncertainty threshold for automated referral of uncertain cases to a medical professional. We demonstrate that MCU-Net combined with epistemic uncertainty and an uncertainty threshold tuned for this application maximizes automated performance on an individual patient level, yet refers truly uncertain cases. This is a step towards uncertainty representations when deploying machine learning based decision support in healthcare settings.",0
"To establish trust and ensure reliable performance on a patient-to-patient basis in healthcare contexts, it is critical to incorporate a human-in-the-loop system when deploying automated decision support. Although deep learning methods have high performance, they lack uncertainty representation, making it difficult to adopt a patient-centered approach. Therefore, we propose a framework for uncertainty representation in medical image segmentation using MCU-Net, which combines a U-Net with Monte Carlo Dropout and is evaluated with four uncertainty metrics. The framework includes a human-in-the-loop aspect based on an uncertainty threshold for automated referral of uncertain cases to a medical professional. Our research shows that MCU-Net combined with epistemic uncertainty and an uncertainty threshold tuned for this application maximizes automated performance on an individual patient level while referring truly uncertain cases. This represents a significant advancement in the deployment of machine learning-based decision support in healthcare settings.",1
"This work presents use of Fully Convolutional Network (FCN-8) for semantic segmentation of high-resolution RGB earth surface satel-lite images into land use land cover (LULC) categories. Specically, we propose a non-overlapping grid-based approach to train a Fully Convo-lutional Network (FCN-8) with vgg-16 weights to segment satellite im-ages into four (forest, built-up, farmland and water) classes. The FCN-8 semantically projects the discriminating features in lower resolution learned by the encoder onto the pixel space in higher resolution to get a dense classi cation. We experimented the proposed system with Gaofen-2 image dataset, that contains 150 images of over 60 di erent cities in china. For comparison, we used available ground-truth along with images segmented using a widely used commeriial GIS software called eCogni-tion. With the proposed non-overlapping grid-based approach, FCN-8 obtains signi cantly improved performance, than the eCognition soft-ware. Our model achieves average accuracy of 91.0% and average Inter-section over Union (IoU) of 0.84. In contrast, eCognitions average accu-racy is 74.0% and IoU is 0.60. This paper also reports a detail analysis of errors occurred at the LULC boundary.",0
"This study utilizes the Fully Convolutional Network (FCN-8) to perform semantic segmentation of high-resolution RGB earth surface satellite images into land use land cover (LULC) categories. The proposed method involves a non-overlapping grid-based approach to train the FCN-8 with vgg-16 weights, which can accurately segment satellite images into four classes: forest, built-up, farmland, and water. By semantically projecting the lower resolution features learned by the encoder onto the pixel space in higher resolution, the FCN-8 achieves dense classification. The proposed system is evaluated with the Gaofen-2 image dataset, consisting of 150 images from over 60 cities in China. The results show that the FCN-8 with the non-overlapping grid-based approach outperforms the widely used commercial GIS software eCognition, achieving an average accuracy of 91.0% and an average Intersection over Union (IoU) of 0.84, compared to eCognition's average accuracy of 74.0% and IoU of 0.60. Furthermore, this paper provides a detailed analysis of errors that occur at the LULC boundary.",1
"Semantic segmentation is a critical method in the field of autonomous driving. When performing semantic image segmentation, a wider field of view (FoV) helps to obtain more information about the surrounding environment, making automatic driving safer and more reliable, which could be offered by fisheye cameras. However, large public fisheye datasets are not available, and the fisheye images captured by the fisheye camera with large FoV comes with large distortion, so commonly-used semantic segmentation model cannot be directly utilized. In this paper, a seven degrees of freedom (DoF) augmentation method is proposed to transform rectilinear image to fisheye image in a more comprehensive way. In the training process, rectilinear images are transformed into fisheye images in seven DoF, which simulates the fisheye images taken by cameras of different positions, orientations and focal lengths. The result shows that training with the seven-DoF augmentation can improve the model's accuracy and robustness against different distorted fisheye data. This seven-DoF augmentation provides a universal semantic segmentation solution for fisheye cameras in different autonomous driving applications. Also, we provide specific parameter settings of the augmentation for autonomous driving. At last, we tested our universal semantic segmentation model on real fisheye images and obtained satisfactory results. The code and configurations are released at https://github.com/Yaozhuwa/FisheyeSeg.",0
"Semantic image segmentation is a crucial technique for autonomous driving, and fisheye cameras can offer a wider field of view to gather more information about the surrounding environment, enhancing safety and reliability. However, large public fisheye datasets are scarce, and fisheye images captured by cameras with a large field of view often come with significant distortion, which makes it difficult to use commonly-used semantic segmentation models. This paper proposes a seven-degree-of-freedom (DoF) augmentation method to transform rectilinear images to fisheye images comprehensively. During training, rectilinear images are transformed into fisheye images in seven DoF, simulating fisheye images captured by cameras with different positions, orientations, and focal lengths. The results demonstrate that training with the seven-DoF augmentation improves the model's accuracy and robustness against distorted fisheye data, offering a universal semantic segmentation solution for fisheye cameras in various autonomous driving applications. Additionally, specific parameter settings for autonomous driving are provided, and the universal semantic segmentation model is evaluated on real fisheye images, achieving satisfactory results. The code and configurations are available at https://github.com/Yaozhuwa/FisheyeSeg.",1
"This paper presents an interactive approach for multi-class segmentation of aerial images. Precisely, it is based on a deep neural network which exploits both RGB images and annotations. Starting from an initial output based on the image only, our network then interactively refines this segmentation map using a concatenation of the image and user annotations. Importantly, user annotations modify the inputs of the network - not its weights - enabling a fast and smooth process. Through experiments on two public aerial datasets, we show that user annotations are extremely rewarding: each click corrects roughly 5000 pixels. We analyze the impact of different aspects of our framework such as the representation of the annotations, the volume of training data or the network architecture. Code is available at https://github.com/delair-ai/DISIR.",0
"An interactive method for multi-class segmentation of aerial images is introduced in this article. The method utilizes a deep neural network that incorporates both RGB images and annotations. Initially, the network generates a segmentation map based on the image alone. Then, the map is refined through an interactive process where user annotations are concatenated with the image. It is noteworthy that the user annotations modify the inputs of the network, not the weights, making the process fast and seamless. The authors demonstrate the efficacy of the method by conducting experiments on two public aerial datasets. They found that user annotations significantly improve the accuracy, with each click correcting approximately 5000 pixels. Additionally, the article examines different aspects of the framework, such as the representation of the annotations, the volume of training data, and the network architecture. The code is available at https://github.com/delair-ai/DISIR.",1
"The 3D volumetric shape of the heart's left ventricle (LV) myocardium (MYO) wall provides important information for diagnosis of cardiac disease and invasive procedure navigation. Many cardiac image segmentation methods have relied on detection of region-of-interest as a pre-requisite for shape segmentation and modeling. With segmentation results, a 3D surface mesh and a corresponding point cloud of the segmented cardiac volume can be reconstructed for further analyses. Although state-of-the-art methods (e.g., U-Net) have achieved decent performance on cardiac image segmentation in terms of accuracy, these segmentation results can still suffer from imaging artifacts and noise, which will lead to inaccurate shape modeling results. In this paper, we propose a PC-U net that jointly reconstructs the point cloud of the LV MYO wall directly from volumes of 2D CT slices and generates its segmentation masks from the predicted 3D point cloud. Extensive experimental results show that by incorporating a shape prior from the point cloud, the segmentation masks are more accurate than the state-of-the-art U-Net results in terms of Dice's coefficient and Hausdorff distance.The proposed joint learning framework of our PC-U net is beneficial for automatic cardiac image analysis tasks because it can obtain simultaneously the 3D shape and segmentation of the LV MYO walls.",0
"Accurate detection of cardiac disease and guiding invasive procedures requires knowledge of the 3D volumetric shape of the left ventricle myocardium (LV MYO) wall. Although many image segmentation methods rely on region-of-interest detection for shape segmentation and modeling, state-of-the-art approaches (such as U-Net) can still produce inaccurate results due to imaging artifacts and noise. To address this issue, we present a joint learning framework called PC-U net, which reconstructs the LV MYO wall's point cloud directly from 2D CT slices and generates segmentation masks from the predicted 3D point cloud. By incorporating a shape prior from the point cloud, our method achieves higher accuracy in terms of Dice's coefficient and Hausdorff distance compared to U-Net. Our approach is advantageous for automatic cardiac image analysis tasks as it simultaneously obtains the 3D shape and segmentation of the LV MYO walls.",1
"Real-time semantic video segmentation is a challenging task due to the strict requirements of inference speed. Recent approaches mainly devote great efforts to reducing the model size for high efficiency. In this paper, we rethink this problem from a different viewpoint: using knowledge contained in compressed videos. We propose a simple and effective framework, dubbed TapLab, to tap into resources from the compressed domain. Specifically, we design a fast feature warping module using motion vectors for acceleration. To reduce the noise introduced by motion vectors, we design a residual-guided correction module and a residual-guided frame selection module using residuals. TapLab significantly reduces redundant computations of the state-of-the-art fast semantic image segmentation models, running 3 to 10 times faster with controllable accuracy degradation. The experimental results show that TapLab achieves 70.6% mIoU on the Cityscapes dataset at 99.8 FPS with a single GPU card for the 1024x2048 videos. A high-speed version even reaches the speed of 160+ FPS. Codes will be available soon at https://github.com/Sixkplus/TapLab.",0
"Real-time semantic video segmentation presents a challenge due to the strict need for inference speed. To address this, recent approaches have focused on reducing the model size for efficiency. However, this paper proposes a different approach by utilizing knowledge from compressed videos. Their framework, TapLab, incorporates a fast feature warping module using motion vectors for acceleration. To minimize noise from motion vectors, the authors also designed a correction module and a frame selection module using residuals. TapLab significantly reduces redundant computations compared to state-of-the-art models, achieving 70.6% mIoU on the Cityscapes dataset at 99.8 FPS with a single GPU card for 1024x2048 videos. A faster version even reaches 160+ FPS. The code will soon be available at https://github.com/Sixkplus/TapLab.",1
"This paper describes the results of formally evaluating the MCV (Markov concurrent vision) image labeling algorithm which is a (semi-) hierarchical algorithm commencing with a partition made up of single pixel regions and merging regions or subsets of regions using a Markov random field (MRF) image model. It is an example of a general approach to computer vision called concurrent vision in which the operations of image segmentation and image classification are carried out concurrently. While many image labeling algorithms output a single partition, or segmentation, the MCV algorithm outputs a sequence of partitions and this more elaborate structure may provide information that is valuable for higher level vision systems. With certain types of MRF the component of the system for image evaluation can be implemented as a hardwired feed forward neural network. While being applicable to images (i.e. 2D signals), the algorithm is equally applicable to 1D signals (e.g. speech) or 3D signals (e.g. video sequences) (though its performance in such domains remains to be tested). The algorithm is assessed using subjective and objective criteria with very good results.",0
"The paper presents the findings of a formal evaluation of the MCV (Markov concurrent vision) algorithm for image labeling. This (semi-) hierarchical algorithm starts with a partition of single pixel regions and merges regions or subsets of regions using a Markov random field (MRF) image model. It is an instance of concurrent vision, a general approach to computer vision that carries out image segmentation and classification simultaneously. Unlike other image labeling algorithms that produce a single partition, the MCV algorithm generates a sequence of partitions, which could be useful for higher level vision systems. The algorithm can be implemented as a hardwired feed forward neural network with certain types of MRF. It can be used for 2D, 1D signals (e.g., speech), and 3D signals (e.g., video sequences), although its effectiveness in the latter domains is yet to be established. The algorithm is evaluated based on subjective and objective criteria and yields very good results.",1
"In this paper, we address cell image segmentation task by Feedback Attention mechanism like feedback processing. Unlike conventional neural network models of feedforward processing, we focused on the feedback processing in human brain and assumed that the network learns like a human by connecting feature maps from deep layers to shallow layers. We propose some Feedback Attentions which imitate human brain and feeds back the feature maps of output layer to close layer to the input. U-Net with Feedback Attention showed better result than the conventional methods using only feedforward processing.",0
"This paper explores the use of Feedback Attention mechanism, inspired by human brain's feedback processing, for cell image segmentation task. Unlike feedforward neural network models, we focused on connecting feature maps from deep layers to shallow layers, mimicking the human brain's learning process. Our proposed Feedback Attentions imitate this process by feeding back feature maps from the output layer to the close layer and eventually to the input. Our experiments using U-Net with Feedback Attention showed superior results compared to conventional methods that only use feedforward processing.",1
"In this paper, we propose an easily trained yet powerful representation learning approach with performance highly competitive to deep neural networks in a digital pathology image segmentation task. The method, called sparse coding driven deep decision tree ensembles that we abbreviate as ScD2TE, provides a new perspective on representation learning. We explore the possibility of stacking several layers based on non-differentiable pairwise modules and generate a densely concatenated architecture holding the characteristics of feature map reuse and end-to-end dense learning. Under this architecture, fast convolutional sparse coding is used to extract multi-level features from the output of each layer. In this way, rich image appearance models together with more contextual information are integrated by learning a series of decision tree ensembles. The appearance and the high-level context features of all the previous layers are seamlessly combined by concatenating them to feed-forward as input, which in turn makes the outputs of subsequent layers more accurate and the whole model efficient to train. Compared with deep neural networks, our proposed ScD2TE does not require back-propagation computation and depends on less hyper-parameters. ScD2TE is able to achieve a fast end-to-end pixel-wise training in a layer-wise manner. We demonstrated the superiority of our segmentation technique by evaluating it on the multi-disease state and multi-organ dataset where consistently higher performances were obtained for comparison against several state-of-the-art deep learning methods such as convolutional neural networks (CNN), fully convolutional networks (FCN), etc.",0
"This paper introduces a novel approach to representation learning called ScD2TE, which stands for sparse coding driven deep decision tree ensembles. ScD2TE utilizes a densely concatenated architecture that leverages the benefits of feature map reuse and end-to-end dense learning. The approach involves stacking several layers based on non-differentiable pairwise modules to extract multi-level features using fast convolutional sparse coding. These features are then integrated into a series of decision tree ensembles to provide rich image appearance models and contextual information. The appearance and high-level context features of previous layers are seamlessly combined by concatenating them to feed-forward as input, leading to more accurate outputs and a more efficient training process. Compared to deep neural networks, ScD2TE requires fewer hyper-parameters and does not rely on back-propagation computation. Our experiments on a multi-disease state and multi-organ dataset demonstrate the superior performance of ScD2TE compared to state-of-the-art deep learning methods such as CNN and FCN.",1
"In this paper, we propose a new approach for building cellular automata to solve real-world segmentation problems. We design and train a cellular automaton that can successfully segment high-resolution images. We consider a colony that densely inhabits the pixel grid, and all cells are governed by a randomized update that uses the current state, the color, and the state of the $3\times 3$ neighborhood. The space of possible rules is defined by a small neural network. The update rule is applied repeatedly in parallel to a large random subset of cells and after convergence is used to produce segmentation masks that are then back-propagated to learn the optimal update rules using standard gradient descent methods. We demonstrate that such models can be learned efficiently with only limited trajectory length and that they show remarkable ability to organize the information to produce a globally consistent segmentation result, using only local information exchange. From a practical perspective, our approach allows us to build very efficient models -- our smallest automaton uses less than 10,000 parameters to solve complex segmentation tasks.",0
"This paper proposes a novel method for creating cellular automata that can effectively solve real-world segmentation challenges. Our approach involves training a cellular automaton to segment high-resolution images by densely populating the pixel grid with cells governed by a randomized update. The update considers the current state, color, and $3\times 3$ neighborhood of each cell, and a small neural network defines the space of possible rules. We apply the update rule repeatedly to a large random subset of cells, leading to segmentation masks that we back-propagate to learn optimal update rules through standard gradient descent methods. Our results show that these models can be learned efficiently with limited trajectory length and can produce globally consistent segmentation outcomes using only local information exchange. Practically speaking, our approach enables us to develop highly efficient models, with our smallest automaton requiring less than 10,000 parameters to address complex segmentation tasks.",1
"In medical imaging, the heterogeneity of multi-centre data impedes the applicability of deep learning-based methods and results in significant performance degradation when applying models in an unseen data domain, e.g. a new centreor a new scanner. In this paper, we propose an unsupervised domain adaptation framework for boosting image segmentation performance across multiple domains without using any manual annotations from the new target domains, but by re-calibrating the networks on few images from the target domain. To achieve this, we enforce architectures to be adaptive to new data by rejecting improbable segmentation patterns and implicitly learning through semantic and boundary information, thus to capture disease-specific spatial patterns in an adversarial optimization. The adaptation process needs continuous monitoring, however, as we cannot assume the presence of ground-truth masks for the target domain, we propose two new metrics to monitor the adaptation process, and strategies to train the segmentation algorithm in a stable fashion. We build upon well-established 2D and 3D architectures and perform extensive experiments on three cross-centre brain lesion segmentation tasks, involving multicentre public and in-house datasets. We demonstrate that recalibrating the deep networks on a few unlabeled images from the target domain improves the segmentation accuracy significantly.",0
"The heterogeneity of multi-centre data in medical imaging poses a challenge to the effectiveness of deep learning-based methods. This results in a significant degradation of performance when applying models in a new domain, such as a new centre or scanner. Our paper proposes an unsupervised domain adaptation framework that enhances image segmentation performance across multiple domains without using manual annotations from the new target domains. Instead, we re-calibrate the networks on a few images from the target domain. Our approach enforces adaptive architectures that reject improbable segmentation patterns and learn through semantic and boundary information to capture disease-specific spatial patterns. This is achieved through adversarial optimization. As we cannot assume the presence of ground-truth masks for the target domain, we propose two new metrics to monitor the adaptation process and strategies to train the segmentation algorithm in a stable manner. We perform experiments on three cross-centre brain lesion segmentation tasks using established 2D and 3D architectures. The results demonstrate that recalibrating the deep networks on a few unlabeled images from the target domain significantly improves segmentation accuracy.",1
"In convolutional neural network based medical image segmentation, the periphery of foreground regions representing malignant tissues may be disproportionately assigned as belonging to the background class of healthy tissues \cite{attenUnet}\cite{AttenUnet2018}\cite{InterSeg}\cite{UnetFrontNeuro}\cite{LearnActiveContour}. This leads to high false negative detection rates. In this paper, we propose a novel attention mechanism to directly address such high false negative rates, called Paying Attention to Mistakes. Our attention mechanism steers the models towards false positive identification, which counters the existing bias towards false negatives. The proposed mechanism has two complementary implementations: (a) ""explicit"" steering of the model to attend to a larger Effective Receptive Field on the foreground areas; (b) ""implicit"" steering towards false positives, by attending to a smaller Effective Receptive Field on the background areas. We validated our methods on three tasks: 1) binary dense prediction between vehicles and the background using CityScapes; 2) Enhanced Tumour Core segmentation with multi-modal MRI scans in BRATS2018; 3) segmenting stroke lesions using ultrasound images in ISLES2018. We compared our methods with state-of-the-art attention mechanisms in medical imaging, including self-attention, spatial-attention and spatial-channel mixed attention. Across all of the three different tasks, our models consistently outperform the baseline models in Intersection over Union (IoU) and/or Hausdorff Distance (HD). For instance, in the second task, the ""explicit"" implementation of our mechanism reduces the HD of the best baseline by more than $26\%$, whilst improving the IoU by more than $3\%$. We believe our proposed attention mechanism can benefit a wide range of medical and computer vision tasks, which suffer from over-detection of background.",0
"The identification of malignant tissues in medical images using convolutional neural networks can be inaccurate due to the misclassification of the periphery of foreground regions as healthy tissue. This can result in high false negative detection rates, which are addressed in this paper through a novel attention mechanism called Paying Attention to Mistakes. The mechanism focuses on false positive identification, thereby counteracting the bias towards false negatives. Two complementary implementations are proposed: increasing the Effective Receptive Field on foreground areas and decreasing it on background areas. The proposed method is validated on three tasks and compared to state-of-the-art attention mechanisms in medical imaging. The models consistently outperform baseline models in Intersection over Union and/or Hausdorff Distance, demonstrating the potential of the proposed attention mechanism to address over-detection of background in medical and computer vision tasks.",1
"In medical image analysis, semi-supervised learning is an effective method to extract knowledge from a small amount of labeled data and a large amount of unlabeled data. This paper focuses on a popular pipeline known as self learning, and points out a weakness named lazy learning that refers to the difficulty for a model to learn from the pseudo labels generated by itself. To alleviate this issue, we propose ATSO, an asynchronous version of teacher-student optimization. ATSO partitions the unlabeled data into two subsets and alternately uses one subset to fine-tune the model and updates the label on the other subset. We evaluate ATSO on two popular medical image segmentation datasets and show its superior performance in various semi-supervised settings. With slight modification, ATSO transfers well to natural image segmentation for autonomous driving data.",0
"The utilization of semi-supervised learning in medical image analysis is a successful approach that enables the extraction of knowledge from a limited amount of labeled data and a vast quantity of unlabeled data. The main focus of this paper is on a widely used pipeline called self-learning, which exposes a weakness termed ""lazy learning"". This concept pertains to the challenge of models to learn from self-generated pseudo labels. To tackle this problem, we introduce ATSO, an asynchronous version of teacher-student optimization. ATSO divides the unlabeled data into two groups and alternatively employs one set to fine-tune the model and updates the label on the other set. We assess the efficiency of ATSO on two popular medical image segmentation datasets and demonstrate its superior performance in distinct semi-supervised scenarios. With minor modifications, ATSO also exhibits promising results in natural image segmentation for autonomous driving data.",1
"Although deep convolutional networks have reached state-of-the-art performance in many medical image segmentation tasks, they have typically demonstrated poor generalisation capability. To be able to generalise from one domain (e.g. one imaging modality) to another, domain adaptation has to be performed. While supervised methods may lead to good performance, they require to fully annotate additional data which may not be an option in practice. In contrast, unsupervised methods don't need additional annotations but are usually unstable and hard to train. In this work, we propose a novel weakly-supervised method. Instead of requiring detailed but time-consuming annotations, scribbles on the target domain are used to perform domain adaptation. This paper introduces a new formulation of domain adaptation based on structured learning and co-segmentation. Our method is easy to train, thanks to the introduction of a regularised loss. The framework is validated on Vestibular Schwannoma segmentation (T1 to T2 scans). Our proposed method outperforms unsupervised approaches and achieves comparable performance to a fully-supervised approach.",0
"Despite achieving state-of-the-art performance in many medical image segmentation tasks, deep convolutional networks have shown limited generalisation capabilities. Domain adaptation is necessary to enable generalisation across different domains, but supervised methods require fully annotated additional data, which may not be practical. On the other hand, unsupervised methods do not require additional annotations but are often unstable and difficult to train. This study proposes a novel weakly-supervised method that uses scribbles on the target domain for domain adaptation instead of detailed annotations. The method is based on structured learning and co-segmentation and is easy to train due to the introduction of a regularised loss. The proposed framework is validated on Vestibular Schwannoma segmentation (T1 to T2 scans) and outperforms unsupervised methods while achieving comparable performance to a fully-supervised approach.",1
"Polarimetric synthetic aperture radar (PolSAR) image segmentation is currently of great importance in image processing for remote sensing applications. However, it is a challenging task due to two main reasons. Firstly, the label information is difficult to acquire due to high annotation costs. Secondly, the speckle effect embedded in the PolSAR imaging process remarkably degrades the segmentation performance. To address these two issues, we present a contextual PolSAR image semantic segmentation method in this paper.With a newly defined channelwise consistent feature set as input, the three-dimensional discrete wavelet transform (3D-DWT) technique is employed to extract discriminative multi-scale features that are robust to speckle noise. Then Markov random field (MRF) is further applied to enforce label smoothness spatially during segmentation. By simultaneously utilizing 3D-DWT features and MRF priors for the first time, contextual information is fully integrated during the segmentation to ensure accurate and smooth segmentation. To demonstrate the effectiveness of the proposed method, we conduct extensive experiments on three real benchmark PolSAR image data sets. Experimental results indicate that the proposed method achieves promising segmentation accuracy and preferable spatial consistency using a minimal number of labeled pixels.",0
"Image segmentation in polarimetric synthetic aperture radar (PolSAR) is crucial for remote sensing applications, but it is challenging due to the difficulty in acquiring label information and the presence of speckle noise that degrades segmentation performance. To address these issues, our study presents a contextual PolSAR image semantic segmentation method. We utilized a newly defined feature set that is consistent across channels and applied the 3D-DWT technique to extract multi-scale features that are robust to speckle noise. We also employed the Markov random field (MRF) to ensure label smoothness spatially during segmentation. By simultaneously using 3D-DWT features and MRF priors, we integrated contextual information to achieve accurate and smooth segmentation. Our experiments on three benchmark PolSAR image datasets demonstrate the effectiveness of our approach, achieving promising segmentation accuracy and spatial consistency using only a minimal number of labeled pixels.",1
"Medical image segmentation is inherently an ambiguous task due to factors such as partial volumes and variations in anatomical definitions. While in most cases the segmentation uncertainty is around the border of structures of interest, there can also be considerable inter-rater differences. The class of conditional variational autoencoders (cVAE) offers a principled approach to inferring distributions over plausible segmentations that are conditioned on input images. Segmentation uncertainty estimated from samples of such distributions can be more informative than using pixel level probability scores. In this work, we propose a novel conditional generative model that is based on conditional Normalizing Flow (cFlow). The basic idea is to increase the expressivity of the cVAE by introducing a cFlow transformation step after the encoder. This yields improved approximations of the latent posterior distribution, allowing the model to capture richer segmentation variations. With this we show that the quality and diversity of samples obtained from our conditional generative model is enhanced. Performance of our model, which we call cFlow Net, is evaluated on two medical imaging datasets demonstrating substantial improvements in both qualitative and quantitative measures when compared to a recent cVAE based model.",0
"Medical image segmentation is a challenging task due to various factors such as partial volumes and variations in anatomical definitions. Although segmentation uncertainty is typically found around the border of structures of interest, there can be significant differences between raters. The use of conditional variational autoencoders (cVAE) can provide a reliable way to infer distributions over plausible segmentations based on input images. Rather than relying on pixel level probability scores, segmentation uncertainty estimated from samples of such distributions can be more informative. In this study, we propose a novel approach using a conditional generative model based on a conditional Normalizing Flow (cFlow). By introducing a cFlow transformation step after the encoder, the expressivity of the cVAE is increased, allowing for more accurate approximations of the latent posterior distribution and capturing richer segmentation variations. Our model, called cFlow Net, outperforms a recent cVAE-based model on two medical imaging datasets, demonstrating substantial improvements in both qualitative and quantitative measures.",1
"We consider the problem of segmenting image regions given a natural language phrase, and study it on a novel dataset of 77,262 images and 345,486 phrase-region pairs. Our dataset is collected on top of the Visual Genome dataset and uses the existing annotations to generate a challenging set of referring phrases for which the corresponding regions are manually annotated. Phrases in our dataset correspond to multiple regions and describe a large number of object and stuff categories as well as their attributes such as color, shape, parts, and relationships with other entities in the image. Our experiments show that the scale and diversity of concepts in our dataset poses significant challenges to the existing state-of-the-art. We systematically handle the long-tail nature of these concepts and present a modular approach to combine category, attribute, and relationship cues that outperforms existing approaches.",0
"Our focus is on the task of segmenting image regions based on natural language phrases, which we explore using a new dataset of 77,262 images and 345,486 phrase-region pairs. Our dataset builds on the Visual Genome dataset, utilizing its annotations to create a difficult set of referring phrases that are manually annotated alongside their corresponding regions. The phrases in our dataset are associated with multiple regions and encompass a wide range of object and stuff categories, as well as attributes like color, shape, parts, and relationships with other entities in the image. Our experiments reveal that the variety and scope of concepts in our dataset present significant challenges for existing state-of-the-art techniques. We tackle the long-tail distribution of these concepts and introduce a modular approach that combines category, attribute, and relationship cues, resulting in superior performance compared to existing methods.",1
"Modern deep learning models have revolutionized the field of computer vision. But, a significant drawback of most of these models is that they require a large number of labelled examples to generalize properly. Recent developments in few-shot learning aim to alleviate this requirement. In this paper, we propose a novel lightweight CNN architecture for 1-shot image segmentation. The proposed model is created by taking inspiration from well-performing architectures for semantic segmentation and adapting it to the 1-shot domain. We train our model using 4 meta-learning algorithms that have worked well for image classification and compare the results. For the chosen dataset, our proposed model has a 70% lower parameter count than the benchmark, while having better or comparable mean IoU scores using all 4 of the meta-learning algorithms.",0
"The realm of computer vision has been transformed by modern deep learning models. However, most of these models have a major limitation in that they need a large number of labeled examples to generalize effectively. Few-shot learning techniques have emerged as a solution to this problem. Our paper introduces a new, lightweight CNN architecture for 1-shot image segmentation. We drew inspiration from successful semantic segmentation models and tailored them to the 1-shot domain. We trained our model with 4 meta-learning algorithms that have yielded positive results in image classification and compared the outcomes. Our proposed model has a 70% lower parameter count than the benchmark for the chosen dataset. Despite this, it achieves mean IoU scores that are either comparable or better than those of the benchmark when using all 4 of the meta-learning algorithms.",1
"Image segmentation is the initial step for every image analysis task. A large variety of segmentation algorithm has been proposed in the literature during several decades with some mixed success. Among them, the fuzzy energy based active contour models get attention to the researchers during last decade which results in development of various methods. A good segmentation algorithm should perform well in a large number of images containing noise, blur, low contrast, region in-homogeneity, etc. However, the performances of the most of the existing fuzzy energy based active contour models have been evaluated typically on the limited number of images. In this article, our aim is to review the existing fuzzy active contour models from the theoretical point of view and also evaluate them experimentally on a large set of images under the various conditions. The analysis under a large variety of images provides objective insight into the strengths and weaknesses of various fuzzy active contour models. Finally, we discuss several issues and future research direction on this particular topic.",0
"The first step in any image analysis task is image segmentation. Over the years, a wide range of segmentation algorithms have been proposed in the literature with varying degrees of success. In recent years, researchers have shown particular interest in fuzzy energy based active contour models, which have led to the development of numerous methods. An effective segmentation algorithm should be able to perform well on a diverse range of images that may contain noise, blur, low contrast, and region in-homogeneity, among other challenges. However, most fuzzy energy based active contour models have only been tested on a limited number of images. This article aims to provide a theoretical review of existing fuzzy active contour models while also evaluating their performance experimentally on a large set of images under various conditions. By analyzing a diverse range of images, we can gain objective insights into the strengths and weaknesses of various fuzzy active contour models. Finally, we discuss several issues and future research directions related to this topic.",1
"The well-known technique outlined in the paper of Leon A. Gatys et al., A Neural Algorithm of Artistic Style, has become a trending topic both in academic literature and industrial applications. Neural Style Transfer (NST) constitutes an essential tool for a wide range of applications, such as artistic stylization of 2D images, user-assisted creation tools and production tools for entertainment applications. The purpose of this study is to present a method for creating artistic maps from satellite images, based on the NST algorithm. This method includes three basic steps (i) application of semantic image segmentation on the original satellite image, dividing its content into classes (i.e. land, water), (ii) application of neural style transfer for each class and (iii) creation of a collage, i.e. an artistic image consisting of a combination of the two stylized image generated on the previous step.",0
"The paper by Leon A. Gatys et al. titled ""A Neural Algorithm of Artistic Style"" has gained popularity in both academic and industrial settings as a result of its well-known technique. Neural Style Transfer (NST) is an indispensable tool for a variety of applications, such as creating artistic 2D images, user-assisted creation tools, and entertainment production tools. This research aims to introduce a method for generating artistic maps from satellite images using the NST algorithm. The method involves three primary steps, including segmenting the original satellite image into classes using semantic image segmentation, applying neural style transfer to each class, and creating a collage, which is an artistic image produced by merging the two stylized images from the previous step.",1
"Deep neural networks (DNNs) have shown remarkable performance improvements on vision-related tasks such as object detection or image segmentation. Despite their success, they generally lack the understanding of 3D objects which form the image, as it is not always possible to collect 3D information about the scene or to easily annotate it. Differentiable rendering is a novel field which allows the gradients of 3D objects to be calculated and propagated through images. It also reduces the requirement of 3D data collection and annotation, while enabling higher success rate in various applications. This paper reviews existing literature and discusses the current state of differentiable rendering, its applications and open research problems.",0
"DNNs have demonstrated impressive advancements in vision-related tasks, including object detection and image segmentation. However, their understanding of 3D objects within the image is limited, as gathering 3D information or annotating it is often not feasible. Differentiable rendering is a new field that allows for the calculation and propagation of 3D object gradients in images, reducing the need for 3D data collection and annotation and increasing success rates in various applications. This article reviews current literature, explores the current state of differentiable rendering, its applications, and research questions that remain unanswered.",1
"Vision-based lane detection (LD) is a key part of autonomous driving technology, and it is also a challenging problem. As one of the important constraints of scene composition, vanishing point (VP) may provide a useful clue for lane detection. In this paper, we proposed a new multi-task fusion network architecture for high-precision lane detection. Firstly, the ERFNet was used as the backbone to extract the hierarchical features of the road image. Then, the lanes were detected using image segmentation. Finally, combining the output of lane detection and the hierarchical features extracted by the backbone, the lane VP was predicted using heatmap regression. The proposed fusion strategy was tested using the public CULane dataset. The experimental results suggest that the lane detection accuracy of our method outperforms those of state-of-the-art (SOTA) methods.",0
"Autonomous driving technology heavily relies on vision-based lane detection (LD), which is a challenging problem. Vanishing point (VP) is an important constraint in scene composition and can aid in lane detection. In this study, we proposed a multi-task fusion network architecture that enables high-precision lane detection. Our approach involved using ERFNet as the backbone to extract hierarchical features of the road image, followed by image segmentation to detect lanes. Finally, combining the output of lane detection and hierarchical features, we predicted the lane VP using heatmap regression. We evaluated our approach on the public CULane dataset and found that it outperformed existing state-of-the-art (SOTA) methods in terms of lane detection accuracy.",1
"We present a multiple instance learning class activation map (MIL-CAM) approach for pixel-level minirhizotron image segmentation given weak image-level labels. Minirhizotrons are used to image plant roots in situ. Minirhizotron imagery is often composed of soil containing a few long and thin root objects of small diameter. The roots prove to be challenging for existing semantic image segmentation methods to discriminate. In addition to learning from weak labels, our proposed MIL-CAM approach re-weights the root versus soil pixels during analysis for improved performance due to the heavy imbalance between soil and root pixels. The proposed approach outperforms other attention map and multiple instance learning methods for localization of root objects in minirhizotron imagery.",0
"A method called the Multiple Instance Learning Class Activation Map (MIL-CAM) is presented for the segmentation of pixel-level minirhizotron images using weak image-level labels. The images are of plant roots in their natural habitat, with a few thin, small-diameter root objects embedded in soil. This proves challenging for current semantic image segmentation methods. The proposed approach utilizes weak labels and re-weights root and soil pixels for better performance due to the significant imbalance between the two. MIL-CAM outperforms other methods for localizing root objects in minirhizotron images.",1
"We present a method combining affinity prediction with region agglomeration, which improves significantly upon the state of the art of neuron segmentation from electron microscopy (EM) in accuracy and scalability. Our method consists of a 3D U-NET, trained to predict affinities between voxels, followed by iterative region agglomeration. We train using a structured loss based on MALIS, encouraging topologically correct segmentations obtained from affinity thresholding. Our extension consists of two parts: First, we present a quasi-linear method to compute the loss gradient, improving over the original quadratic algorithm. Second, we compute the gradient in two separate passes to avoid spurious gradient contributions in early training stages. Our predictions are accurate enough that simple learning-free percentile-based agglomeration outperforms more involved methods used earlier on inferior predictions. We present results on three diverse EM datasets, achieving relative improvements over previous results of 27%, 15%, and 250%. Our findings suggest that a single method can be applied to both nearly isotropic block-face EM data and anisotropic serial sectioned EM data. The runtime of our method scales linearly with the size of the volume and achieves a throughput of about 2.6 seconds per megavoxel, qualifying our method for the processing of very large datasets.",0
"Our method for neuron segmentation from electron microscopy (EM) improves accuracy and scalability compared to the current state of the art. We combine affinity prediction with region agglomeration using a 3D U-NET trained to predict affinities between voxels, followed by iterative region agglomeration. To encourage topologically correct segmentations, we use a structured loss based on MALIS. Our extension includes a quasi-linear method for computing the loss gradient and computing the gradient in two separate passes to avoid spurious gradient contributions in early training stages. Simple learning-free percentile-based agglomeration outperforms more involved methods used on inferior predictions due to the accuracy of our predictions. Our method achieves relative improvements over previous results of 27%, 15%, and 250% on three diverse EM datasets and can be applied to both nearly isotropic block-face EM data and anisotropic serial sectioned EM data. The runtime of our method scales linearly with the volume size and has a throughput of approximately 2.6 seconds per megavoxel, making it suitable for processing very large datasets.",1
"Deep learning has achieved great success as a powerful classification tool and also made great progress in sematic segmentation. As a result, many researchers also believe that deep learning is the most powerful tool for pixel level image segmentation. Could deep learning achieve the same pixel level accuracy as traditional image segmentation techniques by mapping the features of the object into a non-linear function? This paper gives a short survey of the accuracies achieved by deep learning so far in image classification and image segmentation. Compared to the high accuracies achieved by deep learning in classifying limited categories in international vision challenges, the image segmentation accuracies achieved by deep learning in the same challenges are only about eighty percent. On the contrary, the image segmentation accuracies achieved in international biomedical challenges are close to ninty five percent. Why the difference is so big? Since the accuracies of the competitors methods are only evaluated based on their submitted results instead of reproducing the results by submitting the source codes or the software, are the achieved accuracies verifiable or overhyped? We are going to find it out by analyzing the working principle of deep learning. Finally, we compared the accuracies of state of the art deep learning methods with a threshold selection method quantitatively. Experimental results showed that the threshold selection method could achieve significantly higher accuracy than deep learning methods in image segmentation.",0
"Deep learning has proven to be a highly effective tool for classification and sematic segmentation, leading many researchers to believe it is the most powerful option for pixel-level image segmentation. The question remains whether deep learning can match the accuracy of traditional image segmentation techniques by mapping object features into a non-linear function. This paper provides a brief overview of deep learning's successes in image classification and segmentation, highlighting its high accuracy in limited categories in international vision challenges compared to its lower accuracy in image segmentation challenges. Interestingly, deep learning achieves close to 95% accuracy in international biomedical challenges. However, since competitors' methods are evaluated solely on their submitted results, it's unclear if these accuracies are genuine. To understand deep learning's working principle and accuracy, we compared state-of-the-art deep learning methods to a threshold selection method quantitatively. The experimental results show that the threshold selection method performs significantly better in image segmentation than deep learning methods.",1
"The automated segmentation of buildings in remote sensing imagery is a challenging task that requires the accurate delineation of multiple building instances over typically large image areas. Manual methods are often laborious and current deep-learning-based approaches fail to delineate all building instances and do so with adequate accuracy. As a solution, we present Trainable Deep Active Contours (TDACs), an automatic image segmentation framework that intimately unites Convolutional Neural Networks (CNNs) and Active Contour Models (ACMs). The Eulerian energy functional of the ACM component includes per-pixel parameter maps that are predicted by the backbone CNN, which also initializes the ACM. Importantly, both the ACM and CNN components are fully implemented in TensorFlow and the entire TDAC architecture is end-to-end automatically differentiable and backpropagation trainable without user intervention. TDAC yields fast, accurate, and fully automatic simultaneous delineation of arbitrarily many buildings in the image. We validate the model on two publicly available aerial image datasets for building segmentation, and our results demonstrate that TDAC establishes a new state-of-the-art performance.",0
"Segmenting buildings in remote sensing imagery is a difficult task that involves accurately outlining multiple building instances across large image areas. Manual methods are often time-consuming and current deep-learning-based approaches struggle to accurately identify every building instance. To address this issue, we introduce Trainable Deep Active Contours (TDACs), an automated image segmentation framework that combines Convolutional Neural Networks (CNNs) and Active Contour Models (ACMs). The ACM component's Eulerian energy functional includes per-pixel parameter maps predicted by the backbone CNN, which also initializes the ACM. Both the ACM and CNN components are fully implemented in TensorFlow, and TDAC is entirely end-to-end automatically differentiable and backpropagation trainable without user intervention. TDAC can quickly and accurately delineate any number of buildings in an image, as demonstrated by our validation on two publicly available aerial image datasets for building segmentation. Our results show that TDAC achieves state-of-the-art performance.",1
"Greenhouse segmentation has pivotal importance for climate-smart agricultural land-use planning. Deep learning-based approaches provide state-of-the-art performance in natural image segmentation. However, semantic segmentation on high-resolution optical satellite imagery is a challenging task because of the complex environment. In this paper, a sound methodology is proposed for pixel-wise classification on images acquired by the Azersky (SPOT-7) optical satellite. In particular, customized variations of U-Net-like architectures are employed to identify greenhouses. Two models are proposed which uniquely incorporate dilated convolutions and skip connections, and the results are compared to that of the baseline U-Net model. The dataset used consists of pan-sharpened orthorectified Azersky images (red, green, blue,and near infrared channels) with 1.5-meter resolution and annotation masks, collected from 15 regions in Azerbaijan where the greenhouses are densely congested. The images cover the cumulative area of 1008 $km^2$ and annotation masks contain 47559 polygons in total. The $F_1, Kappa, AUC$, and $IOU$ scores are used for performance evaluation. It is observed that the use of the deconvolutional layers alone throughout the expansive path does not yield satisfactory results; therefore, they are either replaced or coupled with bilinear interpolation. All models benefit from the hard example mining (HEM) strategy. It is also reported that the best accuracy of $93.29\%$ ($F_1\,score$) is recorded when the weighted binary cross-entropy loss is coupled with the dice loss. Experimental results showed that both of the proposed models outperformed the baseline U-Net architecture such that the best model proposed scored $4.48\%$ higher in comparison to the baseline architecture.",0
"The segmentation of greenhouses is crucial for effective climate-smart agricultural land-use planning. While deep learning-based approaches have shown impressive results in natural image segmentation, semantic segmentation of high-resolution optical satellite imagery is a complex task due to the intricate environment. This study proposes a reliable methodology for pixel-wise classification of Azersky (SPOT-7) optical satellite images using customized variations of U-Net-like architectures to identify greenhouses. The proposed models incorporate dilated convolutions and skip connections, and are compared to the baseline U-Net model. The dataset used consists of pan-sharpened orthorectified Azersky images with 1.5-meter resolution and annotation masks from 15 regions in Azerbaijan. The performance evaluation is based on the $F_1, Kappa, AUC$, and $IOU$ scores. The results show that the proposed models outperform the baseline U-Net architecture, with the best model achieving a $F_1\,score$ of $93.29\%$ and scoring $4.48\%$ higher than the baseline architecture. The study also reports that the deconvolutional layers alone do not yield satisfactory results and need to be replaced or coupled with bilinear interpolation. All models benefit from the hard example mining (HEM) strategy.",1
"Segmentation of multiple surfaces in medical images is a challenging problem, further complicated by the frequent presence of weak boundary and mutual influence between adjacent objects. The traditional graph-based optimal surface segmentation method has proven its effectiveness with its ability of capturing various surface priors in a uniform graph model. However, its efficacy heavily relies on handcrafted features that are used to define the surface cost for the ""goodness"" of a surface. Recently, deep learning (DL) is emerging as powerful tools for medical image segmentation thanks to its superior feature learning capability. Unfortunately, due to the scarcity of training data in medical imaging, it is nontrivial for DL networks to implicitly learn the global structure of the target surfaces, including surface interactions. In this work, we propose to parameterize the surface cost functions in the graph model and leverage DL to learn those parameters. The multiple optimal surfaces are then simultaneously detected by minimizing the total surface cost while explicitly enforcing the mutual surface interaction constraints. The optimization problem is solved by the primal-dual Internal Point Method, which can be implemented by a layer of neural networks, enabling efficient end-to-end training of the whole network. Experiments on Spectral Domain Optical Coherence Tomography (SD-OCT) retinal layer segmentation and Intravascular Ultrasound (IVUS) vessel wall segmentation demonstrated very promising results. All source code is public to facilitate further research at this direction.",0
"The segmentation of multiple surfaces in medical images is a difficult task due to weak boundaries and mutual influence between objects. Traditional graph-based optimal surface segmentation methods have been effective at capturing surface priors but rely heavily on handcrafted features. Deep learning has shown promise in medical image segmentation but struggles with the scarcity of training data and learning global surface structure. To address this, we propose parameterizing the surface cost functions in the graph model and using DL to learn those parameters. We simultaneously detect multiple optimal surfaces by minimizing the total surface cost while enforcing mutual interaction constraints. We use the primal-dual Internal Point Method to solve the optimization problem, which can be implemented with neural networks for efficient end-to-end training. Our experiments on SD-OCT retinal layer segmentation and IVUS vessel wall segmentation show very promising results. We have made our source code public to facilitate further research in this direction.",1
"Semi-supervised learning has attracted much attention in medical image segmentation due to challenges in acquiring pixel-wise image annotations, which is a crucial step for building high-performance deep learning methods. Most existing semi-supervised segmentation approaches either tend to neglect geometric constraint in object segments, leading to incomplete object coverage, or impose strong shape prior that requires extra alignment. In this work, we propose a novel shapeaware semi-supervised segmentation strategy to leverage abundant unlabeled data and to enforce a geometric shape constraint on the segmentation output. To achieve this, we develop a multi-task deep network that jointly predicts semantic segmentation and signed distance map(SDM) of object surfaces. During training, we introduce an adversarial loss between the predicted SDMs of labeled and unlabeled data so that our network is able to capture shape-aware features more effectively. Experiments on the Atrial Segmentation Challenge dataset show that our method outperforms current state-of-the-art approaches with improved shape estimation, which validates its efficacy. Code is available at https://github.com/kleinzcy/SASSnet.",0
"The difficulty in obtaining pixel-level image annotations is a significant challenge for developing high-performance deep learning models for medical image segmentation, which has led to an increased interest in semi-supervised learning. However, most current semi-supervised segmentation techniques either ignore geometric constraints in object segments, resulting in incomplete object coverage, or require additional alignment to impose strong shape priors. To address these limitations, we propose a novel approach that incorporates a geometric shape constraint on the segmentation output, leveraging the abundance of unlabeled data. Our method involves developing a multi-task deep network that predicts both semantic segmentation and signed distance maps of object surfaces, while introducing an adversarial loss between the predicted SDMs of labeled and unlabeled data during training. Experimental results on the Atrial Segmentation Challenge dataset demonstrate that our approach outperforms current state-of-the-art techniques by improving shape estimation. The code for our approach is available at https://github.com/kleinzcy/SASSnet.",1
"Panoramic segmentation is a scene where image segmentation tasks is more difficult. With the development of CNN networks, panoramic segmentation tasks have been sufficiently developed.However, the current panoramic segmentation algorithms are more concerned with context semantics, but the details of image are not processed enough. Moreover, they cannot solve the problems which contains the accuracy of occluded object segmentation,little object segmentation,boundary pixel in object segmentation etc. Aiming to address these issues, this paper presents some useful tricks. (a) By changing the basic segmentation model, the model can take into account the large objects and the boundary pixel classification of image details. (b) Modify the loss function so that it can take into account the boundary pixels of multiple objects in the image. (c) Use a semi-supervised approach to regain control of the training process. (d) Using multi-scale training and reasoning. All these operations named AinnoSeg, AinnoSeg can achieve state-of-art performance on the well-known dataset ADE20K.",0
"Panoramic segmentation is a challenging task in image segmentation, but with the advancement of CNN networks, it has become more feasible. However, current algorithms prioritize contextual semantics over image details and struggle with accurately segmenting occluded or small objects and boundary pixels. To address these issues, this paper proposes several methods. Firstly, by modifying the basic segmentation model, the algorithm can better handle large objects and boundary pixel classification. Secondly, the loss function is adjusted to consider boundary pixels of multiple objects. Thirdly, a semi-supervised approach is utilized to improve the training process. Lastly, multi-scale training and reasoning are employed. These methods, collectively known as AinnoSeg, achieve state-of-the-art performance on the ADE20K dataset.",1
"The usage of convolutional neural networks (CNNs) for unsupervised image segmentation was investigated in this study. In the proposed approach, label prediction and network parameter learning are alternately iterated to meet the following criteria: (a) pixels of similar features should be assigned the same label, (b) spatially continuous pixels should be assigned the same label, and (c) the number of unique labels should be large. Although these criteria are incompatible, the proposed approach minimizes the combination of similarity loss and spatial continuity loss to find a plausible solution of label assignment that balances the aforementioned criteria well. The contributions of this study are four-fold. First, we propose a novel end-to-end network of unsupervised image segmentation that consists of normalization and an argmax function for differentiable clustering. Second, we introduce a spatial continuity loss function that mitigates the limitations of fixed segment boundaries possessed by previous work. Third, we present an extension of the proposed method for segmentation with scribbles as user input, which showed better accuracy than existing methods while maintaining efficiency. Finally, we introduce another extension of the proposed method: unseen image segmentation by using networks pre-trained with a few reference images without re-training the networks. The effectiveness of the proposed approach was examined on several benchmark datasets of image segmentation.",0
"This study explored the use of convolutional neural networks (CNNs) for unsupervised image segmentation. The approach involves alternating label prediction and network parameter learning to satisfy three criteria: assigning the same label to pixels with similar features, assigning the same label to spatially continuous pixels, and generating a large number of unique labels. Although these criteria are conflicting, the proposed approach minimizes the combination of similarity loss and spatial continuity loss to achieve a reasonable solution for label assignment that balances the criteria. The study's contributions are four-fold, including proposing a novel end-to-end network for unsupervised image segmentation, introducing a spatial continuity loss function to address the limitations of fixed segment boundaries in previous work, presenting an extension of the method for segmentation with user input scribbles, and proposing another extension for unseen image segmentation using pre-trained networks. The proposed approach's effectiveness was assessed on several benchmark datasets for image segmentation.",1
"Supervised learning in large discriminative models is a mainstay for modern computer vision. Such an approach necessitates investing in large-scale human-annotated datasets for achieving state-of-the-art results. In turn, the efficacy of supervised learning may be limited by the size of the human annotated dataset. This limitation is particularly notable for image segmentation tasks, where the expense of human annotation is especially large, yet large amounts of unlabeled data may exist. In this work, we ask if we may leverage semi-supervised learning in unlabeled video sequences and extra images to improve the performance on urban scene segmentation, simultaneously tackling semantic, instance, and panoptic segmentation. The goal of this work is to avoid the construction of sophisticated, learned architectures specific to label propagation (e.g., patch matching and optical flow). Instead, we simply predict pseudo-labels for the unlabeled data and train subsequent models with both human-annotated and pseudo-labeled data. The procedure is iterated for several times. As a result, our Naive-Student model, trained with such simple yet effective iterative semi-supervised learning, attains state-of-the-art results at all three Cityscapes benchmarks, reaching the performance of 67.8% PQ, 42.6% AP, and 85.2% mIOU on the test set. We view this work as a notable step towards building a simple procedure to harness unlabeled video sequences and extra images to surpass state-of-the-art performance on core computer vision tasks.",0
"Modern computer vision relies heavily on supervised learning for large discriminative models. However, this approach requires investing in human-annotated datasets to achieve optimal results. The effectiveness of supervised learning can be limited by the size of the annotated dataset, which is especially challenging for image segmentation tasks due to the high cost of human annotation. In this study, we explore the potential of using semi-supervised learning with unlabeled video sequences and extra images to improve urban scene segmentation performance, including semantic, instance, and panoptic segmentation. Our approach does not require complex architectures for label propagation and instead relies on predicting pseudo-labels for the unlabeled data and training models with both human-annotated and pseudo-labeled data. This process is repeated several times, resulting in our Naive-Student model achieving state-of-the-art results on all three Cityscapes benchmarks with 67.8% PQ, 42.6% AP, and 85.2% mIOU on the test set. Our findings suggest that leveraging unlabeled data can significantly improve core computer vision tasks without requiring complex procedures.",1
"The performance of deep networks for semantic image segmentation largely depends on the availability of large-scale training images which are labelled at the pixel level. Typically, such pixel-level image labellings are obtained manually by a labour-intensive process. To alleviate the burden of manual image labelling, we propose an interesting learning approach to generate pixel-level image labellings automatically. A Guided Filter Network (GFN) is first developed to learn the segmentation knowledge from a source domain, and such GFN then transfers such segmentation knowledge to generate coarse object masks in the target domain. Such coarse object masks are treated as pseudo labels and they are further integrated to optimize/refine the GFN iteratively in the target domain. Our experiments on six image sets have demonstrated that our proposed approach can generate fine-grained object masks (i.e., pixel-level object labellings), whose quality is very comparable to the manually-labelled ones. Our proposed approach can also achieve better performance on semantic image segmentation than most existing weakly-supervised approaches.",0
"The effectiveness of semantic image segmentation using deep networks is heavily reliant on the availability of large-scale training images that have been labelled at the pixel level, which is typically a laborious manual process. To ease this burden, we suggest a novel learning approach that automatically generates pixel-level image labellings. We begin with the development of a Guided Filter Network (GFN) that learns segmentation knowledge from a source domain, which is then transferred to generate coarse object masks in the target domain. These masks act as pseudo labels and are integrated to refine the GFN iteratively in the target domain. Our experiments on six image sets have shown that our approach can produce high-quality pixel-level object labellings that are comparable to manually labelled ones, and it can outperform most existing weakly-supervised approaches in semantic image segmentation.",1
"Single encoder-decoder methodologies for semantic segmentation are reaching their peak in terms of segmentation quality and efficiency per number of layers. To address these limitations, we propose a new architecture based on a decoder which uses a set of shallow networks for capturing more information content. The new decoder has a new topology of skip connections, namely backward and stacked residual connections. In order to further improve the architecture we introduce a weight function which aims to re-balance classes to increase the attention of the networks to under-represented objects. We carried out an extensive set of experiments that yielded state-of-the-art results for the CamVid, Gatech and Freiburg Forest datasets. Moreover, to further prove the effectiveness of our decoder, we conducted a set of experiments studying the impact of our decoder to state-of-the-art segmentation techniques. Additionally, we present a set of experiments augmenting semantic segmentation with optical flow information, showing that motion clues can boost pure image based semantic segmentation approaches.",0
"The quality and efficiency of single encoder-decoder methods for semantic segmentation have peaked in terms of layer count. To overcome these limitations, we have devised a novel decoder architecture that employs several shallow networks to capture more information. This decoder has a unique topology of backward and stacked residual connections. To enhance the architecture, we have included a weight function that rebalances classes to increase network attention on under-represented objects. We conducted extensive experiments that produced top-notch results for the CamVid, Gatech, and Freiburg Forest datasets. Furthermore, we conducted experiments to assess the impact of our decoder on state-of-the-art segmentation techniques. We also performed experiments that augmented semantic segmentation with optical flow information, demonstrating that motion clues can enhance image-based semantic segmentation methods.",1
"Segmentation of objects of interest is one of the central tasks in medical image analysis, which is indispensable for quantitative analysis. When developing machine-learning based methods for automated segmentation, manual annotations are usually used as the ground truth toward which the models learn to mimic. While the bulky parts of the segmentation targets are relatively easy to label, the peripheral areas are often difficult to handle due to ambiguous boundaries and the partial volume effect, etc., and are likely to be labeled with uncertainty. This uncertainty in labeling may, in turn, result in unsatisfactory performance of the trained models. In this paper, we propose superpixel-based label softening to tackle the above issue. Generated by unsupervised over-segmentation, each superpixel is expected to represent a locally homogeneous area. If a superpixel intersects with the annotation boundary, we consider a high probability of uncertain labeling within this area. Driven by this intuition, we soften labels in this area based on signed distances to the annotation boundary and assign probability values within [0, 1] to them, in comparison with the original ""hard"", binary labels of either 0 or 1. The softened labels are then used to train the segmentation models together with the hard labels. Experimental results on a brain MRI dataset and an optical coherence tomography dataset demonstrate that this conceptually simple and implementation-wise easy method achieves overall superior segmentation performances to baseline and comparison methods for both 3D and 2D medical images.",0
"Medical image analysis involves the crucial task of segmenting objects of interest, which is vital for quantitative analysis. Machine-learning based methods for automated segmentation typically rely on manual annotations as ground truth to train models. However, labeling the peripheral areas of segmentation targets can be challenging due to uncertain boundaries and partial volume effects, leading to unsatisfactory performance of trained models. To address this issue, we propose a superpixel-based label softening approach, where each superpixel represents a locally homogeneous area. Uncertain labeling within a superpixel intersecting with the annotation boundary is softened based on signed distances to the boundary, assigning probability values within [0, 1] instead of binary labels of 0 or 1. This softened labeling is combined with hard labeling to train segmentation models. Experimental results on brain MRI and optical coherence tomography datasets demonstrate the superior performance of our approach compared to baseline and comparison methods for both 2D and 3D medical images, offering a simple and easy-to-implement solution.",1
"As the resolution of digital images increase significantly, the processing of images becomes more challenging in terms of accuracy and efficiency. In this paper, we consider image segmentation by solving a partial differentiation equation (PDE) model based on the Mumford-Shah functional. We develop a new algorithm by combining anisotropic mesh adaptation for image representation and finite element method for solving the PDE model. Comparing to traditional algorithms solved by finite difference method, our algorithm provides faster and better results without the need to resizing the images to lower quality. We also extend the algorithm to segment images with multiple regions.",0
"As digital images continue to improve in resolution, accurate and efficient processing becomes increasingly difficult. This study focuses on image segmentation using a partial differentiation equation (PDE) model based on the Mumford-Shah functional. We propose a novel algorithm that combines anisotropic mesh adaptation for image representation with the finite element method for solving the PDE model. Compared to traditional algorithms that use the finite difference method, our approach delivers faster and superior outcomes without requiring image resizing. Furthermore, we expand the algorithm to segment images with multiple regions.",1
"In this work, we propose a new unsupervised image segmentation approach based on mutual information maximization between different constructed views of the inputs. Taking inspiration from autoregressive generative models that predict the current pixel from past pixels in a raster-scan ordering created with masked convolutions, we propose to use different orderings over the inputs using various forms of masked convolutions to construct different views of the data. For a given input, the model produces a pair of predictions with two valid orderings, and is then trained to maximize the mutual information between the two outputs. These outputs can either be low-dimensional features for representation learning or output clusters corresponding to semantic labels for clustering. While masked convolutions are used during training, in inference, no masking is applied and we fall back to the standard convolution where the model has access to the full input. The proposed method outperforms current state-of-the-art on unsupervised image segmentation. It is simple and easy to implement, and can be extended to other visual tasks and integrated seamlessly into existing unsupervised learning methods requiring different views of the data.",0
"Our work introduces a novel method for unsupervised image segmentation. It involves maximizing mutual information between different views of the input, inspired by autoregressive generative models. We use various forms of masked convolutions to create distinct orderings of the data, resulting in a pair of predictions for each input. The model is trained to optimize mutual information between these outputs, which can be low-dimensional features or semantic labels. During training, masked convolutions are employed, but in inference, standard convolutions are used. Our proposed approach achieves superior performance compared to current state-of-the-art methods, while being straightforward to implement and adaptable to other visual tasks. It can also be seamlessly integrated into existing unsupervised learning techniques that require multiple views of the data.",1
"Convolutional neural networks have shown to achieve superior performance on image segmentation tasks. However, convolutional neural networks, operating as black-box systems, generally do not provide a reliable measure about the confidence of their decisions. This leads to various problems in industrial settings, amongst others, inadequate levels of trust from users in the model's outputs as well as a non-compliance with current policy guidelines (e.g., EU AI Strategy). To address these issues, we use uncertainty measures based on Monte-Carlo dropout in the context of a human-in-the-loop system to increase the system's transparency and performance. In particular, we demonstrate the benefits described above on a real-world multi-class image segmentation task of wear analysis in the machining industry. Following previous work, we show that the quality of a prediction correlates with the model's uncertainty. Additionally, we demonstrate that a multiple linear regression using the model's uncertainties as independent variables significantly explains the quality of a prediction (\(R^2=0.718\)). Within the uncertainty-based human-in-the-loop system, the multiple regression aims at identifying failed predictions on an image-level. The system utilizes a human expert to label these failed predictions manually. A simulation study demonstrates that the uncertainty-based human-in-the-loop system increases performance for different levels of human involvement in comparison to a random-based human-in-the-loop system. To ensure generalizability, we show that the presented approach achieves similar results on the publicly available Cityscapes dataset.",0
"Although convolutional neural networks have been demonstrated to outperform other methods for image segmentation tasks, they are typically opaque systems that do not provide reliable information about the confidence of their decisions. This can lead to problems in industrial settings, such as reduced trust from users and non-compliance with policy guidelines. To address these issues, we propose using uncertainty measures based on Monte-Carlo dropout within a human-in-the-loop system to improve transparency and performance. We demonstrate the effectiveness of this approach on a real-world multi-class image segmentation task in the machining industry, showing that prediction quality is correlated with model uncertainty and that a multiple linear regression using uncertainty measures can significantly explain prediction quality. The human-in-the-loop system identifies failed predictions and utilizes a human expert to manually label them. Simulation studies show that our approach outperforms a random-based human-in-the-loop system for different levels of human involvement. Our approach's generalizability is demonstrated by achieving similar results on the publicly available Cityscapes dataset.",1
"In this work, the case of semantic segmentation on a small image dataset (simulated by 1000 randomly selected images from PASCAL VOC 2012), where only weak supervision signals (scribbles from user interaction) are available is studied. Especially, to tackle the problem of limited data annotations in image segmentation, transferring different pre-trained models and CRF based methods are applied to enhance the segmentation performance. To this end, RotNet, DeeperCluster, and Semi&Weakly Supervised Learning (SWSL) pre-trained models are transferred and finetuned in a DeepLab-v2 baseline, and dense CRF is applied both as a post-processing and loss regularization technique. The results of my study show that, on this small dataset, using a pre-trained ResNet50 SWSL model gives results that are 7.4% better than applying an ImageNet pre-trained model; moreover, for the case of training on the full PASCAL VOC 2012 training data, this pre-training approach increases the mIoU results by almost 4%. On the other hand, dense CRF is shown to be very effective as well, enhancing the results both as a loss regularization technique in weakly supervised training and as a post-processing tool.",0
"This study examines the issue of semantic segmentation on a small image dataset consisting of 1000 randomly selected images from PASCAL VOC 2012, where only weak supervision signals in the form of user scribbles are available. The study explores various approaches to address the challenge of limited data annotations in image segmentation, including the use of pre-trained models and CRF based methods to improve the segmentation performance. Specifically, the study transfers and finetunes pre-trained models such as RotNet, DeeperCluster, and Semi&Weakly Supervised Learning (SWSL) in a DeepLab-v2 baseline, and applies dense CRF as a post-processing and loss regularization technique. The findings reveal that, when using a pre-trained ResNet50 SWSL model, the segmentation performance is 7.4% better compared to using an ImageNet pre-trained model on this small dataset. Furthermore, when training on the full PASCAL VOC 2012 training data, this pre-training approach leads to an almost 4% increase in mIoU results. Additionally, the study demonstrates that dense CRF is highly effective in improving the results both as a loss regularization technique in weakly supervised training and as a post-processing tool.",1
"The strict security requirements placed on medical records by various privacy regulations become major obstacles in the age of big data. To ensure efficient machine learning as a service schemes while protecting data confidentiality, in this work, we propose blind UNET (BUNET), a secure protocol that implements privacy-preserving medical image segmentation based on the UNET architecture. In BUNET, we efficiently utilize cryptographic primitives such as homomorphic encryption and garbled circuits (GC) to design a complete secure protocol for the UNET neural architecture. In addition, we perform extensive architectural search in reducing the computational bottleneck of GC-based secure activation protocols with high-dimensional input data. In the experiment, we thoroughly examine the parameter space of our protocol, and show that we can achieve up to 14x inference time reduction compared to the-state-of-the-art secure inference technique on a baseline architecture with negligible accuracy degradation.",0
"Privacy regulations impose strict security requirements on medical records, which can hinder the use of big data. In order to facilitate machine learning services while maintaining data confidentiality, we propose a secure protocol called blind UNET (BUNET) that uses homomorphic encryption and garbled circuits (GC) to achieve privacy-preserving medical image segmentation based on the UNET architecture. We conducted an extensive architectural search to reduce the computational bottleneck of GC-based secure activation protocols with high-dimensional input data. In our experiment, we thoroughly explored the parameter space of our protocol and found that we can achieve up to 14x faster inference time compared to the current state-of-the-art secure inference technique, while maintaining high accuracy levels.",1
"Uncertainty estimation is important for interpreting the trustworthiness of machine learning models in many applications. This is especially critical in the data-driven active learning setting where the goal is to achieve a certain accuracy with minimum labeling effort. In such settings, the model learns to select the most informative unlabeled samples for annotation based on its estimated uncertainty. The highly uncertain predictions are assumed to be more informative for improving model performance. In this paper, we explore uncertainty calibration within an active learning framework for medical image segmentation, an area where labels often are scarce. Various uncertainty estimation methods and acquisition strategies (regions and full images) are investigated. We observe that selecting regions to annotate instead of full images leads to more well-calibrated models. Additionally, we experimentally show that annotating regions can cut 50% of pixels that need to be labeled by humans compared to annotating full images.",0
"The assessment of uncertainty is crucial in assessing the reliability of machine learning models in various applications. This is particularly important in data-driven active learning scenarios where the aim is to achieve high accuracy with minimal labeling effort. In such cases, the model selects the most informative unlabeled samples for annotation based on its estimated uncertainty. The predictions with high uncertainty are deemed to be more valuable for enhancing model performance. In this study, we investigate uncertainty calibration in active learning for medical image segmentation, an area where labels are often sparse. We explore different uncertainty estimation techniques and acquisition strategies, such as selecting regions or entire images for annotation. Our findings demonstrate that selecting regions for annotation instead of full images leads to more accurately calibrated models. Furthermore, we experimentally demonstrate that annotating regions can reduce the number of pixels that need to be labeled by humans by 50% compared to annotating entire images.",1
"Medical image annotations are prohibitively time-consuming and expensive to obtain. To alleviate annotation scarcity, many approaches have been developed to efficiently utilize extra information, e.g.,semi-supervised learning further exploring plentiful unlabeled data, domain adaptation including multi-modality learning and unsupervised domain adaptation resorting to the prior knowledge from additional modality. In this paper, we aim to investigate the feasibility of simultaneously leveraging abundant unlabeled data and well-established cross-modality data for annotation-efficient medical image segmentation. To this end, we propose a novel semi-supervised domain adaptation approach, namely Dual-Teacher, where the student model not only learns from labeled target data (e.g., CT), but also explores unlabeled target data and labeled source data (e.g., MR) by two teacher models. Specifically, the student model learns the knowledge of unlabeled target data from intra-domain teacher by encouraging prediction consistency, as well as the shape priors embedded in labeled source data from inter-domain teacher via knowledge distillation. Consequently, the student model can effectively exploit the information from all three data resources and comprehensively integrate them to achieve improved performance. We conduct extensive experiments on MM-WHS 2017 dataset and demonstrate that our approach is able to concurrently utilize unlabeled data and cross-modality data with superior performance, outperforming semi-supervised learning and domain adaptation methods with a large margin.",0
"Obtaining medical image annotations is a costly and time-consuming process. In order to overcome the scarcity of annotations, various approaches have been developed to efficiently utilize additional information, such as semi-supervised learning, domain adaptation, and unsupervised domain adaptation. The objective of this paper is to examine the feasibility of using plentiful unlabeled data and well-established cross-modality data to enhance medical image segmentation with fewer annotations. We propose a novel approach called Dual-Teacher, which employs two teacher models to enable the student model to learn from labeled target data as well as unlabeled target data and labeled source data. The student model learns the knowledge of unlabeled target data from the intra-domain teacher and the shape priors embedded in labeled source data from the inter-domain teacher. By integrating information from all three data resources, our approach achieves superior performance compared to other semi-supervised learning and domain adaptation methods. We conduct extensive experiments on the MM-WHS 2017 dataset to demonstrate the effectiveness of our approach.",1
"Surgical tool segmentation in endoscopic images is an important problem: it is a crucial step towards full instrument pose estimation and it is used for integration of pre- and intra-operative images into the endoscopic view. While many recent approaches based on convolutional neural networks have shown great results, a key barrier to progress lies in the acquisition of a large number of manually-annotated images which is necessary for an algorithm to generalize and work well in diverse surgical scenarios. Unlike the surgical image data itself, annotations are difficult to acquire and may be of variable quality. On the other hand, synthetic annotations can be automatically generated by using forward kinematic model of the robot and CAD models of tools by projecting them onto an image plane. Unfortunately, this model is very inaccurate and cannot be used for supervised learning of image segmentation models. Since generated annotations will not directly correspond to endoscopic images due to errors, we formulate the problem as an unpaired image-to-image translation where the goal is to learn the mapping between an input endoscopic image and a corresponding annotation using an adversarial model. Our approach allows to train image segmentation models without the need to acquire expensive annotations and can potentially exploit large unlabeled endoscopic image collection outside the annotated distributions of image/annotation data. We test our proposed method on Endovis 2017 challenge dataset and show that it is competitive with supervised segmentation methods.",0
"The segmentation of surgical tools in endoscopic images is a significant issue as it is vital for full instrument pose estimation and the integration of pre-operative and intra-operative images into the endoscopic view. Although several approaches based on convolutional neural networks have exhibited impressive outcomes, the primary hurdle to progress is acquiring a large number of manually-annotated images, which is essential for the algorithm to function effectively in diverse surgical scenarios. Obtaining annotations is challenging and may vary in quality, whereas synthetic annotations can be generated automatically using the forward kinematic model of the robot and CAD models of tools by projecting them onto an image plane. Unfortunately, this method is not reliable for supervised learning of image segmentation models as the generated annotations may not correspond directly to the endoscopic images due to errors. Hence, we propose an unpaired image-to-image translation, where the objective is to learn the mapping between an input endoscopic image and a corresponding annotation using an adversarial model. Our method enables us to train image segmentation models without the need for expensive annotations and can potentially take advantage of a vast collection of unlabeled endoscopic images outside the annotated distributions of image/annotation data. We evaluated our proposed approach on the Endovis 2017 challenge dataset and demonstrated that it is competitive with supervised segmentation methods.",1
"As constituent parts of image objects, superpixels can improve several higher-level operations. However, image segmentation methods might have their accuracy seriously compromised for reduced numbers of superpixels. We have investigated a solution based on the Iterative Spanning Forest (ISF) framework. In this work, we present Dynamic ISF (DISF) -- a method based on the following steps. (a) It starts from an image graph and a seed set with considerably more pixels than the desired number of superpixels. (b) The seeds compete among themselves, and each seed conquers its most closely connected pixels, resulting in an image partition (spanning forest) with connected superpixels. In step (c), DISF assigns relevance values to seeds based on superpixel analysis and removes the most irrelevant ones. Steps (b) and (c) are repeated until the desired number of superpixels is reached. DISF has the chance to reconstruct relevant edges after each iteration, when compared to region merging algorithms. As compared to other seed-based superpixel methods, DISF is more likely to find relevant seeds. It also introduces dynamic arc-weight estimation in the ISF framework for more effective superpixel delineation, and we demonstrate all results on three datasets with distinct object properties.",0
"Superpixels can enhance various high-level functions as parts of image objects. Yet, the precision of image segmentation approaches may be greatly affected by a reduced number of superpixels. To address this issue, we have explored a resolution using the Iterative Spanning Forest (ISF) framework. Our approach, Dynamic ISF (DISF), is based on three steps. Firstly, DISF commences with an image graph and a seed set containing more pixels than the desired number of superpixels. Secondly, the seeds compete and conquer their closest connected pixels, resulting in a connected image partition (spanning forest) with superpixels. Thirdly, DISF assigns importance values to seeds based on superpixel analysis and removes those that are irrelevant. Steps two and three are repeated until the desired number of superpixels is achieved. In contrast to region merging algorithms, DISF has the potential to restore relevant edges after each iteration. Our method is more likely to identify significant seeds than other seed-based superpixel approaches. Additionally, DISF integrates dynamic arc-weight estimation into the ISF framework to facilitate more effective superpixel delineation. We present our findings on three datasets with distinct object characteristics.",1
"To assist researchers to identify Environmental Microorganisms (EMs) effectively, a Multiscale CNN-CRF (MSCC) framework for the EM image segmentation is proposed in this paper. There are two parts in this framework: The first is a novel pixel-level segmentation approach, using a newly introduced Convolutional Neural Network (CNN), namely, ""mU-Net-B3"", with a dense Conditional Random Field (CRF) postprocessing. The second is a VGG-16 based patch-level segmentation method with a novel ""buffer"" strategy, which further improves the segmentation quality of the details of the EMs. In the experiment, compared with the state-of-the-art methods on 420 EM images, the proposed MSCC method reduces the memory requirement from 355 MB to 103 MB, improves the overall evaluation indexes (Dice, Jaccard, Recall, Accuracy) from 85.24%, 77.42%, 82.27%, and 96.76% to 87.13%, 79.74%, 87.12%, and 96.91%, respectively, and reduces the volume overlap error from 22.58% to 20.26%. Therefore, the MSCC method shows great potential in the EM segmentation field.",0
"This paper introduces a Multiscale CNN-CRF (MSCC) framework that assists researchers in effectively identifying Environmental Microorganisms (EMs). The framework consists of two parts: Firstly, a novel pixel-level segmentation approach using a Convolutional Neural Network (CNN) called ""mU-Net-B3"" with a dense Conditional Random Field (CRF) postprocessing. Secondly, a VGG-16 based patch-level segmentation method with a new ""buffer"" strategy that further enhances the segmentation quality of the EMs' details. The proposed MSCC method outperforms state-of-the-art methods on 420 EM images by reducing memory requirements from 355 MB to 103 MB, improving evaluation indexes (Dice, Jaccard, Recall, Accuracy) from 85.24%, 77.42%, 82.27%, and 96.76% to 87.13%, 79.74%, 87.12%, and 96.91%, respectively, and reducing volume overlap errors from 22.58% to 20.26%. Therefore, the MSCC method has great potential in the EM segmentation field.",1
"Convolutional Neural Networks (CNN) have recently seen tremendous success in various computer vision tasks. However, their application to problems with high dimensional input and output, such as high-resolution image and video segmentation or 3D medical imaging, has been limited by various factors. Primarily, in the training stage, it is necessary to store network activations for back propagation. In these settings, the memory requirements associated with storing activations can exceed what is feasible with current hardware, especially for problems in 3D. Motivated by the propagation of signals over physical networks, that are governed by the hyperbolic Telegraph equation, in this work we introduce a fully conservative hyperbolic network for problems with high dimensional input and output. We introduce a coarsening operation that allows completely reversible CNNs by using a learnable Discrete Wavelet Transform and its inverse to both coarsen and interpolate the network state and change the number of channels. We show that fully reversible networks are able to achieve results comparable to the state of the art in 4D time-lapse hyper spectral image segmentation and full 3D video segmentation, with a much lower memory footprint that is a constant independent of the network depth. We also extend the use of such networks to Variational Auto Encoders with high resolution input and output.",0
"While Convolutional Neural Networks (CNN) have found success in computer vision tasks, they have struggled with high dimensional input and output problems like 3D medical imaging or high-resolution image and video segmentation due to memory requirements associated with network activations in the training stage. To address this issue, this work introduces a fully conservative hyperbolic network inspired by the hyperbolic Telegraph equation. The network uses a coarsening operation with a learnable Discrete Wavelet Transform and its inverse to make CNNs completely reversible, allowing for a reduced memory footprint that is constant regardless of network depth. The results of this reversible network are comparable to the state of the art in 4D time-lapse hyper-spectral image segmentation and full 3D video segmentation, and can also be extended to Variational Auto Encoders with high resolution input and output.",1
"Deep neural networks have achieved satisfactory performance in piles of medical image analysis tasks. However the training of deep neural network requires a large amount of samples with high-quality annotations. In medical image segmentation, it is very laborious and expensive to acquire precise pixel-level annotations. Aiming at training deep segmentation models on datasets with probably corrupted annotations, we propose a novel Meta Corrupted Pixels Mining (MCPM) method based on a simple meta mask network. Our method is targeted at automatically estimate a weighting map to evaluate the importance of every pixel in the learning of segmentation network. The meta mask network which regards the loss value map of the predicted segmentation results as input, is capable of identifying out corrupted layers and allocating small weights to them. An alternative algorithm is adopted to train the segmentation network and the meta mask network, simultaneously. Extensive experimental results on LIDC-IDRI and LiTS datasets show that our method outperforms state-of-the-art approaches which are devised for coping with corrupted annotations.",0
"Numerous medical image analysis tasks have been successfully accomplished by deep neural networks, but their training necessitates a substantial amount of samples with high-quality annotations. Obtaining precise pixel-level annotations for medical image segmentation is both laborious and expensive. To overcome this obstacle, we have devised a novel approach named Meta Corrupted Pixels Mining (MCPM) that is based on a straightforward meta mask network. Our technique automatically assesses the importance of each pixel in segmentation network learning by creating a weighting map for datasets with potentially corrupt annotations. The meta mask network receives the loss value map of the predicted segmentation outcomes as input and identifies corrupt layers while allocating small weights to them. We employ an alternative algorithm to train both the segmentation network and the meta mask network concurrently. Our method surpasses state-of-the-art approaches meant to address corrupted annotations in LIDC-IDRI and LiTS datasets, according to extensive experimental results.",1
"For the majority of the learning-based segmentation methods, a large quantity of high-quality training data is required. In this paper, we present a novel learning-based segmentation model that could be trained semi- or un- supervised. Specifically, in the unsupervised setting, we parameterize the Active contour without edges (ACWE) framework via a convolutional neural network (ConvNet), and optimize the parameters of the ConvNet using a self-supervised method. In another setting (semi-supervised), the auxiliary segmentation ground truth is used during training. We show that the method provides fast and high-quality bone segmentation in the context of single-photon emission computed tomography (SPECT) image.",0
"The majority of segmentation methods that rely on learning require a significant amount of high-quality training data. This paper introduces a new segmentation model that can be trained with partial or no supervision. To accomplish this, we employ a convolutional neural network (ConvNet) to parameterize the Active contour without edges (ACWE) framework in the unsupervised scenario. We optimize the parameters of the ConvNet using a self-supervised approach. In a semi-supervised setting, we use auxiliary segmentation ground truth during training. Our results demonstrate that this method yields fast and precise bone segmentation in SPECT images.",1
"We introduce a fluid-based image augmentation method for medical image analysis. In contrast to existing methods, our framework generates anatomically meaningful images via interpolation from the geodesic subspace underlying given samples. Our approach consists of three steps: 1) given a source image and a set of target images, we construct a geodesic subspace using the Large Deformation Diffeomorphic Metric Mapping (LDDMM) model; 2) we sample transformations from the resulting geodesic subspace; 3) we obtain deformed images and segmentations via interpolation. Experiments on brain (LPBA) and knee (OAI) data illustrate the performance of our approach on two tasks: 1) data augmentation during training and testing for image segmentation; 2) one-shot learning for single atlas image segmentation. We demonstrate that our approach generates anatomically meaningful data and improves performance on these tasks over competing approaches. Code is available at https://github.com/uncbiag/easyreg.",0
"Our new technique for augmenting medical images using fluid dynamics generates images with anatomical significance by interpolating from the geodesic subspace underlying the given samples. Unlike existing methods, our approach involves three steps: constructing a geodesic subspace using the LDDMM model from a source image and a set of target images, sampling transformations from this subspace, and obtaining deformed images and segmentations through interpolation. We performed experiments on brain (LPBA) and knee (OAI) data and demonstrated the effectiveness of our approach on two tasks: data augmentation during training and testing for image segmentation, and single atlas image segmentation using one-shot learning. Our method outperforms competing techniques and the code can be accessed at https://github.com/uncbiag/easyreg.",1
"In the interactive image segmentation task, the Particle Competition and Cooperation (PCC) model is fed with a complex network, which is built from the input image. In the network construction phase, a weight vector is needed to define the importance of each element in the feature set, which consists of color and location information of the corresponding pixels, thus demanding a specialist's intervention. The present paper proposes the elimination of the weight vector through modifications in the network construction phase. The proposed model and the reference model, without the use of a weight vector, were compared using 151 images extracted from the Grabcut dataset, the PASCAL VOC dataset and the Alpha matting dataset. Each model was applied 30 times to each image to obtain an error average. These simulations resulted in an error rate of only 0.49\% when classifying pixels with the proposed model while the reference model had an error rate of 3.14\%. The proposed method also presented less error variation in the diversity of the evaluated images, when compared to the reference model.",0
"The Particle Competition and Cooperation (PCC) model is utilized for interactive image segmentation by feeding it with a complex network constructed from the input image. However, the network construction phase requires the intervention of a specialist to assign weight values to the feature set, consisting of color and location information of corresponding pixels. This paper suggests removing the weight vector by modifying the network construction phase. To compare the proposed model and the reference model without using a weight vector, 151 images from the Grabcut dataset, PASCAL VOC dataset, and Alpha matting dataset were used. Each model was applied to each image 30 times to obtain an average error rate. Results showed that the proposed model had an error rate of only 0.49\% when classifying pixels, while the reference model had an error rate of 3.14\%. Additionally, the proposed method demonstrated less error variation among the diverse images evaluated compared to the reference model.",1
"Machine learning has been widely adopted for medical image analysis in recent years given its promising performance in image segmentation and classification tasks. As a data-driven science, the success of machine learning, in particular supervised learning, largely depends on the availability of manually annotated datasets. For medical imaging applications, such annotated datasets are not easy to acquire. It takes a substantial amount of time and resource to curate an annotated medical image set. In this paper, we propose an efficient annotation framework for brain tumour images that is able to suggest informative sample images for human experts to annotate. Our experiments show that training a segmentation model with only 19% suggestively annotated patient scans from BraTS 2019 dataset can achieve a comparable performance to training a model on the full dataset for whole tumour segmentation task. It demonstrates a promising way to save manual annotation cost and improve data efficiency in medical imaging applications.",0
"In recent years, machine learning has become a popular choice for medical image analysis due to its impressive performance in tasks like image segmentation and classification. However, the success of machine learning, especially supervised learning, is largely dependent on the availability of annotated datasets, which can be difficult to acquire for medical imaging applications. This is because creating annotated medical image sets is a time-consuming and resource-intensive process. To address this issue, we propose an annotation framework for brain tumour images that can suggest informative sample images for human experts to annotate. Our experiments demonstrate that training a segmentation model with only 19% suggestively annotated patient scans from the BraTS 2019 dataset can yield comparable results to training on the full dataset for whole tumour segmentation. This approach shows promise in reducing manual annotation costs and improving data efficiency in medical imaging applications.",1
"Computer vision tasks such as semantic segmentation perform very well in good weather conditions, but if the weather turns bad, they have problems to achieve this performance in these conditions. One possibility to obtain more robust and reliable results in adverse weather conditions is to use video-segmentation approaches instead of commonly used single-image segmentation methods. Video-segmentation approaches capture temporal information of the previous video-frames in addition to current image information, and hence, they are more robust against disturbances, especially if they occur in only a few frames of the video-sequence. However, video-segmentation approaches, which are often based on recurrent neural networks, cannot be applied in real-time applications anymore, since their recurrent structures in the network are computational expensive. For instance, the inference time of the LSTM-ICNet, in which recurrent units are placed at proper positions in the single-segmentation approach ICNet, increases up to 61 percent compared to the basic ICNet. Hence, in this work, the LSTM-ICNet is sped up by modifying the recurrent units of the network so that it becomes real-time capable again. Experiments on different datasets and various weather conditions show that the inference time can be decreased by about 23 percent by these modifications, while they achieve similar performance than the LSTM-ICNet and outperform the single-segmentation approach enormously in adverse weather conditions.",0
"Semantic segmentation is a computer vision task that performs well in favorable weather conditions, but struggles when the weather turns bad. To improve its reliability and robustness in adverse weather conditions, video-segmentation approaches are recommended. These methods capture temporal information from previous video frames along with the current image information, making them more resistant to disturbances, especially those that occur in only a few frames of the video sequence. However, video-segmentation approaches that rely on recurrent neural networks are not suitable for real-time applications due to their high computational cost. To address this issue, this study modified the recurrent units of the LSTM-ICNet network, which is based on the single-segmentation approach ICNet, to make it real-time capable again. The modified LSTM-ICNet achieved similar performance to the original LSTM-ICNet while outperforming the single-segmentation approach considerably in adverse weather conditions. Furthermore, the inference time of the network was reduced by about 23 percent due to these modifications.",1
"Although spatial information of images usually enhance the robustness of the Fuzzy C-Means (FCM) algorithm, it greatly increases the computational costs for image segmentation. To achieve a sound trade-off between the segmentation performance and the speed of clustering, we come up with a Kullback-Leibler (KL) divergence-based FCM algorithm by incorporating a tight wavelet frame transform and a morphological reconstruction operation. To enhance FCM's robustness, an observed image is first filtered by using the morphological reconstruction. A tight wavelet frame system is employed to decompose the observed and filtered images so as to form their feature sets. Considering these feature sets as data of clustering, an modified FCM algorithm is proposed, which introduces a KL divergence term in the partition matrix into its objective function. The KL divergence term aims to make membership degrees of each image pixel closer to those of its neighbors, which brings that the membership partition becomes more suitable and the parameter setting of FCM becomes simplified. On the basis of the obtained partition matrix and prototypes, the segmented feature set is reconstructed by minimizing the inverse process of the modified objective function. To modify abnormal features produced in the reconstruction process, each reconstructed feature is reassigned to the closest prototype. As a result, the segmentation accuracy of KL divergence-based FCM is further improved. What's more, the segmented image is reconstructed by using a tight wavelet frame reconstruction operation. Finally, supporting experiments coping with synthetic, medical and color images are reported. Experimental results exhibit that the proposed algorithm works well and comes with better segmentation performance than other comparative algorithms. Moreover, the proposed algorithm requires less time than most of the FCM-related algorithms.",0
"While incorporating spatial information into the Fuzzy C-Means (FCM) algorithm can increase its robustness, it also leads to higher computational costs for image segmentation. To address this issue, we propose a Kullback-Leibler (KL) divergence-based FCM algorithm that utilizes a tight wavelet frame transform and morphological reconstruction to strike a balance between segmentation accuracy and clustering speed. Firstly, the observed image undergoes morphological reconstruction to enhance FCM's robustness. Next, the tight wavelet frame system is used to decompose the observed and filtered images into feature sets for clustering. The modified FCM algorithm introduces a KL divergence term into its objective function to make membership degrees of each pixel closer to those of its neighbors. This results in a more suitable membership partition and simplified parameter setting for FCM. The segmented feature set is reconstructed by minimizing the inverse process of the modified objective function and by reassigning abnormal features to the closest prototype. The segmented image is reconstructed using a tight wavelet frame reconstruction operation. The proposed algorithm is tested on synthetic, medical, and color images, and the results show that it outperforms other comparative algorithms in terms of segmentation accuracy and computational time.",1
"Automated pavement crack image segmentation is challenging because of inherent irregular patterns, lighting conditions, and noise in images. Conventional approaches require a substantial amount of feature engineering to differentiate crack regions from non-affected regions. In this paper, we propose a deep learning technique based on a convolutional neural network to perform segmentation tasks on pavement crack images. Our approach requires minimal feature engineering compared to other machine learning techniques. We propose a U-Net-based network architecture in which we replace the encoder with a pretrained ResNet-34 neural network. We use a ""one-cycle"" training schedule based on cyclical learning rates to speed up the convergence. Our method achieves an F1 score of 96% on the CFD dataset and 73% on the Crack500 dataset, outperforming other algorithms tested on these datasets. We perform ablation studies on various techniques that helped us get marginal performance boosts, i.e., the addition of spatial and channel squeeze and excitation (SCSE) modules, training with gradually increasing image sizes, and training various neural network layers with different learning rates.",0
"Segmenting pavement cracks from images is difficult due to their irregular patterns, lighting conditions, and noise. Traditional methods require significant feature engineering to distinguish between crack and non-affected regions. To address this issue, we introduce a deep learning technique based on a convolutional neural network which minimizes the need for feature engineering. Our approach utilizes a U-Net-based network architecture, with a ResNet-34 neural network replacing the encoder. We use a ""one-cycle"" training schedule with cyclical learning rates to accelerate convergence. Our method achieves a 96% F1 score on the CFD dataset and a 73% F1 score on the Crack500 dataset, outperforming other algorithms. We also conduct ablation studies on various techniques, such as incorporating spatial and channel squeeze and excitation (SCSE) modules, gradually increasing image sizes during training, and training neural network layers with different learning rates, which result in marginal performance improvements.",1
"Although having achieved great success in medical image segmentation, deep learning-based approaches usually require large amounts of well-annotated data, which can be extremely expensive in the field of medical image analysis. Unlabeled data, on the other hand, is much easier to acquire. Semi-supervised learning and unsupervised domain adaptation both take the advantage of unlabeled data, and they are closely related to each other. In this paper, we propose uncertainty-aware multi-view co-training (UMCT), a unified framework that addresses these two tasks for volumetric medical image segmentation. Our framework is capable of efficiently utilizing unlabeled data for better performance. We firstly rotate and permute the 3D volumes into multiple views and train a 3D deep network on each view. We then apply co-training by enforcing multi-view consistency on unlabeled data, where an uncertainty estimation of each view is utilized to achieve accurate labeling. Experiments on the NIH pancreas segmentation dataset and a multi-organ segmentation dataset show state-of-the-art performance of the proposed framework on semi-supervised medical image segmentation. Under unsupervised domain adaptation settings, we validate the effectiveness of this work by adapting our multi-organ segmentation model to two pathological organs from the Medical Segmentation Decathlon Datasets. Additionally, we show that our UMCT-DA model can even effectively handle the challenging situation where labeled source data is inaccessible, demonstrating strong potentials for real-world applications.",0
"Deep learning-based methods for medical image segmentation have been successful, but they require a large amount of well-annotated data, which can be costly. In contrast, obtaining unlabeled data is easier. Semi-supervised learning and unsupervised domain adaptation utilize unlabeled data and are closely related. In this paper, we propose a unified framework called uncertainty-aware multi-view co-training (UMCT) for volumetric medical image segmentation, which efficiently utilizes unlabeled data. Our approach involves rotating and permuting 3D volumes into multiple views and training a 3D deep network for each view. Co-training is then applied, which enforces multi-view consistency on unlabeled data. Our framework also employs an uncertainty estimation of each view to achieve accurate labeling. We conducted experiments on two datasets and achieved state-of-the-art performance for semi-supervised medical image segmentation. Under unsupervised domain adaptation settings, we adapted our multi-organ segmentation model to two pathological organs from the Medical Segmentation Decathlon Datasets and showed that our UMCT-DA model can handle the challenging situation where labeled source data is inaccessible. This work demonstrates strong potential for real-world applications.",1
"Deep learning techniques have successfully been employed in numerous computer vision tasks including image segmentation. The techniques have also been applied to medical image segmentation, one of the most critical tasks in computer-aided diagnosis. Compared with natural images, the medical image is a gray-scale image with low-contrast (even with some invisible parts). Because some organs have similar intensity and texture with neighboring organs, there is usually a need to refine automatic segmentation results. In this paper, we propose an interactive deep refinement framework to improve the traditional semantic segmentation networks such as U-Net and fully convolutional network. In the proposed framework, we added a refinement network to traditional segmentation network to refine the segmentation results.Experimental results with public dataset revealed that the proposed method could achieve higher accuracy than other state-of-the-art methods.",0
"Various computer vision tasks including image segmentation have successfully implemented deep learning techniques. Medical image segmentation is a crucial task in computer-aided diagnosis and has also been subject to these techniques. Medical images are grayscale with low contrast and invisible parts, making it challenging to distinguish organs with similar intensity and texture. Automatic segmentation results frequently require refinement. Our interactive deep refinement framework proposes to improve traditional semantic segmentation networks such as U-Net and fully convolutional network by adding a refinement network. Our experiment with a public dataset demonstrates that our framework achieves higher accuracy than other state-of-the-art methods.",1
"Self-supervised learning has proven to be invaluable in making best use of all of the available data in biomedical image segmentation. One particularly simple and effective mechanism to achieve self-supervision is inpainting, the task of predicting arbitrary missing areas based on the rest of an image. In this work, we focus on image inpainting as the self-supervised proxy task, and propose two novel structural changes to further enhance the performance of a deep neural network. We guide the process of generating images to inpaint by using supervoxel-based masking instead of random masking, and also by focusing on the area to be segmented in the primary task, which we term as the region-of-interest. We postulate that these additions force the network to learn semantics that are more attuned to the primary task, and test our hypotheses on two applications: brain tumour and white matter hyperintensities segmentation. We empirically show that our proposed approach consistently outperforms both supervised CNNs, without any self-supervision, and conventional inpainting-based self-supervision methods on both large and small training set sizes.",0
"The use of self-supervised learning has been highly beneficial in effectively utilizing all available data for biomedical image segmentation. One effective means of achieving self-supervision is through inpainting, which involves predicting missing areas within an image based on the remaining content. This study focuses on utilizing image inpainting as a form of self-supervised proxy task, and presents two innovative structural modifications to improve the performance of a deep neural network. To guide the image inpainting process, supervoxel-based masking is utilized instead of random masking, and the region-of-interest for the primary task is emphasized. These modifications are believed to encourage the network to learn more semantically relevant information for the primary task. This approach is tested on two applications: brain tumour and white matter hyperintensities segmentation. The results demonstrate that this approach outperforms both supervised CNNs without self-supervision and conventional inpainting-based self-supervision methods, regardless of training set size.",1
"We introduce Post-DAE, a post-processing method based on denoising autoencoders (DAE) to improve the anatomical plausibility of arbitrary biomedical image segmentation algorithms. Some of the most popular segmentation methods (e.g. based on convolutional neural networks or random forest classifiers) incorporate additional post-processing steps to ensure that the resulting masks fulfill expected connectivity constraints. These methods operate under the hypothesis that contiguous pixels with similar aspect should belong to the same class. Even if valid in general, this assumption does not consider more complex priors like topological restrictions or convexity, which cannot be easily incorporated into these methods. Post-DAE leverages the latest developments in manifold learning via denoising autoencoders. First, we learn a compact and non-linear embedding that represents the space of anatomically plausible segmentations. Then, given a segmentation mask obtained with an arbitrary method, we reconstruct its anatomically plausible version by projecting it onto the learnt manifold. The proposed method is trained using unpaired segmentation mask, what makes it independent of intensity information and image modality. We performed experiments in binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images. We show how erroneous and noisy segmentation masks can be improved using Post-DAE. With almost no additional computation cost, our method brings erroneous segmentations back to a feasible space.",0
"Our new method, Post-DAE, utilizes denoising autoencoders (DAE) to enhance the accuracy of biomedical image segmentation algorithms. Many popular segmentation techniques use post-processing steps to ensure that the resulting masks are anatomically plausible, but these steps only consider simple connectivity constraints based on pixel similarity. They do not account for more complex priors such as topological restrictions or convexity. Post-DAE overcomes this limitation by incorporating the latest advancements in manifold learning via DAE. We first learn a non-linear embedding that represents the space of anatomically plausible segmentations. Then, we use this knowledge to reconstruct a more accurate segmentation mask from an arbitrary method. Our method is trained using unpaired segmentation masks, making it independent of image modality and intensity information. We tested Post-DAE on binary and multi-label segmentation of chest X-ray and cardiac magnetic resonance images and demonstrated its effectiveness in improving erroneous and noisy segmentation masks at a minimal additional computation cost.",1
"We propose a deep learning framework to detect and categorize oil spills in synthetic aperture radar (SAR) images at a large scale. By means of a carefully designed neural network model for image segmentation trained on an extensive dataset, we are able to obtain state-of-the-art performance in oil spill detection, achieving results that are comparable to results produced by human operators. We also introduce a classification task, which is novel in the context of oil spill detection in SAR. Specifically, after being detected, each oil spill is also classified according to different categories pertaining to its shape and texture characteristics. The classification results provide valuable insights for improving the design of oil spill services by world-leading providers. As the last contribution, we present our operational pipeline and a visualization tool for large-scale data, which allows to detect and analyze the historical presence of oil spills worldwide.",0
"Our proposal involves utilizing deep learning to detect and categorize oil spills in synthetic aperture radar (SAR) images on a large scale. Through the use of a meticulously designed neural network model for image segmentation and extensive dataset training, we can achieve state-of-the-art performance in detecting oil spills, comparable to human operators' results. Furthermore, we introduce a novel classification task related to oil spill detection in SAR, where each oil spill is categorized based on its shape and texture characteristics. The classification results offer valuable insights for enhancing oil spill services provided by leading providers. Finally, we present our operational pipeline and visualization tool for analyzing the historical presence of oil spills worldwide.",1
"A challenge still to be overcome in the field of visual perception for vehicle and robotic navigation on heavily damaged and unpaved roads is the task of reliable path and obstacle detection. The vast majority of the researches have as scenario roads in good condition, from developed countries. These works cope with few situations of variation on the road surface and even fewer situations presenting surface damages. In this paper we present an approach for road detection considering variation in surface types, identifying paved and unpaved surfaces and also detecting damage and other information on other road surface that may be relevant to driving safety. We also present a new Ground Truth with image segmentation, used in our approach and that allowed us to evaluate our results. Our results show that it is possible to use passive vision for these purposes, even using images captured with low cost cameras.",0
"Detecting reliable paths and obstacles on damaged and unpaved roads remains a challenge in the field of visual perception for vehicle and robotic navigation. Most research studies have been conducted in developed countries with well-maintained roads, which limits their ability to handle variations in road surface conditions and damages. In this study, we propose an approach that can detect both paved and unpaved surfaces, as well as identify damages and other crucial information for safe driving. We also introduce a new Ground Truth with image segmentation to evaluate our results. Our findings demonstrate that passive vision with low-cost cameras can be used for these purposes.",1
"Image segmentation is a fundamental and challenging problem in computer vision with applications spanning multiple areas, such as medical imaging, remote sensing, and autonomous vehicles. Recently, convolutional neural networks (CNNs) have gained traction in the design of automated segmentation pipelines. Although CNN-based models are adept at learning abstract features from raw image data, their performance is dependent on the availability and size of suitable training datasets. Additionally, these models are often unable to capture the details of object boundaries and generalize poorly to unseen classes. In this thesis, we devise novel methodologies that address these issues and establish robust representation learning frameworks for fully-automatic semantic segmentation in medical imaging and mainstream computer vision. In particular, our contributions include (1) state-of-the-art 2D and 3D image segmentation networks for computer vision and medical image analysis, (2) an end-to-end trainable image segmentation framework that unifies CNNs and active contour models with learnable parameters for fast and robust object delineation, (3) a novel approach for disentangling edge and texture processing in segmentation networks, and (4) a novel few-shot learning model in both supervised settings and semi-supervised settings where synergies between latent and image spaces are leveraged to learn to segment images given limited training data.",0
"Computer vision faces a challenging and fundamental problem in image segmentation, which has numerous applications in various fields such as autonomous vehicles, medical imaging, and remote sensing. While convolutional neural networks (CNNs) have become popular in designing automated segmentation pipelines, their performance depends on the availability and size of suitable training datasets. They often struggle to capture object boundaries and fail to generalize to unseen classes. In this thesis, we propose innovative methodologies to tackle these issues and establish robust representation learning frameworks for fully-automatic semantic segmentation in medical imaging and mainstream computer vision. Our contributions include state-of-the-art 2D and 3D segmentation networks, an end-to-end trainable segmentation framework that combines CNNs and active contour models with learnable parameters, a novel approach for edge and texture processing in segmentation networks, and a few-shot learning model that leverages synergies between latent and image spaces in both supervised and semi-supervised settings.",1
"This work introduces pyramidal convolution (PyConv), which is capable of processing the input at multiple filter scales. PyConv contains a pyramid of kernels, where each level involves different types of filters with varying size and depth, which are able to capture different levels of details in the scene. On top of these improved recognition capabilities, PyConv is also efficient and, with our formulation, it does not increase the computational cost and parameters compared to standard convolution. Moreover, it is very flexible and extensible, providing a large space of potential network architectures for different applications. PyConv has the potential to impact nearly every computer vision task and, in this work, we present different architectures based on PyConv for four main tasks on visual recognition: image classification, video action classification/recognition, object detection and semantic image segmentation/parsing. Our approach shows significant improvements over all these core tasks in comparison with the baselines. For instance, on image recognition, our 50-layers network outperforms in terms of recognition performance on ImageNet dataset its counterpart baseline ResNet with 152 layers, while having 2.39 times less parameters, 2.52 times lower computational complexity and more than 3 times less layers. On image segmentation, our novel framework sets a new state-of-the-art on the challenging ADE20K benchmark for scene parsing. Code is available at: https://github.com/iduta/pyconv",0
"The PyConv, presented in this study, is a novel convolutional technique that can process input at various filter scales. It consists of multiple levels of kernels, each with different filters of varying size and depth, capable of capturing diverse details in the scene and improving recognition abilities. Additionally, PyConv is efficient and does not increase computational cost or parameters when compared to standard convolution. It is also highly flexible and adaptable, allowing for a wide range of network architectures for various applications. This technique has the potential to revolutionize computer vision tasks, as demonstrated in this study where PyConv-based networks for image classification, video action classification/recognition, object detection, and semantic image segmentation/parsing were developed. The results showed significant enhancements over baseline models, such as outperforming ResNet with 152 layers in recognition performance on ImageNet dataset, despite having 2.39 times fewer parameters, 2.52 times lower computational complexity, and over three times fewer layers in a 50-layers network. Similarly, the novel framework for image segmentation achieved a new state-of-the-art on the challenging ADE20K benchmark for scene parsing. The code for PyConv is available at https://github.com/iduta/pyconv.",1
"Deep convolutional neural networks (DCNNs) have contributed many breakthroughs in segmentation tasks, especially in the field of medical imaging. However, \textit{domain shift} and \textit{corrupted annotations}, which are two common problems in medical imaging, dramatically degrade the performance of DCNNs in practice. In this paper, we propose a novel robust cross-denoising framework using two peer networks to address domain shift and corrupted label problems with a peer-review strategy. Specifically, each network performs as a mentor, mutually supervised to learn from reliable samples selected by the peer network to combat with corrupted labels. In addition, a noise-tolerant loss is proposed to encourage the network to capture the key location and filter the discrepancy under various noise-contaminant labels. To further reduce the accumulated error, we introduce a class-imbalanced cross learning using most confident predictions at the class-level. Experimental results on REFUGE and Drishti-GS datasets for optic disc (OD) and optic cup (OC) segmentation demonstrate the superior performance of our proposed approach to the state-of-the-art methods.",0
"DCNNs have been successful in segmentation tasks, particularly in medical imaging. Nevertheless, in medical imaging, there are two common problems, namely domain shift and corrupted annotations, which significantly affect the performance of DCNNs. This study introduces a new robust cross-denoising framework that addresses these issues with a peer-review approach using two peer networks. Each network acts as a mentor and is mutually supervised to learn from trustworthy samples chosen by the other network to combat corrupted labels. Additionally, a noise-tolerant loss function is proposed to encourage the network to identify the critical location and filter the inconsistency under different noise-contaminated labels. To further minimize the accumulated error, the study includes class-imbalanced cross-learning using the most confident predictions at the class level. The proposed approach outperforms existing state-of-the-art methods, as demonstrated through experiments on optic disc (OD) and optic cup (OC) segmentation using REFUGE and Drishti-GS datasets.",1
"Convolutional neural networks (CNN) have had unprecedented success in medical imaging and, in particular, in medical image segmentation. However, despite the fact that segmentation results are closer than ever to the inter-expert variability, CNNs are not immune to producing anatomically inaccurate segmentations, even when built upon a shape prior. In this paper, we present a framework for producing cardiac image segmentation maps that are guaranteed to respect pre-defined anatomical criteria, while remaining within the inter-expert variability. The idea behind our method is to use a well-trained CNN, have it process cardiac images, identify the anatomically implausible results and warp these results toward the closest anatomically valid cardiac shape. This warping procedure is carried out with a constrained variational autoencoder (cVAE) trained to learn a representation of valid cardiac shapes through a smooth, yet constrained, latent space. With this cVAE, we can project any implausible shape into the cardiac latent space and steer it toward the closest correct shape. We tested our framework on short-axis MRI as well as apical two and four-chamber view ultrasound images, two modalities for which cardiac shapes are drastically different. With our method, CNNs can now produce results that are both within the inter-expert variability and always anatomically plausible without having to rely on a shape prior.",0
"Medical imaging has seen exceptional progress in segmentation with the use of convolutional neural networks (CNNs). However, even when incorporating a shape prior, anatomically incorrect segmentations are still produced by CNNs. Although segmentation results are approaching inter-expert variability, this issue persists. Our paper proposes a framework that guarantees cardiac image segmentation respecting pre-defined anatomical criteria within inter-expert variability. The framework employs a well-trained CNN to analyze cardiac images, identify anatomically implausible results, and warp them towards the nearest anatomically correct cardiac shape. This warping procedure utilizes a constrained variational autoencoder (cVAE) that learns valid cardiac shapes through a smooth, yet restricted, latent space. Our framework was tested on short-axis MRI and apical two and four-chamber view ultrasound images, both of which exhibit drastically different cardiac shapes. With our approach, CNNs can produce results that are both within inter-expert variability and consistently anatomically plausible, eliminating the need for a shape prior.",1
"We introduce a new spectral method for image segmentation that incorporates long range relationships for global appearance modeling. The approach combines two different graphs, one is a sparse graph that captures spatial relationships between nearby pixels and another is a dense graph that captures pairwise similarity between all pairs of pixels. We extend the spectral method for Normalized Cuts to this setting by combining the transition matrices of Markov chains associated with each graph. We also derive an efficient method that uses importance sampling for sparsifying the dense graph of appearance relationships. This leads to a practical algorithm for segmenting high-resolution images. The resulting method can segment challenging images without any filtering or pre-processing.",0
"A novel spectral method is presented in this study, which employs long-range relationships to model global appearance for image segmentation. The proposed technique integrates two graphs: a sparse graph to capture spatial relationships between neighboring pixels and a dense graph to capture pairwise similarity between all pixel pairs. The spectral method for Normalized Cuts is expanded to this scenario by merging the transition matrices of Markov chains associated with each graph. Additionally, an effective method is introduced to use importance sampling for sparsifying the dense graph of appearance relationships, resulting in a practical algorithm for segmenting high-resolution images. Remarkably, the proposed method can segment challenging images without any filtering or pre-processing.",1
"Deep neural network (DNN) based approaches have been widely investigated and deployed in medical image analysis. For example, fully convolutional neural networks (FCN) achieve the state-of-the-art performance in several applications of 2D/3D medical image segmentation. Even the baseline neural network models (U-Net, V-Net, etc.) have been proven to be very effective and efficient when the training process is set up properly. Nevertheless, to fully exploit the potentials of neural networks, we propose an automated searching approach for the optimal training strategy with reinforcement learning. The proposed approach can be utilized for tuning hyper-parameters, and selecting necessary data augmentation with certain probabilities. The proposed approach is validated on several tasks of 3D medical image segmentation. The performance of the baseline model is boosted after searching, and it can achieve comparable accuracy to other manually-tuned state-of-the-art segmentation approaches.",0
"Medical image analysis has widely explored and implemented DNN-based approaches. 2D/3D medical image segmentation applications have achieved state-of-the-art performance through FCN. Even baseline neural network models like U-Net and V-Net have proven to be efficient and effective when correctly trained. However, to maximize the potential of neural networks, we suggest an automated search approach using reinforcement learning to determine the optimal training strategy. This approach can tune hyper-parameters and select necessary data augmentation with specific probabilities. We validate this approach on various 3D medical image segmentation tasks. After searching, the performance of the baseline model improves, resulting in comparable accuracy to other manually-tuned state-of-the-art segmentation approaches.",1
"Mining and learning the shape variability of underlying population has benefited the applications including parametric shape modeling, 3D animation, and image segmentation. The current statistical shape modeling method works well on learning unstructured shape variations without obvious pose changes (relative rotations of the body parts). Studying the pose variations within a shape population involves segmenting the shapes into different articulated parts and learning the transformations of the segmented parts. This paper formulates the pose learning problem as mixtures of factor analyzers. The segmentation is obtained by components posterior probabilities and the rotations in pose variations are learned by the factor loading matrices. To guarantee that the factor loading matrices are composed by rotation matrices, constraints are imposed and the corresponding closed form optimal solution is derived. Based on the proposed method, the pose variations are automatically learned from the given shape populations. The method is applied in motion animation where new poses are generated by interpolating the existing poses in the training set. The obtained results are smooth and realistic.",0
"The study of the variability in the shape of a population has proved useful for applications such as 3D animation, image segmentation, and parametric shape modeling. While the current statistical shape modeling method is effective in learning shape variations that are unstructured and without obvious pose changes, studying the pose variations within a shape population requires segmenting the shapes into articulated parts and learning the transformations of those parts. This paper presents a method for pose learning, using mixtures of factor analyzers, where segmentation is obtained through components' posterior probabilities and rotations in pose variations are learned through factor loading matrices. To ensure that these matrices consist of rotation matrices, constraints are placed and a corresponding optimal solution is found. This approach enables automatic learning of pose variations from a given shape population, and its effectiveness is demonstrated in motion animation, where new poses can be generated by interpolating existing ones in the training set. The results are realistic and smooth.",1
"Shortage of fully annotated datasets has been a limiting factor in developing deep learning based image segmentation algorithms and the problem becomes more pronounced in multi-organ segmentation. In this paper, we propose a unified training strategy that enables a novel multi-scale deep neural network to be trained on multiple partially labeled datasets for multi-organ segmentation. In addition, a new network architecture for multi-scale feature abstraction is proposed to integrate pyramid input and feature analysis into a U-shape pyramid structure. To bridge the semantic gap caused by directly merging features from different scales, an equal convolutional depth mechanism is introduced. Furthermore, we employ a deep supervision mechanism to refine the outputs in different scales. To fully leverage the segmentation features from all the scales, we design an adaptive weighting layer to fuse the outputs in an automatic fashion. All these mechanisms together are integrated into a Pyramid Input Pyramid Output Feature Abstraction Network (PIPO-FAN). Our proposed method was evaluated on four publicly available datasets, including BTCV, LiTS, KiTS and Spleen, where very promising performance has been achieved. The source code of this work is publicly shared at https://github.com/DIAL-RPI/PIPO-FAN for others to easily reproduce the work and build their own models with the introduced mechanisms.",0
"The lack of fully annotated datasets has hindered the development of deep learning image segmentation algorithms, especially in multi-organ segmentation. To address this issue, we propose a unified training strategy that trains a multi-scale neural network on multiple partially labeled datasets. We also introduce a novel network architecture for multi-scale feature abstraction that integrates pyramid input and feature analysis into a U-shape pyramid structure. To overcome the challenge of merging features from different scales, we use an equal convolutional depth mechanism and employ a deep supervision mechanism to refine the outputs. Additionally, we design an adaptive weighting layer to fuse the outputs in an automatic manner. Our method, called the Pyramid Input Pyramid Output Feature Abstraction Network (PIPO-FAN), achieves promising results on four publicly available datasets. The source code for this work is publicly available for others to reproduce and build upon.",1
"We focus on an important yet challenging problem: using a 2D deep network to deal with 3D segmentation for medical image analysis. Existing approaches either applied multi-view planar (2D) networks or directly used volumetric (3D) networks for this purpose, but both of them are not ideal: 2D networks cannot capture 3D contexts effectively, and 3D networks are both memory-consuming and less stable arguably due to the lack of pre-trained models.   In this paper, we bridge the gap between 2D and 3D using a novel approach named Elastic Boundary Projection (EBP). The key observation is that, although the object is a 3D volume, what we really need in segmentation is to find its boundary which is a 2D surface. Therefore, we place a number of pivot points in the 3D space, and for each pivot, we determine its distance to the object boundary along a dense set of directions. This creates an elastic shell around each pivot which is initialized as a perfect sphere. We train a 2D deep network to determine whether each ending point falls within the object, and gradually adjust the shell so that it gradually converges to the actual shape of the boundary and thus achieves the goal of segmentation. EBP allows boundary-based segmentation without cutting a 3D volume into slices or patches, which stands out from conventional 2D and 3D approaches. EBP achieves promising accuracy in abdominal organ segmentation. Our code has been open-sourced https://github.com/twni2016/Elastic-Boundary-Projection.",0
"The primary focus of our research is tackling the challenging task of utilizing a 2D deep network to handle 3D segmentation for medical image analysis. Current methods either employ multi-view planar networks or volumetric networks, but both have their drawbacks. 2D networks are not effective in capturing 3D contexts, while 3D networks are memory-intensive and less stable due to the lack of pre-trained models. Our approach, Elastic Boundary Projection (EBP), bridges the gap between 2D and 3D by placing pivot points in 3D space and determining their distance to the object boundary along a dense set of directions. This process creates an elastic shell around each pivot that is gradually adjusted to converge to the actual shape of the boundary, allowing for boundary-based segmentation without the need to slice or patch a 3D volume. EBP achieves promising results in abdominal organ segmentation and our code has been open-sourced at https://github.com/twni2016/Elastic-Boundary-Projection.",1
"Blur detection is the separation of blurred and clear regions of an image, which is an important and challenging task in computer vision. In this work, we regard blur detection as an image segmentation problem. Inspired by the success of the U-net architecture for image segmentation, we design a Multi-Scale Dilated convolutional neural network based on U-net, which we call MSDU-net. The MSDU-net uses a group of multi-scale feature extractors with dilated convolutions to extract texture information at different scales. The U-shape architecture of the MSDU-net fuses the different-scale texture features and generates a semantic feature which allows us to achieve better results on the blur detection task. We show that using the MSDU-net we are able to outperform other state of the art blur detection methods on two publicly available benchmarks.",0
"Detecting blurred and clear regions of an image is a difficult but crucial task in computer vision, known as blur detection. In this study, we approach blur detection as an image segmentation challenge and draw inspiration from the U-net architecture for image segmentation. Our proposed solution, the MSDU-net, is a Multi-Scale Dilated convolutional neural network based on U-net. The MSDU-net utilizes a group of multi-scale feature extractors with dilated convolutions to extract texture information from different scales. The U-shape architecture of the MSDU-net merges the different-scale texture features to generate a semantic feature resulting in enhanced performance in blur detection. Our experiments demonstrate that the MSDU-net surpasses other contemporary blur detection techniques on two publicly available datasets.",1
"Most existing black-box optimization methods assume that all variables in the system being optimized have equal cost and can change freely at each iteration. However, in many real world systems, inputs are passed through a sequence of different operations or modules, making variables in earlier stages of processing more costly to update. Such structure imposes a cost on switching variables in early parts of a data processing pipeline. In this work, we propose a new algorithm for switch cost-aware optimization called Lazy Modular Bayesian Optimization (LaMBO). This method efficiently identifies the global optimum while minimizing cost through a passive change of variables in early modules. The method is theoretical grounded and achieves vanishing regret when augmented with switching cost. We apply LaMBO to multiple synthetic functions and a three-stage image segmentation pipeline used in a neuroscience application, where we obtain promising improvements over prevailing cost-aware Bayesian optimization algorithms. Our results demonstrate that LaMBO is an effective strategy for black-box optimization that is capable of minimizing switching costs in modular systems.",0
"The majority of current black-box optimization techniques assume that all variables in the system being optimized are of equal value and can be altered freely during each iteration. However, this does not reflect the reality of many real-world systems where inputs move through a sequence of different operations or modules. This means that variables in earlier stages of processing are more expensive to update. Consequently, there is a cost associated with changing variables in the initial parts of a data processing pipeline. To address this issue, we propose a new algorithm called Lazy Modular Bayesian Optimization (LaMBO) that is aware of switch costs and optimizes efficiently by making passive changes to variables in early modules. LaMBO is grounded in theory and can achieve vanishing regret when incorporating switching cost. We demonstrate the effectiveness of LaMBO by applying it to various synthetic functions and a three-stage image segmentation pipeline utilized in a neuroscience application. Our results show promising improvements over existing cost-aware Bayesian optimization algorithms, indicating that LaMBO is a valuable approach for minimizing switching costs in black-box optimization of modular systems.",1
"The semantic image segmentation task consists of classifying each pixel of an image into an instance, where each instance corresponds to a class. This task is a part of the concept of scene understanding or better explaining the global context of an image. In the medical image analysis domain, image segmentation can be used for image-guided interventions, radiotherapy, or improved radiological diagnostics. In this review, we categorize the leading deep learning-based medical and non-medical image segmentation solutions into six main groups of deep architectural, data synthesis-based, loss function-based, sequenced models, weakly supervised, and multi-task methods and provide a comprehensive review of the contributions in each of these groups. Further, for each group, we analyze each variant of these groups and discuss the limitations of the current approaches and present potential future research directions for semantic image segmentation.",0
"The task of semantic image segmentation involves assigning a class to each pixel in an image, with each class corresponding to an instance. This task falls under the umbrella of scene understanding, which aims to provide a more comprehensive understanding of the context of an image. In the medical image analysis field, image segmentation can be applied to image-guided interventions, radiotherapy, and radiological diagnostics to improve outcomes. This article reviews the top deep learning-based medical and non-medical image segmentation approaches, which are categorized into six groups: deep architectural, data synthesis-based, loss function-based, sequenced models, weakly supervised, and multi-task methods. Within each group, the different variations are analyzed, and the limitations of current approaches are discussed. Finally, potential future research directions for semantic image segmentation are presented.",1
"Deep Convolutional Neural Networks (DCNNs) are used extensively in medical image segmentation and hence 3D navigation for robot-assisted Minimally Invasive Surgeries (MISs). However, current DCNNs usually use down sampling layers for increasing the receptive field and gaining abstract semantic information. These down sampling layers decrease the spatial dimension of feature maps, which can be detrimental to image segmentation. Atrous convolution is an alternative for the down sampling layer. It increases the receptive field whilst maintains the spatial dimension of feature maps. In this paper, a method for effective atrous rate setting is proposed to achieve the largest and fully-covered receptive field with a minimum number of atrous convolutional layers. Furthermore, a new and full resolution DCNN - Atrous Convolutional Neural Network (ACNN), which incorporates cascaded atrous II-blocks, residual learning and Instance Normalization (IN) is proposed. Application results of the proposed ACNN to Magnetic Resonance Imaging (MRI) and Computed Tomography (CT) image segmentation demonstrate that the proposed ACNN can achieve higher segmentation Intersection over Unions (IoUs) than U-Net and Deeplabv3+, but with reduced trainable parameters.",0
"DCNNs are widely used in medical image segmentation and 3D navigation for robot-assisted MISs. However, these networks typically use down sampling layers to increase their receptive field and extract abstract semantic information. Unfortunately, this downsampling can have a negative impact on image segmentation. To address this issue, atrous convolution is proposed as an alternative to down sampling. This method increases the receptive field while maintaining the spatial dimension of feature maps. In this paper, we propose an effective method for setting atrous rates that achieves the largest receptive field with the fewest atrous convolutional layers. We also introduce a novel DCNN, called the Atrous Convolutional Neural Network (ACNN), which includes cascaded atrous II-blocks, residual learning, and Instance Normalization (IN). Our experiments on MRI and CT image segmentation demonstrate that the proposed ACNN outperforms U-Net and Deeplabv3+ in terms of segmentation Intersection over Unions (IoUs), while reducing the number of trainable parameters.",1
"Transfer learning is widely used for training machine learning models. Here, we study the role of transfer learning for training fully convolutional networks (FCNs) for medical image segmentation. Our experiments show that although transfer learning reduces the training time on the target task, the improvement in segmentation accuracy is highly task/data-dependent. Larger improvements in accuracy are observed when the segmentation task is more challenging and the target training data is smaller. We observe that convolutional filters of an FCN change little during training for medical image segmentation, and still look random at convergence. We further show that quite accurate FCNs can be built by freezing the encoder section of the network at random values and only training the decoder section. At least for medical image segmentation, this finding challenges the common belief that the encoder section needs to learn data/task-specific representations. We examine the evolution of FCN representations to gain a better insight into the effects of transfer learning on the training dynamics. Our analysis shows that although FCNs trained via transfer learning learn different representations than FCNs trained with random initialization, the variability among FCNs trained via transfer learning can be as high as that among FCNs trained with random initialization. Moreover, feature reuse is not restricted to the early encoder layers; rather, it can be more significant in deeper layers. These findings offer new insights and suggest alternative ways of training FCNs for medical image segmentation.",0
"The use of transfer learning is prevalent in the training of machine learning models. This study focuses on the application of transfer learning in training fully convolutional networks (FCNs) for medical image segmentation. Our experiments indicate that transfer learning can reduce the time required for training on the target task, but the improvement in segmentation accuracy is heavily influenced by the task and data involved. We observed that FCN filters undergo minimal changes during medical image segmentation training and remain random at convergence. Surprisingly, we found that freezing the encoder section of the network at random values and only training the decoder section can still produce accurate FCNs, challenging the common belief that the encoder section needs to learn data/task-specific representations. To gain a better understanding of the effects of transfer learning on training dynamics, we examined the evolution of FCN representations. Our analysis revealed that while FCNs trained via transfer learning learn different representations than those trained with random initialization, variability among FCNs trained via transfer learning can be as high as that among FCNs trained with random initialization. Furthermore, feature reuse is not limited to the early encoder layers, but can be more significant in deeper layers. These findings provide new insights and suggest alternative methods for training FCNs for medical image segmentation.",1
"Image segmentation is a fundamental vision task and a crucial step for many applications. In this paper, we propose a fast image segmentation method based on a novel super boundary-to-pixel direction (super-BPD) and a customized segmentation algorithm with super-BPD. Precisely, we define BPD on each pixel as a two-dimensional unit vector pointing from its nearest boundary to the pixel. In the BPD, nearby pixels from different regions have opposite directions departing from each other, and adjacent pixels in the same region have directions pointing to the other or each other (i.e., around medial points). We make use of such property to partition an image into super-BPDs, which are novel informative superpixels with robust direction similarity for fast grouping into segmentation regions. Extensive experimental results on BSDS500 and Pascal Context demonstrate the accuracy and efficency of the proposed super-BPD in segmenting images. In practice, the proposed super-BPD achieves comparable or superior performance with MCG while running at ~25fps vs. 0.07fps. Super-BPD also exhibits a noteworthy transferability to unseen scenes. The code is publicly available at https://github.com/JianqiangWan/Super-BPD.",0
"The process of image segmentation is a vital task for various applications related to vision. In this paper, we present a speedy image segmentation approach that is based on a unique super boundary-to-pixel direction (super-BPD), and a tailored segmentation algorithm also using super-BPD. Essentially, we define BPD on every pixel as a two-dimensional unit vector that points from its closest boundary to the pixel. With BPD, nearby pixels from different regions possess opposite directions, while adjacent pixels in the same region have directions pointing towards each other or around medial points. We leverage this property to divide an image into informative superpixels with robust direction similarity known as super-BPDs for quick grouping into segmentation regions. Our extensive experimental results on BSDS500 and Pascal Context show that the proposed super-BPD method accurately and efficiently segments images. Furthermore, our proposed super-BPD outperforms MCG while running at approximately 25fps versus 0.07fps and demonstrates notable transferability to unseen scenes. We have made the code publicly available at https://github.com/JianqiangWan/Super-BPD.",1
"In deep networks, the lost data details significantly degrade the performances of image segmentation. In this paper, we propose to apply Discrete Wavelet Transform (DWT) to extract the data details during feature map down-sampling, and adopt Inverse DWT (IDWT) with the extracted details during the up-sampling to recover the details. We firstly transform DWT/IDWT as general network layers, which are applicable to 1D/2D/3D data and various wavelets like Haar, Cohen, and Daubechies, etc. Then, we design wavelet integrated deep networks for image segmentation (WaveSNets) based on various architectures, including U-Net, SegNet, and DeepLabv3+. Due to the effectiveness of the DWT/IDWT in processing data details, experimental results on CamVid, Pascal VOC, and Cityscapes show that our WaveSNets achieve better segmentation performances than their vanilla versions.",0
"The performance of image segmentation in deep networks is significantly impacted by lost data details. This paper proposes the use of Discrete Wavelet Transform (DWT) to extract data details during feature map down-sampling and to use Inverse DWT (IDWT) with the extracted details during up-sampling to recover the details. The DWT/IDWT are transformed into general network layers that are applicable to 1D/2D/3D data and various wavelets like Haar, Cohen, and Daubechies. Wavelet integrated deep networks for image segmentation (WaveSNets) are designed based on various architectures, including U-Net, SegNet, and DeepLabv3+. The DWT/IDWT are effective in processing data details, and experimental results on CamVid, Pascal VOC, and Cityscapes show that WaveSNets achieve better segmentation performances than their vanilla versions.",1
"From the autonomous car driving to medical diagnosis, the requirement of the task of image segmentation is everywhere. Segmentation of an image is one of the indispensable tasks in computer vision. This task is comparatively complicated than other vision tasks as it needs low-level spatial information. Basically, image segmentation can be of two types: semantic segmentation and instance segmentation. The combined version of these two basic tasks is known as panoptic segmentation. In the recent era, the success of deep convolutional neural networks (CNN) has influenced the field of segmentation greatly and gave us various successful models to date. In this survey, we are going to take a glance at the evolution of both semantic and instance segmentation work based on CNN. We have also specified comparative architectural details of some state-of-the-art models and discuss their training details to present a lucid understanding of hyper-parameter tuning of those models. We have also drawn a comparison among the performance of those models on different datasets. Lastly, we have given a glimpse of some state-of-the-art panoptic segmentation models.",0
"The task of image segmentation is ubiquitous, from self-driving cars to medical diagnosis, and is a crucial aspect of computer vision. This task is complex as it requires low-level spatial information. Image segmentation can be categorized into two types: semantic segmentation and instance segmentation, while a combination of both is referred to as panoptic segmentation. The success of deep convolutional neural networks (CNN) has positively impacted the field of segmentation, resulting in various successful models. This survey provides an overview of the evolution of semantic and instance segmentation based on CNN, including comparative architectural details and training information. It also compares the performance of these models on different datasets and provides a glimpse of some state-of-the-art panoptic segmentation models.",1
"The standard petrography test method for measuring air voids in concrete (ASTM C457) requires a meticulous and long examination of sample phase composition under a stereomicroscope. The high expertise and specialized equipment discourage this test for routine concrete quality control. Though the task can be alleviated with the aid of color-based image segmentation, additional surface color treatment is required. Recently, deep learning algorithms using convolutional neural networks (CNN) have achieved unprecedented segmentation performance on image testing benchmarks. In this study, we investigated the feasibility of using CNN to conduct concrete segmentation without the use of color treatment. The CNN demonstrated a strong potential to process a wide range of concretes, including those not involved in model training. The experimental results showed that CNN outperforms the color-based segmentation by a considerable margin, and has comparable accuracy to human experts. Furthermore, the segmentation time is reduced to mere seconds.",0
"The current method for measuring air voids in concrete, known as ASTM C457, involves a lengthy and meticulous examination of the sample composition under a stereomicroscope. This requires specialized equipment and expertise, making it unsuitable for routine quality control. While color-based image segmentation can make the task easier, it still requires additional treatment. However, recent advancements in deep learning algorithms using convolutional neural networks (CNN) have shown promising results on image testing benchmarks. In this study, we explored the possibility of using CNN for concrete segmentation without the need for color treatment. The results showed that CNN has the potential to process a wide range of concretes, including those not used in training, and outperforms color-based segmentation with similar accuracy to human experts. Additionally, the segmentation time is significantly reduced to just a few seconds.",1
"Convolutional Neural Networks (CNNs) have shown to be powerful medical image segmentation models. In this study, we address some of the main unresolved issues regarding these models. Specifically, training of these models on small medical image datasets is still challenging, with many studies promoting techniques such as transfer learning. Moreover, these models are infamous for producing over-confident predictions and for failing silently when presented with out-of-distribution (OOD) data at test time. In this paper, we advocate for multi-task learning, i.e., training a single model on several different datasets, spanning several different organs of interest and different imaging modalities. We show that not only a single CNN learns to automatically recognize the context and accurately segment the organ of interest in each context, but also that such a joint model often has more accurate and better-calibrated predictions than dedicated models trained separately on each dataset. Our experiments show that multi-task learning can outperform transfer learning in medical image segmentation tasks. For detecting OOD data, we propose a method based on spectral analysis of CNN feature maps. We show that different datasets, representing different imaging modalities and/or different organs of interest, have distinct spectral signatures, which can be used to identify whether or not a test image is similar to the images used to train a model. We show that this approach is far more accurate than OOD detection based on prediction uncertainty. The methods proposed in this paper contribute significantly to improving the accuracy and reliability of CNN-based medical image segmentation models.",0
"CNNs have proven to be highly effective models for medical image segmentation. However, there are still unresolved issues with training these models on small medical image datasets, leading to the promotion of techniques like transfer learning. Additionally, these models are known for producing overconfident predictions and failing silently when presented with out-of-distribution (OOD) data during testing. To address these issues, we propose using multi-task learning, training a single model on multiple datasets of varying organs of interest and imaging modalities. Our experiments show that this approach results in more accurate and better-calibrated predictions than training dedicated models separately on each dataset. We also propose a method for detecting OOD data based on spectral analysis of CNN feature maps, which is more accurate than traditional methods based on prediction uncertainty. Overall, our proposed methods significantly improve the accuracy and reliability of CNN-based medical image segmentation models.",1
"Recently, Deep-Neural-Network (DNN) based edge prediction is progressing fast. Although the DNN based schemes outperform the traditional edge detectors, they have much higher computational complexity. It could be that the DNN based edge detectors often adopt the neural net structures designed for high-level computer vision tasks, such as image segmentation and object recognition. Edge detection is a rather local and simple job, the over-complicated architecture and massive parameters may be unnecessary. Therefore, we propose a traditional method inspired framework to produce good edges with minimal complexity. We simplify the network architecture to include Feature Extractor, Enrichment, and Summarizer, which roughly correspond to gradient, low pass filter, and pixel connection in the traditional edge detection schemes. The proposed structure can effectively reduce the complexity and retain the edge prediction quality. Our TIN2 (Traditional Inspired Network) model has an accuracy higher than the recent BDCN2 (Bi-Directional Cascade Network) but with a smaller model.",0
"Edge prediction using Deep-Neural-Network (DNN) is advancing rapidly, with DNN outperforming traditional edge detectors. However, DNN schemes have greater computational complexity due to the adoption of structures designed for high-level computer vision tasks. As edge detection is a simple and local job, the over-complicated architecture and vast parameters may be unnecessary. To address this issue, we propose a framework inspired by traditional methods to produce high-quality edges with minimal complexity. The proposed structure simplifies the network architecture to include Feature Extractor, Enrichment, and Summarizer, similar to gradient, low pass filter, and pixel connection in traditional edge detection schemes. This structure effectively reduces complexity while retaining edge prediction quality. Our TIN2 model has greater accuracy than the recent BDCN2 model, with a smaller size.",1
"Deep learning based image segmentation methods have achieved great success, even having human-level accuracy in some applications. However, due to the black box nature of deep learning, the best method may fail in some situations. Thus predicting segmentation quality without ground truth would be very crucial especially in clinical practice. Recently, people proposed to train neural networks to estimate the quality score by regression. Although it can achieve promising prediction accuracy, the network suffers robustness problem, e.g. it is vulnerable to adversarial attacks. In this paper, we propose to alleviate this problem by utilizing the difference between the input image and the reconstructed image, which is conditioned on the segmentation to be assessed, to lower the chance to overfit to the undesired image features from the original input image, and thus to increase the robustness. Results on ACDC17 dataset demonstrated our method is promising.",0
"Image segmentation methods that rely on deep learning have shown remarkable success, sometimes even surpassing human-level accuracy. However, due to the opaque nature of deep learning, the effectiveness of these methods is not guaranteed in all situations. Therefore, it is crucial to predict the quality of segmentation without ground truth, particularly in clinical settings. Recently, researchers have suggested training neural networks to estimate the quality score through regression. Although this approach can yield promising results, the network may be susceptible to robustness problems, such as adversarial attacks. In this study, we propose a solution to this issue by using the difference between the input image and the reconstructed image, which is conditioned on the segmentation being evaluated, to reduce the risk of overfitting to unwanted features from the original input image, thereby increasing robustness. Our method demonstrated promising results on the ACDC17 dataset.",1
"To extract information at scale, researchers increasingly apply semantic segmentation techniques to remotely-sensed imagery. While fully-supervised learning enables accurate pixel-wise segmentation, compiling the exhaustive datasets required is often prohibitively expensive. As a result, many non-urban settings lack the ground-truth needed for accurate segmentation. Existing open source infrastructure data for these regions can be inexact and non-exhaustive. Open source infrastructure annotations like OpenStreetMaps (OSM) are representative of this issue: while OSM labels provide global insights to road and building footprints, noisy and partial annotations limit the performance of segmentation algorithms that learn from them. In this paper, we present a novel and generalizable two-stage framework that enables improved pixel-wise image segmentation given misaligned and missing annotations. First, we introduce the Alignment Correction Network to rectify incorrectly registered open source labels. Next, we demonstrate a segmentation model -- the Pointer Segmentation Network -- that uses corrected labels to predict infrastructure footprints despite missing annotations. We test sequential performance on the AIRS dataset, achieving a mean intersection-over-union score of 0.79; more importantly, model performance remains stable as we decrease the fraction of annotations present. We demonstrate the transferability of our method to lower quality data, by applying the Alignment Correction Network to OSM labels to correct building footprints; we also demonstrate the accuracy of the Pointer Segmentation Network in predicting cropland boundaries in California from medium resolution data. Overall, our methodology is robust for multiple applications with varied amounts of training data present, thus offering a method to extract reliable information from noisy, partial data.",0
"To obtain information on a large scale, researchers are using semantic segmentation techniques on remotely-sensed imagery. Although accurate pixel-wise segmentation is possible with fully-supervised learning, it can be costly to compile the extensive datasets required. Consequently, accurate segmentation in non-urban settings is often hindered by the lack of ground-truth data. Open source infrastructure data for these regions may also be imprecise and incomplete. For instance, OpenStreetMaps (OSM) labels provide global insights, but they are often noisy and partial, which limits the performance of segmentation algorithms. This paper presents a two-stage framework that improves pixel-wise image segmentation by rectifying misaligned and missing annotations. The Alignment Correction Network corrects incorrectly registered open source labels, while the Pointer Segmentation Network predicts infrastructure footprints using corrected labels despite missing annotations. The methodology is transferable to lower quality data with varied amounts of training data present, enabling reliable information extraction from noisy, partial data. The AIRS dataset achieved a mean intersection-over-union score of 0.79, and the Pointer Segmentation Network accurately predicted cropland boundaries in California from medium resolution data.",1
"Fully supervised deep neural networks for segmentation usually require a massive amount of pixel-level labels which are manually expensive to create. In this work, we develop a multi-task learning method to relax this constraint. We regard the segmentation problem as a sequence of approximation subproblems that are recursively defined and in increasing levels of approximation accuracy. The subproblems are handled by a framework that consists of 1) a segmentation task that learns from pixel-level ground truth segmentation masks of a small fraction of the images, 2) a recursive approximation task that conducts partial object regions learning and data-driven mask evolution starting from partial masks of each object instance, and 3) other problem oriented auxiliary tasks that are trained with sparse annotations and promote the learning of dedicated features. Most training images are only labeled by (rough) partial masks, which do not contain exact object boundaries, rather than by their full segmentation masks. During the training phase, the approximation task learns the statistics of these partial masks, and the partial regions are recursively increased towards object boundaries aided by the learned information from the segmentation task in a fully data-driven fashion. The network is trained on an extremely small amount of precisely segmented images and a large set of coarse labels. Annotations can thus be obtained in a cheap way. We demonstrate the efficiency of our approach in three applications with microscopy images and ultrasound images.",0
"Creating fully supervised deep neural networks for segmentation is typically a costly and time-consuming process due to the requirement for a vast number of pixel-level labels. To alleviate this constraint, we have developed a multi-task learning method that treats the segmentation problem as a sequence of approximation subproblems. These subproblems are recursively defined and increase in accuracy as they progress. Our framework consists of a segmentation task that learns from a small subset of images with pixel-level ground truth segmentation masks, a recursive approximation task that starts with partial masks of each object instance and conducts partial object regions learning and data-driven mask evolution, and auxiliary tasks that promote the learning of dedicated features with sparse annotations. During training, most images are only labeled with rough partial masks that do not include exact object boundaries. The approximation task learns the statistics of these partial masks, and the partial regions are recursively increased towards object boundaries with the help of learned information from the segmentation task. Our approach allows for training on a small number of precisely segmented images and a large set of coarse labels, resulting in cost-effective annotations. We demonstrate the effectiveness of our method in three applications using microscopy images and ultrasound images.",1
"Worldwide, prostate cancer is one of the main cancers affecting men. The final diagnosis of prostate cancer is based on the visual detection of Gleason patterns in prostate biopsy by pathologists. Computer-aided-diagnosis systems allow to delineate and classify the cancerous patterns in the tissue via computer-vision algorithms in order to support the physicians' task. The methodological core of this work is a U-Net convolutional neural network for image segmentation modified with residual blocks able to segment cancerous tissue according to the full Gleason system. This model outperforms other well-known architectures, and reaches a pixel-level Cohen's quadratic Kappa of 0.52, at the level of previous image-level works in the literature, but providing also a detailed localisation of the patterns.",0
"Men worldwide are significantly affected by prostate cancer, which is diagnosed through the visual detection of Gleason patterns in prostate biopsy by pathologists. With the assistance of computer-aided-diagnosis systems, physicians can rely on computer-vision algorithms to identify and classify cancerous patterns in the tissue. The U-Net convolutional neural network for image segmentation, modified with residual blocks, forms the methodological core of this work, enabling the segmentation of cancerous tissue based on the full Gleason system. This model is superior to other well-known architectures, achieving a pixel-level Cohen's quadratic Kappa of 0.52, matching previous image-level works in the literature, while providing the added benefit of detailed pattern localization.",1
"In some complicated datasets, due to the presence of noisy data points and outliers, cluster validity indices can give conflicting results in determining the optimal number of clusters. This paper presents a new validity index for fuzzy-possibilistic c-means clustering called Fuzzy-Possibilistic (FP) index, which works well in the presence of clusters that vary in shape and density. Moreover, FPCM like most of the clustering algorithms is susceptible to some initial parameters. In this regard, in addition to the number of clusters, FPCM requires a priori selection of the degree of fuzziness and the degree of typicality. Therefore, we presented an efficient procedure for determining their optimal values. The proposed approach has been evaluated using several synthetic and real-world datasets. Final computational results demonstrate the capabilities and reliability of the proposed approach compared with several well-known fuzzy validity indices in the literature. Furthermore, to clarify the ability of the proposed method in real applications, the proposed method is implemented in microarray gene expression data clustering and medical image segmentation.",0
"When dealing with complex datasets, determining the ideal number of clusters can be challenging due to the presence of outliers and noisy data points, which can lead to conflicting results when using cluster validity indices. This paper introduces a novel validity index for fuzzy-possibilistic c-means clustering called the Fuzzy-Possibilistic (FP) index. The FP index is effective in identifying clusters that vary in shape and density. Additionally, the FPCM algorithm, like most clustering algorithms, can be impacted by initial parameters, such as the degree of fuzziness and typicality. To address this, the paper presents a practical method for determining optimal values for these parameters. The effectiveness of the proposed approach is evaluated using both synthetic and real-world datasets, and it is compared to other commonly used fuzzy validity indices. The proposed method is also applied to microarray gene expression data clustering and medical image segmentation to demonstrate its real-world applications.",1
"Convex Shapes (CS) are common priors for optic disc and cup segmentation in eye fundus images. It is important to design proper techniques to represent convex shapes. So far, it is still a problem to guarantee that the output objects from a Deep Neural Convolution Networks (DCNN) are convex shapes. In this work, we propose a technique which can be easily integrated into the commonly used DCNNs for image segmentation and guarantee that outputs are convex shapes. This method is flexible and it can handle multiple objects and allow some of the objects to be convex. Our method is based on the dual representation of the sigmoid activation function in DCNNs. In the dual space, the convex shape prior can be guaranteed by a simple quadratic constraint on a binary representation of the shapes. Moreover, our method can also integrate spatial regularization and some other shape prior using a soft thresholding dynamics (STD) method. The regularization can make the boundary curves of the segmentation objects to be simultaneously smooth and convex. We design a very stable active set projection algorithm to numerically solve our model. This algorithm can form a new plug-and-play DCNN layer called CS-STD whose outputs must be a nearly binary segmentation of convex objects. In the CS-STD block, the convexity information can be propagated to guide the DCNN in both forward and backward propagation during training and prediction process. As an application example, we apply the convexity prior layer to the retinal fundus images segmentation by taking the popular DeepLabV3+ as a backbone network. Experimental results on several public datasets show that our method is efficient and outperforms the classical DCNN segmentation methods.",0
"Convex Shapes (CS) are frequently used as priors for segmenting optic disc and cup in eye fundus images. Ensuring the proper representation of convex shapes is crucial. However, it remains a challenge to ensure that the output objects from a Deep Neural Convolution Networks (DCNN) are convex shapes. This study proposes a technique that can be easily integrated into commonly used DCNNs for image segmentation and guarantees convex shape outputs. The method is flexible, handles multiple objects, and allows some objects to be convex. It is based on the dual representation of the sigmoid activation function in DCNNs and guarantees convex shape prior through a quadratic constraint in the dual space. Additionally, spatial regularization and other shape priors are integrated using a soft thresholding dynamics (STD) method. The regularization smooths and ensures convex boundary curves of segmentation objects. A stable active set projection algorithm is designed to numerically solve the model, forming a new plug-and-play DCNN layer called CS-STD. The CS-STD block propagates convexity information to guide the DCNN during training and prediction. The method is applied to retinal fundus images segmentation using DeepLabV3+ as a backbone network, and experimental results on public datasets demonstrate its efficiency and superiority over classical DCNN segmentation methods.",1
"Electrocardiogram (ECG) detection and delineation are key steps for numerous tasks in clinical practice, as ECG is the most performed non-invasive test for assessing cardiac condition. State-of-the-art algorithms employ digital signal processing (DSP), which require laborious rule adaptation to new morphologies. In contrast, deep learning (DL) algorithms, especially for classification, are gaining weight in academic and industrial settings. However, the lack of model explainability and small databases hinder their applicability. We demonstrate DL can be successfully applied to low interpretative tasks by embedding ECG detection and delineation onto a segmentation framework. For this purpose, we adapted and validated the most used neural network architecture for image segmentation, the U-Net, to one-dimensional data. The model was trained using PhysioNet's QT database, comprised of 105 ambulatory ECG recordings, for single- and multi-lead scenarios. To alleviate data scarcity, data regularization techniques such as pre-training with low-quality data labels, performing ECG-based data augmentation and applying strong model regularizers to the architecture were attempted. Other variations in the model's capacity (U-Net's depth and width), alongside the application of state-of-the-art additions, were evaluated. These variations were exhaustively validated in a 5-fold cross-validation manner. The best performing configuration reached precisions of 90.12%, 99.14% and 98.25% and recalls of 98.73%, 99.94% and 99.88% for the P, QRS and T waves, respectively, on par with DSP-based approaches. Despite being a data-hungry technique trained on a small dataset, DL-based approaches demonstrate to be a viable alternative to traditional DSP-based ECG processing techniques.",0
"In clinical practice, detecting and delineating Electrocardiogram (ECG) is crucial for various tasks since it is the most commonly used non-invasive test for assessing cardiac health. Digital signal processing (DSP) algorithms, which require time-consuming rule adaptation, are currently state-of-the-art. However, deep learning (DL) algorithms are becoming increasingly popular in academic and industrial settings, especially for classification. Nevertheless, there are still challenges such as the lack of model interpretability and small databases that limit their applicability. Our study demonstrates that DL can be successfully applied to low interpretative tasks by embedding ECG detection and delineation onto a segmentation framework. We adapted and validated the U-Net, the most commonly used neural network architecture for image segmentation, to one-dimensional data. To overcome data scarcity, we employed data regularization techniques such as pre-training with low-quality data labels, ECG-based data augmentation, and strong model regularizers. We also evaluated various modifications to the U-Net's capacity and applied state-of-the-art additions. Our exhaustive 5-fold cross-validation showed that the best performing configuration achieved precision and recall rates on par with DSP-based approaches. Despite being a data-hungry technique, DL-based approaches prove to be a viable alternative to traditional DSP-based ECG processing techniques.",1
"Deep convolutional neural networks have achieved remarkable progress on a variety of medical image computing tasks. A common problem when applying supervised deep learning methods to medical images is the lack of labeled data, which is very expensive and time-consuming to be collected. In this paper, we present a novel semi-supervised method for medical image segmentation, where the network is optimized by the weighted combination of a common supervised loss for labeled inputs only and a regularization loss for both labeled and unlabeled data. To utilize the unlabeled data, our method encourages the consistent predictions of the network-in-training for the same input under different regularizations. Aiming for the semi-supervised segmentation problem, we enhance the effect of regularization for pixel-level predictions by introducing a transformation, including rotation and flipping, consistent scheme in our self-ensembling model. With the aim of semi-supervised segmentation tasks, we introduce a transformation consistent strategy in our self-ensembling model to enhance the regularization effect for pixel-level predictions. We have extensively validated the proposed semi-supervised method on three typical yet challenging medical image segmentation tasks: (i) skin lesion segmentation from dermoscopy images on International Skin Imaging Collaboration (ISIC) 2017 dataset, (ii) optic disc segmentation from fundus images on Retinal Fundus Glaucoma Challenge (REFUGE) dataset, and (iii) liver segmentation from volumetric CT scans on Liver Tumor Segmentation Challenge (LiTS) dataset. Compared to the state-of-the-arts, our proposed method shows superior segmentation performance on challenging 2D/3D medical images, demonstrating the effectiveness of our semi-supervised method for medical image segmentation.",0
"Significant advancements have been made by deep convolutional neural networks in various medical image computing tasks. However, applying supervised deep learning methods to medical images is often challenging due to the expensive and time-consuming process of collecting labeled data. To address this problem, we present a novel semi-supervised method for medical image segmentation in which the network is optimized by combining a supervised loss for labeled inputs and a regularization loss for both labeled and unlabeled data. Our method encourages the network-in-training to produce consistent predictions for the same input under different regularizations, thereby utilizing the unlabeled data. For pixel-level predictions, we introduce a transformation-consistent scheme in our self-ensembling model, which enhances the effect of regularization. We validate our proposed method on three challenging medical image segmentation tasks, including skin lesion segmentation, optic disc segmentation, and liver segmentation. Our method outperforms the state-of-the-art approaches, demonstrating its effectiveness for medical image segmentation.",1
"Lake ice is a strong climate indicator and has been recognised as part of the Essential Climate Variables (ECV) by the Global Climate Observing System (GCOS). The dynamics of freezing and thawing, and possible shifts of freezing patterns over time, can help in understanding the local and global climate systems. One way to acquire the spatio-temporal information about lake ice formation, independent of clouds, is to analyse webcam images. This paper intends to move towards a universal model for monitoring lake ice with freely available webcam data. We demonstrate good performance, including the ability to generalise across different winters and different lakes, with a state-of-the-art Convolutional Neural Network (CNN) model for semantic image segmentation, Deeplab v3+. Moreover, we design a variant of that model, termed Deep-U-Lab, which predicts sharper, more correct segmentation boundaries. We have tested the model's ability to generalise with data from multiple camera views and two different winters. On average, it achieves intersection-over-union (IoU) values of ~71% across different cameras and ~69% across different winters, greatly outperforming prior work. Going even further, we show that the model even achieves 60% IoU on arbitrary images scraped from photo-sharing web sites. As part of the work, we introduce a new benchmark dataset of webcam images, Photi-LakeIce, from multiple cameras and two different winters, along with pixel-wise ground truth annotations.",0
"Lake ice is an important indicator of climate and is considered part of Essential Climate Variables by the Global Climate Observing System. By studying the dynamics of freezing and thawing, researchers can gain insight into local and global climate systems. Webcam images are a useful tool for gathering spatio-temporal information about lake ice formation, and this paper aims to develop a model for monitoring lake ice using freely available webcam data. The study utilizes a state-of-the-art Convolutional Neural Network called Deeplab v3+ for semantic image segmentation and proposes a variant called Deep-U-Lab that predicts sharper, more accurate boundaries. The model's ability to generalize is tested using data from multiple cameras and different winters, achieving superior performance compared to prior work. The study also introduces a new benchmark dataset called Photi-LakeIce, which includes pixel-wise annotations for multiple cameras and two different winters.",1
"We extend first-order model agnostic meta-learning algorithms (including FOMAML and Reptile) to image segmentation, present a novel neural network architecture built for fast learning which we call EfficientLab, and leverage a formal definition of the test error of meta-learning algorithms to decrease error on out of distribution tasks. We show state of the art results on the FSS-1000 dataset by meta-training EfficientLab with FOMAML and using Bayesian optimization to infer the optimal test-time adaptation routine hyperparameters. We also construct a small benchmark dataset, FP-k, for the empirical study of how meta-learning systems perform in both few- and many-shot settings. On the FP-k dataset, we show that meta-learned initializations provide value for canonical few-shot image segmentation but their performance is quickly matched by conventional transfer learning with performance being equal beyond 10 labeled examples. Our code, meta-learned model, and the FP-k dataset are available at https://github.com/ml4ai/mliis .",0
"Our study involves the extension of first-order model agnostic meta-learning algorithms, such as FOMAML and Reptile, to image segmentation. Additionally, we present a new neural network architecture called EfficientLab, which facilitates quick learning. By using a formal definition of meta-learning algorithm test error, we aim to reduce errors on out of distribution tasks. Our meta-training of EfficientLab with FOMAML, along with Bayesian optimization for identifying optimal test-time adaptation routine hyperparameters, results in state-of-the-art FSS-1000 dataset outcomes. We also create a small benchmark dataset, FP-k, to evaluate how meta-learning systems perform in both few- and many-shot settings. Our findings indicate that while meta-learned initializations offer value for canonical few-shot image segmentation, conventional transfer learning can match their performance beyond 10 labeled examples. Our code, meta-learned model, and the FP-k dataset are available at https://github.com/ml4ai/mliis .",1
"Semi-supervised learning has recently been attracting attention as an alternative to fully supervised models that require large pools of labeled data. Moreover, optimizing a model for multiple tasks can provide better generalizability than single-task learning. Leveraging self-supervision and adversarial training, we propose a novel general purpose semi-supervised, multiple-task model---namely, self-supervised, semi-supervised, multitask learning (S$^4$MTL)---for accomplishing two important tasks in medical imaging, segmentation and diagnostic classification. Experimental results on chest and spine X-ray datasets suggest that our S$^4$MTL model significantly outperforms semi-supervised single task, semi/fully-supervised multitask, and fully-supervised single task models, even with a 50\% reduction of class and segmentation labels. We hypothesize that our proposed model can be effective in tackling limited annotation problems for joint training, not only in medical imaging domains, but also for general-purpose vision tasks.",0
"As opposed to fully supervised models that rely on large amounts of labeled data, semi-supervised learning has recently gained attention. Additionally, optimizing a model for multiple tasks can lead to better generalization than single-task learning. Using self-supervision and adversarial training techniques, we have developed a new general-purpose semi-supervised, multiple-task model called self-supervised, semi-supervised, multitask learning (S$^4$MTL) for segmenting and diagnosing medical images. Results from experiments on chest and spine X-ray datasets indicate that our S$^4$MTL model performs significantly better than semi-supervised single-task, semi/fully-supervised multitask, and fully-supervised single-task models, even with a 50% reduction of class and segmentation labels. We believe that our proposed model can be useful in addressing limited annotation problems for joint training not only in medical imaging but also in general-purpose vision tasks.",1
"Few-shot segmentation (FSS) methods perform image segmentation for a particular object class in a target (query) image, using a small set of (support) image-mask pairs. Recent deep neural network based FSS methods leverage high-dimensional feature similarity between the foreground features of the support images and the query image features. In this work, we demonstrate gaps in the utilization of this similarity information in existing methods, and present a framework - SimPropNet, to bridge those gaps. We propose to jointly predict the support and query masks to force the support features to share characteristics with the query features. We also propose to utilize similarities in the background regions of the query and support images using a novel foreground-background attentive fusion mechanism. Our method achieves state-of-the-art results for one-shot and five-shot segmentation on the PASCAL-5i dataset. The paper includes detailed analysis and ablation studies for the proposed improvements and quantitative comparisons with contemporary methods.",0
"FSS techniques are utilized to perform image segmentation for a specific object class in a target image by utilizing a small number of image-mask pairs. Recently, FSS methods based on deep neural networks utilize the high-dimensional similarity between the foreground features of the support images and the query image features. However, this work demonstrates that there are gaps in the application of this similarity information in current methods. To address this issue, the SimPropNet framework is presented, which jointly predicts the support and query masks to ensure that the support features share characteristics with the query features. Additionally, a novel foreground-background attentive fusion mechanism is proposed to utilize the similarities in the background regions of the query and support images. The proposed method achieves state-of-the-art results for one-shot and five-shot segmentation on the PASCAL-5i dataset. The paper includes a detailed analysis and ablation studies of the proposed enhancements, as well as quantitative comparisons with contemporary methods.",1
"We propose adversarial constrained-CNN loss, a new paradigm of constrained-CNN loss methods, for weakly supervised medical image segmentation. In the new paradigm, prior knowledge is encoded and depicted by reference masks, and is further employed to impose constraints on segmentation outputs through adversarial learning with reference masks. Unlike pseudo label methods for weakly supervised segmentation, such reference masks are used to train a discriminator rather than a segmentation network, and thus are not required to be paired with specific images. Our new paradigm not only greatly facilitates imposing prior knowledge on network's outputs, but also provides stronger and higher-order constraints, i.e., distribution approximation, through adversarial learning. Extensive experiments involving different medical modalities, different anatomical structures, different topologies of the object of interest, different levels of prior knowledge and weakly supervised annotations with different annotation ratios is conducted to evaluate our ACCL method. Consistently superior segmentation results over the size constrained-CNN loss method have been achieved, some of which are close to the results of full supervision, thus fully verifying the effectiveness and generalization of our method. Specifically, we report an average Dice score of 75.4% with an average annotation ratio of 0.65%, surpassing the prior art, i.e., the size constrained-CNN loss method, by a large margin of 11.4%. Our codes are made publicly available at https://github.com/PengyiZhang/ACCL.",0
"We introduce a new approach for weakly supervised medical image segmentation called adversarial constrained-CNN loss. This paradigm incorporates prior knowledge through reference masks, which are used to impose constraints on the segmentation outputs through adversarial learning. Unlike pseudo label methods, the reference masks are utilized to train a discriminator rather than a segmentation network and do not need to be paired with specific images. Our method enables stronger and higher-order constraints through distribution approximation achieved by adversarial learning. We conduct extensive experiments to evaluate our ACCL method on various medical modalities, anatomical structures, object topologies, and levels of prior knowledge and weakly supervised annotations. The results show consistently superior segmentation compared to the size constrained-CNN loss method, with an average Dice score of 75.4% and an average annotation ratio of 0.65%. Our approach is publicly available at https://github.com/PengyiZhang/ACCL.",1
"The ability of neural networks to continuously learn and adapt to new tasks while retaining prior knowledge is crucial for many applications. However, current neural networks tend to forget previously learned tasks when trained on new ones, i.e., they suffer from Catastrophic Forgetting (CF). The objective of Continual Learning (CL) is to alleviate this problem, which is particularly relevant for medical applications, where it may not be feasible to store and access previously used sensitive patient data. In this work, we propose a Continual Learning approach for brain segmentation, where a single network is consecutively trained on samples from different domains. We build upon an importance driven approach and adapt it for medical image segmentation. Particularly, we introduce learning rate regularization to prevent the loss of the network's knowledge. Our results demonstrate that directly restricting the adaptation of important network parameters clearly reduces Catastrophic Forgetting for segmentation across domains.",0
"The ability of neural networks to learn and adapt to new tasks while retaining past knowledge is vital for various applications. However, current neural networks suffer from Catastrophic Forgetting (CF) and forget previously learned tasks when trained on new ones. This issue is crucial for medical applications where storing and accessing sensitive patient data may not be feasible. To address this problem, Continual Learning (CL) aims to alleviate CF. This study proposes a CL approach for brain segmentation, where a single network is consecutively trained on samples from different domains. The approach builds upon an importance-driven method and adapts it for medical image segmentation. Furthermore, learning rate regularization is introduced to prevent the loss of the network's knowledge. The results demonstrate that restricting the adaptation of critical network parameters reduces CF for segmentation across domains.",1
"Human brain is a layered structure, and performs not only a feedforward process from a lower layer to an upper layer but also a feedback process from an upper layer to a lower layer. The layer is a collection of neurons, and neural network is a mathematical model of the function of neurons. Although neural network imitates the human brain, everyone uses only feedforward process from the lower layer to the upper layer, and feedback process from the upper layer to the lower layer is not used. Therefore, in this paper, we propose Feedback U-Net using Convolutional LSTM which is the segmentation method using Convolutional LSTM and feedback process. The output of U-net gave feedback to the input, and the second round is performed. By using Convolutional LSTM, the features in the second round are extracted based on the features acquired in the first round. On both of the Drosophila cell image and Mouse cell image datasets, our method outperformed conventional U-Net which uses only feedforward process.",0
"The human brain is a complex structure that employs both feedforward and feedback processes between different layers of neurons. Neural networks are mathematical models that imitate the function of neurons and are made up of layers of these cells. However, current neural networks only use feedforward processes from lower to upper layers and do not utilize feedback processes from upper to lower layers. To address this limitation, we propose a new segmentation method, called Feedback U-Net using Convolutional LSTM, that incorporates feedback processes. Our method uses Convolutional LSTM to extract features from the output of the first round and then use these features to perform a second round of processing. We tested our method on Drosophila and Mouse cell image datasets and found that it outperformed conventional U-Net, which uses only feedforward processes.",1
"Semantic image segmentation is one of the most important tasks in medical image analysis. Most state-of-the-art deep learning methods require a large number of accurately annotated examples for model training. However, accurate annotation is difficult to obtain especially in medical applications. In this paper, we propose a spatially constrained deep convolutional neural network (DCNN) to achieve smooth and robust image segmentation using inaccurately annotated labels for training. In our proposed method, image segmentation is formulated as a graph optimization problem that is solved by a DCNN model learning process. The cost function to be optimized consists of a unary term that is calculated by cross entropy measurement and a pairwise term that is based on enforcing a local label consistency. The proposed method has been evaluated based on corneal confocal microscopic (CCM) images for nerve fiber segmentation, where accurate annotations are extremely difficult to be obtained. Based on both the quantitative result of a synthetic dataset and qualitative assessment of a real dataset, the proposed method has achieved superior performance in producing high quality segmentation results even with inaccurate labels for training.",0
"Medical image analysis relies heavily on semantic image segmentation, which is a crucial task. Deep learning methods that are currently state-of-the-art require a vast number of accurately annotated examples for effective model training. Nonetheless, obtaining accurate annotation, particularly in medical applications, poses a significant challenge. This study introduces a spatially constrained deep convolutional neural network (DCNN) that ensures smooth and robust image segmentation using inaccurately annotated labels for training. The study formulates image segmentation as a graph optimization problem solved by DCNN model learning. The cost function comprises a unary term calculated using cross-entropy measurement and a pairwise term based on enforcing local label consistency. The proposed method evaluates corneal confocal microscopic (CCM) images for nerve fiber segmentation, where obtaining precise annotations is exceptionally challenging. The proposed method delivers superior performance in generating high-quality segmentation results, even with inaccurate labels for training. This is evident from both the quantitative result of a synthetic dataset and the qualitative assessment of a real dataset.",1
"We study the energy minimization problem in low-level vision tasks from a novel perspective. We replace the heuristic regularization term with a learnable subspace constraint, and preserve the data term to exploit domain knowledge derived from the first principle of a task. This learning subspace minimization (LSM) framework unifies the network structures and the parameters for many low-level vision tasks, which allows us to train a single network for multiple tasks simultaneously with completely shared parameters, and even generalizes the trained network to an unseen task as long as its data term can be formulated. We demonstrate our LSM framework on four low-level tasks including interactive image segmentation, video segmentation, stereo matching, and optical flow, and validate the network on various datasets. The experiments show that the proposed LSM generates state-of-the-art results with smaller model size, faster training convergence, and real-time inference.",0
"We take a fresh approach to studying the energy minimization problem in low-level vision tasks. By substituting the heuristic regularization term with a learnable subspace constraint, we keep the data term intact to leverage the fundamental principles of a given task. Our learning subspace minimization (LSM) framework offers a unified solution for network structures and parameters across a range of low-level vision tasks, enabling simultaneous training of a single network with completely shared parameters. Moreover, the trained network can be extended to new tasks as long as the data term can be formulated. We showcase the LSM framework on four low-level tasks, including interactive image segmentation, video segmentation, stereo matching, and optical flow, and evaluate its efficacy on various datasets. Our experiments reveal that LSM produces state-of-the-art results with a smaller model size, quicker training convergence, and real-time inference.",1
"3D convolution neural networks (CNN) have been proved very successful in parsing organs or tumours in 3D medical images, but it remains sophisticated and time-consuming to choose or design proper 3D networks given different task contexts. Recently, Neural Architecture Search (NAS) is proposed to solve this problem by searching for the best network architecture automatically. However, the inconsistency between search stage and deployment stage often exists in NAS algorithms due to memory constraints and large search space, which could become more serious when applying NAS to some memory and time consuming tasks, such as 3D medical image segmentation. In this paper, we propose coarse-to-fine neural architecture search (C2FNAS) to automatically search a 3D segmentation network from scratch without inconsistency on network size or input size. Specifically, we divide the search procedure into two stages: 1) the coarse stage, where we search the macro-level topology of the network, i.e. how each convolution module is connected to other modules; 2) the fine stage, where we search at micro-level for operations in each cell based on previous searched macro-level topology. The coarse-to-fine manner divides the search procedure into two consecutive stages and meanwhile resolves the inconsistency. We evaluate our method on 10 public datasets from Medical Segmentation Decalthon (MSD) challenge, and achieve state-of-the-art performance with the network searched using one dataset, which demonstrates the effectiveness and generalization of our searched models.",0
"Although 3D convolution neural networks (CNN) have been successful in parsing organs or tumours in 3D medical images, it is still challenging and time-consuming to choose or design appropriate 3D networks for different task contexts. Recently, Neural Architecture Search (NAS) has been introduced to automatically search for the optimal network architecture, but the inconsistencies between the search and deployment stages can be significant due to memory constraints and large search spaces. These issues are amplified when using NAS for memory and time-consuming tasks such as 3D medical image segmentation. To address this problem, we propose the Coarse-to-Fine Neural Architecture Search (C2FNAS) approach to automatically search for a 3D segmentation network from scratch without inconsistencies in network size and input size. We divide the search process into two stages: 1) the coarse stage, where we search for the macro-level topology of the network; and 2) the fine stage, where we search for the micro-level operations in each cell based on the previous macro-level topology. Our approach resolves the inconsistencies by dividing the search process into two consecutive stages. We evaluated our method on 10 public datasets from the Medical Segmentation Decathlon (MSD) challenge and achieved state-of-the-art performance with the network searched using one dataset. This demonstrates the effectiveness and generalization of our searched models.",1
"Segmentation partitions an image into different regions containing pixels with similar attributes. A standard non-contextual variant of Fuzzy C-means clustering algorithm (FCM), considering its simplicity is generally used in image segmentation. Using FCM has its disadvantages like it is dependent on the initial guess of the number of clusters and highly sensitive to noise. Satisfactory visual segments cannot be obtained using FCM. Particle Swarm Optimization (PSO) belongs to the class of evolutionary algorithms and has good convergence speed and fewer parameters compared to Genetic Algorithms (GAs). An optimized version of PSO can be combined with FCM to act as a proper initializer for the algorithm thereby reducing its sensitivity to initial guess. A hybrid PSO algorithm named Adaptive Particle Swarm Optimization (APSO) which improves in the calculation of various hyper parameters like inertia weight, learning factors over standard PSO, using insights from swarm behaviour, leading to improvement in cluster quality can be used. This paper presents a new image segmentation algorithm called Adaptive Particle Swarm Optimization and Fuzzy C-means Clustering Algorithm (APSOF), which is based on Adaptive Particle Swarm Optimization (APSO) and Fuzzy C-means clustering. Experimental results show that APSOF algorithm has edge over FCM in correctly identifying the optimum cluster centers, there by leading to accurate classification of the image pixels. Hence, APSOF algorithm has superior performance in comparison with classic Particle Swarm Optimization (PSO) and Fuzzy C-means clustering algorithm (FCM) for image segmentation.",0
"Image segmentation involves dividing an image into distinct regions that contain pixels with similar attributes. Typically, a non-contextual variant of Fuzzy C-means clustering algorithm (FCM) is employed for image segmentation due to its simplicity. However, FCM has limitations such as dependence on the initial guess of the number of clusters and sensitivity to noise, resulting in unsatisfactory visual segments. To mitigate these drawbacks, Particle Swarm Optimization (PSO) can be utilized as an evolutionary algorithm that has good convergence speed and fewer parameters than Genetic Algorithms (GAs). PSO can be optimized and combined with FCM to act as a proper initializer, thereby reducing sensitivity to initial guess. An adaptive PSO algorithm named APSO, which improves hyper parameter calculation and cluster quality by using insights from swarm behavior, can also be used. This paper introduces a new image segmentation algorithm called APSOF, which is based on APSO and Fuzzy C-means clustering. Experimental results demonstrate that APSOF outperforms classic PSO and FCM in identifying optimal cluster centers and accurately classifying image pixels. Therefore, APSOF is a superior algorithm for image segmentation.",1
"Deep learning based image segmentation has achieved the state-of-the-art performance in many medical applications such as lesion quantification, organ detection, etc. However, most of the methods rely on supervised learning, which require a large set of high-quality labeled data. Data annotation is generally an extremely time-consuming process. To address this problem, we propose a generic semi-supervised learning framework for image segmentation based on a deep convolutional neural network (DCNN). An encoder-decoder based DCNN is initially trained using a few annotated training samples. This initially trained model is then copied into sub-models and improved iteratively using random subsets of unlabeled data with pseudo labels generated from models trained in the previous iteration. The number of sub-models is gradually decreased to one in the final iteration. We evaluate the proposed method on a public grand-challenge dataset for skin lesion segmentation. Our method is able to significantly improve beyond fully supervised model learning by incorporating unlabeled data.",0
"Numerous medical applications such as organ detection and lesion quantification have benefited from deep learning based image segmentation, which has achieved impressive results. However, these methods typically rely on supervised learning and necessitate a vast amount of high-quality labeled data, which is a time-consuming and laborious process. To combat this obstacle, we suggest a comprehensive semi-supervised learning structure for image segmentation that employs a deep convolutional neural network (DCNN). An encoder-decoder based DCNN is initially trained using a limited number of annotated training samples. This initial model is then copied into sub-models and gradually refined using random subsets of unlabeled data with pseudo labels created from models trained in previous iterations. The number of sub-models is reduced gradually to one in the final iteration. We put our proposed method to test on a public grand-challenge dataset for skin lesion segmentation and found that it outperforms fully supervised model learning by incorporating unlabeled data.",1
"In machine learning and other fields, suggesting a good solution to a problem is usually a harder task than evaluating the quality of such a solution. This asymmetry is the basis for a large number of selection oriented methods that use a generator system to guess a set of solutions and an evaluator system to rank and select the best solutions. This work examines the use of this approach to the problem of panoptic image segmentation and class agnostic parts segmentation. The generator/evaluator approach for this case consists of two independent convolutional neural nets: a generator net that suggests variety segments corresponding to objects, stuff and parts regions in the image, and an evaluator net that chooses the best segments to be merged into the segmentation map. The result is a trial and error evolutionary approach in which a generator that guesses segments with low average accuracy, but with wide variability, can still produce good results when coupled with an accurate evaluator. The generator consists of a Pointer net that receives an image and a point in the image, and predicts the region of the segment containing the point. Generating and evaluating each segment separately is essential in this case since it demands exponentially fewer guesses compared to a system that guesses and evaluates the full segmentation map in each try. The classification of the selected segments is done by an independent region-specific classification net. This allows the segmentation to be class agnostic and hence, capable of segmenting unfamiliar categories that were not part of the training set. The method was examined on the COCO Panoptic segmentation benchmark and gave results comparable to those of the basic semantic segmentation and Mask-RCNN methods. In addition, the system was used for the task of splitting objects of unseen classes (that did not appear in the training set) into parts.",0
"It is often more challenging to propose a good solution to a problem in fields such as machine learning than to evaluate the quality of the solution. This asymmetry has led to the development of selection-oriented methods that use a generator system to generate a set of solutions and an evaluator system to rank and select the best solutions. This study explores the use of this approach for panoptic image segmentation and class-agnostic parts segmentation. The approach involves two separate convolutional neural nets: a generator net that proposes various segments corresponding to objects, stuff, and parts regions in the image, and an evaluator net that selects the best segments to merge into the segmentation map. The method uses a trial and error evolutionary approach, where a generator that produces segments with low average accuracy but wide variability can still yield good results when coupled with an accurate evaluator. The generator utilizes a Pointer net that predicts the segment containing a given point in the image. By generating and evaluating each segment separately, the system requires exponentially fewer guesses than a system that guesses and evaluates the full segmentation map in each try. The selected segments are classified by an independent region-specific classification net, allowing the segmentation to be class-agnostic and capable of segmenting unfamiliar categories. The method was tested on the COCO Panoptic segmentation benchmark and achieved results comparable to those of the basic semantic segmentation and Mask-RCNN methods. Additionally, the system was used to split objects of unseen classes into parts.",1
"At present, adversarial attacks are designed in a task-specific fashion. However, for downstream computer vision tasks such as image captioning, image segmentation etc., the current deep learning systems use an image classifier like VGG16, ResNet50, Inception-v3 etc. as a feature extractor. Keeping this in mind, we propose Mimic and Fool, a task agnostic adversarial attack. Given a feature extractor, the proposed attack finds an adversarial image which can mimic the image feature of the original image. This ensures that the two images give the same (or similar) output regardless of the task. We randomly select 1000 MSCOCO validation images for experimentation. We perform experiments on two image captioning models, Show and Tell, Show Attend and Tell and one VQA model, namely, end-to-end neural module network (N2NMN). The proposed attack achieves success rate of 74.0%, 81.0% and 87.1% for Show and Tell, Show Attend and Tell and N2NMN respectively. We also propose a slight modification to our attack to generate natural-looking adversarial images. In addition, we also show the applicability of the proposed attack for invertible architecture. Since Mimic and Fool only requires information about the feature extractor of the model, it can be considered as a gray-box attack.",0
"Currently, adversarial attacks are task-specific. However, popular computer vision tasks like image captioning and segmentation rely on deep learning systems that use image classifiers such as VGG16, ResNet50, or Inception-v3 as feature extractors. To address this, our proposed Mimic and Fool attack is task-agnostic. Using a feature extractor, the attack generates an adversarial image that can mimic the original image's features, ensuring similar output regardless of the task. We conducted experiments on 1000 MSCOCO validation images with two image captioning models (Show and Tell, Show Attend and Tell) and one VQA model (end-to-end neural module network). Our proposed attack achieved success rates of 74.0%, 81.0%, and 87.1% for each model, respectively. We also modified the attack to generate natural-looking adversarial images and demonstrated its applicability for invertible architecture. As it only requires information about the feature extractor, Mimic and Fool can be considered a gray-box attack.",1
"Recent years have witnessed the great progress of deep neural networks on semantic segmentation, particularly in medical imaging. Nevertheless, training high-performing models require large amounts of pixel-level ground truth masks, which can be prohibitive to obtain in the medical domain. Furthermore, training such models in a low-data regime highly increases the risk of overfitting. Recent attempts to alleviate the need for large annotated datasets have developed training strategies under the few-shot learning paradigm, which addresses this shortcoming by learning a novel class from only a few labeled examples. In this context, a segmentation model is trained on episodes, which represent different segmentation problems, each of them trained with a very small labeled dataset. In this work, we propose a novel few-shot learning framework for semantic segmentation, where unlabeled images are also made available at each episode. To handle this new learning paradigm, we propose to include surrogate tasks that can leverage very powerful supervisory signals --derived from the data itself-- for semantic feature learning. We show that including unlabeled surrogate tasks in the episodic training leads to more powerful feature representations, which ultimately results in better generability to unseen tasks. We demonstrate the efficiency of our method in the task of skin lesion segmentation in two publicly available datasets. Furthermore, our approach is general and model-agnostic, which can be combined with different deep architectures.",0
"In recent years, there has been significant progress in the use of deep neural networks for semantic segmentation, particularly in medical imaging. However, creating accurate models requires a large number of pixel-level ground truth masks, which can be difficult to obtain in the medical field. Additionally, training such models with limited data increases the risk of overfitting. To address this issue, recent efforts have focused on few-shot learning, where a segmentation model is trained on a small number of labeled examples. In this study, we propose a new few-shot learning framework for semantic segmentation that includes unlabeled images in each episode. To address this new learning paradigm, we suggest using surrogate tasks that provide powerful supervisory signals for semantic feature learning. Our approach leads to more effective feature representations, resulting in better generability for unseen tasks. We demonstrate the effectiveness of our method in skin lesion segmentation using two publicly available datasets. Our approach is versatile and can be used with various deep architectures.",1
"Exploiting more information from ground truth (GT) images now is a new research direction for further improving CNN's performance in CT image segmentation. Previous methods focus on devising the loss function for fulfilling such a purpose. However, it is rather difficult to devise a general and optimization-friendly loss function. We here present a novel and practical method that exploits GT images beyond the loss function. Our insight is that feature maps of two CNNs trained respectively on GT and CT images should be similar on some metric space, because they both are used to describe the same objects for the same purpose. We hence exploit GT images by enforcing such two CNNs' feature maps to be consistent. We assess the proposed method on two data sets, and compare its performance to several competitive methods. Extensive experimental results show that the proposed method is effective, outperforming all the compared methods.",0
"A new research direction involves using more information from ground truth (GT) images to enhance the performance of CNNs in CT image segmentation. Previous methods have focused on developing a loss function to achieve this goal, but creating a general and optimization-friendly one has proven challenging. Our proposed approach is innovative and practical, as it goes beyond the loss function and capitalizes on the similarities between feature maps of two CNNs trained on GT and CT images. We ensure consistency between these feature maps, as they both depict the same objects for the same purpose. We evaluate our method on two data sets and compare it to various other methods, demonstrating its effectiveness in outperforming all of them.",1
"As supervised semantic segmentation is reaching satisfying results, many recent papers focused on making segmentation network architectures faster, smaller and more efficient. In particular, studies often aim to reach the stage to which they can claim to be ""real-time"". Achieving this goal is especially relevant in the context of real-time video operations for autonomous vehicles and robots, or medical imaging during surgery.   The common metric used for assessing these methods is so far the same as the ones used for image segmentation without time constraint: mean Intersection over Union (mIoU). In this paper, we argue that this metric is not relevant enough for real-time video as it does not take into account the processing time (latency) of the network. We propose a similar but more relevant metric called FLAME for video-segmentation networks, that compares the output segmentation of the network with the ground truth segmentation of the current video frame at the time when the network finishes the processing.   We perform experiments to compare a few networks using this metric and propose a simple addition to network training to enhance results according to that metric.",0
"Recently, research papers have shifted their focus to making segmentation network architectures faster, smaller, and more efficient as supervised semantic segmentation has achieved satisfactory results. These studies aim to achieve real-time segmentation, which is especially relevant for autonomous vehicles, robots, and medical imaging during surgeries. The current metric used for evaluating these methods is mean Intersection over Union (mIoU), which is also used for image segmentation without time constraints. However, we argue that this metric does not account for the processing time (latency) of the network in real-time video operations. Therefore, we propose a more relevant metric called FLAME for video-segmentation networks, which compares the output segmentation with the ground truth segmentation at the time the network completes processing. We conduct experiments to compare networks using this metric and suggest a simple addition to network training to improve results based on this metric.",1
"Deep Convolutional Neural Networks (DCNNs) have recently shown outstanding performance in semantic image segmentation. However, state-of-the-art DCNN-based semantic segmentation methods usually suffer from high computational complexity due to the use of complex network architectures. This greatly limits their applications in the real-world scenarios that require real-time processing. In this paper, we propose a real-time high-performance DCNN-based method for robust semantic segmentation of urban street scenes, which achieves a good trade-off between accuracy and speed. Specifically, a Lightweight Baseline Network with Atrous convolution and Attention (LBN-AA) is firstly used as our baseline network to efficiently obtain dense feature maps. Then, the Distinctive Atrous Spatial Pyramid Pooling (DASPP), which exploits the different sizes of pooling operations to encode the rich and distinctive semantic information, is developed to detect objects at multiple scales. Meanwhile, a Spatial detail-Preserving Network (SPN) with shallow convolutional layers is designed to generate high-resolution feature maps preserving the detailed spatial information. Finally, a simple but practical Feature Fusion Network (FFN) is used to effectively combine both shallow and deep features from the semantic branch (DASPP) and the spatial branch (SPN), respectively. Extensive experimental results show that the proposed method respectively achieves the accuracy of 73.6% and 68.0% mean Intersection over Union (mIoU) with the inference speed of 51.0 fps and 39.3 fps on the challenging Cityscapes and CamVid test datasets (by only using a single NVIDIA TITAN X card). This demonstrates that the proposed method offers excellent performance at the real-time speed for semantic segmentation of urban street scenes.",0
"Semantic image segmentation has been revolutionized by Deep Convolutional Neural Networks (DCNNs). However, current DCNN-based semantic segmentation methods are often hampered by complex network architectures, which result in high computational requirements, thereby limiting their practical use for real-time processing in real-world scenarios. Therefore, we present a novel DCNN-based method for the semantic segmentation of urban street scenes, which offers a balance between speed and accuracy. Our approach involves employing a Lightweight Baseline Network with Atrous convolution and Attention (LBN-AA) as the baseline network to efficiently obtain dense feature maps. To detect objects at multiple scales, we developed the Distinctive Atrous Spatial Pyramid Pooling (DASPP), which utilizes different sizes of pooling operations to encode rich and distinct semantic information. Additionally, we designed a Spatial detail-Preserving Network (SPN) with shallow convolutional layers to generate high-resolution feature maps that preserve detailed spatial information. Finally, we employed a simple Feature Fusion Network (FFN) to effectively combine shallow and deep features from the semantic branch (DASPP) and the spatial branch (SPN), respectively. Our extensive experiments show that our approach achieves 73.6% and 68.0% mean Intersection over Union (mIoU) accuracy with an inference speed of 51.0 fps and 39.3 fps on the Cityscapes and CamVid test datasets, respectively, using only a single NVIDIA TITAN X card. Therefore, our proposed method provides excellent performance at real-time speed for semantic segmentation of urban street scenes.",1
"Flow-based generative models have highly desirable properties like exact log-likelihood evaluation and exact latent-variable inference, however they are still in their infancy and have not received as much attention as alternative generative models. In this paper, we introduce C-Flow, a novel conditioning scheme that brings normalizing flows to an entirely new scenario with great possibilities for multi-modal data modeling. C-Flow is based on a parallel sequence of invertible mappings in which a source flow guides the target flow at every step, enabling fine-grained control over the generation process. We also devise a new strategy to model unordered 3D point clouds that, in combination with the conditioning scheme, makes it possible to address 3D reconstruction from a single image and its inverse problem of rendering an image given a point cloud. We demonstrate our conditioning method to be very adaptable, being also applicable to image manipulation, style transfer and multi-modal image-to-image mapping in a diversity of domains, including RGB images, segmentation maps, and edge masks.",0
"Although flow-based generative models possess desirable properties such as exact log-likelihood evaluation and exact latent-variable inference, they have not received as much attention as other generative models due to their early stage of development. This paper introduces C-Flow, a novel conditioning scheme that expands the application of normalizing flows to a new scenario with great potential for multi-modal data modeling. C-Flow is based on a parallel sequence of invertible mappings where a source flow guides the target flow, allowing for precise control over the generation process. Additionally, a new 3D point cloud modeling strategy is developed to address the challenges of reconstructing a 3D object from a single image and rendering an image from a point cloud. The conditioning method presented in this paper is highly adaptable and can be applied to image manipulation, style transfer, and multi-modal image-to-image mapping across various domains such as RGB images, segmentation maps, and edge masks.",1
"Video feedback provides a wealth of information about surgical procedures and is the main sensory cue for surgeons. Scene understanding is crucial to computer assisted interventions (CAI) and to post-operative analysis of the surgical procedure. A fundamental building block of such capabilities is the identification and localization of surgical instruments and anatomical structures through semantic segmentation. Deep learning has advanced semantic segmentation techniques in the recent years but is inherently reliant on the availability of labeled datasets for model training. This paper introduces a dataset for semantic segmentation of cataract surgery videos. The annotated images are part of the publicly available CATARACTS challenge dataset. In addition, we benchmark the performance of several state-of-the-art deep learning models for semantic segmentation on the presented dataset. The dataset is publicly available at https://cataracts.grand-challenge.org/CaDIS/ .",0
"The primary sensory cue for surgeons is video feedback, which provides a wealth of information about surgical procedures. Scene understanding is critical for computer-assisted interventions and post-operative analysis of surgical procedures. To achieve this, the identification and localization of surgical instruments and anatomical structures through semantic segmentation is a fundamental building block. Although deep learning has made significant progress in semantic segmentation techniques, it relies on labeled datasets for model training. This article introduces a dataset of annotated images for semantic segmentation of cataract surgery videos, which is part of the publicly available CATARACTS challenge dataset. Additionally, the performance of several state-of-the-art deep learning models for semantic segmentation on the presented dataset is benchmarked. The dataset is available to the public via https://cataracts.grand-challenge.org/CaDIS/.",1
"The Know Your Customer (KYC) and Anti Money Laundering (AML) are worldwide practices to online customer identification based on personal identification documents, similarity and liveness checking, and proof of address. To answer the basic regulation question: are you whom you say you are? The customer needs to upload valid identification documents (ID). This task imposes some computational challenges since these documents are diverse, may present different and complex backgrounds, some occlusion, partial rotation, poor quality, or damage. Advanced text and document segmentation algorithms were used to process the ID images. In this context, we investigated a method based on U-Net to detect the document edges and text regions in ID images. Besides the promising results on image segmentation, the U-Net based approach is computationally expensive for a real application, since the image segmentation is a customer device task. We propose a model optimization based on Octave Convolutions to qualify the method to situations where storage, processing, and time resources are limited, such as in mobile and robotic applications. We conducted the evaluation experiments in two new datasets CDPhotoDataset and DTDDataset, which are composed of real ID images of Brazilian documents. Our results showed that the proposed models are efficient to document segmentation tasks and portable.",0
"The identification of online customers through personal identification documents, similarity and liveness checks, and proof of address is a global practice known as Know Your Customer (KYC) and Anti Money Laundering (AML). To ensure that customers are who they claim to be, they must provide valid identification documents (ID). However, this can be challenging due to the diverse nature of these documents, which may feature complex backgrounds, occlusion, partial rotation, poor quality, or damage. To address this issue, advanced text and document segmentation algorithms have been employed to process the ID images. This study investigates the use of a U-Net based method to detect document edges and text regions in ID images, which has shown promising results in image segmentation. However, this approach is computationally expensive for real-world applications where storage, processing, and time resources are limited. To address this challenge, we propose a model optimization approach based on Octave Convolutions, which is ideal for mobile and robotic applications. We evaluated our approach on two new datasets, CDPhotoDataset and DTDDataset, which contain real ID images of Brazilian documents. Our findings demonstrate that the proposed models are efficient for document segmentation tasks and are portable.",1
"Biomedical imaging is a driver of scientific discovery and core component of medical care, currently stimulated by the field of deep learning. While semantic segmentation algorithms enable 3D image analysis and quantification in many applications, the design of respective specialised solutions is non-trivial and highly dependent on dataset properties and hardware conditions. We propose nnU-Net, a deep learning framework that condenses the current domain knowledge and autonomously takes the key decisions required to transfer a basic architecture to different datasets and segmentation tasks. Without manual tuning, nnU-Net surpasses most specialised deep learning pipelines in 19 public international competitions and sets a new state of the art in the majority of the 49 tasks. The results demonstrate a vast hidden potential in the systematic adaptation of deep learning methods to different datasets. We make nnU-Net publicly available as an open-source tool that can effectively be used out-of-the-box, rendering state of the art segmentation accessible to non-experts and catalyzing scientific progress as a framework for automated method design.",0
"The use of biomedical imaging is an important aspect of medical care and scientific advancement, with deep learning being a significant contributor to its progress. Although semantic segmentation algorithms are useful in analyzing and quantifying 3D images, creating specialized solutions can be complex and influenced by various factors such as dataset properties and hardware conditions. Our solution is nnU-Net, a deep learning framework that incorporates current domain knowledge and can independently make crucial decisions to adapt a basic architecture to different datasets and segmentation tasks. With nnU-Net, manual adjustments are unnecessary, and it has outperformed most specialized deep learning pipelines in 19 international competitions and achieved a new state-of-the-art level in 49 tasks. This underscores the potential of deep learning methods in adapting to diverse datasets systematically. We are making nnU-Net publicly available as an open-source tool that can be effortlessly utilized, thus providing non-experts with access to cutting-edge segmentation techniques and promoting scientific advancement by offering an automated method design framework.",1
"This paper presents an efficient annotation procedure and an application thereof to end-to-end, rich semantic segmentation of the sensed environment using FMCW scanning radar. We advocate radar over the traditional sensors used for this task as it operates at longer ranges and is substantially more robust to adverse weather and illumination conditions. We avoid laborious manual labelling by exploiting the largest radar-focused urban autonomy dataset collected to date, correlating radar scans with RGB cameras and LiDAR sensors, for which semantic segmentation is an already consolidated procedure. The training procedure leverages a state-of-the-art natural image segmentation system which is publicly available and as such, in contrast to previous approaches, allows for the production of copious labels for the radar stream by incorporating four camera and two LiDAR streams. Additionally, the losses are computed taking into account labels to the radar sensor horizon by accumulating LiDAR returns along a pose-chain ahead and behind of the current vehicle position. Finally, we present the network with multi-channel radar scan inputs in order to deal with ephemeral and dynamic scene objects.",0
"In this paper, we introduce a new annotation procedure and its application to semantic segmentation of the environment using FMCW scanning radar. We argue that radar is a better choice than traditional sensors for this task because it has a longer range and can handle harsh weather and lighting conditions. To avoid the tedious process of manual labeling, we use a large dataset that combines radar scans with RGB cameras and LiDAR sensors, which have already established semantic segmentation procedures. Our training method uses a publicly available natural image segmentation system, allowing us to produce multiple labels for the radar stream by incorporating four camera and two LiDAR streams. We also compute losses by accumulating LiDAR returns along a pose-chain ahead and behind of the current vehicle position to consider labels to the radar sensor horizon. Finally, we present a network that takes multi-channel radar scans as input to handle dynamic scene objects.",1
"Land use and land cover mapping are essential to various fields of study, including forestry, agriculture, and urban management. Using earth observation satellites both facilitate and accelerate the task. Lately, deep learning methods have proven to be excellent at automating the mapping via semantic image segmentation. However, because deep neural networks require large amounts of labeled data, it is not easy to exploit the full potential of satellite imagery. Additionally, the land cover tends to differ in appearance from one region to another; therefore, having labeled data from one location does not necessarily help in mapping others. Furthermore, satellite images come in various multispectral bands (the bands could range from RGB to over twelve bands). In this paper, we aim at using domain adaptation to solve the aforementioned problems. We applied a well-performing domain adaptation approach on datasets we have built using RGB images from Sentinel-2, WorldView-2, and Pleiades-1 satellites with Corine Land Cover as ground-truth labels. We have also used the DeepGlobe land cover dataset. Experiments show a significant improvement over results obtained without the use of domain adaptation. In some cases, an improvement of over 20% MIoU. At times it even manages to correct errors in the ground-truth labels.",0
"The mapping of land use and land cover is crucial in a variety of fields, such as agriculture, forestry, and urban management. The utilization of earth observation satellites has made this task more efficient and effective. Recently, deep learning techniques have demonstrated their ability to automate mapping through semantic image segmentation. However, due to the large amount of labeled data required by deep neural networks, fully exploiting the potential of satellite imagery remains challenging. Additionally, land cover varies in appearance across regions, rendering labeled data from one location ineffective in mapping others. Furthermore, satellite images come in various multispectral bands, ranging from RGB to over twelve bands. This paper proposes the use of domain adaptation to address these challenges. The approach was applied to datasets comprising RGB images from Sentinel-2, WorldView-2, and Pleiades-1 satellites with Corine Land Cover as ground-truth labels, as well as the DeepGlobe land cover dataset. The results of experiments indicate a significant improvement in accuracy, with some cases demonstrating over 20% MIoU increase, and even correcting errors in ground-truth labels.",1
"We present BiLingUNet, a state-of-the-art model for image segmentation using referring expressions. BiLingUNet uses language to customize visual filters and outperforms approaches that concatenate a linguistic representation to the visual input. We find that using language to modulate both bottom-up and top-down visual processing works better than just making the top-down processing language-conditional. We argue that common 1x1 language-conditional filters cannot represent relational concepts and experimentally demonstrate that wider filters work better. Our model achieves state-of-the-art performance on four referring expression datasets.",0
"Introducing BiLingUNet, an advanced image segmentation model that utilizes referring expressions. BiLingUNet adapts visual filters using language and surpasses techniques that attach a linguistic representation to the visual input. Our research shows that employing language to regulate both bottom-up and top-down visual processing is more effective than solely making top-down processing language-dependent. We contend that typical 1x1 language-dependent filters are inadequate in representing relational concepts and prove through experimentation that broader filters are more successful. Our model attains the highest level of performance in four referring expression datasets.",1
"The perceptual-based grouping process produces a hierarchical and compositional image representation that helps both human and machine vision systems recognize heterogeneous visual concepts. Examples can be found in the classical hierarchical superpixel segmentation or image parsing works. However, the grouping process is largely overlooked in modern CNN-based image segmentation networks due to many challenges, including the inherent incompatibility between the grid-shaped CNN feature map and the irregular-shaped perceptual grouping hierarchy. Overcoming these challenges, we propose a deep grouping model (DGM) that tightly marries the two types of representations and defines a bottom-up and a top-down process for feature exchanging. When evaluating the model on the recent Broden+ dataset for the unified perceptual parsing task, it achieves state-of-the-art results while having a small computational overhead compared to other contextual-based segmentation models. Furthermore, the DGM has better interpretability compared with modern CNN methods.",0
"The way in which visual information is grouped based on perception creates a layered and complex image representation that is useful for both human and machine vision systems in identifying a variety of visual concepts. This can be seen in techniques like hierarchical superpixel segmentation and image parsing. However, this grouping process is often not utilized in modern CNN-based image segmentation networks due to various challenges, such as the difficulty of reconciling the grid-like CNN feature map with the irregular perceptual grouping hierarchy. To address these challenges, we propose a deep grouping model (DGM) that effectively merges both types of representations through a bottom-up and top-down feature exchange process. Our evaluation of this model on the Broden+ dataset for perceptual parsing demonstrates its state-of-the-art performance and relatively low computational cost compared to other contextual-based segmentation models. Additionally, the DGM allows for better interpretability than modern CNN methods.",1
"Over the past few years, state-of-the-art image segmentation algorithms are based on deep convolutional neural networks. To render a deep network with the ability to understand a concept, humans need to collect a large amount of pixel-level annotated data to train the models, which is time-consuming and tedious. Recently, few-shot segmentation is proposed to solve this problem. Few-shot segmentation aims to learn a segmentation model that can be generalized to novel classes with only a few training images. In this paper, we propose a cross-reference network (CRNet) for few-shot segmentation. Unlike previous works which only predict the mask in the query image, our proposed model concurrently make predictions for both the support image and the query image. With a cross-reference mechanism, our network can better find the co-occurrent objects in the two images, thus helping the few-shot segmentation task. We also develop a mask refinement module to recurrently refine the prediction of the foreground regions. For the $k$-shot learning, we propose to finetune parts of networks to take advantage of multiple labeled support images. Experiments on the PASCAL VOC 2012 dataset show that our network achieves state-of-the-art performance.",0
"In recent years, advanced image segmentation algorithms have relied on deep convolutional neural networks. However, these networks require extensive pixel-level annotated data to properly comprehend a concept, which can be both tedious and time-consuming for humans to collect. To address this issue, few-shot segmentation has been proposed, which aims to teach a segmentation model with only a few training images that can be generalized to new classes. In this paper, we present the cross-reference network (CRNet) for few-shot segmentation. Unlike previous models that only predict the mask in the query image, our model simultaneously predicts both the support image and the query image. By utilizing a cross-reference mechanism, our network can better identify co-occurrent objects in the two images, thus improving the few-shot segmentation task. Additionally, we have designed a mask refinement module to repeatedly refine the forecast of the foreground regions. For k-shot learning, we suggest fine-tuning parts of the network to leverage multiple labeled support images. Our experiments on the PASCAL VOC 2012 dataset demonstrate that our network outperforms previous models and achieves state-of-the-art performance.",1
"We present a generalized and scalable method, called Gen-LaneNet, to detect 3D lanes from a single image. The method, inspired by the latest state-of-the-art 3D-LaneNet, is a unified framework solving image encoding, spatial transform of features and 3D lane prediction in a single network. However, we propose unique designs for Gen-LaneNet in two folds. First, we introduce a new geometry-guided lane anchor representation in a new coordinate frame and apply a specific geometric transformation to directly calculate real 3D lane points from the network output. We demonstrate that aligning the lane points with the underlying top-view features in the new coordinate frame is critical towards a generalized method in handling unfamiliar scenes. Second, we present a scalable two-stage framework that decouples the learning of image segmentation subnetwork and geometry encoding subnetwork. Compared to 3D-LaneNet, the proposed Gen-LaneNet drastically reduces the amount of 3D lane labels required to achieve a robust solution in real-world application. Moreover, we release a new synthetic dataset and its construction strategy to encourage the development and evaluation of 3D lane detection methods. In experiments, we conduct extensive ablation study to substantiate the proposed Gen-LaneNet significantly outperforms 3D-LaneNet in average precision(AP) and F-score.",0
"Our article introduces Gen-LaneNet, a method that can detect 3D lanes from a single image in a scalable and generalized way. This approach builds on the latest 3D-LaneNet, but we have made two unique design choices. Firstly, we created a new geometry-guided lane anchor representation in a new coordinate frame that allows us to directly calculate the real 3D lane points from the network output. This is critical in handling unfamiliar scenes. Secondly, we developed a two-stage framework that separates the learning of image segmentation subnetwork and geometry encoding subnetwork, which reduces the need for 3D lane labels in real-world applications. We also provide a new synthetic dataset and construction strategy to encourage the development and evaluation of 3D lane detection methods. Our extensive experiments show that Gen-LaneNet outperforms 3D-LaneNet in both average precision and F-score.",1
"We introduce a one-shot segmentation method to alleviate the burden of manual annotation for medical images. The main idea is to treat one-shot segmentation as a classical atlas-based segmentation problem, where voxel-wise correspondence from the atlas to the unlabelled data is learned. Subsequently, segmentation label of the atlas can be transferred to the unlabelled data with the learned correspondence. However, since ground truth correspondence between images is usually unavailable, the learning system must be well-supervised to avoid mode collapse and convergence failure. To overcome this difficulty, we resort to the forward-backward consistency, which is widely used in correspondence problems, and additionally learn the backward correspondences from the warped atlases back to the original atlas. This cycle-correspondence learning design enables a variety of extra, cycle-consistency-based supervision signals to make the training process stable, while also boost the performance. We demonstrate the superiority of our method over both deep learning-based one-shot segmentation methods and a classical multi-atlas segmentation method via thorough experiments.",0
"We present a method for one-shot segmentation that reduces the need for manual annotation of medical images. Our approach treats one-shot segmentation as a traditional atlas-based segmentation problem, where voxel-wise correspondence is established between the atlas and unlabelled data. This allows the segmentation label of the atlas to be transferred to the unlabelled data using the learned correspondence. However, as ground truth correspondence is typically unavailable, our learning system must be well-supervised to prevent mode collapse and convergence failure. To address this issue, we use forward-backward consistency, a technique commonly used in correspondence problems, and learn backward correspondences from the warped atlases back to the original atlas. This cycle-correspondence learning design provides additional supervision signals that make the training process more stable and improves performance. Our method outperforms both deep learning-based one-shot segmentation approaches and classical multi-atlas segmentation methods, as demonstrated in our experiments.",1
"One usage of medical ultrasound imaging is to visualize and characterize human tongue shape and motion during a real-time speech to study healthy or impaired speech production. Due to the low-contrast characteristic and noisy nature of ultrasound images, it might require expertise for non-expert users to recognize tongue gestures in applications such as visual training of a second language. Moreover, quantitative analysis of tongue motion needs the tongue dorsum contour to be extracted, tracked, and visualized. Manual tongue contour extraction is a cumbersome, subjective, and error-prone task. Furthermore, it is not a feasible solution for real-time applications. The growth of deep learning has been vigorously exploited in various computer vision tasks, including ultrasound tongue contour tracking. In the current methods, the process of tongue contour extraction comprises two steps of image segmentation and post-processing. This paper presents a new novel approach of automatic and real-time tongue contour tracking using deep neural networks. In the proposed method, instead of the two-step procedure, landmarks of the tongue surface are tracked. This novel idea enables researchers in this filed to benefits from available previously annotated databases to achieve high accuracy results. Our experiment disclosed the outstanding performances of the proposed technique in terms of generalization, performance, and accuracy.",0
"Medical ultrasound imaging can be used to visualize and analyze the shape and movements of the human tongue during speech production in real-time, which can aid in studying healthy and impaired speech. However, due to the low-contrast and noisy nature of ultrasound images, recognizing tongue gestures in applications like visual language training can be challenging for non-expert users. Additionally, quantitative analysis requires manual extraction, tracking, and visualization of the tongue dorsum contour, which is a tedious and subjective process that is not suitable for real-time applications. To address these issues, deep learning has been used to develop a new approach for automatic and real-time tongue contour tracking. Instead of the traditional two-step image segmentation and post-processing method, this approach involves tracking the landmarks of the tongue surface, which allows for high-accuracy results and benefits from previously annotated databases. Our experiment revealed exceptional performance and accuracy of this novel technique.",1
"In the literature, many fusion techniques are registered for the segmentation of images, but they primarily focus on observed output or belief score or probability score of the output classes. In the present work, we have utilized inter source statistical dependency among different classifiers for ensembling of different deep learning techniques for semantic segmentation of images. For this purpose, in the present work, a class-wise Copula-based ensembling method is newly proposed for solving the multi-class segmentation problem. Experimentally, it is observed that the performance has improved more for semantic image segmentation using the proposed class-specific Copula function than the traditionally used single Copula function for the problem. The performance is also compared with three state-of-the-art ensembling methods.",0
"Numerous fusion techniques have been documented in the literature for segmenting images, but they mainly concentrate on the observed output, belief score, or probability score of the output classes. In this study, we have employed the statistical dependency among different classifiers to combine multiple deep learning techniques for semantic image segmentation. To achieve this, we have introduced a new class-specific Copula-based ensembling approach to address the multi-class segmentation issue. The experimental results demonstrate that our proposed method outperforms the conventional single Copula function and three state-of-the-art ensembling techniques in enhancing semantic image segmentation performance.",1
"In this paper, we propose deep learning algorithms for ranking response surfaces, with applications to optimal stopping problems in financial mathematics. The problem of ranking response surfaces is motivated by estimating optimal feedback policy maps in stochastic control problems, aiming to efficiently find the index associated to the minimal response across the entire continuous input space $\mathcal{X} \subseteq \mathbb{R}^d$. By considering points in $\mathcal{X}$ as pixels and indices of the minimal surfaces as labels, we recast the problem as an image segmentation problem, which assigns a label to every pixel in an image such that pixels with the same label share certain characteristics. This provides an alternative method for efficiently solving the problem instead of using sequential design in our previous work [R. Hu and M. Ludkovski, SIAM/ASA Journal on Uncertainty Quantification, 5 (2017), 212--239].   Deep learning algorithms are scalable, parallel and model-free, i.e., no parametric assumptions needed on the response surfaces. Considering ranking response surfaces as image segmentation allows one to use a broad class of deep neural networks, e.g., UNet, SegNet, DeconvNet, which have been widely applied and numerically proved to possess high accuracy in the field. We also systematically study the dependence of deep learning algorithms on the input data generated on uniform grids or by sequential design sampling, and observe that the performance of deep learning is {\it not} sensitive to the noise and locations (close to/away from boundaries) of training data. We present a few examples including synthetic ones and the Bermudan option pricing problem to show the efficiency and accuracy of this method.",0
"This paper proposes the use of deep learning algorithms to rank response surfaces and solve optimal stopping problems in financial mathematics. The aim is to efficiently find the index associated with the minimum response across the entire continuous input space $\mathcal{X} \subseteq \mathbb{R}^d$. To achieve this, the problem is recast as an image segmentation problem, where each point in $\mathcal{X}$ is considered as a pixel and the indices of the minimal surfaces are treated as labels. This provides an alternative to the sequential design approach used in previous work. Deep learning algorithms are scalable, parallel, and model-free, making them well-suited for this task. The use of image segmentation allows for the application of a variety of deep neural networks, such as UNet, SegNet, and DeconvNet, which have been shown to be highly accurate. The dependence of deep learning algorithms on input data generated on uniform grids or by sequential design sampling is also studied, and the results show that the performance of deep learning is not affected by the noise or location of the training data. Several examples, including the Bermudan option pricing problem, are presented to illustrate the efficiency and accuracy of this approach.",1
"Learning Enabled Components (LECs) are widely being used in a variety of perception based autonomy tasks like image segmentation, object detection, end-to-end driving, etc. These components are trained with large image datasets with multimodal factors like weather conditions, time-of-day, traffic-density, etc. The LECs learn from these factors during training, and while testing if there is variation in any of these factors, the components get confused resulting in low confidence predictions. The images with factors not seen during training is commonly referred to as Out-of-Distribution (OOD). For safe autonomy it is important to identify the OOD images, so that a suitable mitigation strategy can be performed. Classical one-class classifiers like SVM and SVDD are used to perform OOD detection. However, the multiple labels attached to the images in these datasets, restricts the direct application of these techniques. We address this problem using the latent space of the $\beta$-Variational Autoencoder ($\beta$-VAE). We use the fact that compact latent space generated by an appropriately selected $\beta$-VAE will encode the information about these factors in a few latent variables, and that can be used for computationally inexpensive detection. We evaluate our approach on the nuScenes dataset, and our results shows the latent space of $\beta$-VAE is sensitive to encode changes in the values of the generative factor.",0
"LECs are frequently used in perception-based autonomy tasks such as image segmentation, object detection, and end-to-end driving. These components are trained using large datasets that include various factors such as weather conditions, traffic density, and time-of-day. During training, LECs learn from these factors, and if there is any variation in these factors during testing, the components become confused and produce low-confidence predictions. This is commonly known as Out-of-Distribution (OOD) images, which need to be identified for safe autonomy. To tackle this problem, we use the latent space of the $\beta$-VAE, which encodes information about these factors in a few latent variables. We evaluate our approach on the nuScenes dataset and find that the latent space of $\beta$-VAE is sensitive to changes in the generative factor values. Although classical one-class classifiers like SVM and SVDD are typically used for OOD detection, the multiple labels attached to the images in these datasets make it difficult to apply these techniques directly.",1
"For proper generalization performance of convolutional neural networks (CNNs) in medical image segmentation, the learnt features should be invariant under particular non-linear shape variations of the input. To induce invariance in CNNs to such transformations, we propose Probabilistic Augmentation of Data using Diffeomorphic Image Transformation (PADDIT) -- a systematic framework for generating realistic transformations that can be used to augment data for training CNNs. We show that CNNs trained with PADDIT outperforms CNNs trained without augmentation and with generic augmentation in segmenting white matter hyperintensities from T1 and FLAIR brain MRI scans.",0
"In order to ensure the convolutional neural networks (CNNs) used for medical image segmentation have reliable generalization capabilities, it is crucial that the features they learn are not affected by specific non-linear variations in the input's shape. To address this issue and improve the CNNs' invariance to such transformations, we present a systematic approach called Probabilistic Augmentation of Data using Diffeomorphic Image Transformation (PADDIT), which generates realistic transformations to augment training data. Our results demonstrate that CNNs trained with PADDIT outperform those trained without augmentation or with generic augmentation when it comes to segmenting white matter hyperintensities in T1 and FLAIR brain MRI scans.",1
"Boosting is a method for learning a single accurate predictor by linearly combining a set of less accurate weak learners. Recently, structured learning has found many applications in computer vision. Inspired by structured support vector machines (SSVM), here we propose a new boosting algorithm for structured output prediction, which we refer to as StructBoost. StructBoost supports nonlinear structured learning by combining a set of weak structured learners. As SSVM generalizes SVM, our StructBoost generalizes standard boosting approaches such as AdaBoost, or LPBoost to structured learning. The resulting optimization problem of StructBoost is more challenging than SSVM in the sense that it may involve exponentially many variables and constraints. In contrast, for SSVM one usually has an exponential number of constraints and a cutting-plane method is used. In order to efficiently solve StructBoost, we formulate an equivalent $ 1 $-slack formulation and solve it using a combination of cutting planes and column generation. We show the versatility and usefulness of StructBoost on a range of problems such as optimizing the tree loss for hierarchical multi-class classification, optimizing the Pascal overlap criterion for robust visual tracking and learning conditional random field parameters for image segmentation.",0
"Boosting is a technique used to create a precise predictor by combining a group of weak learners. Recently, structured learning has been widely applied in computer vision. Our proposed boosting algorithm for structured output prediction, called StructBoost, is inspired by structured support vector machines (SSVM). StructBoost allows for nonlinear structured learning by combining weak structured learners. This approach generalizes standard boosting methods, such as AdaBoost or LPBoost, to structured learning. However, the optimization problem for StructBoost is more complex than that of SSVM because it may involve a large number of variables and constraints. In contrast, SSVM typically has an exponential number of constraints and uses a cutting-plane method. To efficiently solve StructBoost, we use a 1-slack formulation and a combination of cutting planes and column generation. We demonstrate the versatility and effectiveness of StructBoost in optimizing tree loss for hierarchical multi-class classification, Pascal overlap criterion for visual tracking, and learning conditional random field parameters for image segmentation.",1
"Fine-grained annotations---e.g. dense image labels, image segmentation and text tagging---are useful in many ML applications but they are labor-intensive to generate. Moreover there are often systematic, structured errors in these fine-grained annotations. For example, a car might be entirely unannotated in the image, or the boundary between a car and street might only be coarsely annotated. Standard ML training on data with such structured errors produces models with biases and poor performance. In this work, we propose a novel framework of Error-Correcting Networks (ECN) to address the challenge of learning in the presence structured error in fine-grained annotations. Given a large noisy dataset with commonly occurring structured errors, and a much smaller dataset with more accurate annotations, ECN is able to substantially improve the prediction of fine-grained annotations compared to standard approaches for training on noisy data. It does so by learning to leverage the structures in the annotations and in the noisy labels. Systematic experiments on image segmentation and text tagging demonstrate the strong performance of ECN in improving training on noisy structured labels.",0
"The generation of fine-grained annotations, such as dense image labels, image segmentation, and text tagging, can be beneficial for various ML applications. However, the process of creating such annotations is laborious and error-prone. In fine-grained annotations, there can be systematic and structured errors, such as missing annotations or imprecise boundaries. Training ML models on data with such errors can result in biases and poor performance. To overcome this challenge, we propose a new framework called Error-Correcting Networks (ECN). By leveraging the structures in both accurate and noisy annotations, ECN can significantly enhance the prediction of fine-grained annotations. Our experiments on image segmentation and text tagging demonstrate the superior performance of ECN in dealing with noisy structured labels and improving training outcomes.",1
"Usually, Neural Networks models are trained with a large dataset of images in homogeneous backgrounds. The issue is that the performance of the network models trained could be significantly degraded in a complex and heterogeneous environment. To mitigate the issue, this paper develops a framework that permits to autonomously generate a training dataset in heterogeneous cluttered backgrounds. It is clear that the learning effectiveness of the proposed framework should be improved in complex and heterogeneous environments, compared with the ones with the typical dataset. In our framework, a state-of-the-art image segmentation technique called DeepLab is used to extract objects of interest from a picture and Chroma-key technique is then used to merge the extracted objects of interest into specific heterogeneous backgrounds. The performance of the proposed framework is investigated through empirical tests and compared with that of the model trained with the COCO dataset. The results show that the proposed framework outperforms the model compared. This implies that the learning effectiveness of the framework developed is superior to the models with the typical dataset.",0
"Neural Network models are typically trained using a large dataset of images featuring uniform backgrounds; however, in complex and diverse environments, the performance of these models may suffer. To address this issue, this paper presents a framework for generating a training dataset with diverse backgrounds and cluttered environments. This framework utilizes the DeepLab image segmentation technique to extract objects of interest from an image, which are then merged into heterogeneous backgrounds using the Chroma-key technique. Our empirical tests demonstrate that this framework outperforms models trained using the COCO dataset, indicating that it is more effective in complex and diverse environments. Therefore, the proposed framework offers superior learning effectiveness compared to models trained with a typical dataset.",1
"Convolutional neural networks have become state-of-the-art in a wide range of image recognition tasks. The interpretation of their predictions, however, is an active area of research. Whereas various interpretation methods have been suggested for image classification, the interpretation of image segmentation still remains largely unexplored. To that end, we propose SEG-GRAD-CAM, a gradient-based method for interpreting semantic segmentation. Our method is an extension of the widely-used Grad-CAM method, applied locally to produce heatmaps showing the relevance of individual pixels for semantic segmentation.",0
"A broad array of image recognition tasks has seen convolutional neural networks emerge as the leading technology. However, interpreting the outcomes of these networks remains an ongoing subject of study. Image classification interpretation methods have been suggested, but image segmentation interpretation is still largely uncharted territory. To address this, we have developed SEG-GRAD-CAM, a gradient-based approach to interpreting semantic segmentation. Our method is a localized extension of the popular Grad-CAM method, which generates heatmaps indicating the significance of individual pixels for semantic segmentation.",1
"Building a large image dataset with high-quality object masks for semantic segmentation is costly and time consuming. In this paper, we introduce a principled semi-supervised framework that only uses a small set of fully supervised images (having semantic segmentation labels and box labels) and a set of images with only object bounding box labels (we call it the weak set). Our framework trains the primary segmentation model with the aid of an ancillary model that generates initial segmentation labels for the weak set and a self-correction module that improves the generated labels during training using the increasingly accurate primary model. We introduce two variants of the self-correction module using either linear or convolutional functions. Experiments on the PASCAL VOC 2012 and Cityscape datasets show that our models trained with a small fully supervised set perform similar to, or better than, models trained with a large fully supervised set while requiring ~7x less annotation effort.",0
"The process of creating a large image dataset with high-quality object masks for semantic segmentation is both expensive and time-consuming. This article presents a semi-supervised approach that uses a small number of fully supervised images (which have both semantic segmentation labels and box labels) and a group of images with only object bounding box labels, called the weak set. Our framework trains the primary segmentation model with the help of an ancillary model that generates initial segmentation labels for the weak set and a self-correction module. This module improves the generated labels using the increasingly accurate primary model during training. We introduce two variations of the self-correction module using linear or convolutional functions. Our experiments on the PASCAL VOC 2012 and Cityscape datasets show that our models trained with a small fully supervised set perform similarly to or better than models trained with a large fully supervised set while requiring ~7x less annotation effort.",1
"Until now, all single level segmentation algorithms except CNN-based ones lead to over segmentation. And CNN-based segmentation algorithms have their own problems. To avoid over segmentation, multiple thresholds of criteria are adopted in region merging process to produce hierarchical segmentation results. However, there still has extreme over segmentation in the low level of the hierarchy, and outstanding tiny objects are merged to their large adjacencies in the high level of the hierarchy. This paper proposes a region-merging-based image segmentation method that we call it Dam Burst. As a single level segmentation algorithm, this method avoids over segmentation and retains details by the same time. It is named because of that it simulates a flooding from underground destroys dams between water-pools. We treat edge detection results as strengthening structure of a dam if it is on the dam. To simulate a flooding from underground, regions are merged by ascending order of the average gra-dient inside the region.",0
"Previously, all single level segmentation algorithms, excluding CNN-based ones, resulted in over segmentation. However, CNN-based segmentation algorithms also have their own set of issues. To address this problem, multiple thresholds of criteria are utilized in the region merging process, which produces hierarchical segmentation outcomes. Despite this, there is still a considerable amount of over segmentation in the lower levels of the hierarchy, while small objects are merged with larger adjacent objects in the higher levels of the hierarchy. In this paper, we propose a novel region-merging-based image segmentation approach called Dam Burst, which is a single level segmentation algorithm that prevents over segmentation while preserving details. The name Dam Burst is derived from the idea that it mimics the flooding that occurs when dams between water-pools are destroyed from underground. We consider edge detection results as a strengthening structure of a dam if it is located on the dam. To simulate underground flooding, regions are merged based on the ascending order of the average gradient within the region.",1
"Convolutional neural networks (CNNs) have been successfully applied to medical image classification, segmentation, and related tasks. Among the many CNNs architectures, U-Net and its improved versions based are widely used and achieve state-of-the-art performance these years. These improved architectures focus on structural improvements and the size of the convolution kernel is generally fixed. In this paper, we propose a module that combines the benefits of multiple kernel sizes and we apply the proposed module to U-Net and its variants. We test our module on three segmentation benchmark datasets and experimental results show significant improvement.",0
"Medical image classification, segmentation, and related tasks have seen successful application of Convolutional neural networks (CNNs). U-Net and its enhanced versions have been extensively used among various CNN architectures and have achieved state-of-the-art performance in recent years. These improved architectures mainly concentrate on structural enhancements with a fixed size of the convolution kernel. We introduce a module that integrates the advantages of multiple kernel sizes and apply it to U-Net and its variations in this study. We evaluate our module on three segmentation benchmark datasets and observe a substantial improvement in experimental outcomes.",1
"Image segmentation is a fundamental research topic in image processing and computer vision. In the last decades, researchers developed a large number of segmentation algorithms for various applications. Amongst these algorithms, the Normalized cut (Ncut) segmentation method is widely applied due to its good performance. The Ncut segmentation model is an optimization problem whose energy is defined on a specifically designed graph. Thus, the segmentation results of the existing Ncut method are largely dependent on a pre-constructed similarity measure on the graph since this measure is usually given empirically by users. This flaw will lead to some undesirable segmentation results. In this paper, we propose a Ncut-based segmentation algorithm by integrating an adaptive similarity measure and spatial regularization. The proposed model combines the Parzen-Rosenblatt window method, non-local weights entropy, Ncut energy, and regularizer of phase field in a variational framework. Our method can adaptively update the similarity measure function by estimating some parameters. This adaptive procedure enables the proposed algorithm finding a better similarity measure for classification than the Ncut method. We provide some mathematical interpretation of the proposed adaptive similarity from multi-viewpoints such as statistics and convex optimization. In addition, the regularizer of phase field can guarantee that the proposed algorithm has a robust performance in the presence of noise, and it can also rectify the similarity measure with a spatial priori. The well-posed theory such as the existence of the minimizer for the proposed model is given in the paper. Compared with some existing segmentation methods such as the traditional Ncut-based model and the classical Chan-Vese model, the numerical experiments show that our method can provide promising segmentation results.",0
"Image segmentation is a crucial area of study in computer vision and image processing. Over the years, numerous segmentation algorithms have been developed to cater to various applications. The Normalized cut (Ncut) segmentation method is widely used due to its excellent performance among these algorithms. However, the existing Ncut method's segmentation results depend heavily on a pre-constructed similarity measure on the graph, which is usually provided by users. This dependence can lead to undesirable segmentation results. To address this flaw, we propose a Ncut-based segmentation algorithm that integrates an adaptive similarity measure and spatial regularization. Our approach combines the Parzen-Rosenblatt window method, non-local weights entropy, Ncut energy, and regularizer of phase field in a variational framework. The proposed algorithm can adaptively update the similarity measure function by estimating parameters, which enables it to find a better similarity measure for classification than the Ncut method. We provide a mathematical interpretation of the proposed adaptive similarity measure from multi-viewpoints such as statistics and convex optimization. Our algorithm's regularizer of phase field ensures robust performance in the presence of noise and can rectify the similarity measure with a spatial priori. We also provide a well-posed theory, including the existence of the minimizer for the proposed model in the paper. Our numerical experiments show that our method outperforms existing segmentation methods such as the traditional Ncut-based model and the classical Chan-Vese model and provides promising segmentation results.",1
"While making a tremendous impact in various fields, deep neural networks usually require large amounts of labeled data for training which are expensive to collect in many applications, especially in the medical domain. Unlabeled data, on the other hand, is much more abundant. Semi-supervised learning techniques, such as co-training, could provide a powerful tool to leverage unlabeled data. In this paper, we propose a novel framework, uncertainty-aware multi-view co-training (UMCT), to address semi-supervised learning on 3D data, such as volumetric data from medical imaging. In our work, co-training is achieved by exploiting multi-viewpoint consistency of 3D data. We generate different views by rotating or permuting the 3D data and utilize asymmetrical 3D kernels to encourage diversified features in different sub-networks. In addition, we propose an uncertainty-weighted label fusion mechanism to estimate the reliability of each view's prediction with Bayesian deep learning. As one view requires the supervision from other views in co-training, our self-adaptive approach computes a confidence score for the prediction of each unlabeled sample in order to assign a reliable pseudo label. Thus, our approach can take advantage of unlabeled data during training. We show the effectiveness of our proposed semi-supervised method on several public datasets from medical image segmentation tasks (NIH pancreas & LiTS liver tumor dataset). Meanwhile, a fully-supervised method based on our approach achieved state-of-the-art performances on both the LiTS liver tumor segmentation and the Medical Segmentation Decathlon (MSD) challenge, demonstrating the robustness and value of our framework, even when fully supervised training is feasible.",0
"Deep neural networks have had a significant impact across various fields, but they typically require large amounts of labeled data for training, which can be costly and difficult to obtain in certain applications, such as in the medical field. In contrast, unlabeled data is more abundant. To address this issue, semi-supervised learning techniques, like co-training, can leverage unlabeled data. This paper proposes a new framework called uncertainty-aware multi-view co-training (UMCT) that focuses on semi-supervised learning for 3D data, specifically volumetric data from medical imaging. UMCT utilizes co-training by exploiting the multi-viewpoint consistency of 3D data. This is achieved by generating various views through 3D data rotation or permutation, and using asymmetrical 3D kernels to encourage diversified features in different sub-networks. Additionally, UMCT proposes an uncertainty-weighted label fusion mechanism to estimate the reliability of each view's prediction using Bayesian deep learning. As each view requires supervision from other views in co-training, UMCT uses a self-adaptive approach to compute a confidence score for the prediction of each unlabeled sample to assign a reliable pseudo label. This allows UMCT to take advantage of unlabeled data during training. The proposed semi-supervised method is effective on several public datasets for medical image segmentation tasks, such as the NIH pancreas and LiTS liver tumor dataset. Additionally, a fully-supervised method based on UMCT achieved state-of-the-art performances on both the LiTS liver tumor segmentation and the Medical Segmentation Decathlon (MSD) challenge, demonstrating the robustness and value of the framework even when fully supervised training is feasible.",1
"Accurate medical image segmentation commonly requires effective learning of the complementary information from multimodal data. However, in clinical practice, we often encounter the problem of missing imaging modalities. We tackle this challenge and propose a novel multimodal segmentation framework which is robust to the absence of imaging modalities. Our network uses feature disentanglement to decompose the input modalities into the modality-specific appearance code, which uniquely sticks to each modality, and the modality-invariant content code, which absorbs multimodal information for the segmentation task. With enhanced modality-invariance, the disentangled content code from each modality is fused into a shared representation which gains robustness to missing data. The fusion is achieved via a learning-based strategy to gate the contribution of different modalities at different locations. We validate our method on the important yet challenging multimodal brain tumor segmentation task with the BRATS challenge dataset. With competitive performance to the state-of-the-art approaches for full modality, our method achieves outstanding robustness under various missing modality(ies) situations, significantly exceeding the state-of-the-art method by over 16% in average for Dice on whole tumor segmentation.",0
"In order to accurately segment medical images, it is important to learn from multiple sources of data. However, in clinical settings, we often face the issue of missing imaging sources. To address this problem, we propose a new framework for multimodal segmentation that is able to handle the absence of certain imaging sources. Our network uses a feature disentanglement method to separate the input modalities into appearance codes (which are unique to each modality) and content codes (which absorb information from multiple modalities for segmentation purposes). By increasing modality-invariance, the disentangled content codes from each modality are fused into a shared representation that is more robust to missing data. This fusion is achieved via a learning-based strategy that gates the contribution of different modalities at different locations. We tested our method on the challenging task of brain tumor segmentation using the BRATS challenge dataset. Our method achieved competitive performance compared to state-of-the-art approaches for full modality, and demonstrated outstanding robustness under various missing modality situations, surpassing the state-of-the-art method by over 16% on average for whole tumor segmentation.",1
"Despite recent progress on semantic segmentation, there still exist huge challenges in medical ultra-resolution image segmentation. The methods based on multi-branch structure can make a good balance between computational burdens and segmentation accuracy. However, the fusion structure in these methods require to be designed elaborately to achieve desirable result, which leads to model redundancy. In this paper, we propose Meta Segmentation Network (MSN) to solve this challenging problem. With the help of meta-learning, the fusion module of MSN is quite simple but effective. MSN can fast generate the weights of fusion layers through a simple meta-learner, requiring only a few training samples and epochs to converge. In addition, to avoid learning all branches from scratch, we further introduce a particular weight sharing mechanism to realize a fast knowledge adaptation and share the weights among multiple branches, resulting in the performance improvement and significant parameters reduction. The experimental results on two challenging ultra-resolution medical datasets BACH and ISIC show that MSN achieves the best performance compared with the state-of-the-art methods.",0
"Although there have been recent advancements in semantic segmentation, the medical ultra-resolution image segmentation still poses substantial challenges. Multi-branch structure methods can maintain an equilibrium between computational burdens and segmentation accuracy. Nevertheless, the fusion structure in these methods necessitates a meticulous design to produce desirable outcomes, leading to model redundancy. This paper proposes the Meta Segmentation Network (MSN) to address this challenge. With the assistance of meta-learning, the fusion module of MSN is uncomplicated yet effective. MSN can rapidly generate fusion layer weights through a simple meta-learner, demanding only a few training samples and epochs to converge. Furthermore, to evade learning all branches from scratch, a specific weight sharing mechanism is introduced to achieve quick knowledge adaptation and weight sharing among multiple branches, leading to performance enhancement and significant parameter reduction. The experimental results on two challenging ultra-resolution medical datasets BACH and ISIC demonstrate that MSN outperforms state-of-the-art methods.",1
"Deep learning has shown its great promise in various biomedical image segmentation tasks. Existing models are typically based on U-Net and rely on an encoder-decoder architecture with stacked local operators to aggregate long-range information gradually. However, only using the local operators limits the efficiency and effectiveness. In this work, we propose the non-local U-Nets, which are equipped with flexible global aggregation blocks, for biomedical image segmentation. These blocks can be inserted into U-Net as size-preserving processes, as well as down-sampling and up-sampling layers. We perform thorough experiments on the 3D multimodality isointense infant brain MR image segmentation task to evaluate the non-local U-Nets. Results show that our proposed models achieve top performances with fewer parameters and faster computation.",0
"Various biomedical image segmentation tasks have benefited greatly from deep learning. The current models primarily rely on U-Net and an encoder-decoder architecture with stacked local operators to gradually aggregate long-range information. However, such models' limited efficiency and effectiveness prompted us to introduce non-local U-Nets. These include flexible global aggregation blocks that can be used as size-preserving processes, down-sampling, and up-sampling layers. We tested the non-local U-Nets on the 3D multimodality isointense infant brain MR image segmentation task and found that they performed exceptionally well. The proposed models achieved top performance with fewer parameters and faster computation.",1
"Arbitrary style transfer is the task of synthesis of an image that has never been seen before, using two given images: content image and style image. The content image forms the structure, the basic geometric lines and shapes of the resulting image, while the style image sets the color and texture of the result. The word ""arbitrary"" in this context means the absence of any one pre-learned style. So, for example, convolutional neural networks capable of transferring a new style only after training or retraining on a new amount of data are not con-sidered to solve such a problem, while networks based on the attention mech-anism that are capable of performing such a transformation without retraining - yes. An original image can be, for example, a photograph, and a style image can be a painting of a famous artist. The resulting image in this case will be the scene depicted in the original photograph, made in the stylie of this picture. Recent arbitrary style transfer algorithms make it possible to achieve good re-sults in this task, however, in processing portrait images of people, the result of such algorithms is either unacceptable due to excessive distortion of facial features, or weakly expressed, not bearing the characteristic features of a style image. In this paper, we consider an approach to solving this problem using the combined architecture of deep neural networks with a attention mechanism that transfers style based on the contents of a particular image segment: with a clear predominance of style over the form for the background part of the im-age, and with the prevalence of content over the form in the image part con-taining directly the image of a person.",0
"Arbitrary style transfer involves creating a new image by combining a content image and a style image. The content image determines the structure of the resulting image, while the style image determines the color and texture. The term ""arbitrary"" means that there is no pre-learned style involved. For example, networks that can transfer a new style without retraining using an attention mechanism are considered to solve this problem, while those that require training or retraining are not. The resulting image can be a scene from a photograph made in the style of a painting. However, current algorithms struggle with portrait images, either distorting facial features or producing weak results. This paper proposes a solution using a deep neural network with an attention mechanism that transfers style based on image segments, emphasizing style for the background and content for the person in the image.",1
"Complex classification performance metrics such as the F${}_\beta$-measure and Jaccard index are often used, in order to handle class-imbalanced cases such as information retrieval and image segmentation. These performance metrics are not decomposable, that is, they cannot be expressed in a per-example manner, which hinders a straightforward application of M-estimation widely used in supervised learning. In this paper, we consider linear-fractional metrics, which are a family of classification performance metrics that encompasses many standard ones such as the F${}_\beta$-measure and Jaccard index, and propose methods to directly maximize performances under those metrics. A clue to tackle their direct optimization is a calibrated surrogate utility, which is a tractable lower bound of the true utility function representing a given metric. We characterize sufficient conditions which make the surrogate maximization coincide with the maximization of the true utility. Simulation results on benchmark datasets validate the effectiveness of our calibrated surrogate maximization especially if the sample sizes are extremely small.",0
"In order to handle class-imbalanced cases like information retrieval and image segmentation, complex classification performance metrics such as the F${}_\beta$-measure and Jaccard index are commonly used. However, these metrics cannot be expressed in a per-example manner, which makes it difficult to apply M-estimation that is widely used in supervised learning. This paper proposes a solution by considering linear-fractional metrics, a family of classification performance metrics that includes standard ones like the F${}_\beta$-measure and Jaccard index. We suggest methods to maximize performances under these metrics, using a calibrated surrogate utility as a clue to tackle their direct optimization. This surrogate utility is a tractable lower bound of the true utility function representing a given metric. We also identify sufficient conditions which make the surrogate maximization coincide with the maximization of the true utility. Simulation results on benchmark datasets confirm the effectiveness of our calibrated surrogate maximization, particularly when the sample sizes are very small.",1
"We present a new method for efficient high-quality image segmentation of objects and scenes. By analogizing classical computer graphics methods for efficient rendering with over- and undersampling challenges faced in pixel labeling tasks, we develop a unique perspective of image segmentation as a rendering problem. From this vantage, we present the PointRend (Point-based Rendering) neural network module: a module that performs point-based segmentation predictions at adaptively selected locations based on an iterative subdivision algorithm. PointRend can be flexibly applied to both instance and semantic segmentation tasks by building on top of existing state-of-the-art models. While many concrete implementations of the general idea are possible, we show that a simple design already achieves excellent results. Qualitatively, PointRend outputs crisp object boundaries in regions that are over-smoothed by previous methods. Quantitatively, PointRend yields significant gains on COCO and Cityscapes, for both instance and semantic segmentation. PointRend's efficiency enables output resolutions that are otherwise impractical in terms of memory or computation compared to existing approaches. Code has been made available at https://github.com/facebookresearch/detectron2/tree/master/projects/PointRend.",0
"We have developed a new method for the effective and high-quality segmentation of images depicting objects and scenes. Our approach draws inspiration from classical computer graphics techniques that are used for efficient rendering, and we have applied this to overcome the challenges of over- and undersampling in pixel labeling tasks. By viewing image segmentation as a rendering problem, we have created the PointRend (Point-based Rendering) neural network module, which performs segmentations at adaptively selected locations based on an iterative subdivision algorithm. PointRend can be used for instance and semantic segmentation tasks and can be incorporated into state-of-the-art models. Despite its simplicity, PointRend produces outstanding results, with sharp object boundaries and significant improvements in precision for instance and semantic segmentation on COCO and Cityscapes datasets. PointRend's efficiency allows for output resolutions that would otherwise be impractical in terms of memory or computation compared to alternative approaches. Code for PointRend is available at https://github.com/facebookresearch/detectron2/tree/master/projects/PointRend.",1
"Learning-based approaches for semantic segmentation have two inherent challenges. First, acquiring pixel-wise labels is expensive and time-consuming. Second, realistic segmentation datasets are highly unbalanced: some categories are much more abundant than others, biasing the performance to the most represented ones. In this paper, we are interested in focusing human labelling effort on a small subset of a larger pool of data, minimizing this effort while maximizing performance of a segmentation model on a hold-out set. We present a new active learning strategy for semantic segmentation based on deep reinforcement learning (RL). An agent learns a policy to select a subset of small informative image regions -- opposed to entire images -- to be labeled, from a pool of unlabeled data. The region selection decision is made based on predictions and uncertainties of the segmentation model being trained. Our method proposes a new modification of the deep Q-network (DQN) formulation for active learning, adapting it to the large-scale nature of semantic segmentation problems. We test the proof of concept in CamVid and provide results in the large-scale dataset Cityscapes. On Cityscapes, our deep RL region-based DQN approach requires roughly 30% less additional labeled data than our most competitive baseline to reach the same performance. Moreover, we find that our method asks for more labels of under-represented categories compared to the baselines, improving their performance and helping to mitigate class imbalance.",0
"The use of learning-based methods for semantic segmentation presents two major challenges. Firstly, obtaining pixel-wise labels is a time-consuming and costly process. Secondly, the available segmentation datasets are imbalanced, with some categories being more prevalent than others, leading to biased performance towards the over-represented categories. This study aims to reduce human labelling effort while maximizing segmentation model performance on a hold-out set by focusing on a small subset of a larger pool of data. A new approach based on deep reinforcement learning (RL) is proposed, where an agent learns a policy to select informative image regions instead of entire images for labelling. The deep Q-network (DQN) formulation for active learning is modified to suit large-scale semantic segmentation problems. The proof of concept is tested in CamVid and Cityscapes, with results showing that the RL region-based DQN approach requires 30% less additional labeled data than the most competitive baseline to achieve the same performance. Additionally, the proposed method requests more labels for under-represented categories, thereby improving their performance and reducing class imbalance.",1
"Even though convolutional neural networks (CNNs) are driving progress in medical image segmentation, standard models still have some drawbacks. First, the use of multi-scale approaches, i.e., encoder-decoder architectures, leads to a redundant use of information, where similar low-level features are extracted multiple times at multiple scales. Second, long-range feature dependencies are not efficiently modeled, resulting in non-optimal discriminative feature representations associated with each semantic class. In this paper we attempt to overcome these limitations with the proposed architecture, by capturing richer contextual dependencies based on the use of guided self-attention mechanisms. This approach is able to integrate local features with their corresponding global dependencies, as well as highlight interdependent channel maps in an adaptive manner. Further, the additional loss between different modules guides the attention mechanisms to neglect irrelevant information and focus on more discriminant regions of the image by emphasizing relevant feature associations. We evaluate the proposed model in the context of semantic segmentation on three different datasets: abdominal organs, cardiovascular structures and brain tumors. A series of ablation experiments support the importance of these attention modules in the proposed architecture. In addition, compared to other state-of-the-art segmentation networks our model yields better segmentation performance, increasing the accuracy of the predictions while reducing the standard deviation. This demonstrates the efficiency of our approach to generate precise and reliable automatic segmentations of medical images. Our code is made publicly available at https://github.com/sinAshish/Multi-Scale-Attention",0
"While convolutional neural networks (CNNs) have advanced medical image segmentation, standard models have limitations. Firstly, the use of multi-scale approaches leads to redundant extraction of similar low-level features at multiple scales. Secondly, long-range feature dependencies are not efficiently modeled, resulting in non-optimal discriminative feature representations. To address these limitations, this paper proposes an architecture that captures richer contextual dependencies using guided self-attention mechanisms. This approach integrates local features with their corresponding global dependencies and highlights interdependent channel maps adaptively. The proposed model is evaluated on three different datasets and compared to other state-of-the-art segmentation networks. Results demonstrate better segmentation performance, increasing prediction accuracy and reducing standard deviation. Our approach generates precise and reliable automatic segmentations of medical images, and the code is publicly available at https://github.com/sinAshish/Multi-Scale-Attention.",1
"Particle competition and cooperation (PCC) is a graph-based semi-supervised learning approach. When PCC is applied to interactive image segmentation tasks, pixels are converted into network nodes, and each node is connected to its k-nearest neighbors, according to the distance between a set of features extracted from the image. Building a proper network to feed PCC is crucial to achieve good segmentation results. However, some features may be more important than others to identify the segments, depending on the characteristics of the image to be segmented. In this paper, an index to evaluate candidate networks is proposed. Thus, building the network becomes a problem of optimizing some feature weights based on the proposed index. Computer simulations are performed on some real-world images from the Microsoft GrabCut database, and the segmentation results related in this paper show the effectiveness of the proposed method.",0
"The approach known as Particle Competition and Cooperation (PCC) is a type of semi-supervised learning that relies on graphs. When applied to interactive image segmentation tasks, PCC converts pixels into network nodes and connects each node to its k-nearest neighbors based on feature distance extracted from the image. Creating an appropriate network for PCC is essential to achieve accurate segmentation outcomes, but certain features may be more critical in identifying segments depending on the image's properties. This study introduces an index to assess candidate networks, making network construction a matter of optimizing feature weights based on the proposed metric. The paper presents computer simulations using actual images from the Microsoft GrabCut database, and the segmentation results demonstrate the effectiveness of the proposed method.",1
"Instead of directly utilizing an observed image including some outliers, noise or intensity inhomogeneity, the use of its ideal value (e.g. noise-free image) has a favorable impact on clustering. Hence, the accurate estimation of the residual (e.g. unknown noise) between the observed image and its ideal value is an important task. To do so, we propose an $\ell_0$ regularization-based Fuzzy $C$-Means (FCM) algorithm incorporating a morphological reconstruction operation and a tight wavelet frame transform. To achieve a sound trade-off between detail preservation and noise suppression, morphological reconstruction is used to filter an observed image. By combining the observed and filtered images, a weighted sum image is generated. Since a tight wavelet frame system has sparse representations of an image, it is employed to decompose the weighted sum image, thus forming its corresponding feature set. Taking it as data for clustering, we present an improved FCM algorithm by imposing an $\ell_0$ regularization term on the residual between the feature set and its ideal value, which implies that the favorable estimation of the residual is obtained and the ideal value participates in clustering. Spatial information is also introduced into clustering since it is naturally encountered in image segmentation. Furthermore, it makes the estimation of the residual more reliable. To further enhance the segmentation effects of the improved FCM algorithm, we also employ the morphological reconstruction to smoothen the labels generated by clustering. Finally, based on the prototypes and smoothed labels, the segmented image is reconstructed by using a tight wavelet frame reconstruction operation. Experimental results reported for synthetic, medical, and color images show that the proposed algorithm is effective and efficient, and outperforms other algorithms.",0
"Clustering can be improved by using an ideal value of an observed image, such as a noise-free image, instead of directly using the observed image with outliers, noise, or intensity inhomogeneity. However, accurately estimating the residual between the observed image and its ideal value is important. To accomplish this, we propose a Fuzzy C-Means algorithm incorporating an $\ell_0$ regularization, morphological reconstruction, and a tight wavelet frame transform. Morphological reconstruction is used to filter the observed image and generate a weighted sum image, which is then decomposed using a tight wavelet frame system to form a feature set for clustering. The improved FCM algorithm imposes an $\ell_0$ regularization on the residual between the feature set and its ideal value to obtain a favorable estimation of the residual and include the ideal value in clustering. Spatial information is also introduced to enhance the clustering results. Morphological reconstruction is also used to smooth the labels generated by clustering, and the segmented image is reconstructed using a tight wavelet frame reconstruction operation. Experimental results demonstrate the effectiveness and efficiency of our proposed algorithm for synthetic, medical, and color images, outperforming other algorithms.",1
"Accurate image segmentation of the liver is a challenging problem owing to its large shape variability and unclear boundaries. Although the applications of fully convolutional neural networks (CNNs) have shown groundbreaking results, limited studies have focused on the performance of generalization. In this study, we introduce a CNN for liver segmentation on abdominal computed tomography (CT) images that shows high generalization performance and accuracy. To improve the generalization performance, we initially propose an auto-context algorithm in a single CNN. The proposed auto-context neural network exploits an effective high-level residual estimation to obtain the shape prior. Identical dual paths are effectively trained to represent mutual complementary features for an accurate posterior analysis of a liver. Further, we extend our network by employing a self-supervised contour scheme. We trained sparse contour features by penalizing the ground-truth contour to focus more contour attentions on the failures. The experimental results show that the proposed network results in better accuracy when compared to the state-of-the-art networks by reducing 10.31% of the Hausdorff distance. We used 180 abdominal CT images for training and validation. Two-fold cross-validation is presented for a comparison with the state-of-the-art neural networks. Novel multiple N-fold cross-validations are conducted to verify the performance of generalization. The proposed network showed the best generalization performance among the networks. Additionally, we present a series of ablation experiments that comprehensively support the importance of the underlying concepts.",0
"The liver is a challenging organ to accurately segment in medical images due to its variable shape and unclear boundaries. Although fully convolutional neural networks have had groundbreaking results in liver segmentation, few studies have focused on generalization performance. In this study, we introduce a CNN that achieves high generalization performance and accuracy in liver segmentation on abdominal CT images. To improve generalization, we propose an auto-context algorithm that uses high-level residual estimation to obtain shape prior. Identical dual paths are trained to represent complementary features for accurate posterior analysis. We also use a self-supervised contour scheme to train sparse contour features and focus more attention on failures. Our experimental results show better accuracy than state-of-the-art networks, reducing the Hausdorff distance by 10.31%. We train and validate on 180 CT images and use two-fold cross-validation for comparison. Multiple N-fold cross-validations confirm our network's superior generalization performance. Ablation experiments support the importance of our proposed concepts.",1
"Measuring similarity between two objects is the core operation in existing cluster analyses in grouping similar objects into clusters. Cluster analyses have been applied to a number of applications, including image segmentation, social network analysis, and computational biology. This paper introduces a new similarity measure called point-set kernel which computes the similarity between an object and a sample of objects generated from an unknown distribution. The proposed clustering procedure utilizes this new measure to characterize both the typical point of every cluster and the cluster grown from the typical point. We show that the new clustering procedure is both effective and efficient such that it can deal with large scale datasets. In contrast, existing clustering algorithms are either efficient or effective; and even efficient ones have difficulty dealing with large scale datasets without special hardware. We show that the proposed algorithm is more effective and runs orders of magnitude faster than the state-of-the-art density-peak clustering and scalable kernel k-means clustering when applying to datasets of millions of data points, on commonly used computing machines.",0
"The central operation in cluster analyses is to measure the similarity between two objects, which groups similar objects into clusters. A variety of applications, such as image segmentation, social network analysis, and computational biology, have utilized cluster analyses. This study presents a novel similarity measure, called point-set kernel, that calculates the similarity between an object and a sample of objects from an unknown distribution. Using this measure, the proposed clustering procedure characterizes both the typical point of each cluster and the cluster grown from the typical point. The study demonstrates that this new clustering method is both efficient and effective, particularly for large-scale datasets. In contrast, other clustering algorithms are either efficient or effective, and even efficient ones struggle with large datasets without specialized hardware. The study shows that the proposed algorithm is more effective and runs significantly faster than the density-peak clustering and scalable kernel k-means clustering, which are currently state-of-the-art, when applied to datasets containing millions of data points on standard computing machines.",1
"Many interactive image segmentation techniques are based on semi-supervised learning. The user may label some pixels from each object and the SSL algorithm will propagate the labels from the labeled to the unlabeled pixels, finding object boundaries. This paper proposes a new SSL graph-based interactive image segmentation approach, using undirected and unweighted kNN graphs, from which the unlabeled nodes receive contributions from other nodes (either labeled or unlabeled). It is simpler than many other techniques, but it still achieves significant classification accuracy in the image segmentation task. Computer simulations are performed using some real-world images, extracted from the Microsoft GrabCut dataset. The segmentation results show the effectiveness of the proposed approach.",0
"Several interactive techniques for image segmentation rely on semi-supervised learning, wherein the user annotates some pixels from each object, and the SSL algorithm spreads the labels from the labeled to the unlabeled pixels to detect object boundaries. In this research, a novel SSL graph-based approach for interactive image segmentation is presented, utilizing undirected and unweighted kNN graphs, whereby unlabeled nodes receive inputs from other nodes, whether labeled or unlabeled. Despite its simplicity, this approach delivers significant classification accuracy in image segmentation, as evidenced by computer simulations conducted using actual images from the Microsoft GrabCut dataset. The segmentation results confirm the efficacy of this proposed technique.",1
"In this thesis, we present new schemes which leverage a constrained clustering method to solve several computer vision tasks ranging from image retrieval, image segmentation and co-segmentation, to person re-identification. In the last decades clustering methods have played a vital role in computer vision applications; herein, we focus on the extension, reformulation, and integration of a well-known graph and game theoretic clustering method known as Dominant Sets. Thus, we have demonstrated the validity of the proposed methods with extensive experiments which are conducted on several benchmark datasets.",0
"New schemes that utilize a restricted clustering approach are introduced in this thesis to tackle various computer vision tasks, including image retrieval, image segmentation and co-segmentation, and person re-identification. Clustering methods have been instrumental in computer vision applications in recent years, and this research concentrates on enhancing, reimagining, and incorporating a popular graph and game theoretic clustering method called Dominant Sets. Through extensive experiments performed on various benchmark datasets, the effectiveness of the suggested approaches has been established.",1
"We use Deep Convolutional Neural Networks (DCNNs) for image segmentation problems. DCNNs can well extract the features from natural images. However, the classification functions in the existing network architecture of CNNs are simple and lack capabilities to handle important spatial information in a way that have been done for many well-known traditional variational models. Prior such as spatial regularity, volume prior and object shapes cannot be well handled by existing DCNNs. We propose a novel Soft Threshold Dynamics (STD) framework which can easily integrate many spatial priors of the classical variational models into the DCNNs for image segmentation. The novelty of our method is to interpret the softmax activation function as a dual variable in a variational problem, and thus many spatial priors can be imposed in the dual space. From this viewpoint, we can build a STD based framework which can enable the outputs of DCNNs to have many special priors such as spatial regularity, volume constraints and star-shape priori. The proposed method is a general mathematical framework and it can be applied to any semantic segmentation DCNNs. To show the efficiency and accuracy of our method, we applied it to the popular DeepLabV3+ image segmentation network, and the experiments results show that our method can work efficiently on data-driven image segmentation DCNNs.",0
"For image segmentation problems, Deep Convolutional Neural Networks (DCNNs) are used as they are proficient in extracting features from natural images. However, the existing network architecture of CNNs has limited classification functions and is unable to handle significant spatial information, such as spatial regularity, volume prior, and object shapes. To address this limitation, we propose a Soft Threshold Dynamics (STD) framework that can integrate numerous spatial priors from classical variational models into DCNNs for image segmentation. Our approach interprets the softmax activation function as a dual variable in a variational problem, enabling the imposition of spatial priors in the dual space. Our STD-based framework allows DCNN outputs to have various spatial priors, such as spatial regularity, volume constraints, and star-shape priori. Our method is a universal mathematical framework that can be applied to any semantic segmentation DCNNs. To demonstrate the effectiveness and accuracy of our approach, we applied it to the well-known DeepLabV3+ image segmentation network. Our experimental results demonstrate that our method is efficient and accurate for data-driven image segmentation DCNNs.",1
"Class imbalance has emerged as one of the major challenges for medical image segmentation. The model cascade (MC) strategy significantly alleviates the class imbalance issue via running a set of individual deep models for coarse-to-fine segmentation. Despite its outstanding performance, however, this method leads to undesired system complexity and also ignores the correlation among the models. To handle these flaws, we propose a light-weight deep model, i.e., the One-pass Multi-task Network (OM-Net) to solve class imbalance better than MC does, while requiring only one-pass computation. First, OM-Net integrates the separate segmentation tasks into one deep model, which consists of shared parameters to learn joint features, as well as task-specific parameters to learn discriminative features. Second, to more effectively optimize OM-Net, we take advantage of the correlation among tasks to design both an online training data transfer strategy and a curriculum learning-based training strategy. Third, we further propose sharing prediction results between tasks and design a cross-task guided attention (CGA) module which can adaptively recalibrate channel-wise feature responses based on the category-specific statistics. Finally, a simple yet effective post-processing method is introduced to refine the segmentation results. Extensive experiments are conducted to demonstrate the effectiveness of the proposed techniques. Most impressively, we achieve state-of-the-art performance on the BraTS 2015 testing set and BraTS 2017 online validation set. Using these proposed approaches, we also won joint third place in the BraTS 2018 challenge among 64 participating teams. The code is publicly available at https://github.com/chenhong-zhou/OM-Net.",0
"Medical image segmentation is hindered by class imbalance, which is a major challenge. The model cascade (MC) strategy is effective in addressing this issue through the use of multiple deep models for coarse-to-fine segmentation. However, this method is complex and disregards model correlation. To overcome these limitations, we propose the One-pass Multi-task Network (OM-Net), a lightweight deep model that outperforms MC in solving class imbalance with only one-pass computation. OM-Net integrates segmentation tasks into one deep model with shared and task-specific parameters. We also utilize task correlation to optimize OM-Net through online training data transfer and curriculum learning-based training. Additionally, we introduce the cross-task guided attention (CGA) module and a post-processing method for further refinement. Our proposed techniques achieved state-of-the-art performance in the BraTS 2015 testing set and BraTS 2017 online validation set, and we won joint third place in the BraTS 2018 challenge among 64 teams. The code is available at https://github.com/chenhong-zhou/OM-Net.",1
This paper presents an extension proposal of the semi-supervised learning method known as Particle Competition and Cooperation for carrying out tasks of image segmentation. Preliminary results show that this is a promising approach.   Este artigo apresenta uma proposta de extens\~ao do modelo de aprendizado semi-supervisionado conhecido como Competi\c{c}\~ao e Coopera\c{c}\~ao entre Part\'iculas para a realiza\c{c}\~ao de tarefas de segmenta\c{c}\~ao de imagens. Resultados preliminares mostram que esta \'e uma abordagem promissora.,0
"In this article, an extension proposal for the semi-supervised learning method called Particle Competition and Cooperation is presented. The aim is to use this method for image segmentation tasks, and initial findings suggest that it is a promising approach.",1
"Unsupervised segmentation of large images using a Potts model Hamiltonian is unique in that segmentation is governed by a resolution parameter which scales the sensitivity to small clusters. Here, the input image is first modeled as a graph, which is then segmented by minimizing a Hamiltonian cost function defined on the graph and the respective segments. However, there exists no closed form solution of this optimization, and using previous iterative algorithmic solution techniques, the problem scales quadratically in the Input Length. Therefore, while Potts model segmentation gives accurate segmentation, it is grossly underutilized as an unsupervised learning technique. We propose a fast statistical down-sampling of input image pixels based on the respective color features, and a new iterative method to minimize the Potts model energy considering pixel to segment relationship. This method is generalizable and can be extended for image pixel texture features as well as spatial features. We demonstrate that this new method is highly efficient, and outperforms existing methods for Potts model based image segmentation. We demonstrate the application of our method in medical microscopy image segmentation; particularly, in segmenting renal glomerular micro-environment in renal pathology. Our method is not limited to image segmentation, and can be extended to any image/data segmentation/clustering task for arbitrary datasets with discrete features.",0
"The use of a Potts model Hamiltonian for unsupervised segmentation of large images is unique due to the incorporation of a resolution parameter that controls sensitivity to small clusters. The image is first converted to a graph and segmented by minimizing a Hamiltonian cost function, however, no closed form solution exists and previous iterative algorithmic solutions scale quadratically with input length. Despite its accuracy, Potts model segmentation is underutilized in unsupervised learning. To address this, we propose a fast statistical down-sampling of input image pixels based on color features and a new iterative method that considers pixel to segment relationships to minimize the Potts model energy. This approach is generalizable and can incorporate texture and spatial features. Our method outperforms existing methods and we demonstrate its effectiveness in medical microscopy image segmentation, specifically in segmenting the renal glomerular micro-environment in renal pathology. This approach is not limited to image segmentation and can be applied to any segmentation or clustering task for datasets with discrete features.",1
"We present a method for segmenting neuron membranes in 2D electron microscopy imagery. This segmentation task has been a bottleneck to reconstruction efforts of the brain's synaptic circuits. One common problem is the misclassification of blurry membrane fragments as cell interior, which leads to merging of two adjacent neuron sections into one via the blurry membrane region. Human annotators can easily avoid such errors by implicitly performing gap completion, taking into account the continuity of membranes.   Drawing inspiration from these human strategies, we formulate the segmentation task as an edge labeling problem on a graph with local topological constraints. We derive an integer linear program (ILP) that enforces membrane continuity, i.e. the absence of gaps. The cost function of the ILP is the pixel-wise deviation of the segmentation from a priori membrane probabilities derived from the data.   Based on membrane probability maps obtained using random forest classifiers and convolutional neural networks, our method improves the neuron boundary segmentation accuracy compared to a variety of standard segmentation approaches. Our method successfully performs gap completion and leads to fewer topological errors. The method could potentially also be incorporated into other image segmentation pipelines with known topological constraints.",0
"In this article, we introduce a technique to segment neuron membranes in 2D electron microscopy images. This task has been a limiting factor in reconstructing the synaptic circuits of the brain. One issue that arises is the incorrect identification of blurred membrane fragments as the cell's interior, which results in merging adjacent neuron segments through the blurry membrane area. To overcome this, we emulate the approach of human annotators who consider membrane continuity when identifying gaps. We model the segmentation task as an edge-labeling problem on a graph with local topological rules and use an integer linear program to enforce membrane continuity. The cost function of the program is based on the deviation of the segmentation from previously determined membrane probabilities. We utilize membrane probability maps obtained through random forest classifiers and convolutional neural networks to improve the accuracy of neuron boundary segmentation compared to standard segmentation techniques. Our method successfully completes gaps and decreases topological errors. It may also be integrated into other image segmentation processes with known topological restrictions.",1
"Image normalization is a critical step in medical imaging. This step is often done on a per-dataset basis, preventing current segmentation algorithms from the full potential of exploiting jointly normalized information across multiple datasets. To solve this problem, we propose an adversarial normalization approach for image segmentation which learns common normalizing functions across multiple datasets while retaining image realism. The adversarial training provides an optimal normalizer that improves both the segmentation accuracy and the discrimination of unrealistic normalizing functions. Our contribution therefore leverages common imaging information from multiple domains. The optimality of our common normalizer is evaluated by combining brain images from both infants and adults. Results on the challenging iSEG and MRBrainS datasets reveal the potential of our adversarial normalization approach for segmentation, with Dice improvements of up to 59.6% over the baseline.",0
"Medical imaging relies heavily on image normalization, which is typically done on a per-dataset basis. However, this limits the ability of segmentation algorithms to fully utilize normalized information across multiple datasets. To address this issue, we propose an adversarial normalization approach for image segmentation. Our method enables the learning of common normalizing functions across multiple datasets while maintaining image realism. Adversarial training optimizes the normalizer to enhance both segmentation accuracy and the identification of unrealistic normalizing functions. Our approach is a valuable contribution as it leverages shared imaging information from multiple domains. To demonstrate the effectiveness of our common normalizer, we evaluate it using brain images from both infants and adults. Our method shows promising results on the challenging iSEG and MRBrainS datasets, with Dice improvements of up to 59.6% over the baseline.",1
"We consider referring image segmentation. It is a problem at the intersection of computer vision and natural language understanding. Given an input image and a referring expression in the form of a natural language sentence, the goal is to segment the object of interest in the image referred by the linguistic query. To this end, we propose a dual convolutional LSTM (ConvLSTM) network to tackle this problem. Our model consists of an encoder network and a decoder network, where ConvLSTM is used in both encoder and decoder networks to capture spatial and sequential information. The encoder network extracts visual and linguistic features for each word in the expression sentence, and adopts an attention mechanism to focus on words that are more informative in the multimodal interaction. The decoder network integrates the features generated by the encoder network at multiple levels as its input and produces the final precise segmentation mask. Experimental results on four challenging datasets demonstrate that the proposed network achieves superior segmentation performance compared with other state-of-the-art methods.",0
"The problem we are examining involves image segmentation, which sits at the crossroads of natural language understanding and computer vision. Our aim is to segment the object in an input image based on a natural language sentence that refers to it. To achieve this, we have developed a dual convolutional LSTM network, comprising an encoder and a decoder network. The ConvLSTM is employed in both networks to capture both spatial and sequential information. The encoder network extracts linguistic and visual features for each word in the expression sentence and uses an attention mechanism to focus on the most informative words in the multimodal interaction. The decoder network takes input from the encoder network at multiple levels, integrating the features to produce a precise segmentation mask. We have tested our model on four challenging datasets and found that it outperforms other state-of-the-art methods.",1
"Generative adversarial networks (GANs) have shown great success in applications such as image generation and inpainting. However, they typically require large datasets, which are often not available, especially in the context of prediction tasks such as image segmentation that require labels. Therefore, methods such as the CycleGAN use more easily available unlabelled data, but do not offer a way to leverage additional labelled data for improved performance. To address this shortcoming, we show how to factorise the joint data distribution into a set of lower-dimensional distributions along with their dependencies. This allows splitting the discriminator in a GAN into multiple ""sub-discriminators"" that can be independently trained from incomplete observations. Their outputs can be combined to estimate the density ratio between the joint real and the generator distribution, which enables training generators as in the original GAN framework. We apply our method to image generation, image segmentation and audio source separation, and obtain improved performance over a standard GAN when additional incomplete training examples are available. For the Cityscapes segmentation task in particular, our method also improves accuracy by an absolute 14.9% over CycleGAN while using only 25 additional paired examples.",0
"GANs have been successful in generating images and filling in missing parts of images. However, these networks often require large datasets, which may not be available for tasks like image segmentation that require labeled data. To address this issue, methods like CycleGAN use unlabelled data, but cannot use additional labeled data to improve performance. Our approach addresses this limitation by breaking down the joint data distribution into lower-dimensional distributions and their dependencies. This allows the discriminator in a GAN to be split into multiple sub-discriminators that can be trained independently with incomplete data. The outputs of these sub-discriminators can be combined to estimate the density ratio between the real and generator distributions, enabling the training of generators in the original GAN framework. We apply our method to image generation, image segmentation, and audio source separation and demonstrate improved performance over a standard GAN when additional incomplete training examples are available. Specifically, for the Cityscapes segmentation task, our method improves accuracy by 14.9% over CycleGAN using only 25 additional paired examples.",1
"Robust Optimization is becoming increasingly important in machine learning applications. This paper studies the problem of robust submodular minimization subject to combinatorial constraints. Constrained Submodular Minimization arises in several applications such as co-operative cuts in image segmentation, co-operative matchings in image correspondence, etc. Many of these models are defined over clusterings of data points (for example pixels in images), and it is important for these models to be robust to perturbations and uncertainty in the data. While several existing papers have studied robust submodular maximization, ours is the first work to study the minimization version under a broad range of combinatorial constraints including cardinality, knapsack, matroid as well as graph-based constraints such as cuts, paths, matchings, and trees. In each case, we provide scalable approximation algorithms and also study hardness bounds. Finally, we empirically demonstrate the utility of our algorithms on synthetic and real-world datasets.",0
"The significance of Robust Optimization in machine learning applications is on the rise. This study delves into the issue of robust submodular minimization subject to combinatorial constraints. Constrained Submodular Minimization is relevant in various scenarios like co-operative cuts in image segmentation, co-operative matchings in image correspondence, and so on. Many of these models rely on clustering of data points, like pixels in images, and their ability to withstand uncertainties and perturbations is crucial. While previous works have looked into robust submodular maximization, this paper is the first to investigate the minimization version within a wide range of combinatorial constraints, such as cardinality, knapsack, matroid, and graph-based constraints like cuts, paths, matchings, and trees. We provide scalable approximation algorithms in each case and also examine the complexity of the problem. Lastly, we showcase the effectiveness of our algorithms on synthetic and real-world datasets.",1
"There has recently been great progress in automatic segmentation of medical images with deep learning algorithms. In most works observer variation is acknowledged to be a problem as it makes training data heterogeneous but so far no attempts have been made to explicitly capture this variation. Here, we propose an approach capable of mimicking different styles of segmentation, which potentially can improve quality and clinical acceptance of automatic segmentation methods. In this work, instead of training one neural network on all available data, we train several neural networks on subgroups of data belonging to different segmentation variations separately. Because a priori it may be unclear what styles of segmentation exist in the data and because different styles do not necessarily map one-on-one to different observers, the subgroups should be automatically determined. We achieve this by searching for the best data partition with a genetic algorithm. Therefore, each network can learn a specific style of segmentation from grouped training data. We provide proof of principle results for open-sourced prostate segmentation MRI data with simulated observer variations. Our approach provides an improvement of up to 23% (depending on simulated variations) in terms of Dice and surface Dice coefficients compared to one network trained on all data.",0
"Recently, there has been significant progress in utilizing deep learning algorithms to automatically segment medical images. However, many studies acknowledge the challenge of observer variation, which creates heterogeneity in the training data. Unfortunately, no explicit attempts have been made to address this issue. In this study, we propose a method that can mimic different segmentation styles to potentially improve the quality and clinical acceptance of automatic segmentation methods. Instead of training one neural network on all available data, we train several networks on subgroups of data that belong to different segmentation variations. Since it may be difficult to determine the different styles of segmentation in the data a priori, we use a genetic algorithm to find the best data partition. This approach allows each network to learn a specific style of segmentation from grouped training data. We provide proof of principle results using open-sourced prostate segmentation MRI data with simulated observer variations. Our proposed method shows an improvement of up to 23% in terms of Dice and surface Dice coefficients compared to a single network trained on all data.",1
"Image segmentation with a volume constraint is an important prior for many real applications. In this work, we present a novel volume preserving image segmentation algorithm, which is based on the framework of entropic regularized optimal transport theory. The classical Total Variation (TV) regularizer and volume preserving are integrated into a regularized optimal transport model, and the volume and classification constraints can be regarded as two measures preserving constraints in the optimal transport problem. By studying the dual problem, we develop a simple and efficient dual algorithm for our model. Moreover, to be different from many variational based image segmentation algorithms, the proposed algorithm can be directly unrolled to a new Volume Preserving and TV regularized softmax (VPTV-softmax) layer for semantic segmentation in the popular Deep Convolution Neural Network (DCNN). The experiment results show that our proposed model is very competitive and can improve the performance of many semantic segmentation nets such as the popular U-net.",0
"A crucial prior for numerous practical applications is image segmentation, which involves a volume constraint. A new algorithm for preserving volume in image segmentation, utilizing the framework of entropic regularized optimal transport theory, is presented here. This algorithm merges the classical Total Variation (TV) regularizer with volume preservation into a regularized optimal transport model, with volume and classification constraints being considered as two constraints that preserve measures in the optimal transport problem. By studying the dual problem, a simple and efficient dual algorithm is developed for the model. Additionally, unlike many variational based image segmentation algorithms, this algorithm can directly unroll into a new Volume Preserving and TV regularized softmax (VPTV-softmax) layer for semantic segmentation in the popular Deep Convolution Neural Network (DCNN). Experimental results demonstrate that this model is highly competitive and can enhance the performance of numerous semantic segmentation nets such as the popular U-net.",1
"This fourth and last tome is focusing on describing the envisioned works for a project that has been presented in the preceding tome. It is about a new approach dedicated to the coding of still and moving pictures, trying to bridge the MPEG-4 and MPEG-7 standard bodies. The aim of this project is to define the principles of self-descriptive video coding. In order to establish them, the document is composed in five chapters that describe the various envisioned techniques for developing such a new approach in visual coding: - image segmentation, - computation of visual descriptors, - computation of perceptual groupings, - building of visual dictionaries, - picture and video coding. Based on the techniques of multiresolution computing, it is proposed to develop an image segmentation made from piecewise regular components, to compute attributes on the frame and the rendering of so produced shapes, independently to the geometric transforms that can occur in the image plane, and to gather them into perceptual groupings so as to be able in performing recognition of partially hidden patterns. Due to vector quantization of shapes frame and rendering, it will appear that simple shapes may be compared to a visual alphabet and that complex shapes then become words written using this alphabet and be recorded into a dictionary. With the help of a nearest neighbour scanning applied on the picture shapes, the self-descriptive coding will then generate a sentence made from words written using the simple shape alphabet.",0
"The final installment of this series focuses on outlining the proposed works for a project introduced in the previous volume. The project aims to merge the MPEG-4 and MPEG-7 standards in order to create a new approach to coding both still and moving images. The primary objective is to establish the principles of self-descriptive video coding. The document is divided into five chapters that detail the various techniques envisioned for developing this approach, including image segmentation, visual descriptor computation, perceptual grouping computation, visual dictionary creation, and picture and video coding. Using multiresolution computing techniques, the proposed method involves segmenting images into regular components, computing attributes, rendering shapes independently of geometric transforms, grouping them perceptually, and recognizing partially hidden patterns. By vector quantizing shapes, it is possible to compare simple shapes to a visual alphabet and complex shapes to words written using this alphabet, with the ability to record them in a dictionary. The self-descriptive coding generates a sentence composed of words written using the simple shape alphabet through nearest neighbor scanning of picture shapes.",1
"We tackle biomedical image segmentation in the scenario of only a few labeled brain MR images. This is an important and challenging task in medical applications, where manual annotations are time-consuming. Current multi-atlas based segmentation methods use image registration to warp segments from labeled images onto a new scan. In a different paradigm, supervised learning-based segmentation strategies have gained popularity. These method consistently use relatively large sets of labeled training data, and their behavior in the regime of a few labeled biomedical images has not been thoroughly evaluated. In this work, we provide two important results for segmentation in the scenario where few labeled images are available. First, we propose a straightforward implementation of efficient semi-supervised learning-based registration method, which we showcase in a multi-atlas segmentation framework. Second, through an extensive empirical study, we evaluate the performance of a supervised segmentation approach, where the training images are augmented via random deformations. Surprisingly, we find that in both paradigms, accurate segmentation is generally possible even in the context of few labeled images.",0
"The challenge of biomedical image segmentation with only a limited number of labeled brain MR images poses a significant problem in medical applications due to the time-consuming nature of manual annotations. Existing multi-atlas based segmentation methods use image registration to transfer segments from labeled images onto a new scan. In contrast, supervised learning-based segmentation techniques have become increasingly popular but their effectiveness with minimal labeled training data has not been thoroughly examined. In this study, we present two key findings for segmentation with limited labeled images. Firstly, we suggest a simple implementation of an efficient semi-supervised learning-based registration approach, which we demonstrate in a multi-atlas segmentation framework. Secondly, we conduct a comprehensive empirical analysis of a supervised segmentation strategy, where training images are augmented through random deformations. Surprisingly, we discover that both approaches can produce precise segmentation results even with a limited number of labeled images.",1
"Multi-modal learning is typically performed with network architectures containing modality-specific layers and shared layers, utilizing co-registered images of different modalities. We propose a novel learning scheme for unpaired cross-modality image segmentation, with a highly compact architecture achieving superior segmentation accuracy. In our method, we heavily reuse network parameters, by sharing all convolutional kernels across CT and MRI, and only employ modality-specific internal normalization layers which compute respective statistics. To effectively train such a highly compact model, we introduce a novel loss term inspired by knowledge distillation, by explicitly constraining the KL-divergence of our derived prediction distributions between modalities. We have extensively validated our approach on two multi-class segmentation problems: i) cardiac structure segmentation, and ii) abdominal organ segmentation. Different network settings, i.e., 2D dilated network and 3D U-net, are utilized to investigate our method's general efficacy. Experimental results on both tasks demonstrate that our novel multi-modal learning scheme consistently outperforms single-modal training and previous multi-modal approaches.",0
"A common approach to multi-modal learning involves using network architectures that have layers specific to each modality as well as shared layers. This involves using co-registered images from different modalities. We have developed a unique learning scheme for unpaired cross-modality image segmentation that uses a highly compact architecture to achieve better segmentation accuracy. Our approach involves sharing all convolutional kernels across CT and MRI while only using modality-specific internal normalization layers that compute respective statistics. To train our compact model effectively, we have introduced a novel loss term that is inspired by knowledge distillation. This involves explicitly constraining the KL-divergence of our derived prediction distributions between modalities. We have extensively tested our approach on two multi-class segmentation problems, including cardiac structure segmentation and abdominal organ segmentation. We have used different network settings, such as 2D dilated network and 3D U-net, to evaluate the efficacy of our method. Our experimental results demonstrate that our multi-modal learning scheme consistently outperforms single-modal training and previous multi-modal approaches.",1
"Image segmentation and classification are the two main fundamental steps in pattern recognition. To perform medical image segmentation or classification with deep learning models, it requires training on large image dataset with annotation. The dermoscopy images (ISIC archive) considered for this work does not have ground truth information for lesion segmentation. Performing manual labelling on this dataset is time-consuming. To overcome this issue, self-learning annotation scheme was proposed in the two-stage deep learning algorithm. The two-stage deep learning algorithm consists of U-Net segmentation model with the annotation scheme and CNN classifier model. The annotation scheme uses a K-means clustering algorithm along with merging conditions to achieve initial labelling information for training the U-Net model. The classifier models namely ResNet-50 and LeNet-5 were trained and tested on the image dataset without segmentation for comparison and with the U-Net segmentation for implementing the proposed self-learning Artificial Intelligence (AI) framework. The classification results of the proposed AI framework achieved training accuracy of 93.8% and testing accuracy of 82.42% when compared with the two classifier models directly trained on the input images.",0
"Pattern recognition involves two fundamental steps: image segmentation and classification. To use deep learning models for medical image segmentation or classification, extensive training on large annotated image datasets is required. However, the dermoscopy images (ISIC archive) utilized in this study lack ground truth information for lesion segmentation, and manual labeling is time-consuming. To address this issue, a self-learning annotation scheme was proposed in a two-stage deep learning algorithm. The algorithm comprises a U-Net segmentation model with the annotation scheme and a CNN classifier model. The annotation scheme uses a K-means clustering algorithm with merging conditions to obtain initial labeling information for training the U-Net model. The proposed self-learning AI framework was compared with two classifier models, ResNet-50 and LeNet-5, trained and tested on the image dataset with and without segmentation. The AI framework achieved training accuracy of 93.8% and testing accuracy of 82.42%, surpassing the two classifier models trained directly on the input images.",1
"In preoperative imaging, the demarcation of rectal cancer with magnetic resonance images provides an important basis for cancer staging and treatment planning. Recently, deep learning has greatly improved the state-of-the-art method in automatic segmentation. However, limitations in data availability in the medical field can cause large variance and consequent overfitting to medical image segmentation networks. In this study, we propose methods to reduce the model variance of a rectal cancer segmentation network by adding a rectum segmentation task and performing data augmentation; the geometric correlation between the rectum and rectal cancer motivated the former approach. Moreover, we propose a method to perform a bias-variance analysis within an arbitrary region-of-interest (ROI) of a segmentation network, which we applied to assess the efficacy of our approaches in reducing model variance. As a result, adding a rectum segmentation task reduced the model variance of the rectal cancer segmentation network within tumor regions by a factor of 0.90; data augmentation further reduced the variance by a factor of 0.89. These approaches also reduced the training duration by a factor of 0.96 and a further factor of 0.78, respectively. Our approaches will improve the quality of rectal cancer staging by increasing the accuracy of its automatic demarcation and by providing rectum boundary information since rectal cancer staging requires the demarcation of both rectum and rectal cancer. Besides such clinical benefits, our method also enables segmentation networks to be assessed with bias-variance analysis within an arbitrary ROI, such as a cancerous region.",0
"The demarcation of rectal cancer through magnetic resonance imaging is crucial for cancer staging and treatment planning in preoperative imaging. While deep learning has greatly improved automatic segmentation, data scarcity in the medical field can cause variation and overfitting in segmentation networks. To address this, we suggest reducing model variance by incorporating a rectum segmentation task and implementing data augmentation. The geometry correlation between the rectum and rectal cancer motivated the former approach. We also propose a method for bias-variance analysis within an arbitrary region-of-interest (ROI) of a segmentation network to evaluate the effectiveness of our approaches. Our methods reduced model variance, training duration, and improved the quality of rectal cancer staging by providing accurate demarcation and rectum boundary information. Additionally, our approach enables the assessment of segmentation networks within an ROI, such as a cancerous region.",1
"This paper tackles the problem of real-time semantic segmentation of high definition videos using a hybrid GPU / CPU approach. We propose an Efficient Video Segmentation(EVS) pipeline that combines:   (i) On the CPU, a very fast optical flow method, that is used to exploit the temporal aspect of the video and propagate semantic information from one frame to the next. It runs in parallel with the GPU.   (ii) On the GPU, two Convolutional Neural Networks: A main segmentation network that is used to predict dense semantic labels from scratch, and a Refiner that is designed to improve predictions from previous frames with the help of a fast Inconsistencies Attention Module (IAM). The latter can identify regions that cannot be propagated accurately.   We suggest several operating points depending on the desired frame rate and accuracy. Our pipeline achieves accuracy levels competitive to the existing real-time methods for semantic image segmentation(mIoU above 60%), while achieving much higher frame rates. On the popular Cityscapes dataset with high resolution frames (2048 x 1024), the proposed operating points range from 80 to 1000 Hz on a single GPU and CPU.",0
"The focus of this research is on solving the challenge of performing real-time semantic segmentation of high definition videos. To achieve this, we have developed a hybrid GPU/CPU approach called Efficient Video Segmentation (EVS) pipeline. The pipeline combines two main components: (i) a rapid optical flow method that utilizes the temporal aspect of the video to propagate semantic information from one frame to the next, running in tandem with the GPU and (ii) two Convolutional Neural Networks on the GPU: a segmentation network that predicts dense semantic labels from scratch, and a Refiner that enhances predictions from previous frames with the help of a fast Inconsistencies Attention Module (IAM). The IAM can accurately identify regions that cannot be propagated. Depending on the desired frame rate and accuracy, we propose several operating points. Our pipeline delivers competitive accuracy levels for semantic image segmentation (mIoU above 60%) while achieving significantly higher frame rates. On the Cityscapes dataset with high resolution frames (2048 x 1024), the proposed operating points range from 80 to 1000 Hz on a single GPU and CPU.",1
"We propose a novel approach for image segmentation that combines Neural Ordinary Differential Equations (NODEs) and the Level Set method. Our approach parametrizes the evolution of an initial contour with a NODE that implicitly learns from data a speed function describing the evolution. In addition, for cases where an initial contour is not available and to alleviate the need for careful choice or design of contour embedding functions, we propose a NODE-based method that evolves an image embedding into a dense per-pixel semantic label space. We evaluate our methods on kidney segmentation (KiTS19) and on salient object detection (PASCAL-S, ECSSD and HKU-IS). In addition to improving initial contours provided by deep learning models while using a fraction of their number of parameters, our approach achieves F scores that are higher than several state-of-the-art deep learning algorithms.",0
"Our innovative approach to image segmentation combines the Level Set method with Neural Ordinary Differential Equations (NODEs). Using a NODE, we are able to parametrize the evolution of an initial contour and implicitly learn a speed function from data. Moreover, we introduce a NODE-based method to evolve an image embedding into a dense per-pixel semantic label space, eliminating the need for careful contour embedding function design. Our methods are tested on kidney segmentation (KiTS19) and salient object detection (PASCAL-S, ECSSD, and HKU-IS), and we achieve higher F scores than several state-of-the-art deep learning algorithms while using a fraction of their parameters. Additionally, our approach improves upon initial contours provided by deep learning models.",1
"That most deep learning models are purely data driven is both a strength and a weakness. Given sufficient training data, the optimal model for a particular problem can be learned. However, this is usually not the case and so instead the model is either learned from scratch from a limited amount of training data or pre-trained on a different problem and then fine-tuned. Both of these situations are potentially suboptimal and limit the generalizability of the model. Inspired by this, we investigate methods to inform or guide deep learning models for geospatial image analysis to increase their performance when a limited amount of training data is available or when they are applied to scenarios other than which they were trained on. In particular, we exploit the fact that there are certain fundamental rules as to how things are distributed on the surface of the Earth and these rules do not vary substantially between locations. Based on this, we develop a novel feature pooling method for convolutional neural networks using Getis-Ord Gi* analysis from geostatistics. Experimental results show our proposed pooling function has significantly better generalization performance compared to a standard data-driven approach when applied to overhead image segmentation.",0
"The strength and weakness of most deep learning models lies in their data-driven nature. With ample training data, the model can learn the optimal solution for a specific problem. However, this is typically not the case, and the model must be either trained from scratch with a limited amount of data or pre-trained on a different problem and fine-tuned. Both situations can be suboptimal and limit the model's generalizability. To address this, we explore methods to enhance deep learning models' performance in geospatial image analysis when faced with limited training data or different scenarios. We utilize the fundamental rules governing the distribution of objects on the Earth's surface, which are consistent across locations, to develop a novel feature pooling method for convolutional neural networks. Our method employs Getis-Ord Gi* analysis from geostatistics. Our experimental results demonstrate that our proposed pooling function performs significantly better in generalization when applied to overhead image segmentation compared to a standard data-driven approach.",1
"Recent advances in AI technology have made the forgery of digital images and videos easier, and it has become significantly more difficult to identify such forgeries. These forgeries, if disseminated with malicious intent, can negatively impact social and political stability, and pose significant ethical and legal challenges as well. Deepfake is a variant of auto-encoders that use deep learning techniques to identify and exchange images of a person's face in a picture or film. Deepfake can result in an erosion of public trust in digital images and videos, which has far-reaching effects on political and social stability. This study therefore proposes a solution for facial forgery detection to determine if a picture or film has ever been processed by Deepfake. The proposed solution reaches detection efficiency by using the recently proposed separable convolutional neural network (CNN) and image segmentation. In addition, this study also examined how different image segmentation methods affect detection results. Finally, the ensemble model is used to improve detection capabilities. Experiment results demonstrated the excellent performance of the proposed solution.",0
"The ease of creating fake digital images and videos has increased due to recent advancements in AI technology. It has become more challenging to detect such forgeries, which can have adverse effects on social and political stability, as well as pose ethical and legal dilemmas. Deepfake, a type of auto-encoder that utilizes deep learning techniques to exchange images of a person's face, can contribute to a loss of trust in digital media, leading to significant consequences for political and social stability. To address this issue, the study suggests a solution for detecting facial forgery in pictures or films processed by Deepfake. The proposed solution relies on the separable CNN and image segmentation to achieve detection efficiency, and the study also examines how different image segmentation methods impact detection results. Finally, the ensemble model is utilized to enhance the detection capabilities, and the results of the experiments demonstrate the efficacy of the proposed solution.",1
"The minimal path model based on the Eikonal partial differential equation (PDE) has served as a fundamental tool for the applications of image segmentation and boundary detection in the passed three decades. However, the existing minimal paths-based image segmentation approaches commonly rely on the image boundary features, potentially limiting their performance in some situations. In this paper, we introduce a new variational image segmentation model based on the minimal path framework and the Eikonal PDE, where the region-based functional that defines the homogeneity criteria can be taken into account for estimating the associated geodesic paths. This is done by establishing a geodesic curve interpretation to the region-based active contour evolution problem. The image segmentation processing is carried out in an iterative manner in our approach. A crucial ingredient in each iteration is to construct an asymmetric Randers geodesic metric using a sufficiently small vector field, such that a set of geodesic paths can be tracked from the geodesic distance map which is the solution to an Eikonal PDE. The object boundary can be delineated by the concatenation of the final geodesic paths. We invoke the Finsler variant of the fast marching method to estimate the geodesic distance map, yielding an efficient implementation of the proposed Eikonal region-based active contour model. Experimental results on both of the synthetic and real images exhibit that our model indeed achieves encouraging segmentation performance.",0
"For the past three decades, the minimal path model based on the Eikonal partial differential equation (PDE) has been widely used for image segmentation and boundary detection. However, the current methods for image segmentation using minimal paths often rely on image boundary features, which may limit their effectiveness in certain situations. In this article, we introduce a new variational image segmentation model that uses the minimal path framework and Eikonal PDE, where the homogeneity criteria for regions can be considered when estimating the associated geodesic paths. We establish a geodesic curve interpretation for the region-based active contour evolution problem and use an iterative approach for image segmentation. In each iteration, we construct an asymmetric Randers geodesic metric using a small vector field to track a set of geodesic paths from the geodesic distance map, which is the solution to the Eikonal PDE. The object boundary is formed by concatenating the final geodesic paths. We employ the Finsler variant of the fast marching method to estimate the geodesic distance map, resulting in an efficient implementation of our proposed Eikonal region-based active contour model. Our experimental results on both synthetic and real images demonstrate that our model achieves promising segmentation performance.",1
"A novel multi-focus image fusion algorithm performed in spatial domain based on similarity characteristics is proposed incorporating with region segmentation. In this paper, a new similarity measure is developed based on the structural similarity (SSIM) index, which is more suitable for multi-focus image segmentation. Firstly, the SSNSIM map is calculated between two input images. Then we segment the SSNSIM map using watershed method, and merge the small homogeneous regions with fuzzy c-means clustering algorithm (FCM). For three source images, a joint region segmentation method based on segmentation of two images is used to obtain the final segmentation result. Finally, the corresponding segmented regions of the source images are fused according to their average gradient. The performance of the image fusion method is evaluated by several criteria including spatial frequency, average gradient, entropy, edge retention etc. The evaluation results indicate that the proposed method is effective and has good visual perception.",0
"This paper introduces a novel algorithm for multi-focus image fusion in the spatial domain, which utilizes similarity characteristics and region segmentation. The algorithm develops a new similarity measure based on the structural similarity (SSIM) index, specifically designed for multi-focus image segmentation. The process involves calculating the SSNSIM map between two input images, segmenting the map using the watershed method, and merging small homogeneous regions with the fuzzy c-means clustering algorithm (FCM). For three source images, a joint region segmentation method is employed to obtain the final segmentation result. The segmented regions of the source images are then fused based on their average gradient. The proposed method's performance is evaluated using various criteria, including spatial frequency, average gradient, entropy, and edge retention. The evaluation results indicate that the algorithm is effective and yields good visual perception.",1
"There is active research targeting local image manipulations that can fool deep neural networks (DNNs) into producing incorrect results. This paper examines a type of global image manipulation that can produce similar adverse effects. Specifically, we explore how strong color casts caused by incorrectly applied computational color constancy - referred to as white balance (WB) in photography - negatively impact the performance of DNNs targeting image segmentation and classification. In addition, we discuss how existing image augmentation methods used to improve the robustness of DNNs are not well suited for modeling WB errors. To address this problem, a novel augmentation method is proposed that can emulate accurate color constancy degradation. We also explore pre-processing training and testing images with a recent WB correction algorithm to reduce the effects of incorrectly white-balanced images. We examine both augmentation and pre-processing strategies on different datasets and demonstrate notable improvements on the CIFAR-10, CIFAR-100, and ADE20K datasets.",0
"Active research is underway to deceive deep neural networks (DNNs) by manipulating local images, leading to incorrect results. This study, on the other hand, delves into the effects of a global image manipulation that also produces adverse outcomes. Specifically, we investigate the negative impact of strong color casts, caused by computational color constancy errors - referred to as white balance (WB) in photography - on DNNs targeting image segmentation and classification. We also discuss the inadequacy of existing image augmentation methods in modeling WB errors. To mitigate this problem, we introduce a unique augmentation method that can simulate accurate color constancy degradation. Moreover, we explore the use of a recent WB correction algorithm in pre-processing training and testing images to minimize the impact of incorrectly white-balanced images. We evaluate both augmentation and pre-processing strategies on various datasets and demonstrate significant improvements on the CIFAR-10, CIFAR-100, and ADE20K datasets.",1
"Semantic image segmentation plays a pivotal role in many vision applications including autonomous driving and medical image analysis. Most of the former approaches move towards enhancing the performance in terms of accuracy with a little awareness of computational efficiency. In this paper, we introduce LiteSeg, a lightweight architecture for semantic image segmentation. In this work, we explore a new deeper version of Atrous Spatial Pyramid Pooling module (ASPP) and apply short and long residual connections, and depthwise separable convolution, resulting in a faster and efficient model. LiteSeg architecture is introduced and tested with multiple backbone networks as Darknet19, MobileNet, and ShuffleNet to provide multiple trade-offs between accuracy and computational cost. The proposed model LiteSeg, with MobileNetV2 as a backbone network, achieves an accuracy of 67.81% mean intersection over union at 161 frames per second with $640 \times 360$ resolution on the Cityscapes dataset.",0
"Semantic image segmentation is a crucial aspect of various vision applications such as autonomous driving and medical image analysis. Previous methods have focused mainly on improving accuracy without much consideration for computational efficiency. This study introduces LiteSeg, a lightweight semantic image segmentation architecture that employs a new, deeper version of the Atrous Spatial Pyramid Pooling module (ASPP), short and long residual connections, and depthwise separable convolution. These techniques resulted in a faster and more efficient model. The LiteSeg architecture was tested with various backbone networks, including Darknet19, MobileNet, and ShuffleNet, to offer different trade-offs between accuracy and computational cost. The proposed LiteSeg model achieved an accuracy of 67.81% mean intersection over union at 161 frames per second with $640 \times 360$ resolution on the Cityscapes dataset, using MobileNetV2 as the backbone network.",1
Vegetation is a relevant feature in the urban scenery and its awareness can be measured in an image by the Green View Index (GVI). Previous approaches to estimate the GVI were based upon heuristics image processing approaches and recently by deep learning networks (DLN). By leveraging some recent DLN architectures tuned to the image segmentation problem and exploiting a weighting strategy in the loss function (LF) we improved previously reported results in similar datasets.,0
"The presence of plants and trees in the urban environment is an important aspect, and this can be gauged through the Green View Index (GVI) as depicted in an image. Previously, the estimation of GVI relied on image processing techniques that were based on heuristics, but now deep learning networks (DLN) have been employed for this purpose. By utilizing DLN architectures specifically designed for image segmentation, and incorporating a weight-based approach in the loss function (LF), we have achieved better outcomes compared to previous studies with similar datasets.",1
"Image segmentation is one of the most fundamental tasks of computer vision. In many practical applications, it is essential to properly evaluate the reliability of individual segmentation results. In this study, we propose a novel framework to provide the statistical significance of segmentation results in the form of p-values. Specifically, we consider a statistical hypothesis test for determining the difference between the object and the background regions. This problem is challenging because the difference can be deceptively large (called segmentation bias) due to the adaptation of the segmentation algorithm to the data. To overcome this difficulty, we introduce a statistical approach called selective inference, and develop a framework to compute valid p-values in which the segmentation bias is properly accounted for. Although the proposed framework is potentially applicable to various segmentation algorithms, we focus in this paper on graph cut-based and threshold-based segmentation algorithms, and develop two specific methods to compute valid p-values for the segmentation results obtained by these algorithms. We prove the theoretical validity of these two methods and demonstrate their practicality by applying them to segmentation problems for medical images.",0
"Computer vision relies heavily on image segmentation, which is a crucial task with real-world applications. To ensure accurate segmentation outcomes, it's important to assess the reliability of individual results. This study introduces a new framework that calculates p-values, indicating the statistical significance of segmentation results. The framework uses a statistical hypothesis test to differentiate between the object and background regions, a difficult task due to segmentation bias. To overcome this challenge, the study employs selective inference and introduces a framework that accounts for segmentation bias. The proposed approach applies to various segmentation algorithms, but the study focuses on graph cut-based and threshold-based methods. The two specific methods implemented to compute valid p-values for these algorithms are theoretically valid and practically useful for medical image segmentation problems.",1
"Modern computer vision (CV) is often based on convolutional neural networks (CNNs) that excel at hierarchical feature extraction. The previous generation of CV approaches was often based on conditional random fields (CRFs) that excel at modeling flexible higher order interactions. As their benefits are complementary they are often combined. However, these approaches generally use mean-field approximations and thus, arguably, did not directly optimize the real problem. Here we revisit dual-decomposition-based approaches to CRF optimization, an alternative to the mean-field approximation. These algorithms can efficiently and exactly solve sub-problems and directly optimize a convex upper bound of the real problem, providing optimality certificates on the way. Our approach uses a novel fixed-point iteration algorithm which enjoys dual-monotonicity, dual-differentiability and high parallelism. The whole system, CRF and CNN can thus be efficiently trained using back-propagation. We demonstrate the effectiveness of our system on semantic image segmentation, showing consistent improvement over baseline models.",0
"Convolutional neural networks (CNNs) are commonly utilized in modern computer vision (CV) for hierarchical feature extraction. In contrast, the older generation of CV techniques relied on conditional random fields (CRFs) for modeling flexible higher order interactions. These two methods complement each other and are often combined. However, their utilization of mean-field approximations may not directly optimize the actual problem. Our approach revisits CRF optimization using dual-decomposition-based algorithms as an alternative to mean-field approximation. These algorithms can efficiently and exactly solve sub-problems and directly optimize a convex upper bound of the real problem, providing optimality certificates. Our approach employs a novel fixed-point iteration algorithm that is dual-monotonic, dual-differentiable, and highly parallel. This enables efficient training of the entire system, CRF and CNN, using back-propagation. We demonstrate the effectiveness of our approach in semantic image segmentation, consistently outperforming baseline models.",1
"Medical image segmentation is a fundamental task in medical image analysis. Despite that deep convolutional neural networks have gained stellar performance in this challenging task, they typically rely on large labeled datasets, which have limited their extension to customized applications. By revisiting the superiority of atlas based segmentation methods, we present a new framework of One-pass aligned Atlas Set for Images Segmentation (OASIS). To address the problem of time-consuming iterative image registration used for atlas warping, the proposed method takes advantage of the power of deep learning to achieve one-pass image registration. In addition, by applying label constraint, OASIS also makes the registration process to be focused on the regions to be segmented for improving the performance of segmentation. Furthermore, instead of using image based similarity for label fusion, which can be distracted by the large background areas, we propose a novel strategy to compute the label similarity based weights for label fusion. Our experimental results on the challenging task of prostate MR image segmentation demonstrate that OASIS is able to significantly increase the segmentation performance compared to other state-of-the-art methods.",0
"Medical image analysis involves the crucial task of medical image segmentation. Although deep convolutional neural networks have excelled in this challenging task, they require extensive labeled datasets, which limits their application to customized cases. To overcome this, we propose a novel framework called One-pass aligned Atlas Set for Images Segmentation (OASIS) that revisits the effectiveness of atlas-based segmentation methods. Our method utilizes deep learning to achieve one-pass image registration, eliminating the need for time-consuming iterative image registration used for atlas warping. Additionally, OASIS focuses on the regions to be segmented by applying label constraint during the registration process, improving segmentation performance. Label fusion is achieved by a unique label similarity-based weight computation strategy, instead of using image-based similarity, which can be distorted by large background areas. Our experimental results demonstrate that OASIS significantly enhances segmentation performance in the challenging task of prostate MR image segmentation compared to other state-of-the-art methods.",1
"Online Normalization is a new technique for normalizing the hidden activations of a neural network. Like Batch Normalization, it normalizes the sample dimension. While Online Normalization does not use batches, it is as accurate as Batch Normalization. We resolve a theoretical limitation of Batch Normalization by introducing an unbiased technique for computing the gradient of normalized activations. Online Normalization works with automatic differentiation by adding statistical normalization as a primitive. This technique can be used in cases not covered by some other normalizers, such as recurrent networks, fully connected networks, and networks with activation memory requirements prohibitive for batching. We show its applications to image classification, image segmentation, and language modeling. We present formal proofs and experimental results on ImageNet, CIFAR, and PTB datasets.",0
"A novel method called Online Normalization has been developed to normalize the hidden activations of a neural network. This technique, similar to Batch Normalization, normalizes the sample dimension but does not require batches. Despite this difference, Online Normalization delivers the same level of accuracy as Batch Normalization. Additionally, we have resolved a theoretical limitation of Batch Normalization by introducing an unbiased technique for calculating the gradient of normalized activations. By incorporating statistical normalization as a primitive, Online Normalization can be used in various cases, including recurrent networks, fully connected networks, and networks with activation memory requirements that make batching impractical. We have demonstrated the effectiveness of Online Normalization in image classification, image segmentation, and language modeling through formal proofs and experimental results on ImageNet, CIFAR, and PTB datasets.",1
"LIDAR point clouds and RGB-images are both extremely essential for 3D object detection. So many state-of-the-art 3D detection algorithms dedicate in fusing these two types of data effectively. However, their fusion methods based on Birds Eye View (BEV) or voxel format are not accurate. In this paper, we propose a novel fusion approach named Point-based Attentive Cont-conv Fusion(PACF) module, which fuses multi-sensor features directly on 3D points. Except for continuous convolution, we additionally add a Point-Pooling and an Attentive Aggregation to make the fused features more expressive. Moreover, based on the PACF module, we propose a 3D multi-sensor multi-task network called Pointcloud-Image RCNN(PI-RCNN as brief), which handles the image segmentation and 3D object detection tasks. PI-RCNN employs a segmentation sub-network to extract full-resolution semantic feature maps from images and then fuses the multi-sensor features via powerful PACF module. Beneficial from the effectiveness of the PACF module and the expressive semantic features from the segmentation module, PI-RCNN can improve much in 3D object detection. We demonstrate the effectiveness of the PACF module and PI-RCNN on the KITTI 3D Detection benchmark, and our method can achieve state-of-the-art on the metric of 3D AP.",0
"Both LIDAR point clouds and RGB-images are crucial for 3D object detection, and many advanced algorithms aim to fuse these two types of data effectively. However, current fusion methods based on Birds Eye View (BEV) or voxel format have inaccuracies. This paper introduces a novel fusion approach called the Point-based Attentive Cont-conv Fusion (PACF) module, which directly fuses multi-sensor features on 3D points and adds a Point-Pooling and Attentive Aggregation to enhance the fused features. Using the PACF module, a 3D multi-sensor multi-task network named Pointcloud-Image RCNN (PI-RCNN) is proposed to handle image segmentation and 3D object detection tasks. PI-RCNN employs a segmentation sub-network to extract semantic feature maps from images and then fuses multi-sensor features via the powerful PACF module. This approach improves 3D object detection significantly due to the effectiveness of the PACF module and the expressive semantic features from the segmentation module. The effectiveness of the PACF module and PI-RCNN is demonstrated on the KITTI 3D Detection benchmark, achieving state-of-the-art results on the 3D AP metric.",1
"We present an image segmentation method that iteratively evolves a polygon. At each iteration, the vertices of the polygon are displaced based on the local value of a 2D shift map that is inferred from the input image via an encoder-decoder architecture. The main training loss that is used is the difference between the polygon shape and the ground truth segmentation mask. The network employs a neural renderer to create the polygon from its vertices, making the process fully differentiable. We demonstrate that our method outperforms the state of the art segmentation networks and deep active contour solutions in a variety of benchmarks, including medical imaging and aerial images. Our code is available at https://github.com/shirgur/ACDRNet.",0
"A method for segmenting images is presented, which involves the iterative evolution of a polygon. The polygon's vertices are moved during each iteration based on the local value of a 2D shift map, which is inferred from the input image using an encoder-decoder architecture. The main training loss is determined by comparing the polygon shape to the ground truth segmentation mask. The process is fully differentiable because a neural renderer is used to create the polygon from its vertices. The method is shown to be superior to state-of-the-art segmentation networks and deep active contour solutions in various benchmarks, including medical imaging and aerial images. The code can be found at https://github.com/shirgur/ACDRNet.",1
"Cutting and pasting image segments feels intuitive: the choice of source templates gives artists flexibility in recombining existing source material. Formally, this process takes an image set as input and outputs a collage of the set elements. Such selection from sets of source templates does not fit easily in classical convolutional neural models requiring inputs of fixed size. Inspired by advances in attention and set-input machine learning, we present a novel architecture that can generate in one forward pass image collages of source templates using set-structured representations. This paper has the following contributions: (i) a novel framework for image generation called Memory Attentive Generation of Image Collages (MAGIC) which gives artists new ways to create digital collages; (ii) from the machine-learning perspective, we show a novel Generative Adversarial Networks (GAN) architecture that uses Set-Transformer layers and set-pooling to blend sets of random image samples - a hybrid non-parametric approach.",0
"The act of cutting and pasting image segments is an intuitive process that allows artists to blend pre-existing source material in a flexible manner. However, this process does not easily fit into traditional convolutional neural models, as they require fixed-size inputs. To address this issue, we have developed a novel architecture that can generate image collages of source templates using set-structured representations. Our innovative framework, Memory Attentive Generation of Image Collages (MAGIC), allows artists to create digital collages in new and exciting ways. Additionally, we present a new Generative Adversarial Networks (GAN) architecture that utilizes Set-Transformer layers and set-pooling to blend sets of random image samples, which is a hybrid non-parametric approach.",1
"Semantic segmentation is one of the basic topics in computer vision, it aims to assign semantic labels to every pixel of an image. Unbalanced semantic label distribution could have a negative influence on segmentation accuracy. In this paper, we investigate using data augmentation approach to balance the semantic label distribution in order to improve segmentation performance. We propose using generative adversarial networks (GANs) to generate realistic images for improving the performance of semantic segmentation networks. Experimental results show that the proposed method can not only improve segmentation performance on those classes with low accuracy, but also obtain 1.3% to 2.1% increase in average segmentation accuracy. It shows that this augmentation method can boost accuracy and be easily applicable to any other segmentation models.",0
"The fundamental concept of computer vision is semantic segmentation, which involves assigning semantic labels to individual pixels within an image. An imbalanced distribution of these labels may have a detrimental effect on the accuracy of segmentation. To enhance segmentation performance, this study explores the use of data augmentation techniques to balance the distribution of semantic labels. Specifically, we suggest utilizing generative adversarial networks (GANs) to create realistic images. Our experiments indicate that this method can enhance the accuracy of segmentation for classes with low accuracy and produce an average segmentation accuracy increase of 1.3% to 2.1%. Consequently, this augmentation approach can improve accuracy and be easily adapted for other segmentation models.",1
"The medical image is characterized by the inter-class indistinction, high variability, and noise, where the recognition of pixels is challenging. Unlike previous self-attention based methods that capture context information from one level, we reformulate the self-attention mechanism from the view of the high-order graph and propose a novel method, namely Hierarchical Attention Network (HANet), to address the problem of medical image segmentation. Concretely, an HA module embedded in the HANet captures context information from neighbors of multiple levels, where these neighbors are extracted from the high-order graph. In the high-order graph, there will be an edge between two nodes only if the correlation between them is high enough, which naturally reduces the noisy attention information caused by the inter-class indistinction. The proposed HA module is robust to the variance of input and can be flexibly inserted into the existing convolution neural networks. We conduct experiments on three medical image segmentation tasks including optic disc/cup segmentation, blood vessel segmentation, and lung segmentation. Extensive results show our method is more effective and robust than the existing state-of-the-art methods.",0
"Medical images are challenging due to factors such as inter-class indistinction, high variability, and noise, which make pixel recognition difficult. Previous self-attention methods only capture context information from one level, but our novel approach, the Hierarchical Attention Network (HANet), uses the high-order graph to reformulate the self-attention mechanism. The HANet's HA module captures context information from multiple levels of neighbors, extracted from the high-order graph. Only nodes with high correlation have edges, reducing noisy attention information caused by inter-class indistinction. The HA module is robust to input variance and can be easily inserted into existing convolution neural networks. Our experiments on optic disc/cup, blood vessel, and lung segmentation tasks show HANet to be more effective and robust than existing state-of-the-art methods.",1
"Existing automatic 3D image segmentation methods usually fail to meet the clinic use. Many studies have explored an interactive strategy to improve the image segmentation performance by iteratively incorporating user hints. However, the dynamic process for successive interactions is largely ignored. We here propose to model the dynamic process of iterative interactive image segmentation as a Markov decision process (MDP) and solve it with reinforcement learning (RL). Unfortunately, it is intractable to use single-agent RL for voxel-wise prediction due to the large exploration space. To reduce the exploration space to a tractable size, we treat each voxel as an agent with a shared voxel-level behavior strategy so that it can be solved with multi-agent reinforcement learning. An additional advantage of this multi-agent model is to capture the dependency among voxels for segmentation task. Meanwhile, to enrich the information of previous segmentations, we reserve the prediction uncertainty in the state space of MDP and derive an adjustment action space leading to a more precise and finer segmentation. In addition, to improve the efficiency of exploration, we design a relative cross-entropy gain-based reward to update the policy in a constrained direction. Experimental results on various medical datasets have shown that our method significantly outperforms existing state-of-the-art methods, with the advantage of fewer interactions and a faster convergence.",0
"The current automatic 3D image segmentation methods are not suitable for clinical use. To improve the segmentation performance, many studies have proposed an interactive approach that incorporates user hints. However, the dynamic process of successive interactions is often overlooked. In this study, we suggest modeling the iterative interactive image segmentation process as a Markov decision process (MDP) and solving it using reinforcement learning (RL). However, using single-agent RL for voxel-wise prediction is not possible due to the large exploration space. Instead, we treat each voxel as an agent with a shared voxel-level behavior strategy, which is solved using multi-agent reinforcement learning. This approach also captures the dependency among voxels for segmentation tasks. Additionally, we preserve the prediction uncertainty in the state space of MDP to derive an adjustment action space, leading to more precise and finer segmentation. We also design a relative cross-entropy gain-based reward to update the policy in a constrained direction, which improves the efficiency of exploration. Our experimental results on various medical datasets show that our method outperforms existing state-of-the-art methods, with fewer interactions and faster convergence.",1
"There has been a debate in 3D medical image segmentation on whether to use 2D or 3D networks, where both pipelines have advantages and disadvantages. 2D methods enjoy a low inference time and greater transfer-ability while 3D methods are superior in performance for hard targets requiring contextual information. This paper investigates efficient 3D segmentation from another perspective, which uses 2D networks to mimic 3D segmentation. To compensate the lack of contextual information in 2D manner, we propose to thicken the 2D network inputs by feeding multiple slices as multiple channels into 2D networks and thus 3D contextual information is incorporated. We also put forward to use early-stage multiplexing and slice sensitive attention to solve the confusion problem of information loss which occurs when 2D networks face thickened inputs. With this design, we achieve a higher performance while maintaining a lower inference latency on a few abdominal organs from CT scans, in particular when the organ has a peculiar 3D shape and thus strongly requires contextual information, demonstrating our method's effectiveness and ability in capturing 3D information. We also point out that ""thickened"" 2D inputs pave a new method of 3D segmentation, and look forward to more efforts in this direction. Experiments on segmenting a few abdominal targets in particular blood vessels which require strong 3D contexts demonstrate the advantages of our approach.",0
"The debate surrounding 3D medical image segmentation has revolved around the use of 2D or 3D networks, each with its own advantages and disadvantages. While 2D methods offer faster inference times and greater transferability, 3D methods outperform them in identifying difficult targets that require contextual information. This paper proposes a novel approach to efficient 3D segmentation, wherein 2D networks are employed to mimic 3D segmentation. To overcome the contextual information deficit in 2D networks, we suggest thickening the input by feeding multiple slices as multiple channels into the 2D networks. This allows for the incorporation of 3D contextual information. We also propose using early-stage multiplexing and slice-sensitive attention to address the information loss confusion problem that arises when 2D networks face thickened inputs. Our design achieves higher performance while maintaining a lower inference latency on a few abdominal organs from CT scans, especially when the organ has a unique 3D shape that requires contextual information. This demonstrates the effectiveness and ability of our method in capturing 3D information. Furthermore, we suggest that ""thickened"" 2D inputs offer a new method for 3D segmentation and anticipate further research in this direction. We conducted experiments on segmenting a few abdominal targets, particularly blood vessels that require strong 3D contexts, which demonstrate the advantages of our approach.",1
"Identify the cells' nuclei is the important point for most medical analyses. To assist doctors finding the accurate cell' nuclei location automatically is highly demanded in the clinical practice. Recently, fully convolutional neural network (FCNs) serve as the back-bone in many image segmentation, like liver and tumer segmentation in medical field, human body block in technical filed. The cells' nuclei identification task is also kind of image segmentation. To achieve this, we prefer to use deep learning algorithms. we construct three general frameworks, one is Mask Region-based Convolutional Neural Network (Mask RCNN), which has the high performance in many image segmentations, one is U-net, which has the high generalization performance on small dataset and the other is DenseUNet, which is mixture network architecture with Dense Net and U-net. we compare the performance of these three frameworks. And we evaluated our method on the dataset of data science bowl 2018 challenge. For single model without any ensemble, they all have good performance.",0
"Most medical analyses require the identification of cells' nuclei, making it a crucial point. In clinical practice, doctors require assistance in locating the accurate cell nuclei location, and there is a high demand for automatic identification. The use of fully convolutional neural networks (FCNs) has been prevalent in many image segmentation tasks, such as liver and tumor segmentation in the medical field and human body block in the technical field. The identification of cells' nuclei also falls under image segmentation tasks and requires the use of deep learning algorithms. We have constructed three general frameworks, namely Mask Region-based Convolutional Neural Network (Mask RCNN), U-net, and DenseUNet, and have compared their performance. Mask RCNN has shown high performance in many image segmentations, while U-net has demonstrated high generalization performance on small datasets. DenseUNet is a mixture network architecture of Dense Net and U-net. We have evaluated our method on the dataset of data science bowl 2018 challenge and found that all three frameworks have good performance without any ensemble in a single model.",1
"In this paper, we demonstrate the ability to discriminate between cultivated maize plant and grass or grass-like weed image segments using the context surrounding the image segments. While convolutional neural networks have brought state of the art accuracies within object detection, errors arise when objects in different classes share similar features. This scenario often occurs when objects in images are viewed at too small of a scale to discern distinct differences in features, causing images to be incorrectly classified or localized. To solve this problem, we will explore using context when classifying image segments. This technique involves feeding a convolutional neural network a central square image along with a border of its direct surroundings at train and test times. This means that although images are labelled at a smaller scale to preserve accurate localization, the network classifies the images and learns features that include the wider context. We demonstrate the benefits of this context technique in the object detection task through a case study of grass (foxtail) and grass-like (yellow nutsedge) weed detection in maize fields. In this standard situation, adding context alone nearly halved the error of the neural network from 7.1% to 4.3%. After only one epoch with context, the network also achieved a higher accuracy than the network without context did after 50 epochs. The benefits of using the context technique are likely to particularly evident in agricultural contexts in which parts (such as leaves) of several plants may appear similar when not taking into account the context in which those parts appear.",0
"This study showcases the ability to differentiate between cultivated maize plants and grass or grass-like weed images by utilizing the surrounding context of the image segments. Although convolutional neural networks have achieved exceptional accuracy in object detection, issues arise when objects from different categories share similar features, particularly at smaller scales where distinct differences are difficult to discern. To address this issue, we propose using context to classify image segments. This approach involves feeding a convolutional neural network with a central square image and its surrounding border during training and testing. By incorporating a wider context into the feature learning process, the network can accurately classify images while preserving localization. We demonstrate the effectiveness of this technique in weed detection in maize fields, where context reduced neural network errors by almost 50%. Furthermore, after just one epoch with context, the network achieved higher accuracy than the network without context did after 50 epochs. This context technique is especially valuable in agricultural settings where similar plant parts may appear identical without considering their context.",1
"The screening of baggage using X-ray scanners is now routine in aviation security with automatic threat detection approaches, based on 3D X-ray computed tomography (CT) images, known as Automatic Threat Recognition (ATR) within the aviation security industry. These current strategies use pre-defined threat material signatures in contrast to adaptability towards new and emerging threat signatures. To address this issue, the concept of adaptive automatic threat recognition (AATR) was proposed in previous work. In this paper, we present a solution to AATR based on such X-ray CT baggage scan imagery. This aims to address the issues of rapidly evolving threat signatures within the screening requirements. Ideally, the detection algorithms deployed within the security scanners should be readily adaptable to different situations with varying requirements of threat characteristics (e.g., threat material, physical properties of objects). We tackle this issue using a novel adaptive machine learning methodology with our solution consisting of a multi-scale 3D CT image segmentation algorithm, a multi-class support vector machine (SVM) classifier for object material recognition and a strategy to enable the adaptability of our approach. Experiments are conducted on both open and sequestered 3D CT baggage image datasets specifically collected for the AATR study. Our proposed approach performs well on both recognition and adaptation. Overall our approach can achieve the probability of detection around 90% with a probability of false alarm below 20%. Our AATR shows the capabilities of adapting to varying types of materials, even the unknown materials which are not available in the training data, adapting to varying required probability of detection and adapting to varying scales of the threat object.",0
"The use of X-ray scanners to screen baggage in aviation security has become a standard practice, with Automatic Threat Recognition (ATR) based on 3D X-ray computed tomography (CT) images being commonly used. However, these current methods rely on pre-defined threat material signatures and are not adaptable to new and emerging threats. To address this issue, a concept called adaptive automatic threat recognition (AATR) was proposed in previous research. In this paper, we present a solution to AATR that utilizes X-ray CT baggage scan imagery to address the rapidly evolving threat signatures in screening requirements. Our approach uses a novel adaptive machine learning methodology that includes a multi-scale 3D CT image segmentation algorithm, a multi-class support vector machine (SVM) classifier for object material recognition, and a strategy to enable adaptability. We conducted experiments on open and sequestered 3D CT baggage image datasets specifically collected for the AATR study, and our proposed approach performed well on both recognition and adaptation. Our AATR can adapt to varying types of materials, even unknown ones, varying probability of detection, and varying scales of the threat object. Our approach achieves a probability of detection around 90% with a probability of false alarm below 20%.",1
"Image co-segmentation is important for its advantage of alleviating the ill-pose nature of image segmentation through exploring the correlation between related images. Many automatic image co-segmentation algorithms have been developed in the last decade, which are investigated comprehensively in this paper. We firstly analyze visual/semantic cues for guiding image co-segmentation, including object cues and correlation cues. Then we describe the traditional methods in three categories of object elements based, object regions/contours based, common object model based. In the next part, deep learning based methods are reviewed. Furthermore, widely used test datasets and evaluation criteria are introduced and the reported performances of the surveyed algorithms are compared with each other. Finally, we discuss the current challenges and possible future directions and conclude the paper. Hopefully, this comprehensive investigation will be helpful for the development of image co-segmentation technique.",0
"Exploring the correlation between related images, image co-segmentation is advantageous in overcoming the ill-posed nature of image segmentation. This paper comprehensively reviews the various automatic image co-segmentation algorithms developed in the last decade. The analysis begins by examining visual/semantic cues, such as object cues and correlation cues, that guide image co-segmentation. Subsequently, traditional methods are described, categorized as object elements based, object regions/contours based, and common object model based. The review then delves into deep learning-based methods. Additionally, commonly used test datasets and evaluation criteria are introduced, and the performances of the surveyed algorithms are compared. Finally, the paper concludes by discussing current challenges, possible future directions, and the potential benefits of this comprehensive investigation for the development of image co-segmentation techniques.",1
"Radar signals have been dramatically increasing in complexity, limiting the source separation ability of traditional approaches. In this paper we propose a Deep Learning-based clustering method, which encodes concurrent signals into images, and, for the first time, tackles clustering with image segmentation. Novel loss functions are introduced to optimize a Neural Network to separate the input pulses into pure and non-fragmented clusters. Outperforming a variety of baselines, the proposed approach is capable of clustering inputs directly with a Neural Network, in an end-to-end fashion.",0
"The complexity of radar signals has significantly increased, which has resulted in traditional methods being unable to separate sources effectively. To address this issue, we suggest a clustering method using Deep Learning. The method transforms concurrent signals into images and uses image segmentation to cluster them for the first time. The approach introduces innovative loss functions that help optimize a Neural Network to identify pure and non-fragmented clusters from input pulses. The proposed technique outperforms several baselines and can cluster inputs directly with a Neural Network, making it an end-to-end solution.",1
"Over the last decade, electron microscopy has improved up to a point that generating high quality gigavoxel sized datasets only requires a few hours. Automated image analysis, particularly image segmentation, however, has not evolved at the same pace. Even though state-of-the-art methods such as U-Net and DeepLab have improved segmentation performance substantially, the required amount of labels remains too expensive. Active learning is the subfield in machine learning that aims to mitigate this burden by selecting the samples that require labeling in a smart way. Many techniques have been proposed, particularly for image classification, to increase the steepness of learning curves. In this work, we extend these techniques to deep CNN based image segmentation. Our experiments on three different electron microscopy datasets show that active learning can improve segmentation quality by 10 to 15% in terms of Jaccard score compared to standard randomized sampling.",0
"In the past ten years, advances in electron microscopy have enabled the creation of high-quality gigavoxel datasets in just a few hours. However, automated image analysis, specifically image segmentation, has not progressed at the same rate. Despite the significant improvements in segmentation performance by state-of-the-art methods like U-Net and DeepLab, the cost of labeling required samples remains prohibitive. Active learning is a subfield of machine learning that seeks to solve this problem by intelligently selecting samples for labeling, and many techniques have been proposed to accelerate the learning process for image classification. In this study, we apply these techniques to deep CNN-based image segmentation and demonstrate that active learning can improve Jaccard scores by 10-15% compared to standard randomized sampling on three different electron microscopy datasets.",1
"Convolutional neural networks (CNNs) have been widely and successfully used for medical image segmentation. However, CNNs are typically considered to require large numbers of dedicated expert-segmented training volumes, which may be limiting in practice. This work investigates whether clinically obtained segmentations which are readily available in picture archiving and communication systems (PACS) could provide a possible source of data to train a CNN for segmentation of organs-at-risk (OARs) in radiotherapy treatment planning. In such data, delineations of structures deemed irrelevant to the target clinical use may be lacking. To overcome this issue, we use multi-label instead of multi-class segmentation. We empirically assess how many clinical delineations would be sufficient to train a CNN for the segmentation of OARs and find that increasing the training set size beyond a limited number of images leads to sharply diminishing returns. Moreover, we find that by using multi-label segmentation, missing structures in the reference standard do not have a negative effect on overall segmentation accuracy. These results indicate that segmentations obtained in a clinical workflow can be used to train an accurate OAR segmentation model.",0
"The effectiveness of convolutional neural networks (CNNs) in medical image segmentation has been well-established. However, their reliance on a significant number of expert-segmented training volumes may hinder their practical application. This study explores the possibility of utilizing clinically-obtained segmentations available in picture archiving and communication systems (PACS) to train a CNN for organs-at-risk (OARs) segmentation in radiotherapy treatment planning. As these segmentations may lack irrelevant structures for the clinical target, multi-label segmentation is used to address this limitation. Through empirical assessment, this study determines the optimal number of clinical delineations required for accurate OAR segmentation and observes that increased training set size beyond a certain point may not yield significant improvements. Furthermore, the use of multi-label segmentation mitigates the negative impact of missing structures in the reference standard on overall segmentation accuracy. Thus, the study concludes that CNNs trained on clinical segmentations can effectively perform OAR segmentation.",1
"Regular inspection of rail valves and engines is an important task to ensure the safety and efficiency of railway networks around the globe. Over the past decade, computer vision and pattern recognition based techniques have gained traction for such inspection and defect detection tasks. An automated end-to-end trained system can potentially provide a low-cost, high throughput, and cheap alternative to manual visual inspection of these components. However, such systems require a huge amount of defective images for networks to understand complex defects. In this paper, a multi-phase deep learning based technique is proposed to perform accurate fault detection of rail-valves. Our approach uses a two-step method to perform high precision image segmentation of rail-valves resulting in pixel-wise accurate segmentation. Thereafter, a computer vision technique is used to identify faulty valves. We demonstrate that the proposed approach results in improved detection performance when compared to current state-of-theart techniques used in fault detection.",0
"Ensuring the safety and efficiency of railway networks globally requires regular inspection of rail valves and engines. In recent years, computer vision and pattern recognition techniques have gained popularity for this task, as they offer a cost-effective and efficient alternative to manual visual inspection. However, such systems require a large number of defective images to accurately detect complex defects. In this study, a multi-phase deep learning technique is proposed to accurately detect faults in rail valves. The proposed approach uses a two-step method for high precision image segmentation and faulty valve identification. Results show that this approach outperforms current state-of-the-art techniques in fault detection.",1
"We introduce a novel Deep Learning framework, which quantitatively estimates image segmentation quality without the need for human inspection or labeling. We refer to this method as a Quality Assurance Network -- QANet. Specifically, given an image and a `proposed' corresponding segmentation, obtained by any method including manual annotation, the QANet solves a regression problem in order to estimate a predefined quality measure with respect to the unknown ground truth. The QANet is by no means yet another segmentation method. Instead, it performs a multi-level, multi-feature comparison of an image-segmentation pair based on a unique network architecture, called the RibCage.   To demonstrate the strength of the QANet, we addressed the evaluation of instance segmentation using two different datasets from different domains, namely, high throughput live cell microscopy images from the Cell Segmentation Benchmark and natural images of plants from the Leaf Segmentation Challenge. While synthesized segmentations were used to train the QANet, it was tested on segmentations obtained by publicly available methods that participated in the different challenges. We show that the QANet accurately estimates the scores of the evaluated segmentations with respect to the hidden ground truth, as published by the challenges' organizers.   The code is available at: TBD.",0
"Our innovative Deep Learning framework, called the Quality Assurance Network (QANet), can quantitatively measure image segmentation quality without requiring human inspection or labeling. The QANet is not a segmentation method, but instead utilizes a unique network architecture, the RibCage, to perform a multi-level, multi-feature comparison of an image-segmentation pair. By solving a regression problem, the QANet can estimate a predefined quality measure for a given image and its corresponding segmentation. We tested the QANet on two different datasets, the Cell Segmentation Benchmark and the Leaf Segmentation Challenge, using synthesized segmentations for training and publicly available methods for testing. We demonstrate that the QANet accurately estimates the scores of the evaluated segmentations relative to the hidden ground truth determined by the challenge organizers. Our code is available at: TBD.",1
"Many recent medical segmentation systems rely on powerful deep learning models to solve highly specific tasks. To maximize performance, it is standard practice to evaluate numerous pipelines with varying model topologies, optimization parameters, pre- & postprocessing steps, and even model cascades. It is often not clear how the resulting pipeline transfers to different tasks. We propose a simple and thoroughly evaluated deep learning framework for segmentation of arbitrary medical image volumes. The system requires no task-specific information, no human interaction and is based on a fixed model topology and a fixed hyperparameter set, eliminating the process of model selection and its inherent tendency to cause method-level over-fitting. The system is available in open source and does not require deep learning expertise to use. Without task-specific modifications, the system performed better than or similar to highly specialized deep learning methods across 3 separate segmentation tasks. In addition, it ranked 5-th and 6-th in the first and second round of the 2018 Medical Segmentation Decathlon comprising another 10 tasks. The system relies on multi-planar data augmentation which facilitates the application of a single 2D architecture based on the familiar U-Net. Multi-planar training combines the parameter efficiency of a 2D fully convolutional neural network with a systematic train- and test-time augmentation scheme, which allows the 2D model to learn a representation of the 3D image volume that fosters generalization.",0
"Recent medical segmentation systems often rely on powerful deep learning models that are highly specific to certain tasks. To ensure optimal performance, it is common practice to evaluate multiple pipelines with varying model configurations, optimization parameters, and pre- and post-processing steps. However, it is unclear how well these pipelines translate to different tasks. To address this issue, we propose a deep learning framework for segmenting medical image volumes that requires no task-specific information, human interaction, or deep learning expertise. The system uses a fixed model topology and hyperparameter set, eliminating the need for model selection and reducing the risk of method-level overfitting. Our system outperformed or performed similarly to specialized deep learning methods across three segmentation tasks and ranked fifth and sixth in the 2018 Medical Segmentation Decathlon. We achieved these results using multi-planar data augmentation, which allows a single 2D architecture based on the U-Net to learn a representation of the 3D image volume that fosters generalization.",1
"The Dice score and Jaccard index are commonly used metrics for the evaluation of segmentation tasks in medical imaging. Convolutional neural networks trained for image segmentation tasks are usually optimized for (weighted) cross-entropy. This introduces an adverse discrepancy between the learning optimization objective (the loss) and the end target metric. Recent works in computer vision have proposed soft surrogates to alleviate this discrepancy and directly optimize the desired metric, either through relaxations (soft-Dice, soft-Jaccard) or submodular optimization (Lov\'asz-softmax). The aim of this study is two-fold. First, we investigate the theoretical differences in a risk minimization framework and question the existence of a weighted cross-entropy loss with weights theoretically optimized to surrogate Dice or Jaccard. Second, we empirically investigate the behavior of the aforementioned loss functions w.r.t. evaluation with Dice score and Jaccard index on five medical segmentation tasks. Through the application of relative approximation bounds, we show that all surrogates are equivalent up to a multiplicative factor, and that no optimal weighting of cross-entropy exists to approximate Dice or Jaccard measures. We validate these findings empirically and show that, while it is important to opt for one of the target metric surrogates rather than a cross-entropy-based loss, the choice of the surrogate does not make a statistical difference on a wide range of medical segmentation tasks.",0
"The Dice score and Jaccard index are commonly used to evaluate segmentation tasks in medical imaging. However, convolutional neural networks trained for these tasks are typically optimized for cross-entropy, creating a discrepancy between the optimization objective and the desired metric. To address this, soft surrogates have been proposed to directly optimize the desired metric, either through relaxations or submodular optimization. This study aims to investigate the theoretical and empirical differences between using a weighted cross-entropy loss and using target metric surrogates. We show that all surrogates are equivalent up to a multiplicative factor and that no optimal weighting of cross-entropy can approximate Dice or Jaccard measures. We also demonstrate that while it is important to use a target metric surrogate, the choice of surrogate does not significantly impact the results on medical segmentation tasks.",1
"The scarcity of labeled data often limits the application of supervised deep learning techniques for medical image segmentation. This has motivated the development of semi-supervised techniques that learn from a mixture of labeled and unlabeled images. In this paper, we propose a novel semi-supervised method that, in addition to supervised learning on labeled training images, learns to predict segmentations consistent under a given class of transformations on both labeled and unlabeled images. More specifically, in this work we explore learning equivariance to elastic deformations. We implement this through: 1) a Siamese architecture with two identical branches, each of which receives a differently transformed image, and 2) a composite loss function with a supervised segmentation loss term and an unsupervised term that encourages segmentation consistency between the predictions of the two branches. We evaluate the method on a public dataset of chest radiographs with segmentations of anatomical structures using 5-fold cross-validation. The proposed method reaches significantly higher segmentation accuracy compared to supervised learning. This is due to learning transformation consistency on both labeled and unlabeled images, with the latter contributing the most. We achieve the performance comparable to state-of-the-art chest X-ray segmentation methods while using substantially fewer labeled images.",0
"Supervised deep learning techniques for medical image segmentation are often limited by the scarcity of labeled data. This has led to the development of semi-supervised methods that utilize both labeled and unlabeled images. In this study, we introduce a new semi-supervised method that not only uses supervised learning on labeled training images, but also learns to predict segmentations that are consistent under a particular class of transformations on both labeled and unlabeled images. Specifically, we investigate equivariance to elastic deformations. This is achieved by using a Siamese architecture with two identical branches, each receiving a differently transformed image, and a composite loss function that includes a supervised segmentation loss term and an unsupervised term that promotes segmentation consistency between the two branches. We evaluate our method on a public dataset of chest radiographs with segmentations of anatomical structures using 5-fold cross-validation. Our proposed method achieves significantly higher segmentation accuracy compared to supervised learning, primarily due to learning transformation consistency on both labeled and unlabeled images, with the latter contributing the most. Furthermore, we achieve comparable performance to state-of-the-art chest X-ray segmentation methods while using substantially fewer labeled images.",1
"In this paper, we aim to improve the performance of semantic image segmentation in a semi-supervised setting in which training is effectuated with a reduced set of annotated images and additional non-annotated images. We present a method based on an ensemble of deep segmentation models. Each model is trained on a subset of the annotated data, and uses the non-annotated images to exchange information with the other models, similar to co-training. Even if each model learns on the same non-annotated images, diversity is preserved with the use of adversarial samples. Our results show that this ability to simultaneously train models, which exchange knowledge while preserving diversity, leads to state-of-the-art results on two challenging medical image datasets.",0
"The purpose of this paper is to enhance the performance of semantic image segmentation in a semi-supervised context where training is carried out with a smaller collection of annotated images and additional non-annotated images. An approach grounded on a group of deep segmentation models is presented. Each model is trained on a segment of the annotated data, and the non-annotated images are utilized to share information with the other models, much like co-training. Despite training on the same non-annotated images, adversarial samples are used to maintain diversity. Our findings indicate that the capacity to train models concurrently while exchanging knowledge and maintaining diversity results in cutting-edge outcomes on two tough medical image datasets.",1
"State-of-the-art approaches for semantic segmentation rely on deep convolutional neural networks trained on fully annotated datasets, that have been shown to be notoriously expensive to collect, both in terms of time and money. To remedy this situation, weakly supervised methods leverage other forms of supervision that require substantially less annotation effort, but they typically present an inability to predict precise object boundaries due to approximate nature of the supervisory signals in those regions. While great progress has been made in improving the performance, many of these weakly supervised methods are highly tailored to their own specific settings. This raises challenges in reusing algorithms and making steady progress. In this paper, we intentionally avoid such practices when tackling weakly supervised semantic segmentation. In particular, we train standard neural networks with partial cross-entropy loss function for the labeled pixels and our proposed Gated CRF loss for the unlabeled pixels. The Gated CRF loss is designed to deliver several important assets: 1) it enables flexibility in the kernel construction to mask out influence from undesired pixel positions; 2) it offloads learning contextual relations to CNN and concentrates on semantic boundaries; 3) it does not rely on high-dimensional filtering and thus has a simple implementation. Throughout the paper we present the advantages of the loss function, analyze several aspects of weakly supervised training, and show that our `purist' approach achieves state-of-the-art performance for both click-based and scribble-based annotations.",0
"Advanced techniques for semantic segmentation currently depend on deep convolutional neural networks that are trained on completely annotated datasets. However, collecting such data is notoriously time-consuming and expensive. To address this issue, weakly supervised methods use alternative forms of supervision that require considerably less annotation effort. Unfortunately, these methods often struggle to precisely predict object boundaries due to the approximate nature of the supervisory signals. While many weakly supervised techniques have been developed to improve performance, they are often customized for specific settings, making it difficult to reuse algorithms and make consistent progress. In our paper, we avoid this issue by adopting a ""purist"" approach to weakly supervised semantic segmentation. Specifically, we train standard neural networks using a partial cross-entropy loss function for labeled pixels and our proposed Gated CRF loss for unlabeled pixels. The Gated CRF loss provides several key benefits, including flexibility in kernel construction, offloading contextual relation learning to CNN, and simple implementation without relying on high-dimensional filtering. We demonstrate the benefits of this approach throughout the paper, analyze various aspects of weakly supervised training, and show that our method achieves state-of-the-art performance for both click-based and scribble-based annotations.",1
"Generalization capability to unseen domains is crucial for machine learning models when deploying to real-world conditions. We investigate the challenging problem of domain generalization, i.e., training a model on multi-domain source data such that it can directly generalize to target domains with unknown statistics. We adopt a model-agnostic learning paradigm with gradient-based meta-train and meta-test procedures to expose the optimization to domain shift. Further, we introduce two complementary losses which explicitly regularize the semantic structure of the feature space. Globally, we align a derived soft confusion matrix to preserve general knowledge about inter-class relationships. Locally, we promote domain-independent class-specific cohesion and separation of sample features with a metric-learning component. The effectiveness of our method is demonstrated with new state-of-the-art results on two common object recognition benchmarks. Our method also shows consistent improvement on a medical image segmentation task.",0
"The ability for machine learning models to generalize to new domains is crucial for real-world deployment. Our research focuses on the challenging issue of domain generalization, which involves training a model on multi-domain source data so that it can effectively generalize to target domains with unknown statistics. To tackle this, we use a model-agnostic approach with meta-train and meta-test procedures that expose the optimization to domain shift. Additionally, we introduce two complementary losses that explicitly regulate the semantic structure of the feature space. We align a derived soft confusion matrix globally to preserve general knowledge about inter-class relationships, and promote domain-independent class-specific cohesion and separation of sample features locally with a metric-learning component. Our approach demonstrates significant performance improvement on two object recognition benchmarks and a medical image segmentation task, achieving state-of-the-art results.",1
"Semantic road region segmentation is a high-level task, which paves the way towards road scene understanding. This paper presents a residual network trained for semantic road segmentation. Firstly, we represent the projections of road disparities in the v-disparity map as a linear model, which can be estimated by optimizing the v-disparity map using dynamic programming. This linear model is then utilized to reduce the redundant information in the left and right road images. The right image is also transformed into the left perspective view, which greatly enhances the road surface similarity between the two images. Finally, the processed stereo images and their disparity maps are concatenated to create a set of 3D images, which are then utilized to train our neural network. The experimental results illustrate that our network achieves a maximum F1-measure of approximately 91.19% when analyzing the images from the KITTI road dataset.",0
"The aim of semantic road region segmentation is to comprehend the road scene at a higher level. This study introduces a residual network that is trained for the purpose of semantic road segmentation. Initially, we create a linear model of the projections of road disparities in the v-disparity map by optimizing it using dynamic programming. This model is then applied to eliminate irrelevant information in the left and right road images. In addition, we transform the right image to the left perspective view, which enhances the road surface similarity between the two images. Eventually, we combine the processed stereo images and their disparity maps to form a set of 3D images, which are used to train our neural network. Our testing results demonstrate that our network attains a maximum F1-measure of approximately 91.19% when analyzing the images from the KITTI road dataset.",1
"We present a collection of 24 multiple object scenes each recorded under 18 multiple light source illumination scenarios. The illuminants are varying in dominant spectral colours, intensity and distance from the scene. We mainly address the realistic scenarios for evaluation of computational colour constancy algorithms, but also have aimed to make the data as general as possible for computational colour science and computer vision. Along with the images of the scenes, we provide spectral characteristics of the camera, light sources and the objects and include pixel-by-pixel ground truth annotation of uniformly coloured object surfaces thus making this useful for benchmarking colour-based image segmentation algorithms. The dataset is freely available at https://github.com/visillect/mls-dataset.",0
"We have compiled a set of 24 scenes, each containing multiple objects that were recorded under 18 different illumination scenarios with varying dominant spectral colors, intensity, and distance from the scene. Our primary focus is on providing realistic scenarios for evaluating computational color constancy algorithms. However, we have also ensured that the data is useful for computational color science and computer vision. In addition to the scene images, we have included spectral characteristics of the camera, light sources, and objects, as well as pixel-by-pixel ground truth annotation of uniformly colored object surfaces, making it a valuable resource for benchmarking color-based image segmentation algorithms. The dataset is available for free on https://github.com/visillect/mls-dataset.",1
"Neural networks are becoming more and more popular for the analysis of physiological time-series. The most successful deep learning systems in this domain combine convolutional and recurrent layers to extract useful features to model temporal relations. Unfortunately, these recurrent models are difficult to tune and optimize. In our experience, they often require task-specific modifications, which makes them challenging to use for non-experts. We propose U-Time, a fully feed-forward deep learning approach to physiological time series segmentation developed for the analysis of sleep data. U-Time is a temporal fully convolutional network based on the U-Net architecture that was originally proposed for image segmentation. U-Time maps sequential inputs of arbitrary length to sequences of class labels on a freely chosen temporal scale. This is done by implicitly classifying every individual time-point of the input signal and aggregating these classifications over fixed intervals to form the final predictions. We evaluated U-Time for sleep stage classification on a large collection of sleep electroencephalography (EEG) datasets. In all cases, we found that U-Time reaches or outperforms current state-of-the-art deep learning models while being much more robust in the training process and without requiring architecture or hyperparameter adaptation across tasks.",0
"Physiological time-series analysis is increasingly using neural networks. The most effective deep learning systems in this field utilize convolutional and recurrent layers to extract useful features for modeling temporal relations. However, these recurrent models are challenging to optimize and often require specific adjustments for each task, making them difficult for non-experts to use. To address this, we introduce U-Time, a fully feed-forward deep learning method for sleep data analysis. U-Time is a temporal fully convolutional network based on the U-Net architecture, originally designed for image segmentation. It maps sequential inputs of any length to sequences of class labels on a chosen temporal scale by classifying every time-point of the input signal and aggregating the classifications over fixed intervals. We assessed U-Time for sleep stage classification using a large collection of sleep EEG datasets and found that it performs as well as or better than current state-of-the-art deep learning models. Additionally, U-Time is more robust in the training process and does not require architecture or hyperparameter adaptation across tasks.",1
"Unsupervised video object segmentation has often been tackled by methods based on recurrent neural networks and optical flow. Despite their complexity, these kinds of approaches tend to favour short-term temporal dependencies and are thus prone to accumulating inaccuracies, which cause drift over time. Moreover, simple (static) image segmentation models, alone, can perform competitively against these methods, which further suggests that the way temporal dependencies are modelled should be reconsidered. Motivated by these observations, in this paper we explore simple yet effective strategies to model long-term temporal dependencies. Inspired by the non-local operators of [70], we introduce a technique to establish dense correspondences between pixel embeddings of a reference ""anchor"" frame and the current one. This allows the learning of pairwise dependencies at arbitrarily long distances without conditioning on intermediate frames. Without online supervision, our approach can suppress the background and precisely segment the foreground object even in challenging scenarios, while maintaining consistent performance over time. With a mean IoU of $81.7\%$, our method ranks first on the DAVIS-2016 leaderboard of unsupervised methods, while still being competitive against state-of-the-art online semi-supervised approaches. We further evaluate our method on the FBMS dataset and the ViSal video saliency dataset, showing results competitive with the state of the art.",0
"Methods for unsupervised video object segmentation often rely on recurrent neural networks and optical flow. However, these approaches have a tendency to accumulate inaccuracies over time due to their focus on short-term temporal dependencies. Interestingly, even simple static image segmentation models can perform well in comparison. Therefore, we propose simple yet effective strategies to model long-term temporal dependencies in this study. By utilizing a technique inspired by non-local operators, we establish dense correspondences between pixel embeddings of a reference frame and the current one, allowing for the learning of pairwise dependencies at arbitrary distances without intermediate frames. Our approach successfully suppresses background and accurately segments foreground objects, even in challenging scenarios, without online supervision. With a mean IoU of 81.7%, our method outperforms other unsupervised methods on the DAVIS-2016 leaderboard and is competitive with state-of-the-art online semi-supervised approaches. Additionally, we demonstrate our method's effectiveness on the FBMS dataset and the ViSal video saliency dataset, achieving results comparable to the current state of the art.",1
"Objective: Herein, a neural network-based liver segmentation algorithm is proposed, and its performance was evaluated using abdominal computed tomography (CT) images. Methods: A fully convolutional network was developed to overcome the volumetric image segmentation problem. To guide a neural network to accurately delineate a target liver object, the network was deeply supervised by applying the adaptive self-supervision scheme to derive the essential contour, which acted as a complement with the global shape. The discriminative contour, shape, and deep features were internally merged for the segmentation results. Results and Conclusion: 160 abdominal CT images were used for training and validation. The quantitative evaluation of the proposed network was performed through an eight-fold cross-validation. The result showed that the method, which uses the contour feature, segmented the liver more accurately than the state-of-the-art with a 2.13% improvement in the dice score. Significance: In this study, a new framework was introduced to guide a neural network and learn complementary contour features. The proposed neural network demonstrates that the guided contour features can significantly improve the performance of the segmentation task.",0
"The aim of this study was to suggest a liver segmentation algorithm using a neural network and to assess its effectiveness with abdominal CT images. A fully convolutional network was created to address volumetric image segmentation challenges. The network was deeply supervised using an adaptive self-supervision scheme to derive the essential contour that complemented the global shape and assisted the network in accurately identifying a target liver object. Discriminative contour, shape, and deep features were combined for the segmentation results. The proposed network was trained and validated using 160 abdominal CT images, and an eight-fold cross-validation was performed to quantitatively evaluate the network's performance. The results demonstrated that the method that utilized the contour feature was more accurate in liver segmentation than the state-of-the-art, with a 2.13% improvement in the dice score. This study introduced a new framework to guide a neural network and learn complementary contour features, which significantly improved the segmentation task's performance.",1
"With the advancement of remote-sensed imaging large volumes of very high resolution land cover images can now be obtained. Automation of object recognition in these 2D images, however, is still a key issue. High intra-class variance and low inter-class variance in Very High Resolution (VHR) images hamper the accuracy of prediction in object recognition tasks. Most successful techniques in various computer vision tasks recently are based on deep supervised learning. In this work, a deep Convolutional Neural Network (CNN) based on symmetric encoder-decoder architecture with skip connections is employed for the 2D semantic segmentation of most common land cover object classes - impervious surface, buildings, low vegetation, trees and cars. Atrous convolutions are employed to have large receptive field in the proposed CNN model. Further, the CNN outputs are post-processed using Fully Connected Conditional Random Field (FCRF) model to refine the CNN pixel label predictions. The proposed CNN-FCRF model achieves an overall accuracy of 90.5% on the ISPRS Vaihingen Dataset.",0
"Obtaining large volumes of highly detailed land cover images has become possible with the advancements in remote-sensed imaging. However, recognizing objects in these 2D images automatically remains a challenge due to the high intra-class variance and low inter-class variance in Very High Resolution (VHR) images. To address this, deep supervised learning techniques have been successful in various computer vision tasks, and this work employs a deep Convolutional Neural Network (CNN) with a symmetric encoder-decoder architecture and skip connections to perform 2D semantic segmentation of common land cover object classes such as buildings, impervious surfaces, cars, low vegetation, and trees. The proposed CNN model utilizes atrous convolutions to increase the receptive field. Additionally, the CNN outputs are refined using a Fully Connected Conditional Random Field (FCRF) model. The overall accuracy of the proposed CNN-FCRF model on the ISPRS Vaihingen Dataset is 90.5%.",1
"Recently, Fully Convolutional Network (FCN) seems to be the go-to architecture for image segmentation, including semantic scene parsing. However, it is difficult for a generic FCN to discriminate pixels around the object boundaries, thus FCN based methods may output parsing results with inaccurate boundaries. Meanwhile, level set based active contours are superior to the boundary estimation due to the sub-pixel accuracy that they achieve. However, they are quite sensitive to initial settings. To address these limitations, in this paper we propose a novel Deep Multiphase Level Set (DMLS) method for semantic scene parsing, which efficiently incorporates multiphase level sets into deep neural networks. The proposed method consists of three modules, i.e., recurrent FCNs, adaptive multiphase level set, and deeply supervised learning. More specifically, recurrent FCNs learn multi-level representations of input images with different contexts. Adaptive multiphase level set drives the discriminative contour for each semantic class, which makes use of the advantages of both global and local information. In each time-step of the recurrent FCNs, deeply supervised learning is incorporated for model training. Extensive experiments on three public benchmarks have shown that our proposed method achieves new state-of-the-art performances.",0
"Image segmentation, particularly semantic scene parsing, has recently favored the use of Fully Convolutional Networks (FCN). However, due to their generic nature, FCN-based methods often struggle to accurately differentiate pixels around object boundaries, leading to parsing results with imprecise boundaries. On the other hand, level set based active contours provide superior boundary estimation with sub-pixel accuracy but are sensitive to initial settings. To overcome these limitations, this paper presents a novel approach, the Deep Multiphase Level Set (DMLS), that integrates multiphase level sets into deep neural networks for semantic scene parsing. The DMLS method comprises three modules: recurrent FCNs that learn multi-level representations of input images, adaptive multiphase level sets that drive discriminative contours for each semantic class by leveraging global and local information, and deeply supervised learning incorporated for model training in each time-step of the recurrent FCNs. Extensive experiments on three public benchmarks demonstrate that our proposed method achieves superior state-of-the-art performances.",1
"Deep neural networks enable highly accurate image segmentation, but require large amounts of manually annotated data for supervised training. Few-shot learning aims to address this shortcoming by learning a new class from a few annotated support examples. We introduce, a novel few-shot framework, for the segmentation of volumetric medical images with only a few annotated slices. Compared to other related works in computer vision, the major challenges are the absence of pre-trained networks and the volumetric nature of medical scans. We address these challenges by proposing a new architecture for few-shot segmentation that incorporates 'squeeze & excite' blocks. Our two-armed architecture consists of a conditioner arm, which processes the annotated support input and generates a task-specific representation. This representation is passed on to the segmenter arm that uses this information to segment the new query image. To facilitate efficient interaction between the conditioner and the segmenter arm, we propose to use 'channel squeeze & spatial excitation' blocks - a light-weight computational module - that enables heavy interaction between both the arms with negligible increase in model complexity. This contribution allows us to perform image segmentation without relying on a pre-trained model, which generally is unavailable for medical scans. Furthermore, we propose an efficient strategy for volumetric segmentation by optimally pairing a few slices of the support volume to all the slices of the query volume. We perform experiments for organ segmentation on whole-body contrast-enhanced CT scans from the Visceral Dataset. Our proposed model outperforms multiple baselines and existing approaches with respect to the segmentation accuracy by a significant margin. The source code is available at https://github.com/abhi4ssj/few-shot-segmentation.",0
"Highly accurate image segmentation is possible with deep neural networks, but the process requires large amounts of manually annotated data for supervised training. To overcome this limitation, few-shot learning has been introduced to learn a new class from a few annotated support examples. Our novel few-shot framework addresses the challenges of volumetric medical image segmentation using only a few annotated slices. Unlike other works in computer vision, we do not rely on pre-trained networks and instead propose a new architecture for few-shot segmentation that incorporates 'squeeze & excite' blocks. Our two-armed architecture comprises a conditioner arm and a segmenter arm for processing the annotated support input and segmenting the new query image. We use 'channel squeeze & spatial excitation' blocks to facilitate efficient interaction between both arms with minimal increase in model complexity. Our approach allows for image segmentation without reliance on a pre-trained model, which is generally unavailable for medical scans. We also propose an efficient strategy for volumetric segmentation by optimally pairing a few slices of the support volume to all the slices of the query volume. Our model outperforms multiple baselines and existing approaches for organ segmentation on whole-body contrast-enhanced CT scans from the Visceral Dataset. The source code is available at https://github.com/abhi4ssj/few-shot-segmentation.",1
"Automated fiber placement (AFP) is an advanced manufacturing technology that increases the rate of production of composite materials. At the same time, the need for adaptable and fast inline control methods of such parts raises. Existing inspection systems make use of handcrafted filter chains and feature detectors, tuned for a specific measurement methods by domain experts. These methods hardly scale to new defects or different measurement devices. In this paper, we propose to formulate AFP defect detection as an image segmentation problem that can be solved in an end-to-end fashion using artificially generated training data. We employ a probabilistic graphical model to generate training images and annotations. We then train a deep neural network based on recent architectures designed for image segmentation. This leads to an appealing method that scales well with new defect types and measurement devices and requires little real world data for training.",0
"AFP is a cutting-edge manufacturing technology that enhances composite material production rates. However, the demand for adaptable and fast inline control techniques for such parts is increasing. Current inspection systems utilize customized filter chains and feature detectors, tailored for a specific measurement method by domain experts. These methods are difficult to adapt to new defects or different measurement devices. In this article, we suggest that AFP defect detection be formulated as an image segmentation issue that can be solved end-to-end using synthetic training data. We use a probabilistic graphical model to create training images and annotations. We then train a deep neural network using recent architectures designed for image segmentation. This produces an attractive method that is adaptable to new defect types and measurement devices and requires minimal real-world data for training.",1
"This paper proposes the first known to us iris recognition methodology designed specifically for post-mortem samples. We propose to use deep learning-based iris segmentation models to extract highly irregular iris texture areas in post-mortem iris images. We show how to use segmentation masks predicted by neural networks in conventional, Gabor-based iris recognition method, which employs circular approximations of the pupillary and limbic iris boundaries. As a whole, this method allows for a significant improvement in post-mortem iris recognition accuracy over the methods designed only for ante-mortem irises, including the academic OSIRIS and commercial IriCore implementations. The proposed method reaches the EER less than 1% for samples collected up to 10 hours after death, when compared to 16.89% and 5.37% of EER observed for OSIRIS and IriCore, respectively. For samples collected up to 369 hours post-mortem, the proposed method achieves the EER 21.45%, while 33.59% and 25.38% are observed for OSIRIS and IriCore, respectively. Additionally, the method is tested on a database of iris images collected from ophthalmology clinic patients, for which it also offers an advantage over the two other algorithms. This work is the first step towards post-mortem-specific iris recognition, which increases the chances of identification of deceased subjects in forensic investigations. The new database of post-mortem iris images acquired from 42 subjects, as well as the deep learning-based segmentation models are made available along with the paper, to ensure all the results presented in this manuscript are reproducible.",0
"In this article, a novel iris recognition technique tailored for post-mortem samples is proposed. The method employs deep learning-based iris segmentation models to extract intricate iris texture areas from post-mortem iris images. The segmentation masks predicted by the neural networks are utilized in the conventional Gabor-based iris recognition approach, which utilizes circular approximations of the iris boundaries. Compared to existing methods designed for ante-mortem irises, including OSIRIS and IriCore, the proposed method significantly improves the accuracy of post-mortem iris recognition, with an EER of less than 1% for samples collected up to 10 hours after death. For samples collected up to 369 hours post-mortem, the EER is 21.45%, while OSIRIS and IriCore have EERs of 33.59% and 25.38%, respectively. The technique is also tested on iris images collected from ophthalmology clinic patients and outperforms the two other algorithms. This study represents an important first step towards post-mortem-specific iris recognition, which is crucial for forensic investigations. The paper provides a new database of post-mortem iris images from 42 subjects, as well as the deep learning-based segmentation models, to ensure reproducibility of the results.",1
"The Active Contour Model (ACM) is a standard image analysis technique whose numerous variants have attracted an enormous amount of research attention across multiple fields. Incorrectly, however, the ACM's differential-equation-based formulation and prototypical dependence on user initialization have been regarded as being largely incompatible with the recently popular deep learning approaches to image segmentation. This paper introduces the first tight unification of these two paradigms. In particular, we devise Deep Convolutional Active Contours (DCAC), a truly end-to-end trainable image segmentation framework comprising a Convolutional Neural Network (CNN) and an ACM with learnable parameters. The ACM's Eulerian energy functional includes per-pixel parameter maps predicted by the backbone CNN, which also initializes the ACM. Importantly, both the CNN and ACM components are fully implemented in TensorFlow, and the entire DCAC architecture is end-to-end automatically differentiable and backpropagation trainable without user intervention. As a challenging test case, we tackle the problem of building instance segmentation in aerial images and evaluate DCAC on two publicly available datasets, Vaihingen and Bing Huts. Our reseults demonstrate that, for building segmentation, the DCAC establishes a new state-of-the-art performance by a wide margin.",0
"The Active Contour Model (ACM) has been a widely used image analysis technique with various adaptations and has garnered significant research attention in different areas. However, there has been a misconception that the ACM's reliance on differential equations and user input makes it incompatible with the popular deep learning approaches to image segmentation. This study presents a groundbreaking fusion of these two methodologies through Deep Convolutional Active Contours (DCAC), an end-to-end trainable image segmentation system that combines a Convolutional Neural Network (CNN) and an ACM with learnable parameters. The ACM's energy functional is Eulerian and includes per-pixel parameter maps predicted by the CNN, which also initializes the ACM. Both components are fully implemented in TensorFlow and the entire DCAC model is automatically differentiable and trainable without user intervention. We evaluate DCAC on two publicly available datasets, Vaihingen and Bing Huts, for building instance segmentation in aerial images, and our results show that the DCAC achieves a significant state-of-the-art performance improvement.",1
"Registration is a fundamental task in medical image analysis which can be applied to several tasks including image segmentation, intra-operative tracking, multi-modal image alignment, and motion analysis. Popular registration tools such as ANTs and NiftyReg optimize an objective function for each pair of images from scratch which is time-consuming for large images with complicated deformation. Facilitated by the rapid progress of deep learning, learning-based approaches such as VoxelMorph have been emerging for image registration. These approaches can achieve competitive performance in a fraction of a second on advanced GPUs. In this work, we construct a neural registration framework, called NeurReg, with a hybrid loss of displacement fields and data similarity, which substantially improves the current state-of-the-art of registrations. Within the framework, we simulate various transformations by a registration simulator which generates fixed image and displacement field ground truth for training. Furthermore, we design three segmentation frameworks based on the proposed registration framework: 1) atlas-based segmentation, 2) joint learning of both segmentation and registration tasks, and 3) multi-task learning with atlas-based segmentation as an intermediate feature. Extensive experimental results validate the effectiveness of the proposed NeurReg framework based on various metrics: the endpoint error (EPE) of the predicted displacement field, mean square error (MSE), normalized local cross-correlation (NLCC), mutual information (MI), Dice coefficient, uncertainty estimation, and the interpretability of the segmentation. The proposed NeurReg improves registration accuracy with fast inference speed, which can greatly accelerate related medical image analysis tasks.",0
"Medical image analysis involves various tasks, such as image segmentation, intra-operative tracking, multi-modal image alignment, and motion analysis, all of which require registration. However, traditional registration tools like ANTs and NiftyReg are time-consuming for large images with complex deformation, as they optimize an objective function for each image pair from scratch. Thanks to the advancements in deep learning, learning-based approaches like VoxelMorph have emerged as a faster alternative for image registration. In this study, we introduce NeurReg, a neural registration framework that employs a hybrid loss of displacement fields and data similarity to improve the state-of-the-art in registration performance. Our framework uses a registration simulator to generate a fixed image and displacement field ground truth for training, and we also design three segmentation frameworks based on NeurReg. We evaluate our framework using various metrics, including endpoint error, mean square error, normalized local cross-correlation, mutual information, Dice coefficient, uncertainty estimation, and segmentation interpretability. Our results demonstrate that NeurReg significantly enhances registration accuracy with fast inference speed, which can expedite medical image analysis tasks.",1
"Thesedays, Convolutional Neural Networks are widely used in semantic segmentation. However, since CNN-based segmentation networks produce low-resolution outputs with rich semantic information, it is inevitable that spatial details (e.g., small bjects and fine boundary information) of segmentation results will be lost. To address this problem, motivated by a variational approach to image segmentation (i.e., level set theory), we propose a novel loss function called the level set loss which is designed to refine spatial details of segmentation results. To deal with multiple classes in an image, we first decompose the ground truth into binary images. Note that each binary image consists of background and regions belonging to a class. Then we convert level set functions into class probability maps and calculate the energy for each class. The network is trained to minimize the weighted sum of the level set loss and the cross-entropy loss. The proposed level set loss improves the spatial details of segmentation results in a time and memory efficient way. Furthermore, our experimental results show that the proposed loss function achieves better performance than previous approaches.",0
"Nowadays, Convolutional Neural Networks are extensively utilized for semantic segmentation. Nevertheless, these networks tend to produce low-resolution outputs that possess substantial semantic information, resulting in the loss of spatial details such as fine boundary information and small objects. To overcome this issue, we propose a novel loss function, namely the level set loss, inspired by a variational approach to image segmentation known as level set theory. This loss function focuses on refining the spatial details of segmentation results. To handle multiple classes in an image, we decompose the ground truth into binary images, with each binary image featuring a background and regions that belong to a particular class. We then convert level set functions into class probability maps and compute the energy for each class. The network is trained to minimize the weighted sum of the level set loss and the cross-entropy loss. Our proposed level set loss enhances the spatial details of segmentation results in a time and memory efficient way. Additionally, our experimental results demonstrate that our proposed loss function outperforms previous methods.",1
"While accelerators such as GPUs have limited memory, deep neural networks are becoming larger and will not fit with the memory limitation of accelerators for training. We propose an approach to tackle this problem by rewriting the computational graph of a neural network, in which swap-out and swap-in operations are inserted to temporarily store intermediate results on CPU memory. In particular, we first revise the concept of a computational graph by defining a concrete semantics for variables in a graph. We then formally show how to derive swap-out and swap-in operations from an existing graph and present rules to optimize the graph. To realize our approach, we developed a module in TensorFlow, named TFLMS. TFLMS is published as a pull request in the TensorFlow repository for contributing to the TensorFlow community. With TFLMS, we were able to train ResNet-50 and 3DUnet with 4.7x and 2x larger batch size, respectively. In particular, we were able to train 3DUNet using images of size of $192^3$ for image segmentation, which, without TFLMS, had been done only by dividing the images to smaller images, which affects the accuracy.",0
"As deep neural networks are becoming larger, they are no longer compatible with the limited memory of accelerators such as GPUs for training. To address this issue, we propose a solution involving the rewriting of the computational graph of a neural network, with the insertion of swap-out and swap-in operations to temporarily store intermediate results on CPU memory. Our approach involves revising the concept of a computational graph by defining concrete semantics for variables within the graph, and formally demonstrating how to derive swap-out and swap-in operations from an existing graph, with rules for optimizing the graph. To implement our approach, we created TFLMS, a module in TensorFlow that is published as a pull request in the TensorFlow repository for the benefit of the community. With TFLMS, we achieved success in training ResNet-50 and 3DUnet with 4.7x and 2x larger batch sizes, respectively. Additionally, we were able to train 3DUnet using images of size $192^3$ for image segmentation, which had previously only been possible by dividing the images into smaller images, which in turn affected accuracy.",1
"Overfitting in deep learning has been the focus of a number of recent works, yet its exact impact on the behavior of neural networks is not well understood. This study analyzes overfitting by examining how the distribution of logits alters in relation to how much the model overfits. Specifically, we find that when training with few data samples, the distribution of logit activations when processing unseen test samples of an under-represented class tends to shift towards and even across the decision boundary, while the over-represented class seems unaffected. In image segmentation, foreground samples are often heavily under-represented. We observe that sensitivity of the model drops as a result of overfitting, while precision remains mostly stable. Based on our analysis, we derive asymmetric modifications of existing loss functions and regularizers including a large margin loss, focal loss, adversarial training and mixup, which specifically aim at reducing the shift observed when embedding unseen samples of the under-represented class. We study the case of binary segmentation of brain tumor core and show that our proposed simple modifications lead to significantly improved segmentation performance over the symmetric variants.",0
"The impact of overfitting on neural networks in deep learning has received attention in recent works, but its exact implications are not yet clear. This study examines overfitting by analyzing how the distribution of logits changes when a model overfits. The study finds that with limited data samples, the distribution of logit activations shifts toward and across the decision boundary when processing unseen test samples of an under-represented class, while the over-represented class remains unaffected. In image segmentation, foreground samples are often under-represented, causing the model's sensitivity to decrease due to overfitting, while precision remains stable. The study proposes asymmetric modifications to existing loss functions and regularizers, including large margin loss, focal loss, adversarial training, and mixup. These modifications aim to reduce the shift observed when embedding unseen samples of the under-represented class. The study demonstrates the effectiveness of these modifications in the case of binary segmentation of brain tumor core, showing significant improvement in segmentation performance over symmetric variants.",1
"A key limitation of deep convolutional neural networks (DCNN) based image segmentation methods is the lack of generalizability. Manually traced training images are typically required when segmenting organs in a new imaging modality or from distinct disease cohort. The manual efforts can be alleviated if the manually traced images in one imaging modality (e.g., MRI) are able to train a segmentation network for another imaging modality (e.g., CT). In this paper, we propose an end-to-end synthetic segmentation network (SynSeg-Net) to train a segmentation network for a target imaging modality without having manual labels. SynSeg-Net is trained by using (1) unpaired intensity images from source and target modalities, and (2) manual labels only from source modality. SynSeg-Net is enabled by the recent advances of cycle generative adversarial networks (CycleGAN) and DCNN. We evaluate the performance of the SynSeg-Net on two experiments: (1) MRI to CT splenomegaly synthetic segmentation for abdominal images, and (2) CT to MRI total intracranial volume synthetic segmentation (TICV) for brain images. The proposed end-to-end approach achieved superior performance to two stage methods. Moreover, the SynSeg-Net achieved comparable performance to the traditional segmentation network using target modality labels in certain scenarios. The source code of SynSeg-Net is publicly available (https://github.com/MASILab/SynSeg-Net).",0
"Deep convolutional neural networks (DCNN) based image segmentation methods are limited in their generalizability. Typically, manually traced training images are required to segment organs in a new imaging modality or from a distinct disease cohort. However, this manual effort can be reduced by training a segmentation network for a target imaging modality using manually traced images from a different imaging modality. In this paper, we propose an end-to-end synthetic segmentation network, SynSeg-Net, that can train a segmentation network for a target imaging modality without manual labels. SynSeg-Net is trained using unpaired intensity images from source and target modalities and manual labels only from the source modality. SynSeg-Net is enabled by the recent advances in cycle generative adversarial networks (CycleGAN) and DCNN. We evaluated the performance of SynSeg-Net on two experiments: MRI to CT splenomegaly synthetic segmentation for abdominal images, and CT to MRI total intracranial volume synthetic segmentation (TICV) for brain images. The proposed end-to-end approach achieved better performance than two-stage methods. Additionally, in certain scenarios, the SynSeg-Net achieved comparable performance to the traditional segmentation network using target modality labels. The source code of SynSeg-Net is publicly available (https://github.com/MASILab/SynSeg-Net).",1
"In this paper we propose a novel deep learning-based algorithm for biomedical image segmentation which uses a sequential attention mechanism able to shift the focus of attention across the image in a selective way, allowing subareas which are more difficult to classify to be processed at increased resolution. The spatial distribution of class information in each subarea is learned using a retina-like representation where resolution decreases with distance from the center of attention. The final segmentation is achieved by averaging class predictions over overlapping subareas, utilizing the power of ensemble learning to increase segmentation accuracy. Experimental results for semantic segmentation task for which only a few training images are available show that a CNN using the proposed method outperforms both a patch-based classification CNN and a fully convolutional-based method.",0
"This paper introduces a new deep learning algorithm for biomedical image segmentation that incorporates a unique sequential attention mechanism. This mechanism enables the algorithm to selectively focus on subareas of the image, particularly those that are difficult to classify, by increasing the resolution at which they are processed. A retina-like representation is utilized to learn the spatial distribution of class information in each subarea, with resolution decreasing as the distance from the center of attention increases. The algorithm achieves the final segmentation by averaging class predictions across overlapping subareas, resulting in higher segmentation accuracy through ensemble learning. Experimental results demonstrate that the proposed CNN method outperforms both a patch-based classification CNN and a fully convolutional-based method, particularly for semantic segmentation tasks with limited training images.",1
"In this chapter, we give an overview of part of our previous work based on the minimal path framework and the Eikonal partial differential equation (PDE). We show that by designing adequate Riemannian and Randers geodesic metrics the minimal paths can be utilized to search for solutions to almost all of the active contour problems and to the Euler-Mumford elastica problem, which allows to blend the advantages from minimal geodesic paths and those original approaches, i.e. the active contours and elastica curves. The proposed minimal path-based models can be applied to deal with a broad variety of image analysis tasks such as boundary detection, image segmentation and tubular structure extraction. The numerical implementations for the computation of minimal paths are known to be quite efficient thanks to the Eikonal solvers such as the Finsler variant of the fast marching method.",0
"This chapter provides an overview of our prior work that utilized the minimal path framework and the Eikonal partial differential equation (PDE). Our research demonstrated that by creating appropriate Riemannian and Randers geodesic metrics, the minimal paths can be used to solve almost all active contour problems and the Euler-Mumford elastica problem. This approach combines the benefits of minimal geodesic paths with those of active contours and elastica curves. The proposed minimal path-based models can be applied to a wide range of image analysis tasks, such as boundary detection, image segmentation, and tubular structure extraction. The numerical implementation of minimal paths is highly efficient, thanks to Eikonal solvers like the Finsler variant of the fast marching method.",1
"Supervised semantic segmentation normally assumes the test data being in a similar data domain as the training data. However, in practice, the domain mismatch between the training and unseen data could lead to a significant performance drop. Obtaining accurate pixel-wise label for images in different domains is tedious and labor intensive, especially for histopathology images. In this paper, we propose a dual adaptive pyramid network (DAPNet) for histopathological gland segmentation adapting from one stain domain to another. We tackle the domain adaptation problem on two levels: 1) the image-level considers the differences of image color and style; 2) the feature-level addresses the spatial inconsistency between two domains. The two components are implemented as domain classifiers with adversarial training. We evaluate our new approach using two gland segmentation datasets with H&E and DAB-H stains respectively. The extensive experiments and ablation study demonstrate the effectiveness of our approach on the domain adaptive segmentation task. We show that the proposed approach performs favorably against other state-of-the-art methods.",0
"Usually, supervised semantic segmentation assumes that the test data belongs to the same data domain as the training data. However, in practice, a mismatch between the training and unseen data's domains can result in a significant drop in performance. Obtaining accurate pixel-wise labels for images in different domains can be laborious, particularly for histopathology images. In this research paper, we present a dual adaptive pyramid network (DAPNet) for histopathological gland segmentation that adapts from one stain domain to another. We address the domain adaptation problem on two levels: 1) the image-level considers the differences in image color and style; 2) the feature-level addresses the spatial inconsistency between the two domains. The two components are domain classifiers implemented using adversarial training. We evaluate our novel approach using two gland segmentation datasets, one with H&E stains and the other with DAB-H stains. Our extensive experiments and ablation study demonstrate the effectiveness of our approach on domain adaptive segmentation tasks. We show that our proposed approach performs favorably against other state-of-the-art methods.",1
"Prognostic tumor growth modeling via volumetric medical imaging observations can potentially lead to better outcomes of tumor treatment and surgical planning. Recent advances of convolutional networks have demonstrated higher accuracy than traditional mathematical models in predicting future tumor volumes. This indicates that deep learning-based techniques may have great potentials on addressing such problem. However, current 2D patch-based modeling approaches cannot make full use of the spatio-temporal imaging context of the tumor's longitudinal 4D (3D + time) data. Moreover, they are incapable to predict clinically-relevant tumor properties, other than volumes. In this paper, we exploit to formulate the tumor growth process through convolutional Long Short-Term Memory (ConvLSTM) that extract tumor's static imaging appearances and capture its temporal dynamic changes within a single network. We extend ConvLSTM into the spatio-temporal domain (ST-ConvLSTM) by jointly learning the inter-slice 3D contexts and the longitudinal or temporal dynamics from multiple patient studies. Our approach can incorporate other non-imaging patient information in an end-to-end trainable manner. Experiments are conducted on the largest 4D longitudinal tumor dataset of 33 patients to date. Results validate that the ST-ConvLSTM produces a Dice score of 83.2%+-5.1% and a RVD of 11.2%+-10.8%, both significantly outperforming (p<0.05) other compared methods of linear model, ConvLSTM, and generative adversarial network (GAN) under the metric of predicting future tumor volumes. Additionally, our new method enables the prediction of both cell density and CT intensity numbers. Last, we demonstrate the generalizability of ST-ConvLSTM by employing it in 4D medical image segmentation task, which achieves an averaged Dice score of 86.3+-1.2% for left-ventricle segmentation in 4D ultrasound with 3 seconds per patient.",0
"The use of volumetric medical imaging observations to model the growth of tumors can improve treatment outcomes and surgical planning. Recent developments in convolutional networks have proved to be more accurate than traditional mathematical models in anticipating future tumor volumes, suggesting the potential of deep learning-based methods to address this issue. However, current 2D patch-based modeling approaches fail to fully utilize the spatio-temporal imaging context of the tumor's longitudinal 4D data and cannot predict clinically-relevant tumor properties other than volumes. In this study, we propose a new approach that utilizes ConvLSTM to extract the tumor's static imaging appearances and capture its temporal dynamic changes. We extend ConvLSTM into the spatio-temporal domain by jointly learning the inter-slice 3D contexts and the longitudinal or temporal dynamics from multiple patient studies. Our approach can incorporate other non-imaging patient information in an end-to-end trainable manner. Our experiments show that this new method significantly outperforms other methods of linear model, ConvLSTM, and generative adversarial network in predicting future tumor volumes. Additionally, our method can predict cell density and CT intensity numbers and can be used in medical image segmentation tasks.",1
"Three-dimensional medical image segmentation is one of the most important problems in medical image analysis and plays a key role in downstream diagnosis and treatment. Recent years, deep neural networks have made groundbreaking success in medical image segmentation problem. However, due to the high variance in instrumental parameters, experimental protocols, and subject appearances, the generalization of deep learning models is often hindered by the inconsistency in medical images generated by different machines and hospitals. In this work, we present StyleSegor, an efficient and easy-to-use strategy to alleviate this inconsistency issue. Specifically, neural style transfer algorithm is applied to unlabeled data in order to minimize the differences in image properties including brightness, contrast, texture, etc. between the labeled and unlabeled data. We also apply probabilistic adjustment on the network output and integrate multiple predictions through ensemble learning. On a publicly available whole heart segmentation benchmarking dataset from MICCAI HVSMR 2016 challenge, we have demonstrated an elevated dice accuracy surpassing current state-of-the-art method and notably, an improvement of the total score by 29.91\%. StyleSegor is thus corroborated to be an accurate tool for 3D whole heart segmentation especially on highly inconsistent data, and is available at https://github.com/horsepurve/StyleSegor.",0
"Medical image segmentation in three dimensions is a crucial aspect of medical image analysis and is pivotal in subsequent diagnoses and treatments. In recent years, deep neural networks have made significant strides in solving medical image segmentation issues. However, inconsistencies in medical images stemming from differences in instrumental parameters, experimental protocols, and subject appearances have posed a challenge to the generalization of deep learning models. To address this issue, we introduce StyleSegor, an efficient and user-friendly approach that leverages neural style transfer algorithms applied to unlabelled data to minimize differences in image properties, such as texture, brightness, and contrast, between labelled and unlabelled data. We also use probabilistic adjustment on network output and integrate multiple predictions via ensemble learning. On a publicly available whole heart segmentation benchmarking dataset from MICCAI HVSMR 2016 challenge, we demonstrate that StyleSegor performs better than current state-of-the-art methods, achieving an elevated dice accuracy and improving the total score by 29.91%. Consequently, StyleSegor is a reliable tool for 3D whole heart segmentation, particularly for highly inconsistent data, and is accessible at https://github.com/horsepurve/StyleSegor.",1
"Recent advances in generative models and adversarial training have led to a flourishing image-to-image (I2I) translation literature. The current I2I translation approaches require training images from the two domains that are either all paired (supervised) or all unpaired (unsupervised). In practice, obtaining paired training data in sufficient quantities is often very costly and cumbersome. Therefore solutions that employ unpaired data, while less accurate, are largely preferred. In this paper, we aim to bridge the gap between supervised and unsupervised I2I translation, with application to semantic image segmentation. We build upon pix2pix and CycleGAN, state-of-the-art seminal I2I translation techniques. We propose a method to select (very few) paired training samples and achieve significant improvements in both supervised and unsupervised I2I translation settings over random selection. Further, we boost the performance by incorporating both (selected) paired and unpaired samples in the training process. Our experiments show that an extremely weak supervised I2I translation solution using only one paired training sample can achieve a quantitative performance much better than the unsupervised CycleGAN model, and comparable to that of the supervised pix2pix model trained on thousands of pairs.",0
"The increasing development of generative models and adversarial training has resulted in a growing body of literature on image-to-image (I2I) translation. Current I2I translation methods require training images from two domains, which can be either paired (supervised) or unpaired (unsupervised). However, the acquisition of paired training data can be expensive and difficult. Consequently, unsupervised solutions are often preferred, despite their lower accuracy. In this paper, we propose a method to bridge the gap between supervised and unsupervised I2I translation, specifically for semantic image segmentation. Our approach builds on state-of-the-art techniques, pix2pix and CycleGAN, and involves the selection of very few paired training samples to achieve significant improvements in both supervised and unsupervised settings. We also incorporate both paired and unpaired samples in the training process to further enhance performance. Our experiments demonstrate that even a weak supervised I2I translation solution using only one paired training sample can outperform the unsupervised CycleGAN model and achieve comparable results to the supervised pix2pix model trained on thousands of pairs.",1
"This work proposes the use of Bayesian approximations of uncertainty from deep learning in a robot planner, showing that this produces more cautious actions in safety-critical scenarios. The case study investigated is motivated by a setup where an aerial robot acts as a ""scout"" for a ground robot. This is useful when the below area is unknown or dangerous, with applications in space exploration, military, or search-and-rescue. Images taken from the aerial view are used to provide a less obstructed map to guide the navigation of the robot on the ground. Experiments are conducted using a deep learning semantic image segmentation, followed by a path planner based on the resulting cost map, to provide an empirical analysis of the proposed method. A comparison with similar approaches is presented to portray the usefulness of certain techniques, or variations within a technique, in similar experimental settings. The method is analyzed to assess the impact of variations in the uncertainty extraction, as well as the absence of an uncertainty metric, on the overall system with the use of a defined metric which measures surprise to the planner. The analysis is performed on multiple datasets, showing a similar trend of lower surprise when uncertainty information is incorporated in the planning, given threshold values of the hyperparameters in the uncertainty extraction have been met. We find that taking uncertainty into account leads to paths that could be 18% less risky on an average.",0
"The paper suggests utilizing Bayesian probability approximations derived from deep learning to enhance the robot planner's cautiousness in safety-critical situations. The study focuses on an aerial robot that acts as a scout for a ground robot in unfamiliar or hazardous environments, such as space exploration, military operations, or search-and-rescue missions. The aerial view captures images that provide a clearer map for the ground robot's navigation, using deep learning semantic image segmentation and a path planner based on the resulting cost map. The authors compare their approach to others and assess the impact of variations in uncertainty extraction and the absence of an uncertainty metric on the system's surprise metric. The findings reveal that incorporating uncertainty information leads to paths that are 18% less risky on average, demonstrating the effectiveness of the proposed method.",1
"In real-world practice, medical images acquired in different phases possess complementary information, {\em e.g.}, radiologists often refer to both arterial and venous scans in order to make the diagnosis. However, in medical image analysis, fusing prediction from two phases is often difficult, because (i) there is a domain gap between two phases, and (ii) the semantic labels are not pixel-wise corresponded even for images scanned from the same patient. This paper studies organ segmentation in two-phase CT scans. We propose Phase Collaborative Network (PCN), an end-to-end framework that contains both generative and discriminative modules. PCN can be mathematically explained to formulate phase-to-phase and data-to-label relations jointly. Experiments are performed on a two-phase CT dataset, on which PCN outperforms the baselines working with one-phase data by a large margin, and we empirically verify that the gain comes from inter-phase collaboration. Besides, PCN transfers well to two public single-phase datasets, demonstrating its potential applications.",0
"Medical images obtained from different phases possess supplementary information in practical situations. For instance, radiologists rely on both arterial and venous scans to diagnose ailments. Nonetheless, combining predictions from two phases during medical image analysis is often challenging due to the domain gap between phases and the absence of pixel-wise semantic label correspondence even in images from the same patient. This research examines organ segmentation in two-phase CT scans and introduces the Phase Collaborative Network (PCN), an end-to-end framework that includes generative and discriminative modules. PCN mathematically formulates joint phase-to-phase and data-to-label relationships. The experiments on a two-phase CT dataset reveal that PCN outperforms one-phase data baselines by a significant margin, and the gain results from inter-phase collaboration. Additionally, PCN demonstrates its potential application by transferring well to two public single-phase datasets.",1
"The segmentation of digital images is one of the essential steps in image processing or a computer vision system. It helps in separating the pixels into different regions according to their intensity level. A large number of segmentation techniques have been proposed, and a few of them use complex computational operations. Among all, the most straightforward procedure that can be easily implemented is thresholding. In this paper, we present a unique heuristic approach for image segmentation that automatically determines multilevel thresholds by sampling the histogram of a digital image. Our approach emphasis on selecting a valley as optimal threshold values. We demonstrated that our approach outperforms the popular Otsu's method in terms of CPU computational time. We demonstrated that our approach outperforms the popular Otsu's method in terms of CPU computational time. We observed a maximum speed-up of 35.58x and a minimum speed-up of 10.21x on popular image processing benchmarks. To demonstrate the correctness of our approach in determining threshold values, we compute PSNR, SSIM, and FSIM values to compare with the values obtained by Otsu's method. This evaluation shows that our approach is comparable and better in many cases as compared to well known Otsu's method.",0
"Segmentation of digital images is a crucial step in image processing and computer vision systems. It involves separating pixels into different regions based on their intensity level, and numerous segmentation techniques have been proposed, some of which are computationally complex. However, thresholding is the most straightforward technique that can be easily implemented. In this paper, we introduce a novel heuristic approach for image segmentation that automatically determines multilevel thresholds by sampling the histogram of a digital image. Our approach emphasizes selecting a valley as the optimal threshold value and outperforms the popular Otsu's method in terms of CPU computational time. We observed a maximum speed-up of 35.58x and a minimum speed-up of 10.21x on popular image processing benchmarks. To validate our approach, we computed PSNR, SSIM, and FSIM values and compared them to those obtained by Otsu's method. Our evaluation showed that our approach is comparable and, in many cases, better than the well-known Otsu's method.",1
"Fully convolutional neural networks (CNNs) have proven to be effective at representing and classifying textural information, thus transforming image intensity into output class masks that achieve semantic image segmentation. In medical image analysis, however, expert manual segmentation often relies on the boundaries of anatomical structures of interest. We propose boundary aware CNNs for medical image segmentation. Our networks are designed to account for organ boundary information, both by providing a special network edge branch and edge-aware loss terms, and they are trainable end-to-end. We validate their effectiveness on the task of brain tumor segmentation using the BraTS 2018 dataset. Our experiments reveal that our approach yields more accurate segmentation results, which makes it promising for more extensive application to medical image segmentation.",0
"Convolutional neural networks (CNNs) have been successful in representing and categorizing textural information, resulting in output class masks that enable semantic image segmentation by transforming image intensity. However, in medical image analysis, manual segmentation by experts relies on the boundaries of anatomical structures of interest. To address this, we introduce boundary aware CNNs for medical image segmentation. Our networks incorporate organ boundary information by including a specialized edge branch and edge-aware loss terms, and can be trained end-to-end. We demonstrate the effectiveness of our approach on brain tumor segmentation using the BraTS 2018 dataset. Our experiments demonstrate that our approach achieves more accurate segmentation results, indicating its potential for broader application in medical image segmentation.",1
"Recent state-of-the-art image segmentation algorithms are mostly based on deep neural networks, thanks to their high performance and fast computation time. However, these methods are usually trained in a supervised manner, which requires large number of high quality ground-truth segmentation masks. On the other hand, classical image segmentation approaches such as level-set methods are formulated in a self-supervised manner by minimizing energy functions such as Mumford-Shah functional, so they are still useful to help generation of segmentation masks without labels. Unfortunately, these algorithms are usually computationally expensive and often have limitation in semantic segmentation. In this paper, we propose a novel loss function based on Mumford-Shah functional that can be used in deep-learning based image segmentation without or with small labeled data. This loss function is based on the observation that the softmax layer of deep neural networks has striking similarity to the characteristic function in the Mumford-Shah functional. We show that the new loss function enables semi-supervised and unsupervised segmentation. In addition, our loss function can be also used as a regularized function to enhance supervised semantic segmentation algorithms. Experimental results on multiple datasets demonstrate the effectiveness of the proposed method.",0
"Most modern image segmentation techniques rely on deep neural networks due to their exceptional performance and quick processing time. Unfortunately, these methods require a large amount of high-quality ground-truth segmentation masks for supervised training. In contrast, traditional image segmentation methods like level-set methods are self-supervised and minimize energy functions such as Mumford-Shah functional, making them useful for generating segmentation masks without labels. However, these algorithms can be computationally expensive and have limitations in semantic segmentation. This paper introduces a new loss function based on the Mumford-Shah functional that can be utilized in deep-learning based image segmentation without or with minimal labeled data. The proposed loss function leverages the similarity between the softmax layer of deep neural networks and the characteristic function in the Mumford-Shah functional. This enables semi-supervised and unsupervised segmentation and can also serve as a regularized function to enhance supervised semantic segmentation algorithms. Multiple datasets were used to demonstrate the effectiveness of the proposed method.",1
"Convolutional neural networks (CNNs) for biomedical image analysis are often of very large size, resulting in high memory requirement and high latency of operations. Searching for an acceptable compressed representation of the base CNN for a specific imaging application typically involves a series of time-consuming training/validation experiments to achieve a good compromise between network size and accuracy. To address this challenge, we propose CC-Net, a new image complexity-guided CNN compression scheme for biomedical image segmentation. Given a CNN model, CC-Net predicts the final accuracy of networks of different sizes based on the average image complexity computed from the training data. It then selects a multiplicative factor for producing a desired network with acceptable network accuracy and size. Experiments show that CC-Net is effective for generating compressed segmentation networks, retaining up to 95% of the base network segmentation accuracy and utilizing only 0.1% of trainable parameters of the full-sized networks in the best case.",0
"Biomedical image analysis using convolutional neural networks (CNNs) often requires large networks that consume high memory and have long operation latency. Finding a suitable compressed representation for a specific imaging application involves conducting several time-intensive training and validation experiments to balance network size and accuracy. To overcome this challenge, we introduce CC-Net, a novel CNN compression approach for biomedical image segmentation that considers image complexity. CC-Net uses a given CNN model to anticipate the final accuracy of various network sizes based on the mean image complexity from the training data. It then selects a multiplication factor to create a network with satisfactory accuracy and size. Our experiments demonstrate that CC-Net is an effective way to produce compressed segmentation networks, retaining up to 95% of the base network's segmentation accuracy and using only 0.1% of trainable parameters of the full-sized networks in the best-case scenario.",1
"Image segmentation as a clustering problem is to identify pixel groups on an image without any preliminary labels available. It remains a challenge in machine vision because of the variations in size and shape of image segments. Furthermore, determining the segment number in an image is NP-hard without prior knowledge of the image content. This paper presents an automatic color image pixel clustering scheme based on mussels wandering optimization. By applying an activation variable to determine the number of clusters along with the cluster centers optimization, an image is segmented with minimal prior knowledge and human intervention. By revising the within- and between-class sum of squares ratio for random natural image contents, we provide a novel fitness function for image pixel clustering tasks. Comprehensive empirical studies of the proposed scheme against other state-of-the-art competitors on synthetic data and the ASD dataset have demonstrated the promising performance of the proposed scheme.",0
"Identifying groups of pixels on an image without prior labels is known as image segmentation, which poses a challenge in machine vision due to the varying sizes and shapes of image segments. Additionally, determining the number of segments in an image is an NP-hard problem without any prior knowledge of the image content. To address this, a color image pixel clustering scheme based on mussels wandering optimization is presented in this paper. The scheme uses an activation variable to determine the number of clusters and optimizes the cluster centers to segment the image with minimal human intervention. A new fitness function is proposed by modifying the within- and between-class sum of squares ratio for random natural image contents. Empirical studies on synthetic data and the ASD dataset show that the proposed scheme outperforms other state-of-the-art competitors, indicating its promising performance.",1
"Yes, it can. Data augmentation is perhaps the oldest preprocessing step in computer vision literature. Almost every computer vision model trained on imaging data uses some form of augmentation. In this paper, we use the inter-vertebral disk segmentation task alongside a deep residual U-Net as the learning model, to explore the effectiveness of augmentation. In the extreme, we observed that a model trained on patches extracted from just one scan, with each patch augmented 50 times; achieved a Dice score of 0.73 in a validation set of 40 cases. Qualitative evaluation indicated a clinically usable segmentation algorithm, which appropriately segments regions of interest, alongside limited false positive specks. When the initial patches are extracted from nine scans the average Dice coefficient jumps to 0.86 and most of the false positives disappear. While this still falls short of state-of-the-art deep learning based segmentation of discs reported in literature, qualitative examination reveals that it does yield segmentation, which can be amended by expert clinicians with minimal effort to generate additional data for training improved deep models. Extreme augmentation of training data, should thus be construed as a strategy for training deep learning based algorithms, when very little manually annotated data is available to work with. Models trained with extreme augmentation can then be used to accelerate the generation of manually labelled data. Hence, we show that extreme augmentation can be a valuable tool in addressing scaling up small imaging data sets to address medical image segmentation tasks.",0
"Data augmentation, which is one of the most well-established preprocessing steps in computer vision, is used by almost all computer vision models that are trained on imaging data. In this study, we utilized a deep residual U-Net as the learning model for inter-vertebral disk segmentation and investigated the effectiveness of augmentation. Our findings showed that a model trained on patches from a single scan, with each patch augmented 50 times, achieved a Dice score of 0.73 on a validation set of 40 cases. This algorithm produced a clinically usable segmentation that accurately identified regions of interest while limiting false positive specks. When patches were extracted from nine scans, the average Dice coefficient increased to 0.86, with most of the false positives eliminated. Although this method falls short of the state-of-the-art deep learning-based segmentation of discs reported in literature, it still yields a segmentation that can be improved further by expert clinicians with minimal effort to generate additional data for training. Thus, extreme augmentation can be employed as a strategy for training deep learning-based algorithms when only a small amount of manually annotated data is available. Models trained with extreme augmentation can then be utilized to speed up the creation of manually labelled data. Therefore, we demonstrate that extreme augmentation is a useful tool for scaling up small imaging data sets in medical image segmentation tasks.",1
"In this work, we study the problem of training deep networks for semantic image segmentation using only a fraction of annotated images, which may significantly reduce human annotation efforts. Particularly, we propose a strategy that exploits the unpaired image style transfer capabilities of CycleGAN in semi-supervised segmentation. Unlike recent works using adversarial learning for semi-supervised segmentation, we enforce cycle consistency to learn a bidirectional mapping between unpaired images and segmentation masks. This adds an unsupervised regularization effect that boosts the segmentation performance when annotated data is limited. Experiments on three different public segmentation benchmarks (PASCAL VOC 2012, Cityscapes and ACDC) demonstrate the effectiveness of the proposed method. The proposed model achieves 2-4% of improvement with respect to the baseline and outperforms recent approaches for this task, particularly in low labeled data regime.",0
"This study focuses on reducing the human effort required for semantic image segmentation by training deep networks using only a fraction of annotated images. To achieve this, we propose a strategy that utilizes CycleGAN's unpaired image style transfer capabilities in semi-supervised segmentation. Our approach differs from recent adversarial learning works for semi-supervised segmentation in that we enforce cycle consistency to establish a bidirectional mapping between unpaired images and segmentation masks. This unsupervised regularization effect improves segmentation performance when annotated data is limited. We conducted experiments on three public segmentation benchmarks (PASCAL VOC 2012, Cityscapes and ACDC), which demonstrate the effectiveness of our proposed method. Our model outperforms recent approaches, particularly in situations where only a few labeled data are available, achieving a 2-4% improvement compared to the baseline.",1
"In recent years, there has been remarkable progress in supervised image segmentation. Video segmentation is less explored, despite the temporal dimension being highly informative. Semantic labels, e.g. that cannot be accurately detected in the current frame, may be inferred by incorporating information from previous frames. However, video segmentation is challenging due to the amount of data that needs to be processed and, more importantly, the cost involved in obtaining ground truth annotations for each frame. In this paper, we tackle the issue of label scarcity by using consecutive frames of a video, where only one frame is annotated. We propose a deep, end-to-end trainable model which leverages temporal information in order to make use of easy to acquire unlabeled data. Our network architecture relies on a novel interconnection of two components: a fully convolutional network to model spatial information and temporal units that are employed at intermediate levels of the convolutional network in order to propagate information through time. The main contribution of this work is the guidance of the temporal signal through the network. We show that only placing a temporal module between the encoder and decoder is suboptimal (baseline). Our extensive experiments on the CityScapes dataset indicate that the resulting model can leverage unlabeled temporal frames and significantly outperform both the frame-by-frame image segmentation and the baseline approach.",0
"Supervised image segmentation has made significant progress in recent years, while video segmentation has been less explored despite the valuable information the temporal dimension can provide. Incorporating information from previous frames can help infer semantic labels that cannot be accurately detected in the current frame. However, video segmentation is challenging due to the amount of data that needs processing and the cost of obtaining ground truth annotations for each frame. This paper proposes a deep, end-to-end trainable model that uses consecutive frames of a video, where only one frame is annotated, to address the issue of label scarcity. The model leverages temporal information and easy-to-acquire unlabeled data. It employs a fully convolutional network to model spatial information and temporal units to propagate information through time. The main contribution is the guidance of the temporal signal through the network. The experiments on the CityScapes dataset show that the resulting model outperforms both the frame-by-frame image segmentation and the baseline approach.",1
"U-Net has been providing state-of-the-art performance in many medical image segmentation problems. Many modifications have been proposed for U-Net, such as attention U-Net, recurrent residual convolutional U-Net (R2-UNet), and U-Net with residual blocks or blocks with dense connections. However, all these modifications have an encoder-decoder structure with skip connections, and the number of paths for information flow is limited. We propose LadderNet in this paper, which can be viewed as a chain of multiple U-Nets. Instead of only one pair of encoder branch and decoder branch in U-Net, a LadderNet has multiple pairs of encoder-decoder branches, and has skip connections between every pair of adjacent decoder and decoder branches in each level. Inspired by the success of ResNet and R2-UNet, we use modified residual blocks where two convolutional layers in one block share the same weights. A LadderNet has more paths for information flow because of skip connections and residual blocks, and can be viewed as an ensemble of Fully Convolutional Networks (FCN). The equivalence to an ensemble of FCNs improves segmentation accuracy, while the shared weights within each residual block reduce parameter number. Semantic segmentation is essential for retinal disease detection. We tested LadderNet on two benchmark datasets for blood vessel segmentation in retinal images, and achieved superior performance over methods in the literature. The implementation is provided \url{https://github.com/juntang-zhuang/LadderNet}",0
"Numerous variations of U-Net, such as attention U-Net, R2-UNet, and U-Net with residual or dense blocks, have been proposed to enhance its state-of-the-art performance in medical image segmentation. However, these modifications have limited information flow paths due to their encoder-decoder structure with skip connections. To address this, we introduce LadderNet, which comprises multiple pairs of encoder-decoder branches with skip connections between adjacent decoder and encoder branches. We utilized modified residual blocks with shared weights between two convolutional layers inspired by ResNet and R2-UNet. LadderNet has more paths for information flow and can be considered an ensemble of FCNs, improving segmentation accuracy while reducing parameter number. We evaluated LadderNet on two benchmark datasets for retinal blood vessel segmentation, and it outperformed existing methods. Our implementation can be found at \url{https://github.com/juntang-zhuang/LadderNet}.",1
"In this paper, we propose a Customizable Architecture Search (CAS) approach to automatically generate a network architecture for semantic image segmentation. The generated network consists of a sequence of stacked computation cells. A computation cell is represented as a directed acyclic graph, in which each node is a hidden representation (i.e., feature map) and each edge is associated with an operation (e.g., convolution and pooling), which transforms data to a new layer. During the training, the CAS algorithm explores the search space for an optimized computation cell to build a network. The cells of the same type share one architecture but with different weights. In real applications, however, an optimization may need to be conducted under some constraints such as GPU time and model size. To this end, a cost corresponding to the constraint will be assigned to each operation. When an operation is selected during the search, its associated cost will be added to the objective. As a result, our CAS is able to search an optimized architecture with customized constraints. The approach has been thoroughly evaluated on Cityscapes and CamVid datasets, and demonstrates superior performance over several state-of-the-art techniques. More remarkably, our CAS achieves 72.3% mIoU on the Cityscapes dataset with speed of 108 FPS on an Nvidia TitanXp GPU.",0
"Our paper introduces a method called Customizable Architecture Search (CAS) for generating a network architecture that can be customized for semantic image segmentation. The network is made up of computation cells, represented as directed acyclic graphs where nodes are hidden representations and edges relate to operations such as convolution and pooling. During training, the CAS algorithm searches for an optimized computation cell to construct the network. However, for real-world applications, the optimization process may need to consider constraints like GPU time and model size. In such cases, each operation is assigned a cost corresponding to the constraint, which is added to the objective when an operation is selected during the search. This allows the CAS to find an optimized architecture that meets the customized constraints. We evaluated our approach on Cityscapes and CamVid datasets and achieved superior performance compared to other state-of-the-art techniques. Notably, our CAS achieved 72.3% mIoU on the Cityscapes dataset with a speed of 108 FPS on an Nvidia TitanXp GPU.",1
"Deep learning based medical image segmentation models usually require large datasets with high-quality dense segmentations to train, which are very time-consuming and expensive to prepare. One way to tackle this challenge is by using the mixed-supervised learning framework, in which only a part of data is densely annotated with segmentation label and the rest is weakly labeled with bounding boxes. The model is trained jointly in a multi-task learning setting. In this paper, we propose Mixed-Supervised Dual-Network (MSDN), a novel architecture which consists of two separate networks for the detection and segmentation tasks respectively, and a series of connection modules between the layers of the two networks. These connection modules are used to transfer useful information from the auxiliary detection task to help the segmentation task. We propose to use a recent technique called ""Squeeze and Excitation"" in the connection module to boost the transfer. We conduct experiments on two medical image segmentation datasets. The proposed MSDN model outperforms multiple baselines.",0
"The development of deep learning models for medical image segmentation is often hindered by the need for large datasets with high-quality dense segmentations, which are costly and time-consuming to prepare. To overcome this challenge, a mixed-supervised learning framework can be employed, where only a portion of the data is densely annotated with segmentation labels while the remainder is weakly labeled with bounding boxes. In this study, we propose a novel architecture called Mixed-Supervised Dual-Network (MSDN) that utilizes two separate networks for detection and segmentation tasks. The networks are connected by a series of modules that transfer valuable information from the detection task to aid the segmentation task. The connection modules employ the ""Squeeze and Excitation"" technique to enhance the transfer. We evaluate the MSDN model on two medical image segmentation datasets, and it outperforms multiple baseline models.",1
"Data for Image segmentation models can be costly to obtain due to the precision required by human annotators. We run a series of experiments showing the effect of different kinds of Dropout training on the DeepLabv3+ Image segmentation model when trained using a small dataset. We find that when appropriate forms of Dropout are applied in the right place in the model architecture that non-insignificant improvement in Mean Intersection over Union (mIoU) score can be observed. In our best case, we find that applying Dropout scheduling in conjunction with SpatialDropout improves baseline mIoU from 0.49 to 0.59. This result shows that even where a model architecture makes extensive use of Batch Normalization, Dropout can still be an effective way of improving performance in low data situations.",0
"Obtaining data for Image segmentation models can be expensive due to the high level of accuracy required by human annotators. Our study involved conducting a series of experiments to analyze the impact of various Dropout training approaches on the DeepLabv3+ Image segmentation model trained with a limited dataset. Our findings indicate that by appropriately implementing Dropout in the model architecture, notable enhancements in Mean Intersection over Union (mIoU) score can be achieved. Our best outcome was observed when we combined Dropout scheduling with SpatialDropout, which elevated the baseline mIoU from 0.49 to 0.59. This outcome demonstrates that even when a model architecture extensively employs Batch Normalization, Dropout can still effectively boost performance in scenarios with limited data.",1
"Nowadays U-net-like FCNs predominate various biomedical image segmentation applications and attain promising performance, largely due to their elegant architectures, e.g., symmetric contracting and expansive paths as well as lateral skip-connections. It remains a research direction to devise novel architectures to further benefit the segmentation. In this paper, we develop an ACE-net that aims to enhance the feature representation and utilization by augmenting the contracting and expansive paths. In particular, we augment the paths by the recently proposed advanced techniques including ASPP, dense connection and deep supervision mechanisms, and novel connections such as directly connecting the raw image to the expansive side. With these augmentations, ACE-net can utilize features from multiple sources, scales and reception fields to segment while still maintains a relative simple architecture. Experiments on two typical biomedical segmentation tasks validate its effectiveness, where highly competitive results are obtained in both tasks while ACE-net still runs fast at inference.",0
"Currently, U-net-like FCNs are widely used in various biomedical image segmentation applications due to their sophisticated architectures that involve symmetric contracting and expansive paths, in addition to lateral skip-connections. However, there is still room for further research to create innovative architectures that can enhance segmentation. In this study, we introduce ACE-net, which aims to improve feature representation and utilization by augmenting the contracting and expansive paths. This is achieved by employing advanced techniques such as ASPP, dense connection, deep supervision mechanisms, and novel connections that directly connect the raw image to the expansive side. By incorporating these augmentations, ACE-net can utilize features from multiple sources, scales, and reception fields to enhance segmentation while maintaining a relatively simple architecture. Our experiments on two typical biomedical segmentation tasks demonstrate the effectiveness of ACE-net, as it achieves highly competitive results in both tasks while still running fast at inference.",1
"Deep convolutional neural networks have driven substantial advancements in the automatic understanding of images. Requiring a large collection of images and their associated annotations is one of the main bottlenecks limiting the adoption of deep networks. In the task of medical image segmentation, requiring pixel-level semantic annotations performed by human experts exacerbate this difficulty. This paper proposes a new framework to train a fully convolutional segmentation network from a large set of cheap unreliable annotations and a small set of expert-level clean annotations. We propose a spatially adaptive reweighting approach to treat clean and noisy pixel-level annotations commensurately in the loss function. We deploy a meta-learning approach to assign higher importance to pixels whose loss gradient direction is closer to those of clean data. Our experiments on training the network using segmentation ground truth corrupted with different levels of annotation noise show how spatial reweighting improves the robustness of deep networks to noisy annotations.",0
"Significant advancements in the automatic understanding of images have been made thanks to deep convolutional neural networks. However, the adoption of deep networks has been hindered by the need for a large collection of images and their annotations. This is particularly challenging in medical image segmentation, where pixel-level semantic annotations require human experts. To overcome this difficulty, a new framework is proposed in this paper to train a fully convolutional segmentation network using a combination of cheap, unreliable annotations and a smaller set of expert-level clean annotations. A spatially adaptive reweighting approach is suggested to treat clean and noisy pixel-level annotations equally in the loss function. Additionally, a meta-learning approach assigns higher importance to pixels whose loss gradient direction is closer to that of clean data. The effectiveness of this approach is demonstrated through experiments on training the network using segmentation ground truth corrupted with varying levels of annotation noise. The results show that spatial reweighting improves the robustness of deep networks to noisy annotations.",1
"The performance of the state-of-the-art image segmentation methods heavily relies on the high-quality annotations, which are not easily affordable, particularly for medical data. To alleviate this limitation, in this study, we propose a weakly supervised image segmentation method based on a deep geodesic prior. We hypothesize that integration of this prior information can reduce the adverse effects of weak labels in segmentation accuracy. Our proposed algorithm is based on a prior information, extracted from an auto-encoder, trained to map objects geodesic maps to their corresponding binary maps. The obtained information is then used as an extra term in the loss function of the segmentor. In order to show efficacy of the proposed strategy, we have experimented segmentation of cardiac substructures with clean and two levels of noisy labels (L1, L2). Our experiments showed that the proposed algorithm boosted the performance of baseline deep learning-based segmentation for both clean and noisy labels by 4.4%, 4.6%(L1), and 6.3%(L2) in dice score, respectively. We also showed that the proposed method was more robust in the presence of high-level noise due to the existence of shape priors.",0
"The accuracy of modern image segmentation methods depends heavily on precise annotations, which can be difficult to obtain, particularly for medical data. To address this issue, we propose a weakly supervised image segmentation method that utilizes a deep geodesic prior. Our hypothesis is that integrating this prior information can improve segmentation accuracy despite weak labels. Our algorithm uses an auto-encoder to extract prior information, which is then included as an additional term in the segmentor's loss function. We tested our approach by segmenting cardiac substructures with clean and two levels of noisy labels (L1, L2). Our results showed that our algorithm improved the performance of the deep learning-based segmentation for clean and noisy labels by 4.4%, 4.6% (L1), and 6.3% (L2) in dice score. Additionally, we demonstrated that our method is more resilient to high-level noise due to the inclusion of shape priors.",1
"In Computer Vision, edge detection is one of the favored approaches for feature and object detection in images since it provides information about their objects boundaries. Other region-based approaches use probabilistic analysis such as clustering and Markov random fields, but those methods cannot be used to analyze edges and their interaction. In fact, only image segmentation can produce regions based on edges, but it requires thresholding by simply separating the regions into binary in-out information. Hence, there is currently a gap between edge-based and region-based algorithms, since edges cannot be used to study the properties of a region and vice versa. The objective of this paper is to present a novel spatial probability analysis that allows determining the probability of inclusion inside a set of partial contours (strokes). To answer this objective, we developed a new approach that uses electromagnetic convolutions and repulsion optimization to compute the required probabilities. Hence, it becomes possible to generate a continuous space of probability based only on the edge information, thus bridging the gap between the edge-based methods and the region-based methods. The developed method is consistent with the fundamental properties of inclusion probabilities and its results are validated by comparing an image with the probability-based estimation given by our algorithm. The method can also be generalized to take into consideration the intensity of the edges or to be used for 3D shapes. This is the first documented method that allows computing a space of probability based on interacting edges, which opens the path to broader applications such as image segmentation and contour completion.",0
"Edge detection is a popular technique for feature and object detection in images in the field of Computer Vision, as it provides valuable information about object boundaries. Although other region-based approaches rely on probabilistic analysis such as clustering and Markov random fields, they cannot be used to analyze edges and their interactions. Image segmentation is the only method that can produce regions based on edges, but it requires thresholding and separation of regions into binary in-out information. Consequently, there is a gap between edge-based and region-based algorithms, making it impossible to study the properties of a region using edges and vice versa. This paper aims to present a new spatial probability analysis approach that utilizes electromagnetic convolutions and repulsion optimization to compute the probability of inclusion within a set of partial contours. This method generates a continuous space of probability based solely on edge information, bridging the gap between edge-based and region-based methods. The method is consistent with inclusion probabilities' fundamental properties and can be extended to consider edge intensity or 3D shapes. The proposed method is the first documented approach that enables computing a probability space based on interacting edges, paving the way for broader applications like image segmentation and contour completion. The algorithm's efficacy is demonstrated by comparing the estimated probability-based results with an image, validating the method's effectiveness.",1
"Long-term visual localization is the problem of estimating the camera pose of a given query image in a scene whose appearance changes over time. It is an important problem in practice, for example, encountered in autonomous driving. In order to gain robustness to such changes, long-term localization approaches often use segmantic segmentations as an invariant scene representation, as the semantic meaning of each scene part should not be affected by seasonal and other changes. However, these representations are typically not very discriminative due to the limited number of available classes. In this paper, we propose a new neural network, the Fine-Grained Segmentation Network (FGSN), that can be used to provide image segmentations with a larger number of labels and can be trained in a self-supervised fashion. In addition, we show how FGSNs can be trained to output consistent labels across seasonal changes. We demonstrate through extensive experiments that integrating the fine-grained segmentations produced by our FGSNs into existing localization algorithms leads to substantial improvements in localization performance.",0
"In the realm of autonomous driving, long-term visual localization is a crucial task that involves determining the camera's position in a dynamic scene. This estimation is challenging because the scene's appearance changes over time. To address this issue, many long-term localization methods use semantic segmentations as a consistent representation of the scene. However, these representations have limited discriminative power due to the limited number of available classes. To overcome this limitation, we propose the Fine-Grained Segmentation Network (FGSN), a neural network that produces image segmentations with a larger number of labels and can be trained in a self-supervised manner. Moreover, we demonstrate how FGSNs can provide consistent labels for seasonal changes. Our experiments show that incorporating fine-grained segmentations produced by FGSNs into existing localization algorithms significantly improves performance.",1
"Accurate segmentation of the prostate from magnetic resonance (MR) images provides useful information for prostate cancer diagnosis and treatment. However, automated prostate segmentation from 3D MR images still faces several challenges. For instance, a lack of clear edge between the prostate and other anatomical structures makes it challenging to accurately extract the boundaries. The complex background texture and large variation in size, shape and intensity distribution of the prostate itself make segmentation even further complicated. With deep learning, especially convolutional neural networks (CNNs), emerging as commonly used methods for medical image segmentation, the difficulty in obtaining large number of annotated medical images for training CNNs has become much more pronounced that ever before. Since large-scale dataset is one of the critical components for the success of deep learning, lack of sufficient training data makes it difficult to fully train complex CNNs. To tackle the above challenges, in this paper, we propose a boundary-weighted domain adaptive neural network (BOWDA-Net). To make the network more sensitive to the boundaries during segmentation, a boundary-weighted segmentation loss (BWL) is proposed. Furthermore, an advanced boundary-weighted transfer leaning approach is introduced to address the problem of small medical imaging datasets. We evaluate our proposed model on the publicly available MICCAI 2012 Prostate MR Image Segmentation (PROMISE12) challenge dataset. Our experimental results demonstrate that the proposed model is more sensitive to boundary information and outperformed other state-of-the-art methods.",0
"Automated segmentation of the prostate from 3D MR images is important for the diagnosis and treatment of prostate cancer, but it is challenging due to unclear edges between the prostate and other anatomical structures, complex background texture, and large variations in size, shape, and intensity distribution of the prostate. Deep learning, particularly CNNs, are popular methods for medical image segmentation but require large annotated datasets for successful training. To overcome these challenges, this paper proposes BOWDA-Net, a boundary-weighted domain adaptive neural network that uses a boundary-weighted segmentation loss and advanced boundary-weighted transfer learning to improve sensitivity to boundaries and address small medical imaging datasets. The proposed model is evaluated on the PROMISE12 dataset and outperforms other state-of-the-art methods.",1
"Parsing sketches via semantic segmentation is attractive but challenging, because (i) free-hand drawings are abstract with large variances in depicting objects due to different drawing styles and skills; (ii) distorting lines drawn on the touchpad make sketches more difficult to be recognized; (iii) the high-performance image segmentation via deep learning technologies needs enormous annotated sketch datasets during the training stage. In this paper, we propose a Sketch-target deep FCN Segmentation Network(SFSegNet) for automatic free-hand sketch segmentation, labeling each sketch in a single object with multiple parts. SFSegNet has an end-to-end network process between the input sketches and the segmentation results, composed of 2 parts: (i) a modified deep Fully Convolutional Network(FCN) using a reweighting strategy to ignore background pixels and classify which part each pixel belongs to; (ii) affine transform encoders that attempt to canonicalize the shaking strokes. We train our network with the dataset that consists of 10,000 annotated sketches, to find an extensively applicable model to segment stokes semantically in one ground truth. Extensive experiments are carried out and segmentation results show that our method outperforms other state-of-the-art networks.",0
"Although there is a strong appeal to parse sketches through semantic segmentation, it is also a difficult task due to several reasons. Firstly, free-hand drawings are often abstract and can vary greatly in their depiction of objects due to different drawing techniques and skills. Additionally, sketches drawn on touchpads can become distorted, making them harder to recognize. Lastly, deep learning technologies require a large amount of annotated sketch data during the training stage, making high-performance image segmentation challenging. To address these challenges, this paper introduces a Sketch-target deep FCN Segmentation Network (SFSegNet) that automatically segments free-hand sketches by labeling each sketch into a single object with multiple parts. SFSegNet utilizes a modified deep Fully Convolutional Network (FCN) with a reweighting strategy to ignore background pixels and classify each pixel's part. Affine transform encoders are also incorporated to standardize the shaking strokes. The network is trained with a dataset of 10,000 annotated sketches to obtain a widely applicable model that semantically segments strokes into one ground truth. Extensive experiments demonstrate that our method outperforms other state-of-the-art networks.",1
"We present a Deep Differentiable Simplex Layer (DDSL) for neural networks for geometric deep learning. The DDSL is a differentiable layer compatible with deep neural networks for bridging simplex mesh-based geometry representations (point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images (e.g., 2D/3D grids). The DDSL uses Non-Uniform Fourier Transform (NUFT) to perform differentiable, efficient, anti-aliased rasterization of simplex-based signals. We present a complete theoretical framework for the process as well as an efficient backpropagation algorithm. Compared to previous differentiable renderers and rasterizers, the DDSL generalizes to arbitrary simplex degrees and dimensions. In particular, we explore its applications to 2D shapes and illustrate two applications of this method: (1) mesh editing and optimization guided by neural network outputs, and (2) using DDSL for a differentiable rasterization loss to facilitate end-to-end training of polygon generators. We are able to validate the effectiveness of gradient-based shape optimization with the example of airfoil optimization, and using the differentiable rasterization loss to facilitate end-to-end training, we surpass state of the art for polygonal image segmentation given ground-truth bounding boxes.",0
"Our study introduces the Deep Differentiable Simplex Layer (DDSL), which is a layer that can be incorporated into deep neural networks for geometric deep learning. The DDSL is designed to connect simplex mesh-based geometry representations (such as point clouds, line mesh, triangular mesh, tetrahedral mesh) with raster images (such as 2D/3D grids) in a differentiable way. To achieve this, the DDSL utilizes the Non-Uniform Fourier Transform (NUFT) for efficient and accurate rasterization of simplex-based signals. We provide a comprehensive theoretical framework for the DDSL process and develop an efficient backpropagation algorithm. Notably, the DDSL is capable of generalizing to arbitrary simplex degrees and dimensions, unlike previous differentiable renderers and rasterizers. We demonstrate two applications of the DDSL: (1) mesh editing and optimization using neural network outputs, and (2) using DDSL for differentiable rasterization loss to enable end-to-end training of polygon generators. We validate these applications by showing that gradient-based shape optimization is effective, as demonstrated by airfoil optimization, and that the differentiable rasterization loss improves the state-of-the-art for polygonal image segmentation with ground-truth bounding boxes.",1
"For the task of medical image segmentation, fully convolutional network (FCN) based architectures have been extensively used with various modifications. A rising trend in these architectures is to employ joint-learning of the target region with an auxiliary task, a method commonly known as multi-task learning. These approaches help impose smoothness and shape priors, which vanilla FCN approaches do not necessarily incorporate. In this paper, we propose a novel plug-and-play module, which we term as Conv-MCD, which exploits structural information in two ways - i) using the contour map and ii) using the distance map, both of which can be obtained from ground truth segmentation maps with no additional annotation costs. The key benefit of our module is the ease of its addition to any state-of-the-art architecture, resulting in a significant improvement in performance with a minimal increase in parameters. To substantiate the above claim, we conduct extensive experiments using 4 state-of-the-art architectures across various evaluation metrics, and report a significant increase in performance in relation to the base networks. In addition to the aforementioned experiments, we also perform ablative studies and visualization of feature maps to further elucidate our approach.",0
"Fully convolutional network (FCN) based architectures have been widely used for medical image segmentation, often with modifications. Multi-task learning is a popular method in which the target region is learned jointly with an auxiliary task to impose smoothness and shape priors, which are not typically incorporated in vanilla FCN approaches. This paper proposes a novel plug-and-play module called Conv-MCD, which leverages structural information from contour and distance maps obtained from ground truth segmentation maps without additional annotation costs. The module can be easily added to any state-of-the-art architecture, resulting in a significant performance improvement with minimal increase in parameters. Extensive experiments were conducted using four state-of-the-art architectures, which demonstrated a substantial increase in performance compared to the base networks. Ablative studies and feature map visualization were also performed to provide further insights into the proposed approach.",1
"Image segmentation is a primary task in many medical applications. Recently, many deep networks derived from U-Net have been extensively used in various medical image segmentation tasks. However, in most of the cases, networks similar to U-net produce coarse and non-smooth segmentations with lots of discontinuities. To improve and refine the performance of U-Net like networks, we propose the use of parallel decoders which along with performing the mask predictions also perform contour prediction and distance map estimation. The contour and distance map aid in ensuring smoothness in the segmentation predictions. To facilitate joint training of three tasks, we propose a novel architecture called Psi-Net with a single encoder and three parallel decoders (thus having a shape of $\Psi$), one decoder to learns the segmentation mask prediction and other two decoders to learn the auxiliary tasks of contour detection and distance map estimation. The learning of these auxiliary tasks helps in capturing the shape and the boundary information. We also propose a new joint loss function for the proposed architecture. The loss function consists of a weighted combination of Negative Log likelihood and Mean Square Error loss. We have used two publicly available datasets: 1) Origa dataset for the task of optic cup and disc segmentation and 2) Endovis segment dataset for the task of polyp segmentation to evaluate our model. We have conducted extensive experiments using our network to show our model gives better results in terms of segmentation, boundary and shape metrics.",0
"In numerous medical applications, image segmentation is a crucial task. Many deep networks based on U-Net have recently been utilized extensively for various medical image segmentation tasks. However, networks similar to U-Net typically generate rough and non-smooth segmentations with a large number of discontinuities. To enhance and refine the performance of U-Net-like networks, we suggest employing parallel decoders that execute mask predictions, contour prediction, and distance map estimation. The contour and distance map aid in ensuring smoothness in the segmentation predictions. To enable joint training of three tasks, we propose a novel architecture called Psi-Net, comprising a single encoder and three parallel decoders (thus having a shape of $\Psi$). One decoder learns the segmentation mask prediction, while the other two decoders learn the auxiliary tasks of contour detection and distance map estimation, respectively. Learning these auxiliary tasks helps capture the shape and boundary information. We also propose a new joint loss function for the proposed architecture, consisting of a weighted combination of Negative Log likelihood and Mean Square Error loss. We evaluated our model using two publicly available datasets: 1) Origa dataset for the task of optic cup and disc segmentation and 2) Endovis segment dataset for the task of polyp segmentation. Our extensive experiments using our network demonstrate that our model provides better results in terms of segmentation, boundary, and shape metrics.",1
"India is an agriculture-dependent country. As we all know that farming is the backbone of our country it is our responsibility to preserve the crops. However, we cannot stop the destruction of crops by natural calamities at least we have to try to protect our crops from diseases. To, detect a plant disease we need a fast automatic way. So, this paper presents a model to identify the particular disease of plant leaves at early stages so that we can prevent or take a remedy to stop spreading of the disease. This proposed model is made into five sessions. Image preprocessing includes the enhancement of the low light image done using inception modules in CNN. Low-resolution image enhancement is done using an Adversarial Neural Network. This also includes Conversion of RGB Image to YCrCb color space. Next, this paper presents a methodology for image segmentation which is an important aspect for identifying the disease symptoms. This segmentation is done using the genetic algorithm. Due to this process the segmentation of the leaf Image this helps in detection of the leaf mage automatically and classifying. Texture extraction is done using the statistical model called GLCM and finally, the classification of the diseases is done using the SVM using Different Kernels with the high accuracy.",0
"India's economy heavily relies on agriculture, making it crucial for us to preserve our crops. Although natural calamities cannot be prevented, we must attempt to protect our crops from diseases. Detecting plant diseases automatically and quickly is necessary. This research paper introduces a model that identifies leaf diseases in their early stages to prevent spreading. The model is divided into five sessions: image preprocessing using inception modules in CNN to enhance low light images, low-resolution image enhancement using an Adversarial Neural Network, conversion of RGB image to YCrCb color space, image segmentation using the genetic algorithm, and texture extraction using GLCM. Finally, the SVM with different kernels classifies the diseases with high accuracy.",1
"In order to completely separate objects with large sections of occluded boundaries in an image, we devise a new variational level set model for image segmentation combining the Chan-Vese model with elastica and landmark constraints. For computational efficiency, we design its Augmented Lagrangian Method (ALM) or Alternating Direction Method of Multiplier (ADMM) method by introducing some auxiliary variables, Lagrange multipliers, and penalty parameters. In each loop of alternating iterative optimization, the sub-problems of minimization can be easily solved via the Gauss-Seidel iterative method and generalized soft thresholding formulas with projection, respectively. Numerical experiments show that the proposed model can not only recover larger broken boundaries but can also improve segmentation efficiency, as well as decrease the dependence of segmentation on parameter tuning and initialization.",0
"A new variational level set model has been created for image segmentation, which combines the Chan-Vese model with elastica and landmark constraints. This model is designed to fully separate objects that have large sections of occluded boundaries in an image. To increase computational efficiency, the Augmented Lagrangian Method (ALM) or Alternating Direction Method of Multiplier (ADMM) method has been used, which introduces auxiliary variables, Lagrange multipliers, and penalty parameters. The minimization sub-problems within each loop of the alternating iterative optimization can be easily solved through the Gauss-Seidel iterative method and generalized soft thresholding formulas with projection. Numerical experiments have shown that this model can recover larger broken boundaries, improve segmentation efficiency, and reduce the dependence on parameter tuning and initialization.",1
"Generative Adversarial Networks (GANs) have the capability of synthesizing images, which have been successfully applied to medical image synthesis tasks. However, most of existing methods merely consider the global contextual information and ignore the fine foreground structures, e.g., vessel, skeleton, which may contain diagnostic indicators for medical image analysis. Inspired by human painting procedure, which is composed of stroking and color rendering steps, we propose a Sketching-rendering Unconditional Generative Adversarial Network (SkrGAN) to introduce a sketch prior constraint to guide the medical image generation. In our SkrGAN, a sketch guidance module is utilized to generate a high quality structural sketch from random noise, then a color render mapping is used to embed the sketch-based representations and resemble the background appearances. Experimental results show that the proposed SkrGAN achieves the state-of-the-art results in synthesizing images for various image modalities, including retinal color fundus, X-Ray, Computed Tomography (CT) and Magnetic Resonance Imaging (MRI). In addition, we also show that the performances of medical image segmentation method have been improved by using our synthesized images as data augmentation.",0
"The ability of Generative Adversarial Networks (GANs) to create images has proven beneficial in medical image synthesis tasks. However, most current methods only consider global contextual information and disregard the detailed foreground structures, such as vessels and skeletons, that may contain crucial diagnostic indicators for medical image analysis. Drawing inspiration from the human painting process, which involves stroking and color rendering, we propose a Sketching-rendering Unconditional Generative Adversarial Network (SkrGAN) that incorporates a sketch prior constraint to guide medical image generation. Our SkrGAN employs a sketch guidance module to generate a high-quality structural sketch from random noise, followed by a color render mapping to incorporate the sketch-based representations and mimic the background appearances. Experimental results demonstrate that our SkrGAN outperforms existing methods in synthesizing images for various image modalities, including retinal color fundus, X-Ray, Computed Tomography (CT), and Magnetic Resonance Imaging (MRI). Additionally, we demonstrate that our synthesized images improve the performance of medical image segmentation methods when used as data augmentation.",1
"Dense prediction models are widely used for image segmentation. One important challenge is to sufficiently train these models to yield good generalizations for hard-to-learn pixels. A typical group of such hard-to-learn pixels are boundaries between instances. Many studies have proposed to give specific attention to learning the boundary pixels. They include designing multi-task networks with an additional task of boundary prediction and increasing the weights of boundary pixels' predictions in the loss function. Such strategies require defining what to attend beforehand and incorporating this defined attention to the learning model. However, there may exist other groups of hard-to-learn pixels and manually defining and incorporating the appropriate attention for each group may not be feasible. In order to provide a more attainable and scalable solution, this paper proposes AttentionBoost, which is a new multi-attention learning model based on adaptive boosting. AttentionBoost designs a multi-stage network and introduces a new loss adjustment mechanism for a dense prediction model to adaptively learn what to attend at each stage directly on image data without necessitating any prior definition about what to attend. This mechanism modulates the attention of each stage to correct the mistakes of previous stages, by adjusting the loss weight of each pixel prediction separately with respect to how accurate the previous stages are on this pixel. This mechanism enables AttentionBoost to learn different attentions for different pixels at the same stage, according to difficulty of learning these pixels, as well as multiple attentions for the same pixel at different stages, according to confidence of these stages on their predictions for this pixel. Using gland segmentation as a showcase application, our experiments demonstrate that AttentionBoost improves the results of its counterparts.",0
"Image segmentation often relies on dense prediction models, but one of the biggest challenges is training these models to accurately predict hard-to-learn pixels. For instance, boundaries between instances can be particularly tricky to predict. Previous studies have attempted to overcome this issue by incorporating attention mechanisms, such as multi-task networks or increasing the weight of boundary pixels in the loss function. However, defining attention for every group of hard-to-learn pixels is not practical. To address this, the authors propose AttentionBoost, a multi-attention learning model that uses adaptive boosting to dynamically adjust the attention of each stage based on image data. This approach allows AttentionBoost to learn different attentions for different pixels and stages, leading to improved results in gland segmentation experiments.",1
