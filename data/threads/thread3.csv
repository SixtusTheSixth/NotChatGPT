"Obtaining continuous representations of structural data such as directed acyclic graphs (DAGs) has gained attention in machine learning and artificial intelligence. However, embedding complex DAGs in which both ancestors and descendants of nodes are exponentially increasing is difficult. Tackling in this problem, we develop Disk Embeddings, which is a framework for embedding DAGs into quasi-metric spaces. Existing state-of-the-art methods, Order Embeddings and Hyperbolic Entailment Cones, are instances of Disk Embedding in Euclidean space and spheres respectively. Furthermore, we propose a novel method Hyperbolic Disk Embeddings to handle exponential growth of relations. The results of our experiments show that our Disk Embedding models outperform existing methods especially in complex DAGs other than trees.",0
"This research investigates hyperbolic disk embeddings as a means to visualize directed acyclic graphs (DAGs). DAGs represent complex relationships among nodes, making them difficult to comprehend visually. Existing approaches struggle to capture the scale differences and the intricacies of these diagrams. Our approach uses conformal mapping techniques from hyperbolic geometry to map the nodes onto disks while preserving their distances. We first define a metric that captures both edge length and topology differences. Using this metric, we develop an algorithm for optimal embedding into a circle of fixed size and aspect ratio. Finally, experiments show significant improvements over existing methods by providing more intuitive layouts and better scalability. These results have direct applications in graph drawing, network analysis, and data visualization domains.",1
"Stochastic blockmodels (SBM) and their variants, $e.g.$, mixed-membership and overlapping stochastic blockmodels, are latent variable based generative models for graphs. They have proven to be successful for various tasks, such as discovering the community structure and link prediction on graph-structured data. Recently, graph neural networks, $e.g.$, graph convolutional networks, have also emerged as a promising approach to learn powerful representations (embeddings) for the nodes in the graph, by exploiting graph properties such as locality and invariance. In this work, we unify these two directions by developing a \emph{sparse} variational autoencoder for graphs, that retains the interpretability of SBMs, while also enjoying the excellent predictive performance of graph neural nets. Moreover, our framework is accompanied by a fast recognition model that enables fast inference of the node embeddings (which are of independent interest for inference in SBM and its variants). Although we develop this framework for a particular type of SBM, namely the \emph{overlapping} stochastic blockmodel, the proposed framework can be adapted readily for other types of SBMs. Experimental results on several benchmarks demonstrate encouraging results on link prediction while learning an interpretable latent structure that can be used for community discovery.",0
"Abstract: In recent years, there has been growing interest in using graph neural networks (GNN) for node classification on large graphs. However, many real world datasets have communities which can only be identified by their characteristic distributions rather than specific node features. To account for these differences, we propose extending GNNs to process stochastic block models (SBM), a popular generative model for community detection. By treating each SBM distribution as a unique layer in our deep learning architecture, we enable robust inference across varying degrees of homophily within and between communities. Our approach uses spectral graph convolutional layers to learn both community structure and node embedding representations, resulting in improved accuracy compared to state-of-the-art methods across multiple benchmark datasets. Additionally, through ablation studies we demonstrate that incorporating SBM priors into the training process yields more accurate estimates of community membership probabilities. Overall, our work bridges traditional random graph models with modern machine learning techniques, showing great potential for future research in the domain of network science.",1
"This work considers the problem of computing distances between structured objects such as undirected graphs, seen as probability distributions in a specific metric space. We consider a new transportation distance (i.e. that minimizes a total cost of transporting probability masses) that unveils the geometric nature of the structured objects space. Unlike Wasserstein or Gromov-Wasserstein metrics that focus solely and respectively on features (by considering a metric in the feature space) or structure (by seeing structure as a metric space), our new distance exploits jointly both information, and is consequently called Fused Gromov-Wasserstein (FGW). After discussing its properties and computational aspects, we show results on a graph classification task, where our method outperforms both graph kernels and deep graph convolutional networks. Exploiting further on the metric properties of FGW, interesting geometric objects such as Fr\'echet means or barycenters of graphs are illustrated and discussed in a clustering context.",0
"Abstract: This paper presents a new method for solving optimal transport problems that applies to structured data such as discrete measures on graphs. We develop a variant of the Sinkhorn-Knopp algorithm, which is well known for solving unstructured optimal transport problems, and extend it to handle structured data by introducing constraints based on the underlying graph structure. Our approach leverages recent advances in linear programming duality theory to efficiently solve large instances of the problem, resulting in significant improvements over existing methods. In addition, we demonstrate the effectiveness of our method through numerical experiments on synthetic and real-world datasets. Finally, we discuss potential applications of our work in areas such as computer vision, machine learning, and image processing.",1
"This paper addresses the challenging problem of retrieval and matching of graph structured objects, and makes two key contributions. First, we demonstrate how Graph Neural Networks (GNN), which have emerged as an effective model for various supervised prediction problems defined on structured data, can be trained to produce embedding of graphs in vector spaces that enables efficient similarity reasoning. Second, we propose a novel Graph Matching Network model that, given a pair of graphs as input, computes a similarity score between them by jointly reasoning on the pair through a new cross-graph attention-based matching mechanism. We demonstrate the effectiveness of our models on different domains including the challenging problem of control-flow-graph based function similarity search that plays an important role in the detection of vulnerabilities in software systems. The experimental analysis demonstrates that our models are not only able to exploit structure in the context of similarity learning but they can also outperform domain-specific baseline systems that have been carefully hand-engineered for these problems.",0
"In recent years, graph matching has emerged as an important problem in computer vision due to its ability to capture structural properties of complex objects such as shapes and scenes. However, traditional methods based on hand-crafted features have limited performance when applied to large-scale datasets or when dealing with noisy data. To address these challenges, we propose a novel approach called Graph Matching Networks (GMN) which uses convolutional neural networks to learn the similarity metric directly from raw image data. Our method extends the popular siamese network architecture by adding additional modules that process spatial hierarchies present in object graphs using dilated convolutions. We demonstrate the effectiveness of our GMN approach through extensive experiments on several benchmark datasets including MNIST, COCO Stuff, and VGGFaces2, achieving state-of-the art results on all three tasks while running significantly faster than competing approaches.",1
"Graph classification receives a great deal of attention from the non-Euclidean machine learning community. Recent advances in graph coarsening have enabled the training of deeper networks and produced new state-of-the-art results in many benchmark tasks. We examine how these architectures train and find that performance is highly-sensitive to initialisation and depends strongly on jumping-knowledge structures. We then show that, despite the great complexity of these models, competitive performance is achieved by the simplest of models -- structure-blind MLP, single-layer GCN and fixed-weight GCN -- and propose these be included as baselines in future.",0
"Graph classification is a subfield within machine learning that deals specifically with classifying graphs into predefined categories based on their topological properties. In recent years, several graph classification datasets have been released to facilitate research and evaluation of new approaches in this area. This has resulted in significant progress, with many state-of-the-art methods proposed by leading researchers in the field.  One of the main challenges faced by scientists working on graph classification networks is finding accurate baseline models against which to compare their own results. Several different techniques have been developed to solve this problem, including using traditional statistical measures such as mean squared error (MSE) and mean absolute error (MAE), as well as more advanced deep learning algorithms like convolutional neural networks (CNNs) and recursive neural networks (RNNs). Despite these advances, there remains room for improvement, particularly in terms of accuracy and computational efficiency.  This paper presents an overview of current methodologies used in graph classification, along with details of popular datasets and benchmarking tools available to researchers in this rapidly evolving field. We examine recent efforts aimed at improving graph classification performance through increased use of cutting-edge technologies, and discuss potential future directions for those seeking to push the boundaries of this exciting area of study even further. Our ultimate goal is to provide readers with valuable insights and guidance to enable them to contribute effectively to the development of groundbreaking graph classification networks and techniques.",1
"Interpretable machine learning has become a strong competitor for traditional black-box models. However, the possible loss of the predictive performance for gaining interpretability is often inevitable, putting practitioners in a dilemma of choosing between high accuracy (black-box models) and interpretability (interpretable models). In this work, we propose a novel framework for building a Hybrid Predictive Model (HPM) that integrates an interpretable model with any black-box model to combine their strengths. The interpretable model substitutes the black-box model on a subset of data where the black-box is overkill or nearly overkill, gaining transparency at no or low cost of the predictive accuracy. We design a principled objective function that considers predictive accuracy, model interpretability, and model transparency (defined as the percentage of data processed by the interpretable substitute.) Under this framework, we propose two hybrid models, one substituting with association rules and the other with linear models, and we design customized training algorithms for both models. We test the hybrid models on structured data and text data where interpretable models collaborate with various state-of-the-art black-box models. Results show that hybrid models obtain an efficient trade-off between transparency and predictive performance, characterized by our proposed efficient frontiers.",0
"This paper presents a hybrid predictive model that combines both interpretability and high accuracy by leveraging the complementary strengths of interpretable models (e.g., decision trees) and black box models (e.g., artificial neural networks). We demonstrate how these two types of models can collaborate effectively to make predictions while ensuring that human experts can understand and trust the underlying logic behind them. Our approach enables us to achieve state-of-the-art performance on several benchmark datasets, including image classification tasks where deep learning has been shown to excel. Through extensive experiments and case studies, we showcase the effectiveness of our methodology across diverse domains, including medical imaging, finance, and natural language processing, among others. Our work paves the way for future research into hybrid models that balance explainability and prediction accuracy, addressing a key challenge facing modern machine learning practitioners today.",1
Recent years have witnessed some exciting developments in the domain of generating images from scene-based text descriptions. These approaches have primarily focused on generating images from a static text description and are limited to generating images in a single pass. They are unable to generate an image interactively based on an incrementally additive text description (something that is more intuitive and similar to the way we describe an image). We propose a method to generate an image incrementally based on a sequence of graphs of scene descriptions (scene-graphs). We propose a recurrent network architecture that preserves the image content generated in previous steps and modifies the cumulative image as per the newly provided scene information. Our model utilizes Graph Convolutional Networks (GCN) to cater to variable-sized scene graphs along with Generative Adversarial image translation networks to generate realistic multi-object images without needing any intermediate supervision during training. We experiment with Coco-Stuff dataset which has multi-object images along with annotations describing the visual scene and show that our model significantly outperforms other approaches on the same dataset in generating visually consistent images for incrementally growing scene graphs.,0
"Artificial intelligence has made significant progress in recent years, enabling machines to perform tasks that were previously thought only possible by humans such as object detection, image generation, and natural language processing. In particular, generative models have achieved impressive results in generating realistic images from text descriptions, demonstrating their capability to capture complex relationships among visual features. However, most state-of-the-art methods rely on large amounts of data and computational resources which can limit their use cases in practice. Therefore, there is still a need for more efficient yet effective approaches to interactive image generation. This paper presents an approach based on scene graphs which addresses these limitations while providing high-quality output. We propose an algorithm capable of iteratively modifying existing images using user feedback and guiding the model towards desired outputs. Our experimental results show that our method outperforms baseline models both qualitatively and quantitatively, offering improvements in efficiency without sacrificing image fidelity. Finally, we demonstrate how our system can be applied to a variety of use cases including fashion design, content creation, and product customization, making it a versatile tool for creatives and non-experts alike. Overall, our work represents an important step forward in the development of interactive machine learning systems able to generate visually compelling images under tight resource constraints.",1
"3D object recognition accuracy can be improved by learning the multi-scale spatial features from 3D spatial geometric representations of objects such as point clouds, 3D models, surfaces, and RGB-D data. Current deep learning approaches learn such features either using structured data representations (voxel grids and octrees) or from unstructured representations (graphs and point clouds). Learning features from such structured representations is limited by the restriction on resolution and tree depth while unstructured representations creates a challenge due to non-uniformity among data samples. In this paper, we propose an end-to-end multi-level learning approach on a multi-level voxel grid to overcome these drawbacks. To demonstrate the utility of the proposed multi-level learning, we use a multi-level voxel representation of 3D objects to perform object recognition. The multi-level voxel representation consists of a coarse voxel grid that contains volumetric information of the 3D object. In addition, each voxel in the coarse grid that contains a portion of the object boundary is subdivided into multiple fine-level voxel grids. The performance of our multi-level learning algorithm for object recognition is comparable to dense voxel representations while using significantly lower memory.",0
"Artificial intelligence (AI) has made tremendous progress in recent years due to advancements in deep learning techniques such as convolutional neural networks (CNNs). In particular, 3D CNNs have been shown to effectively capture spatial features in volumetric data. However, these models often require large amounts of computational resources and may not always generalize well across different scales and resolutions. To address these limitations, we propose a multi-level 3D CNN architecture that learns multi-scale spatial features efficiently. Our approach involves designing a pyramidal network consisting of multiple levels, each with varying depths and widths to capture features at different scales. We use skip connections to combine features from lower layers to higher ones and adopt dilated convolutions to enlarge receptive fields without increasing parameter counts. Experimental results on several benchmark datasets show that our model outperforms existing state-of-the-art methods, demonstrating improved performance in terms of accuracy and efficiency. This work highlights the importance of considering scale-specific information during training and inference in computer vision tasks involving high-dimensional data.",1
"Graph kernels have attracted a lot of attention during the last decade, and have evolved into a rapidly developing branch of learning on structured data. During the past 20 years, the considerable research activity that occurred in the field resulted in the development of dozens of graph kernels, each focusing on specific structural properties of graphs. Graph kernels have proven successful in a wide range of domains, ranging from social networks to bioinformatics. The goal of this survey is to provide a unifying view of the literature on graph kernels. In particular, we present a comprehensive overview of a wide range of graph kernels. Furthermore, we perform an experimental evaluation of several of those kernels on publicly available datasets, and provide a comparative study. Finally, we discuss key applications of graph kernels, and outline some challenges that remain to be addressed.",0
"This survey explores graph kernels, which are functions that map graphs to vectors in a high-dimensional space, allowing them to be compared using standard kernel methods such as support vector machines (SVMs). We examine how graph kernels can be used to solve important problems in data mining, bioinformatics, computer vision, natural language processing, and other fields. Our discussion includes both traditional graph kernels based on algebraic properties of the graphs themselves and modern graph kernels that encode more global structural features of the graphs. After discussing key concepts and fundamental issues related to graph kernels, we provide a comprehensive list of existing approaches along with their corresponding references. Finally, we summarize recent developments and outline future research directions in the field.",1
"Convolution operations designed for graph-structured data usually utilize the graph Laplacian, which can be seen as message passing between the adjacent neighbors through a generic random walk. In this paper, we propose PAN, a new graph convolution framework that involves every path linking the message sender and receiver with learnable weights depending on the path length, which corresponds to the maximal entropy random walk. PAN generalizes the graph Laplacian to a new transition matrix we call \emph{maximal entropy transition} (MET) matrix derived from a path integral formalism. Most previous graph convolutional network architectures can be adapted to our framework, and many variations and derivatives based on the path integral idea can be developed. Experimental results show that the path integral based graph neural networks have great learnability and fast convergence rate, and achieve state-of-the-art performance on benchmark tasks.",0
"In recent years, graph neural networks have emerged as powerful tools for modeling complex relationships in large datasets. However, they often struggle with overfitting due to their high capacity and limited regularization methods available. To address these issues, we propose a novel method called PATH (Path Integral based Approximation for Time Series), which uses path integral calculus to approximate convolution operations on graphs. Our experiments show that our method outperforms existing state-of-the-art techniques by achieving significant improvements across a wide range of tasks while requiring fewer parameters. Additionally, the use of PATH makes deep graph neural networks easier to train, allowing them to converge faster and produce more accurate predictions. Our work demonstrates the potential of using novel mathematical techniques like path integrals to improve the performance of graph neural networks and overcome some of their limitations.",1
"The variational autoencoder (VAE) framework remains a popular option for training unsupervised generative models, especially for discrete data where generative adversarial networks (GANs) require workaround to create gradient for the generator. In our work modeling US postal addresses, we show that our discrete VAE with tree recursive architecture demonstrates limited capability of capturing field correlations within structured data, even after overcoming the challenge of posterior collapse with scheduled sampling and tuning of the KL-divergence weight $\beta$. Worse, VAE seems to have difficulty mapping its generated samples to the latent space, as their VAE loss lags behind or even increases during the training process. Motivated by this observation, we show that augmenting training data with generated variants (augmented training) and training a VAE with multiple values of $\beta$ simultaneously (multiscale VAE) both improve the generation quality of VAE. Despite their differences in motivation and emphasis, we show that augmented training and multiscale VAE are actually connected and have similar effects on the model.",0
"This may contain parts of other scientific papers, but needs to have more original content as well. I need this as soon as possible, thanks! ----- The authors present a method using generated loss and augmented training data within a multiscale framework that improves the performance of variational autoencoders (VAEs). In recent years, there has been significant interest in understanding the latent space learned by deep generative models like Variational Autoencoders (VAE) \cite{kingma2014auto}. However, analyzing these spaces can become cumbersome due to their high dimensionality. Here, we propose a novel algorithm named Generating Latent Spaces using Sparse Activation Networks (GSAN), which maps high-dimensional representations into low dimensions while preserving essential features. We show that GSAN can effectively perform feature visualization on large datasets such as CelebA\textunderscore FrontalFace\cite{liu2015faceattributes} without sacrificing quality. Our approach surpasses state-of-the-art performance on benchmark datasets. Furthermore, we demonstrate our method’s potential impact by examining how facial landmarks are preserved in the reconstructed images and the corresponding lower dimension latent space embeddings. Our work provides insight on how machine learning models could one day be used to synthetically generate missing values from incomplete data matrices instead of down sampling.  -----",1
"We present GraphTSNE, a novel visualization technique for graph-structured data based on t-SNE. The growing interest in graph-structured data increases the importance of gaining human insight into such datasets by means of visualization. Among the most popular visualization techniques, classical t-SNE is not suitable on such datasets because it has no mechanism to make use of information from the graph structure. On the other hand, visualization techniques which operate on graphs, such as Laplacian Eigenmaps and tsNET, have no mechanism to make use of information from node features. Our proposed method GraphTSNE produces visualizations which account for both graph structure and node features. It is based on scalable and unsupervised training of a graph convolutional network on a modified t-SNE loss. By assembling a suite of evaluation metrics, we demonstrate that our method produces desirable visualizations on three benchmark datasets.",0
"This paper presents GraphTSNE (T-distributed Stochastic Neighbor Embedding), a novel visualization technique specifically designed for graph-structured data such as social networks, biological systems, financial transactions, among others. Traditional dimensionality reduction techniques have limitations when applied to graphs due to their unique characteristics, including nonlinear relationships and network connectivity. Therefore, there is a need for a method that can capture these intricacies while providing meaningful insights into complex graph structures.  Our approach introduces two key innovations over existing methods for visualizing graph-structured data. Firstly, we leverage principles from graph theory to ensure that our embedding preserves the global structure of the original graph, resulting in more interpretable representations. Secondly, we incorporate probabilistic measures derived from local neighborhoods within each node's community, further enhancing the fidelity of the embeddings.  We evaluate GraphTSNE on several real-world datasets comprising both benchmark and proprietary sources, demonstrating improved performance compared to state-of-the-art alternatives across a range of evaluation metrics. In particular, our results show significant improvements in visual quality and clustering accuracy, thus confirming the effectiveness of our proposed methodology. Furthermore, the simplicity of our algorithm enables efficient computation and scalability to large datasets, making it readily applicable in practice.  Overall, GraphTSNE provides a powerful toolkit for researchers and practitioners working with graph-structured data, allowing them to gain new insights into complex networks by leveraging advanced machine learning techniques.",1
"In many applications where collecting data is expensive, for example neuroscience or medical imaging, the sample size is typically small compared to the feature dimension. It is challenging in this setting to train expressive, non-linear models without overfitting. These datasets call for intelligent regularization that exploits known structure, such as correlations between the features arising from the measurement device. However, existing structured regularizers need specially crafted solvers, which are difficult to apply to complex models. We propose a new regularizer specifically designed to leverage structure in the data in a way that can be applied efficiently to complex models. Our approach relies on feature grouping, using a fast clustering algorithm inside a stochastic gradient descent loop: given a family of feature groupings that capture feature covariations, we randomly select these groups at each iteration. We show that this approach amounts to enforcing a denoising regularizer on the solution. The method is easy to implement in many model architectures, such as fully connected neural networks, and has a linear computational cost. We apply this regularizer to a real-world fMRI dataset and the Olivetti Faces datasets. Experiments on both datasets demonstrate that the proposed approach produces models that generalize better than those trained with conventional regularizers, and also improves convergence speed.",0
One possible approach to solving high-dimensional problems with structured data involves grouping features together into clusters. These feature groups can then serve as regularizers that reduce overfitting by promoting smoother predictions across groups of similar features. This method allows for efficient model training and outperforms traditional Lasso regularization. Applications have shown improved results on both simulated and real-world datasets including gene expression data and neural recordings from the mouse visual cortex. Future work includes expanding the scope of applicability beyond regression problems and investigating alternative methods for constructing feature groups.,1
"With the prevalence of accessible depth sensors, dynamic human body skeletons have attracted much attention as a robust modality for action recognition. Previous methods model skeletons based on RNN or CNN, which has limited expressive power for irregular skeleton joints. While graph convolutional networks (GCN) have been proposed to address irregular graph-structured data, the fundamental graph construction remains challenging. In this paper, we represent skeletons naturally on graphs, and propose a graph regression based GCN (GR-GCN) for skeleton-based action recognition, aiming to capture the spatio-temporal variation in the data. As the graph representation is crucial to graph convolution, we first propose graph regression to statistically learn the underlying graph from multiple observations. In particular, we provide spatio-temporal modeling of skeletons and pose an optimization problem on the graph structure over consecutive frames, which enforces the sparsity of the underlying graph for efficient representation. The optimized graph not only connects each joint to its neighboring joints in the same frame strongly or weakly, but also links with relevant joints in the previous and subsequent frames. We then feed the optimized graph into the GCN along with the coordinates of the skeleton sequence for feature learning, where we deploy high-order and fast Chebyshev approximation of spectral graph convolution. Further, we provide analysis of the variation characterization by the Chebyshev approximation. Experimental results validate the effectiveness of the proposed graph regression and show that the proposed GR-GCN achieves the state-of-the-art performance on the widely used NTU RGB+D, UT-Kinect and SYSU 3D datasets.",0
"Abstract: In recent years, action recognition has been studied extensively as one of the key research topics in computer vision. This study aimed to develop an optimized skeleton-based action recognition method that effectively captures spatio-temporal relationships by using graph regression techniques based on spatially sparse features extracted from skeletons. By introducing a regularizer term into our proposed model, we achieved accurate and efficient representation learning through minimizing the loss function value during training. Extensive experiments were conducted using various benchmark datasets to validate the effectiveness of our proposed approach, demonstrating superior performance compared to several state-of-the-art methods. Our work provides new insights into the problem of action recognition and can potentially contribute towards developing more advanced human behavior understanding systems in various applications such as surveillance, healthcare monitoring, entertainment, and robotics.",1
"Generating long and semantic-coherent reports to describe medical images poses great challenges towards bridging visual and linguistic modalities, incorporating medical domain knowledge, and generating realistic and accurate descriptions. We propose a novel Knowledge-driven Encode, Retrieve, Paraphrase (KERP) approach which reconciles traditional knowledge- and retrieval-based methods with modern learning-based methods for accurate and robust medical report generation. Specifically, KERP decomposes medical report generation into explicit medical abnormality graph learning and subsequent natural language modeling. KERP first employs an Encode module that transforms visual features into a structured abnormality graph by incorporating prior medical knowledge; then a Retrieve module that retrieves text templates based on the detected abnormalities; and lastly, a Paraphrase module that rewrites the templates according to specific cases. The core of KERP is a proposed generic implementation unit---Graph Transformer (GTR) that dynamically transforms high-level semantics between graph-structured data of multiple domains such as knowledge graphs, images and sequences. Experiments show that the proposed approach generates structured and robust reports supported with accurate abnormality description and explainable attentive regions, achieving the state-of-the-art results on two medical report benchmarks, with the best medical abnormality and disease classification accuracy and improved human evaluation performance.",0
"Introduction Artificial intelligence has made great progress in recent years and has become increasingly relevant in medical image analysis tasks such as diagnosis, segmentation, localization, annotation generation, among others (1). In particular, natural language processing techniques have been successfully applied to generate automatic medical image reports using templates and keywords (2), free text dictation from radiologists (3), neural machine translation (NMT) from German to English (4), paraphrasing of sentence pairs from human annotators through semantic embeddings (5), etc. Recent advances in pre-training large transformer models on diverse data sources have led to significant improvements over these traditional methods that rely on hand-crafted features, expert knowledge, and low resource requirements (6). This includes multi-modal fusion of vision and language by pre-training ViLBERT, VLFeat+ViLBERT, UNITER + external annotations of grounding boxes and attention maps (7); and LXMERT + NLP tasks like named entity recognition, relation extraction, question answering, etc., then finetuning on downstream image report generation (8). All prior work solely focused on either template-based or free text generation without considering both aspects together or incorporating their strengths into a single framework for holistic report generation. Methods Here we present a novel approach called KEAPR: Knowledge Encoding and Application to Paraframing Reports (9). We use T5 pre-trained BART model architecture as our base generator due to its superior performance compared against all other baseline architectures including GPT-J, DistilBART and Hugging Face Corpus Data Sampler (9). Our contributions can be summarized as follows: 1) Develop two novel subtasks that combine advantages o",1
"We provide a new approach to training neural models to exhibit transparency in a well-defined, functional manner. Our approach naturally operates over structured data and tailors the predictor, functionally, towards a chosen family of (local) witnesses. The estimation problem is setup as a co-operative game between an unrestricted predictor such as a neural network, and a set of witnesses chosen from the desired transparent family. The goal of the witnesses is to highlight, locally, how well the predictor conforms to the chosen family of functions, while the predictor is trained to minimize the highlighted discrepancy. We emphasize that the predictor remains globally powerful as it is only encouraged to agree locally with locally adapted witnesses. We analyze the effect of the proposed approach, provide example formulations in the context of deep graph and sequence models, and empirically illustrate the idea in chemical property prediction, temporal modeling, and molecule representation learning.",0
"The goal of this study was to analyze the impact of structural data transparency on decision-making processes from a game theory perspective. We developed a model that simulates interactions between players within different types of games - cooperative, noncooperative, zero-sum, and mixed - under varying levels of functional transparency conditions. Our results show that increased levels of transparency lead to more efficient outcomes in terms of welfare gains across all game scenarios, regardless of whether they were competitive or collaborative environments. In addition, we found evidence suggesting that the effects of transparency extend beyond simple revelation of previously unknown information; actors adjust their strategies based on how others perceive them as well, resulting in positive externalities at both individual and group levels. These findings have important implications for policymakers considering mandating disclosure policies aimed at promoting transparency in industries with market power, such as financial institutions and tech companies, among others. By designing regulations that strike an optimal balance between privacy concerns and public benefit, governments can promote greater accountability while fostering better social outcomes overall.",1
"Finding an optimal parameter of a black-box function is important for searching stable material structures and finding optimal neural network structures, and Bayesian optimization algorithms are widely used for the purpose. However, most of existing Bayesian optimization algorithms can only handle vector data and cannot handle complex structured data. In this paper, we propose the topological Bayesian optimization, which can efficiently find an optimal solution from structured data using \emph{topological information}. More specifically, in order to apply Bayesian optimization to structured data, we extract useful topological information from a structure and measure the proper similarity between structures. To this end, we utilize persistent homology, which is a topological data analysis method that was recently applied in machine learning. Moreover, we propose the Bayesian optimization algorithm that can handle multiple types of topological information by using a linear combination of kernels for persistence diagrams. Through experiments, we show that topological information extracted by persistent homology contributes to a more efficient search for optimal structures compared to the random search baseline and the graph Bayesian optimization algorithm.",0
"Topological data analysis is an important tool for understanding complex datasets, particularly those containing high-dimensional or nonlinear features. One popular method of topological feature extraction is persistent homology, which allows researchers to characterize the global connectivity structure of a dataset by computing Betti numbers at different scales. These persistence diagrams can then be used as descriptors for machine learning tasks such as classification or regression. However, optimizing parameters associated with persistence diagram computations remains challenging due to their complex mathematical nature and sensitivity to noise. In this work, we present a novel approach called ""topological Bayesian optimization"" that leverages recent advances in Gaussian process priors to efficiently search parameter space using only a small number of function evaluations. We showcase the effectiveness of our proposed technique on several benchmark datasets and demonstrate its superiority over state-of-the-art optimization methods in terms of both accuracy and efficiency. Our findings have implications for applications where topology must be considered alongside other factors, including computer vision, medical imaging, and materials science.",1
"We present a novel and hierarchical approach for supervised classification of signals spanning over a fixed graph, reflecting shared properties of the dataset. To this end, we introduce a Convolutional Cluster Pooling layer exploiting a multi-scale clustering in order to highlight, at different resolutions, locally connected regions on the input graph. Our proposal generalises well-established neural models such as Convolutional Neural Networks (CNNs) on irregular and complex domains, by means of the exploitation of the weight sharing property in a graph-oriented architecture. In this work, such property is based on the centrality of each vertex within its soft-assigned cluster. Extensive experiments on NTU RGB+D, CIFAR-10 and 20NEWS demonstrate the effectiveness of the proposed technique in capturing both local and global patterns in graph-structured data out of different domains.",0
"This is an example of how you could write an abstract for a paper: Title: ""Classifying Signals on Irregular Domains via Convolutional Cluster Pooling""",1
"A graph is a powerful concept for representation of relations between pairs of entities. Data with underlying graph structure can be found across many disciplines and there is a natural desire for understanding such data better. Deep learning (DL) has achieved significant breakthroughs in a variety of machine learning tasks in recent years, especially where data is structured on a grid, such as in text, speech, or image understanding. However, surprisingly little has been done to explore the applicability of DL on arbitrary graph-structured data directly.   The goal of this thesis is to investigate architectures for DL on graphs and study how to transfer, adapt or generalize concepts that work well on sequential and image data to this domain. We concentrate on two important primitives: embedding graphs or their nodes into a continuous vector space representation (encoding) and, conversely, generating graphs from such vectors back (decoding). To that end, we make the following contributions.   First, we introduce Edge-Conditioned Convolutions (ECC), a convolution-like operation on graphs performed in the spatial domain where filters are dynamically generated based on edge attributes. The method is used to encode graphs with arbitrary and varying structure.   Second, we propose SuperPoint Graph, an intermediate point cloud representation with rich edge attributes encoding the contextual relationship between object parts. Based on this representation, ECC is employed to segment large-scale point clouds without major sacrifice in fine details.   Third, we present GraphVAE, a graph generator allowing us to decode graphs with variable but upper-bounded number of nodes making use of approximate graph matching for aligning the predictions of an autoencoder with its inputs. The method is applied to the task of molecule generation.",0
"In recent years, deep learning has emerged as one of the most powerful techniques for analyzing complex data sets and making accurate predictions across a variety of domains. One key challenge that arises when applying these methods to large and complex datasets is how to effectively capture patterns and relationships between data points. Traditionally, this task has been addressed using graph representations, which provide a natural way to model both structural and semantic relationships within the data. However, working directly with graphs can be computationally intensive, particularly for larger datasets, leading researchers to seek alternative approaches based on embedding spaces learned via deep neural networks.  In this work, we present an approach that utilizes attributed graphs, a hybrid representation that combines traditional graph structures with additional attribute data associated with each node and edge. We explore a novel framework that applies deep learning principles to learned embeddings from such attributed graphs, allowing us to leverage their strengths while overcoming some of their limitations. Our approach involves training a convolutional neural network to learn feature representations of nodes in the graph, and then incorporating these features into a discriminative downstream machine learning algorithm to obtain high quality outputs. By doing so, we enable our method to automatically identify relevant substructures within the input graphs, significantly improving prediction accuracy over existing baseline methods. Additionally, we propose a multi-task approach that leverages both attributes and learned embeddings simultaneously, further enhancing performance. Finally, by exploiting the correspondence between graphs and their embedded representations, we develop a technique for generating new embeddings from existing ones, opening up possibilities for more flexible application scenarios. Overall, our contributions demonstrate the effectiveness of combining graph and embedding representations for improved predictive performance, highlight the promise of attributing graphs in capturing essential structure for analysis, and offer compelling evidence regarding the power of multitask learning frameworks towards driving higher levels o",1
"Recently, Graph Convolutional Networks (GCNs) have been widely studied for graph-structured data representation and learning. However, in many real applications, data are coming with multiple graphs, and it is non-trivial to adapt GCNs to deal with data representation with multiple graph structures. One main challenge for multi-graph representation is how to exploit both structure information of each individual graph and correlation information across multiple graphs simultaneously. In this paper, we propose a novel Multiple Graph Adversarial Learning (MGAL) framework for multi-graph representation and learning. MGAL aims to learn an optimal structure-invariant and consistent representation for multiple graphs in a common subspace via a novel adversarial learning framework, which thus incorporates both structure information of intra-graph and correlation information of inter-graphs simultaneously. Based on MGAL, we then provide a unified network for semi-supervised learning task. Promising experimental results demonstrate the effectiveness of MGAL model.",0
"Abstract: Deep neural networks (DNNs) have revolutionized numerous applications ranging from image recognition to natural language processing. However, these models remain vulnerable to adversarial attacks, which can cause significant performance degradation by adding minimal perturbations to inputs. In response, recent research has explored defenses that focus on improving robustness against individual attack methods. This work proposes a novel approach called multiple graph adversarial learning (MGAL), which tackles adversarial examples at their source and provides end-to-end training against diverse attack methods concurrently. MGAL constructs multiple graphs during training that capture different aspects of data geometry to learn robust representations. By addressing the root cause of adversarial fragility in deep learning, our method outperforms state-of-the-art defenses across a range of benchmark datasets and architectures while maintaining competitive accuracies. Our findings provide insights into how DNNs respond to input variations and offer new opportunities for advancing theoretical understanding of robust deep learning.",1
"Graph matching is an important and persistent problem in computer vision and pattern recognition for finding node-to-node correspondence between graph-structured data. However, as widely used, graph matching that incorporates pairwise constraints can be formulated as a quadratic assignment problem (QAP), which is NP-complete and results in intrinsic computational difficulties. In this paper, we present a functional representation for graph matching (FRGM) that aims to provide more geometric insights on the problem and reduce the space and time complexities of corresponding algorithms. To achieve these goals, we represent a graph endowed with edge attributes by a linear function space equipped with a functional such as inner product or metric, that has an explicit geometric meaning. Consequently, the correspondence between graphs can be represented as a linear representation map of that functional. Specifically, we reformulate the linear functional representation map as a new parameterization for Euclidean graph matching, which is associative with geometric parameters for graphs under rigid or nonrigid deformations. This allows us to estimate the correspondence and geometric deformations simultaneously. The use of the representation of edge attributes rather than the affinity matrix enables us to reduce the space complexity by two orders of magnitudes. Furthermore, we propose an efficient optimization strategy with low time complexity to optimize the objective function. The experimental results on both synthetic and real-world datasets demonstrate that the proposed FRGM can achieve state-of-the-art performance.",0
"Graph matching is a classical problem in computer science that has applications in areas such as image processing, pattern recognition, and data mining. In graph theory, two graphs G and H are considered a match if there exists a bijection f from the vertices of G to those of H which preserves edge relations. For example, if (u, v) is an edge of G, then (f(u), f(v)) should be an edge of H. In practice, graph matching is often performed using algorithms based on optimization techniques such as linear programming or dynamic programming. However, these methods can become computationally expensive for large graphs, especially when dealing with complex constraints. In addition, they may struggle to find optimal solutions when given noisy or incomplete data. To address these issues, we propose a novel functional representation for graph matching called Spectral Graphlets. This approach models each graph as a collection of overlapping subgraph patterns, or ""graphlets"", obtained by sampling the vertices at different scales. We use spectral clustering to identify natural communities within the graphlet space, allowing us to better capture the underlying structure of real-world networks. Our method efficiently maps vertex correspondences across different graphs and effectively handles missing or ambiguous edges. Experimental results show that our algorithm outperforms state-of-the-art approaches in terms of accuracy and speed on both synthetic and real datasets. We believe that the proposed method has the potential to improve graph matching in many domains where efficient and effective analysis of networked data is crucial.",1
"Semi-supervised learning on graph structured data has received significant attention with the recent introduction of Graph Convolution Networks (GCN). While traditional methods have focused on optimizing a loss augmented with Laplacian regularization framework, GCNs perform an implicit Laplacian type regularization to capture local graph structure. In this work, we propose Lovasz Convolutional Network (LCNs) which are capable of incorporating global graph properties. LCNs achieve this by utilizing Lovasz's orthonormal embeddings of the nodes. We analyse local and global properties of graphs and demonstrate settings where LCNs tend to work better than GCNs. We validate the proposed method on standard random graph models such as stochastic block models (SBM) and certain community structure based graphs where LCNs outperform GCNs and learn more intuitive embeddings. We also perform extensive binary and multi-class classification experiments on real world datasets to demonstrate LCN's effectiveness. In addition to simple graphs, we also demonstrate the use of LCNs on hyper-graphs by identifying settings where they are expected to work better than GCNs.",0
"This paper presents a new method for training convolutional neural networks using Lovász function. We show that by replacing traditional batch normalization layers with Lovász normalization layers, we can achieve better generalization performance on a variety of tasks without increasing computational complexity. Our approach is based on recent theoretical results showing that Lovász functions can approximate arbitrary continuous functions well. By applying the Lovász approximation to each layer in a convolutional network, we can learn more expressive models while maintaining numerical stability. Experiments demonstrate our model outperforms state-of-the-art baselines on benchmark datasets.",1
"We apply network Lasso to semi-supervised regression problems involving network structured data. This approach lends quite naturally to highly scalable learning algorithms in the form of message passing over an empirical graph which represents the network structure of the data. By using a simple non-parametric regression model, which is motivated by a clustering hypothesis, we provide an analysis of the estimation error incurred by network Lasso. This analysis reveals conditions on the the network structure and the available training data which guarantee network Lasso to be accurate. Remarkably, the accuracy of network Lasso is related to the existence of sufficiently large network flows over the empirical graph. Thus, our analysis reveals a connection between network Lasso and maximum flow problems.",0
"This paper presents an analysis of Network Lasso, a semi-supervised regression technique that leverages graph neural networks (GNNs) to predict unlabeled target variables based on partially labeled data. In recent years, GNNs have emerged as powerful tools for modeling complex relationships in graphs such as social networks, citation networks, protein interaction networks, etc. However, training GNNs can often require large amounts of labeled data which may not always be available. To address these limitations, we investigate the effectiveness of Network Lasso, a method that regularizes GNN models using a sparsity-inducing penalty term derived from an additional set of unlabeled examples. Our experimental results demonstrate that Network Lasso outperforms benchmark methods including traditional machine learning techniques as well as other state-of-the-art semi-supervised approaches in many real-world datasets, across various evaluation metrics. Furthermore, our study provides insights into key design choices of Network Lasso and identifies promising future research directions for semi-supervised learning in graphs. Overall, our work highlights the potential utility of Network Lasso in tackling high-dimensional problems characterized by limited labeled samples but abundant unlabeled data, making it applicable to numerous fields where graph structures play critical roles.",1
"We present Deep Graph Infomax (DGI), a general approach for learning node representations within graph-structured data in an unsupervised manner. DGI relies on maximizing mutual information between patch representations and corresponding high-level summaries of graphs---both derived using established graph convolutional network architectures. The learnt patch representations summarize subgraphs centered around nodes of interest, and can thus be reused for downstream node-wise learning tasks. In contrast to most prior approaches to unsupervised learning with GCNs, DGI does not rely on random walk objectives, and is readily applicable to both transductive and inductive learning setups. We demonstrate competitive performance on a variety of node classification benchmarks, which at times even exceeds the performance of supervised learning.",0
"This paper proposes ""Deep Graph Infomax"" (DGInf), a new unsupervised learning framework that utilizes graph neural networks (GNNS) to model complex relationships within data sets and maximize the mutual information (MI) between the input variables and the learned representations. DGInf operates by first mapping inputs into latent spaces using GNNS, then calculating MI between these latent codes and randomly masked versions of themselves, which forces the network to learn patterns that cannot easily be predicted from individual features alone. Through extensive experiments on real world datasets such as image classification problems, we show how DGInf leads to improved performance over other popular self-supervised methods such as BYOL, MoCo, and SimSiam while maintaining similar efficiency due to the use of random Gaussian noise instead of more expensive augmentation techniques like image rotation or jittering. Our method allows for easier hyperparameter selection and offers better results across different models ranging from ResNet-50 to larger variants. We believe this research can open up new opportunities in deep learning applications where large scale dataset collection may become prohibitive in the future, and encourage further experimentation along these lines in order to fully realize its potential benefits.",1
"The training phases of Deep neural network~(DNN) consumes enormous processing time and energy. Compression techniques utilizing the sparsity of DNNs can effectively accelerate the inference phase of DNNs. However, it can be hardly used in the training phase because the training phase involves dense matrix-multiplication using General Purpose Computation on Graphics Processors (GPGPU), which endorse regular and structural data layout. In this paper, we propose the Approximate Random Dropout that replaces the conventional random dropout of neurons and synapses with a regular and predefined patterns to eliminate the unnecessary computation and data access. To compensate the potential performance loss we develop a SGD-based Search Algorithm to produce the distribution of dropout patterns. We prove our approach is statistically equivalent to the previous dropout method. Experiments results on MLP and LSTM using well-known benchmarks show that the proposed Approximate Random Dropout can reduce the training time by $20\%$-$77\%$ ($19\%$-$60\%$) when dropout rate is $0.3$-$0.7$ on MLP (LSTM) with marginal accuracy drop.",0
"As machine learning models continue to grow larger and more complex, training and deploying these models becomes increasingly computationally expensive. One strategy for reducing computational cost is to use approximate inference methods that trade off some degree of accuracy for speed or efficiency. In this work, we propose a new method called Approximate Random Dropout (ARD), which extends the popular technique of random dropout used during training by introducing additional variability at test time. ARD randomly drops out neurons during both training and testing, but uses different rates of dropping out depending on the size of the model and desired level of approximation. We evaluate the performance of ARD on several benchmark datasets and show that it can achieve comparable results to full precision inference while significantly improving computational efficiency. Additionally, we demonstrate that our approach is robust against adversarial attacks, making it an attractive option for deployment in security-critical applications. Overall, ARD offers a flexible and effective solution for enabling fast and accurate machine learning models on resource constrained devices or cloud services with limited computing resources.",1
"We propose Graphical Generative Adversarial Networks (Graphical-GAN) to model structured data. Graphical-GAN conjoins the power of Bayesian networks on compactly representing the dependency structures among random variables and that of generative adversarial networks on learning expressive dependency functions. We introduce a structured recognition model to infer the posterior distribution of latent variables given observations. We generalize the Expectation Propagation (EP) algorithm to learn the generative model and recognition model jointly. Finally, we present two important instances of Graphical-GAN, i.e. Gaussian Mixture GAN (GMGAN) and State Space GAN (SSGAN), which can successfully learn the discrete and temporal structures on visual datasets, respectively.",0
"Recent advances in deep learning have seen significant progress towards generative models that can produce high quality images from textual descriptions or other inputs. One such class of models is Graphical Generative Adversarial Networks (GANs), which use graph structures to encode input-output relationships and improve stability during training. In this work, we present an overview of GANs and their applications in generating realistic images using graphs as priors. We discuss the challenges associated with training GANs on image generation tasks and how graph structures provide a way to regularize and stabilize the optimization process. Additionally, we evaluate several state-of-the-art methods based on graph-structured GANs and compare them against traditional GAN architectures on benchmark datasets. Our results show that graph-based GANs significantly improve both visual fidelity and quantitative metrics compared to non-graph approaches. Finally, we conclude by highlighting some future directions for research on GANs with graph structures.",1
"Tensor network decomposition, originated from quantum physics to model entangled many-particle quantum systems, turns out to be a promising mathematical technique to efficiently represent and process big data in parsimonious manner. In this study, we show that tensor networks can systematically partition structured data, e.g. color images, for distributed storage and communication in privacy-preserving manner. Leveraging the sea of big data and metadata privacy, empirical results show that neighbouring subtensors with implicit information stored in tensor network formats cannot be identified for data reconstruction. This technique complements the existing encryption and randomization techniques which store explicit data representation at one place and highly susceptible to adversarial attacks such as side-channel attacks and de-anonymization. Furthermore, we propose a theory for adversarial examples that mislead convolutional neural networks to misclassification using subspace analysis based on singular value decomposition (SVD). The theory is extended to analyze higher-order tensors using tensor-train SVD (TT-SVD); it helps to explain the level of susceptibility of different datasets to adversarial attacks, the structural similarity of different adversarial attacks including global and localized attacks, and the efficacy of different adversarial defenses based on input transformation. An efficient and adaptive algorithm based on robust TT-SVD is then developed to detect strong and static adversarial attacks.",0
"This paper presents a new approach to convolutional neural network (CNN) design that utilizes transformed input data instead of raw pixel values. By applying transformations such as rotation and scaling to the input images before feeding them into the CNN, we can improve the robustness and generalization performance of the model. We demonstrate this through experiments on several benchmark datasets, showing improved accuracy compared to traditional CNN architectures using untransformed inputs. Additionally, we propose a method for decomposing the tensor representations of the transformed input data into lower-dimensional tensors, which allows us to further reduce the computational complexity of training and testing while maintaining high levels of accuracy. Our results highlight the potential benefits of incorporating transformation preprocessing techniques into CNN architecture design.",1
"Structural health monitoring is a condition-based field of study utilised to monitor infrastructure, via sensing systems. It is therefore used in the field of aerospace engineering to assist in monitoring the health of aerospace structures. A difficulty however is that in structural health monitoring the data input is usually from sensor arrays, which results in data which are highly redundant and correlated, an area in which traditional two-way matrix approaches have had difficulty in deconstructing and interpreting. Newer methods involving tensor analysis allow us to analyse this multi-way structural data in a coherent manner. In our approach, we demonstrate the usefulness of tensor-based learning coupled with for damage detection, on a novel $N$-DoF Lagrangian aeroservoelastic model.",0
"This paper presents a novel approach to structural health monitoring (SHM) for aeroservoelastic systems using tensor techniques. SHM plays a critical role in ensuring the safety and reliability of aircraft structures, as well as reducing maintenance costs. However, traditional methods have limitations in terms of accuracy and robustness, especially when dealing with complex dynamic interactions between aerodynamic forces, flexible dynamics, and control actions. In this work, we propose a new method based on tensors that can handle these complex interactions effectively and provide accurate diagnostics of damage and faults in real time. Our approach uses both sensor measurements and mathematical models to construct a tensor representation of the system state space. This representation captures all relevant information including modal parameters, loadings, airspeed, and other environmental factors. We then use tensor decompositions such as Singular Value Decomposition (SVD), Probabilistic Principal Component Analysis (PPCA), and Tensor PCA (TPCA) to extract meaningful features from the data and identify anomalies indicative of damage or faults. Our results show that our proposed method outperforms existing approaches in detecting and locating damages under different scenarios and configurations. Overall, our study demonstrates the potential benefits of using tensor techniques in advancing SHM for aeroservoelastic systems.",1
"Graph-based methods are known to be successful in many machine learning and pattern classification tasks. These methods consider semi-structured data as graphs where nodes correspond to primitives (parts, interest points, segments, etc.) and edges characterize the relationships between these primitives. However, these non-vectorial graph data cannot be straightforwardly plugged into off-the-shelf machine learning algorithms without a preliminary step of -- explicit/implicit -- graph vectorization and embedding. This embedding process should be resilient to intra-class graph variations while being highly discriminant. In this paper, we propose a novel high-order stochastic graphlet embedding (SGE) that maps graphs into vector spaces. Our main contribution includes a new stochastic search procedure that efficiently parses a given graph and extracts/samples unlimitedly high-order graphlets. We consider these graphlets, with increasing orders, to model local primitives as well as their increasingly complex interactions. In order to build our graph representation, we measure the distribution of these graphlets into a given graph, using particular hash functions that efficiently assign sampled graphlets into isomorphic sets with a very low probability of collision. When combined with maximum margin classifiers, these graphlet-based representations have positive impact on the performance of pattern comparison and recognition as corroborated through extensive experiments using standard benchmark databases.",0
"This paper introduces stochastic graphlet embedding (SGE), which enables efficient computation of node embeddings that capture local structural features of graphs. SGE extends the deterministic graphlet decomposition introduced by Milo et al., but replaces all-or-nothing patterns with stochastically sampled subgraphs. We then define Markov Chain Monte Carlo methods to randomly walk across these stochastic graphlets, allowing us to assign high-quality continuous vector representations directly to nodes in arbitrary complex networks, scalably. Using synthetic and real data sets of different sizes and types we show that our approach works well on graphs of very diverse nature. In particular, results obtained via node embeddings derived from stochastic graphlets perform as well as the widely used DeepWalk method, while scaling at least two orders of magnitude faster. Additionally, we demonstrate how we can leverage these embeddings for downstream analytics like semi-supervised link prediction and anomaly detection. With this work we aim to foster research into network analysis using machine learning and more broadly help make such techniques applicable to big data problems.",1
"Recently, techniques for applying convolutional neural networks to graph-structured data have emerged. Graph convolutional neural networks (GCNNs) have been used to address node and graph classification and matrix completion. Although the performance has been impressive, the current implementations have limited capability to incorporate uncertainty in the graph structure. Almost all GCNNs process a graph as though it is a ground-truth depiction of the relationship between nodes, but often the graphs employed in applications are themselves derived from noisy data or modelling assumptions. Spurious edges may be included; other edges may be missing between nodes that have very strong relationships. In this paper we adopt a Bayesian approach, viewing the observed graph as a realization from a parametric family of random graphs. We then target inference of the joint posterior of the random graph parameters and the node (or graph) labels. We present the Bayesian GCNN framework and develop an iterative learning procedure for the case of assortative mixed-membership stochastic block models. We present the results of experiments that demonstrate that the Bayesian formulation can provide better performance when there are very few labels available during the training process.",0
"Abstract: Semi-supervised learning has emerged as a promising technique that enables the use of large amounts of unlabeled data to improve performance on supervised tasks. In recent years, Graph Convolutional Networks (GCN) have shown state-of-the-art results for many applications ranging from image recognition to natural language processing. However, the traditional GCN training relies heavily on labeled data, which can become impractical or expensive to obtain. This work presents a novel approach based on Bayesian inference and MCMC sampling for training GCN models using both labeled and unlabeled data. We propose a novel method to approximate the evidence lower bound by iterative denoising of the data, combined with variational inference over the model parameters. Our experimental evaluations demonstrate the effectiveness of our proposed framework, achieving significant improvements over baseline methods on several benchmark datasets across different domains. Keywords: Semi-Supervised Learning, Graph Convolutional Networks, Bayesian Methods, Variational Inference",1
"Spectral Graph Convolutional Networks (GCNs) are a generalization of convolutional networks to learning on graph-structured data. Applications of spectral GCNs have been successful, but limited to a few problems where the graph is fixed, such as shape correspondence and node classification. In this work, we address this limitation by revisiting a particular family of spectral graph networks, Chebyshev GCNs, showing its efficacy in solving graph classification tasks with a variable graph structure and size. Chebyshev GCNs restrict graphs to have at most one edge between any pair of nodes. To this end, we propose a novel multigraph network that learns from multi-relational graphs. We model learned edges with abstract meaning and experiment with different ways to fuse the representations extracted from annotated and learned edges, achieving competitive results on a variety of chemical classification benchmarks.",0
"Abstract: In recent years, advancements in machine learning have enabled the development of novel approaches for discovering relationships in molecular data. One such approach involves using spectral multigraph networks to represent complex chemical structures and analyze their underlying patterns. These networks enable the discovery of both local and global relationships within molecules, allowing for more effective analysis and understanding of molecular behavior. By fusing these relationships together, researchers can gain deeper insights into the structural, physical, and chemical properties of molecules. This work presents a comprehensive overview of spectral multigraph networks, highlighting their applications in discovering and fusing relationships in molecular systems. We discuss several case studies that demonstrate the effectiveness of these methods and provide suggestions for future directions in this exciting field.",1
"Link prediction is a key problem for network-structured data. Link prediction heuristics use some score functions, such as common neighbors and Katz index, to measure the likelihood of links. They have obtained wide practical uses due to their simplicity, interpretability, and for some of them, scalability. However, every heuristic has a strong assumption on when two nodes are likely to link, which limits their effectiveness on networks where these assumptions fail. In this regard, a more reasonable way should be learning a suitable heuristic from a given network instead of using predefined ones. By extracting a local subgraph around each target link, we aim to learn a function mapping the subgraph patterns to link existence, thus automatically learning a `heuristic' that suits the current network. In this paper, we study this heuristic learning paradigm for link prediction. First, we develop a novel $\gamma$-decaying heuristic theory. The theory unifies a wide range of heuristics in a single framework, and proves that all these heuristics can be well approximated from local subgraphs. Our results show that local subgraphs reserve rich information related to link existence. Second, based on the $\gamma$-decaying theory, we propose a new algorithm to learn heuristics from local subgraphs using a graph neural network (GNN). Its experimental results show unprecedented performance, working consistently well on a wide range of problems.",0
"This should only describe the content of your proposed work. Your final product may have minor errors, such as punctuation mistakes or run-on sentences, but you should submit clean copy that follows all English capitalization and formatting rules. If you need editing services, please mention them at checkout. Thank you! ---",1
"Generative concept representations have three major advantages over discriminative ones: they can represent uncertainty, they support integration of learning and reasoning, and they are good for unsupervised and semi-supervised learning. We discuss probabilistic and generative deep learning, which generative concept representations are based on, and the use of variational autoencoders and generative adversarial networks for learning generative concept representations, particularly for concepts whose data are sequences, structured data or graphs.",0
"As the field of deep learning continues to grow, there has been increasing interest in developing methods that can represent and manipulate complex concepts. In recent years, researchers have explored ways to use generative models to generate concept representations that capture important aspects of a given task. This paper presents a new approach to generating such representations using a combination of deep learning techniques and domain knowledge. We show how our method can effectively learn and represent concepts by applying it to several challenging tasks and comparing its performance to state-of-the-art baselines. Our results demonstrate the potential of this approach as a powerful tool for analyzing and manipulating conceptual data.",1
"Convolution Neural Network (CNN) has gained tremendous success in computer vision tasks with its outstanding ability to capture the local latent features. Recently, there has been an increasing interest in extending convolution operations to the non-Euclidean geometry. Although various types of convolution operations have been proposed for graphs or manifolds, their connections with traditional convolution over grid-structured data are not well-understood. In this paper, we show that depthwise separable convolution can be successfully generalized for the unification of both graph-based and grid-based convolution methods. Based on this insight we propose a novel Depthwise Separable Graph Convolution (DSGC) approach which is compatible with the tradition convolution network and subsumes existing convolution methods as special cases. It is equipped with the combined strengths in model expressiveness, compatibility (relatively small number of parameters), modularity and computational efficiency in training. Extensive experiments show the outstanding performance of DSGC in comparison with strong baselines on multi-domain benchmark datasets.",0
"Deep learning has been successful on a variety of tasks in recent years, thanks in part to advancements in the architecture design and optimization techniques such as GANs (Generative Adversarial Networks) [1]. To improve results further, more expressive models need to be developed that can capture higher level abstractions through hierarchical composition of primitive operations, which would enable building more complex, yet interpretable models able to perform challenging tasks under limited supervision or even without explicit annotations [2] [3]. Motivated by these observations, we introduce here the first attempt to learn depthwise separable graph convolution operators directly from data using a deep neural network trained end-to-end using backpropagation (dubbed DGNN). Our framework makes use of the recent progress in implicit regularization obtained via randomized ensembles to achieve improved generalizability of the learned model parameters to unseen test cases [4], allowing training without strong inductive biases towards specific task families. We demonstrate high fidelity to the original task while making significant improvements over baselines on several real world datasets taken from multiple domains. With our work we hope to push forward the state-of-the-art in deep learning architectures. [1] Ian Goodfellow et al., “Generative adversarial networks,” Advances in Neural Information Processing Systems, vol. 27, pp. 2672–2680, 2014. [2] Joshua B Krishnan et al., “Hierarchical representation learning: Uniting rule induction and deep learning approaches,” Proceedings of the IEEE International Conference on Computer Vision, 2015. [3] Shuang Li et al., “Deep convolutional sparse coding networks,” In Proceedings of the 29th Annual International Conference on Machine Learning (ICML’12), 2012. [4] Peter Wenzel et al., “Towards understanding robustness in gradient boosting machines.” arXiv preprint arXiv:1804.06340, 2018.",1
"Graphs are essential representations of many real-world data such as social networks. Recent years have witnessed the increasing efforts made to extend the neural network models to graph-structured data. These methods, which are usually known as the graph neural networks, have been applied to advance many graphs related tasks such as reasoning dynamics of the physical system, graph classification, and node classification. Most of the existing graph neural network models have been designed for static graphs, while many real-world graphs are inherently dynamic. For example, social networks are naturally evolving as new users joining and new relations being created. Current graph neural network models cannot utilize the dynamic information in dynamic graphs. However, the dynamic information has been proven to enhance the performance of many graph analytic tasks such as community detection and link prediction. Hence, it is necessary to design dedicated graph neural networks for dynamic graphs. In this paper, we propose DGNN, a new {\bf D}ynamic {\bf G}raph {\bf N}eural {\bf N}etwork model, which can model the dynamic information as the graph evolving. In particular, the proposed framework can keep updating node information by capturing the sequential information of edges (interactions), the time intervals between edges and information propagation coherently. Experimental results on various dynamic graphs demonstrate the effectiveness of the proposed framework.",0
"In recent years, graph neural networks (GNN) have emerged as powerful tools for modeling complex relationships and patterns on graphs. However, many existing GNN architectures suffer from slow training times due to their reliance on batch processing methods. This can limit their applicability in real-time applications where streaming data must be processed efficiently. To address these limitations, we propose the use of streaming graph neural networks that process data online in real-time using incremental updates. Our approach leverages incremental learning techniques commonly used in stream mining systems but tailored specifically for GNNs. We demonstrate the effectiveness of our method through extensive experiments on both synthetic and real-world datasets, showing significant improvements over state-of-the-art batch baselines while maintaining high prediction accuracy. Overall, our work shows great potential for enabling GNN models to handle streaming data, opening up new possibilities for their deployment in diverse domains such as sensor network analysis, social media monitoring, and financial transactions tracking.",1
"With the expeditious advancement of information technologies, health-related data presented unprecedented potentials for medical and health discoveries but at the same time significant challenges for machine learning techniques both in terms of size and complexity. Those challenges include: the structured data with various storage formats and value types caused by heterogeneous data sources; the uncertainty widely existing in every aspect of medical diagnosis and treatments; the high dimensionality of the feature space; the longitudinal medical records data with irregular intervals between adjacent observations; the richness of relations existing among objects with similar genetic factors, location or socio-demographic background. This thesis aims to develop advanced Statistical Relational Learning approaches in order to effectively exploit such health-related data and facilitate the discoveries in medical research. It presents the work on cost-sensitive statistical relational learning for mining structured imbalanced data, the first continuous-time probabilistic logic model for predicting sequential events from longitudinal structured data as well as hybrid probabilistic relational models for learning from heterogeneous structured data. It also demonstrates the outstanding performance of these proposed models as well as other state of the art machine learning models when applied to medical research problems and other real-world large-scale systems, reveals the great potential of statistical relational learning for exploring the structured health-related data to facilitate medical research.",0
"The use of predictive models in healthcare has become increasingly important as they can assist physicians in making informed decisions regarding patient care. One such approach involves using probabilistic models which take into account uncertainty when making predictions. However, training these models requires large amounts of data that may not always be available or accessible. In addition, traditional methods used to train probabilistic models can be computationally expensive and require significant computational resources. This study aimed to develop an efficient method for learning probabilistic models from longitudinal datasets by addressing these challenges. Our proposed method was evaluated on three different clinical datasets demonstrating improved accuracy over existing approaches while requiring significantly less computational time. Overall, our results show great promise for widespread adoption of this novel technique in healthcare settings where timely decision making could greatly improve patient outcomes. Keywords: Probabilistic Model; Longitudinal Dataset; Healthcare Prediction; Efficient Training Algorithm",1
"The development of a metric for structural data is a long-term problem in pattern recognition and machine learning. In this paper, we develop a general metric for comparing nonlinear dynamical systems that is defined with Perron-Frobenius operators in reproducing kernel Hilbert spaces. Our metric includes the existing fundamental metrics for dynamical systems, which are basically defined with principal angles between some appropriately-chosen subspaces, as its special cases. We also describe the estimation of our metric from finite data. We empirically illustrate our metric with an example of rotation dynamics in a unit disk in a complex plane, and evaluate the performance with real-world time-series data.",0
"This paper presents a new metric for analyzing nonlinear dynamical systems using Perron-Frobenius operators. We introduce a novel methodology that builds upon classical techniques from control theory and allows us to quantify the stability properties of complex networks in a more comprehensive manner than existing approaches. Our approach provides a unifying framework for studying different types of dynamic processes such as synchronization, consensus formation, and chaos propagation. By exploiting recent advances in graph signal processing and spectral graph theory, we establish connections between system performance metrics and the eigenvalues of associated matrices. Using numerical simulations, we demonstrate the effectiveness of our proposed metric in accurately predicting the behavior of several prototypical network models subjected to various perturbations and time-varying conditions. Overall, this work represents a significant contribution to the field of control theory and paves the way for future research in understanding how network dynamics can be optimized under uncertainty.",1
"The rise of graph-structured data such as social networks, regulatory networks, citation graphs, and functional brain networks, in combination with resounding success of deep learning in various applications, has brought the interest in generalizing deep learning models to non-Euclidean domains. In this paper, we introduce a new spectral domain convolutional architecture for deep learning on graphs. The core ingredient of our model is a new class of parametric rational complex functions (Cayley polynomials) allowing to efficiently compute spectral filters on graphs that specialize on frequency bands of interest. Our model generates rich spectral filters that are localized in space, scales linearly with the size of the input data for sparsely-connected graphs, and can handle different constructions of Laplacian operators. Extensive experimental results show the superior performance of our approach, in comparison to other spectral domain convolutional architectures, on spectral image classification, community detection, vertex classification and matrix completion tasks.",0
"In recent years, graph neural networks (GNNs) have emerged as powerful tools for processing data that can be represented by graphs. However, many state-of-the-art GNN models rely heavily on the use of simple linear filters, which may not capture all relevant features of complex graph structures. This paper proposes a new method called CayleyNets, which uses rational spectral filters based on Cayley transforms to improve performance on challenging tasks such as node classification and edge prediction. The authors demonstrate through experiments that CayleyNets significantly outperform several popular baseline methods across multiple datasets, achieving state-of-the-art results while using fewer parameters. These findings suggest that the use of complex spectral filtering techniques has great potential for advancing the field of graph convolutional neural networks.",1
"Using predictive models to identify patterns that can act as biomarkers for different neuropathoglogical conditions is becoming highly prevalent. In this paper, we consider the problem of Autism Spectrum Disorder (ASD) classification where previous work has shown that it can be beneficial to incorporate a wide variety of meta features, such as socio-cultural traits, into predictive modeling. A graph-based approach naturally suits these scenarios, where a contextual graph captures traits that characterize a population, while the specific brain activity patterns are utilized as a multivariate signal at the nodes. Graph neural networks have shown improvements in inferencing with graph-structured data. Though the underlying graph strongly dictates the overall performance, there exists no systematic way of choosing an appropriate graph in practice, thus making predictive models non-robust. To address this, we propose a bootstrapped version of graph convolutional neural networks (G-CNNs) that utilizes an ensemble of weakly trained G-CNNs, and reduce the sensitivity of models on the choice of graph construction. We demonstrate its effectiveness on the challenging Autism Brain Imaging Data Exchange (ABIDE) dataset and show that our approach improves upon recently proposed graph-based neural networks. We also show that our method remains more robust to noisy graphs.",0
"Introduction: Autism spectrum disorder (ASD) affects many individuals worldwide. Traditional methods like questionnaires and medical assessments often result in delayed diagnoses due to subjectivity and limited accessibility. Recently, graph convolutional neural networks (GCNNs) have emerged as promising models for classifying ASD using structured data sets, such as brain functional connectomes. However, applying GCNNs on these large-scale datasets can be challenging because they require substantial computational resources that may not always be available. In this study, we propose a novel bootstrapping approach to efficiently train GCNNs for accurate classification of ASD. Methods: We utilized resting state functional magnetic resonance imaging (rsfMRI) data from a publicly available dataset containing both healthy controls and children with ASD. Our bootstrapped model consists of three components: i) building small subsets from large rsfMRI datasets by randomly selecting samples with replacement, ii) training a lightweight model on the subset of each sampled brain network, and iii) aggregating predictions across multiple runs with different random samplings to produce a final prediction. Results: Compared to traditional full-dataset approaches, our method achieved higher accuracy and better balanced performance measures while requiring significantly less computation time and memory usage. Additionally, we demonstrate how this new approach enables us to make more precise predictions than previously reported work in the literature by performing thorough cross-validation experiments. Discussion: This research contributes to addressing crucial limitations faced by current clinical practices used for ASD diagnosis through innovative machine learning techniques applied to rsMRI analysis. Our bootstrapped GCNN framework offers several advantages over existing models: improved efficiency, accuracy, and scalability without sacrificing model performance. By providing accurate predictions at lower costs, our method has potential to enhance patient outcomes through earlier diagnoses and m",1
"Algebraic topology methods have recently played an important role for statistical analysis with complicated geometric structured data such as shapes, linked twist maps, and material data. Among them, \textit{persistent homology} is a well-known tool to extract robust topological features, and outputs as \textit{persistence diagrams} (PDs). However, PDs are point multi-sets which can not be used in machine learning algorithms for vector data. To deal with it, an emerged approach is to use kernel methods, and an appropriate geometry for PDs is an important factor to measure the similarity of PDs. A popular geometry for PDs is the \textit{Wasserstein metric}. However, Wasserstein distance is not \textit{negative definite}. Thus, it is limited to build positive definite kernels upon the Wasserstein distance \textit{without approximation}. In this work, we rely upon the alternative \textit{Fisher information geometry} to propose a positive definite kernel for PDs \textit{without approximation}, namely the Persistence Fisher (PF) kernel. Then, we analyze eigensystem of the integral operator induced by the proposed kernel for kernel machines. Based on that, we derive generalization error bounds via covering numbers and Rademacher averages for kernel machines with the PF kernel. Additionally, we show some nice properties such as stability and infinite divisibility for the proposed kernel. Furthermore, we also propose a linear time complexity over the number of points in PDs for an approximation of our proposed kernel with a bounded error. Throughout experiments with many different tasks on various benchmark datasets, we illustrate that the PF kernel compares favorably with other baseline kernels for PDs.",0
"In this work, we introduce the concept of Persistence Fisher kernels (P FK), which extend classical kernel methods such as Gaussian processes to handle persistence diagrams and other data sets defined on a Riemannian manifold. These kernels provide a natural tool for machine learning and statistical analysis tasks involving geometric invariants of objects, like shapes, flows, and functions. We prove that under certain assumptions, P Fk is equivalent to kernels based on the maximum mean discrepancy (MMD) function but has advantages over competing approaches in terms of computational complexity and memory usage. Furthermore, our method can effectively capture geometric features of persistence diagrams, demonstrating its efficacy through experiments conducted both on synthetic datasets and real-world applications including shape classification and feature extraction problems from image processing tasks. By providing a reliable and efficient approach applicable to complex real-life scenarios, our findings have important implications for the fields of computer vision, topological data analysis, and more broadly, the study of nonlinear manifolds using kernel techniques.",1
"Neural networks have been shown to be an effective tool for learning algorithms over graph-structured data. However, graph representation techniques---that convert graphs to real-valued vectors for use with neural networks---are still in their infancy. Recent works have proposed several approaches (e.g., graph convolutional networks), but these methods have difficulty scaling and generalizing to graphs with different sizes and shapes. We present Graph2Seq, a new technique that represents vertices of graphs as infinite time-series. By not limiting the representation to a fixed dimension, Graph2Seq scales naturally to graphs of arbitrary sizes and shapes. Graph2Seq is also reversible, allowing full recovery of the graph structure from the sequences. By analyzing a formal computational model for graph representation, we show that an unbounded sequence is necessary for scalability. Our experimental results with Graph2Seq show strong generalization and new state-of-the-art performance on a variety of graph combinatorial optimization problems.",0
"This paper presents Graph2Seq, a novel framework for learning dynamics on graphs that scales linearly with the number of nodes. We propose an architecture based on sequence models, which enables efficient training even on large graph datasets. Our approach leverages recent advances in sequential processing, allowing us to model temporal dependencies without relying on explicit time embeddings. In addition, we introduce several techniques for reducing computational complexity while maintaining strong predictive performance. Experimental results demonstrate that our method outperforms state-of-the-art alternatives across a range of challenging tasks such as node classification, link prediction, and anomaly detection, achieving competitive accuracy with significantly fewer parameters and faster inference speed. These findings highlight the promise of Graph2Seq as a practical solution for scaling up machine learning on complex graphs, enabling new possibilities for real-world applications.",1
"We present a novel graph diffusion-embedding networks (GDEN) for graph structured data. GDEN is motivated by our closed-form formulation on regularized feature diffusion on graph. GDEN integrates both regularized feature diffusion and low-dimensional embedding simultaneously in a unified network model. Moreover, based on GDEN, we can naturally deal with structured data with multiple graph structures. Experiments on semi-supervised learning tasks on several benchmark datasets demonstrate the better performance of the proposed GDEN when comparing with the traditional GCN models.",0
"This paper introduces a novel deep learning method called Graph Diffusion-Embedding Network (GDEN) for learning node representations from large-scale complex networks such as graphs. GDEN uses graph diffusion techniques to learn low-dimensional embeddings that capture both structural and attribute information of nodes in the network. These embeddings can then be used for downstream tasks such as classification, clustering, or link prediction. Unlike traditional embedding methods like Node2Vec and DeepWalk which only use random walks, GDEN utilizes a combination of random walk, shortest path matrix factorization, and personalized PageRank matrices to generate multiple scales of temporal information. By using these different diffusion models, GDEN captures a more comprehensive representation of the network structure, allowing for better performance on node classification tasks compared to other state-of-the-art baseline models. Overall, our approach provides a scalable solution for embedding extraction and opens new directions towards better understanding and analyzing massive real-world systems.",1
"Recently, graph convolutional network (GCN) has been widely used for semi-supervised classification and deep feature representation on graph-structured data. However, existing GCN generally fails to consider the local invariance constraint in learning and representation process. That is, if two data points Xi and Xj are close in the intrinsic geometry of the data distribution, then their labels/representations should also be close to each other. This is known as local invariance assumption which plays an essential role in the development of various kinds of traditional algorithms, such as dimensionality reduction and semi-supervised learning, in machine learning area. To overcome this limitation, we introduce a graph Laplacian GCN (gLGCN) approach for graph data representation and semi-supervised classification. The proposed gLGCN model is capable of encoding both graph structure and node features together while maintains the local invariance constraint naturally for robust data representation and semi-supervised classification. Experiments show the benefit of the benefits the proposed gLGCN network.",0
"In recent years, semi-supervised learning has become increasingly important due to the scarcity of labeled data. One approach that has shown promising results is graph convolutional networks (GCNs), which have achieved state-of-the-art performance on several benchmark datasets. However, existing GCN methods suffer from oversmoothing, which leads to decreased model accuracy. To address this issue, we propose Graph Laplacian Regularized Graph Convolutional Networks (GLR-GCN) for semi-supervised learning. Our method regularizes the graph convolution process by introducing a novel Graph Laplacian matrix, which preserves both spatial and spectral structures of graphs. Experimental results demonstrate that our proposed GLR-GCN outperforms other state-of-the-art semi-supervised learning methods across multiple benchmark datasets. Additionally, ablation studies show that each component in our method contributes significantly to improving model performance. Overall, our work represents a significant advancement towards more effective semi-supervised learning through graph convolutional networks.",1
"Deep learning systems extensively use convolution operations to process input data. Though convolution is clearly defined for structured data such as 2D images or 3D volumes, this is not true for other data types such as sparse point clouds. Previous techniques have developed approximations to convolutions for restricted conditions. Unfortunately, their applicability is limited and cannot be used for general point clouds. We propose an efficient and effective method to learn convolutions for non-uniformly sampled point clouds, as they are obtained with modern acquisition techniques. Learning is enabled by four key novelties: first, representing the convolution kernel itself as a multilayer perceptron; second, phrasing convolution as a Monte Carlo integration problem, third, using this notion to combine information from multiple samplings at different levels; and fourth using Poisson disk sampling as a scalable means of hierarchical point cloud learning. The key idea across all these contributions is to guarantee adequate consideration of the underlying non-uniform sample distribution function from a Monte Carlo perspective. To make the proposed concepts applicable to real-world tasks, we furthermore propose an efficient implementation which significantly reduces the GPU memory required during the training process. By employing our method in hierarchical network architectures we can outperform most of the state-of-the-art networks on established point cloud segmentation, classification and normal estimation benchmarks. Furthermore, in contrast to most existing approaches, we also demonstrate the robustness of our method with respect to sampling variations, even when training with uniformly sampled data only. To support the direct application of these concepts, we provide a ready-to-use TensorFlow implementation of these layers at https://github.com/viscom-ulm/MCCNN",0
"In the field of computer vision, point clouds have become increasingly important as they provide highly detailed three-dimensional representations of real world scenes. However, due to the high computational cost of working directly on these dense data sets, researchers often resort to downsampling techniques that reduce the number of points while attempting to retain relevant features. In practice, such methods can lead to severe loss of information or even render certain applications impossible if applied without care. To address these issues, we present a novel framework based on Monte Carlo integration which offers provably better convergence rates than competing methods, as well as flexibility regarding sampling patterns that allows customized tradeoffs between sparsity, speedup gains, and accuracy retention. We demonstrate the effectiveness and efficiency of our approach through extensive evaluation across multiple tasks, including semantic segmentation, surface reconstruction, and scene classification. Our results show consistent improvements over existing approaches, particularly for non-uniformly sampled inputs where state-of-the-art methods fail to perform adequately. Overall, our work provides new insights into how machine learning models operating on raw point cloud data can achieve superior performance by leveraging judicious sparsification strategies derived from principles underlying modern numerical analysis.",1
"Tasks involving the analysis of geometric (graph- and manifold-structured) data have recently gained prominence in the machine learning community, giving birth to a rapidly developing field of geometric deep learning. In this work, we leverage graph neural networks to improve signal detection in the IceCube neutrino observatory. The IceCube detector array is modeled as a graph, where vertices are sensors and edges are a learned function of the sensors' spatial coordinates. As only a subset of IceCube's sensors is active during a given observation, we note the adaptive nature of our GNN, wherein computation is restricted to the input signal support. We demonstrate the effectiveness of our GNN architecture on a task classifying IceCube events, where it outperforms both a traditional physics-based method as well as classical 3D convolution neural networks.",0
"Recently, graph neural networks (GNN) have shown promising results for feature extraction from large-scale spatio-temporal data like images and videos. In this work, we investigate if GNN can provide similar performance enhancements for analyzing data collected by the IceCube neutrino observatory, specifically on signal classification tasks. Our approach involves designing novel layers for encoding directionality within graphs and incorporating temporal dependencies using dilated convolutions. We evaluate our method against state-of-the-art techniques such as convolutional neural networks (CNN), long short-term memory (LSTM), and transformers. Results show that GNN outperforms CNN while performing comparably to LSTM and transformer architectures across various benchmark datasets representative of IceCube signal scenarios. These findings suggest that GNN can serve as effective models for processing complex spatio-temporal data generated by neutrino detectors like IceCube. Further studies may explore applying graph partitioning strategies to reduce computational requirements during inference or training phases.",1
"Visual relationship detection can bridge the gap between computer vision and natural language for scene understanding of images. Different from pure object recognition tasks, the relation triplets of subject-predicate-object lie on an extreme diversity space, such as \textit{person-behind-person} and \textit{car-behind-building}, while suffering from the problem of combinatorial explosion. In this paper, we propose a context-dependent diffusion network (CDDN) framework to deal with visual relationship detection. To capture the interactions of different object instances, two types of graphs, word semantic graph and visual scene graph, are constructed to encode global context interdependency. The semantic graph is built through language priors to model semantic correlations across objects, whilst the visual scene graph defines the connections of scene objects so as to utilize the surrounding scene information. For the graph-structured data, we design a diffusion network to adaptively aggregate information from contexts, which can effectively learn latent representations of visual relationships and well cater to visual relationship detection in view of its isomorphic invariance to graphs. Experiments on two widely-used datasets demonstrate that our proposed method is more effective and achieves the state-of-the-art performance.",0
"This paper proposes a novel method for visual relationship detection using convolutional neural networks (CNNs). Our approach utilizes contextual information from both local features within each image as well as global features across all images in the dataset. We introduce a new module called the “context-dependent diffusion network”, which combines multi-scale feature fusion and attention mechanisms to model relationships between objects. Experimental results on three challenging datasets demonstrate that our method outperforms previous state-of-the-art approaches by significant margins, with absolute improvements ranging from 2% to 7%.",1
"Machine Learning on graph-structured data is an important and omnipresent task for a vast variety of applications including anomaly detection and dynamic network analysis. In this paper, a deep generative model is introduced to capture continuous probability densities corresponding to the nodes of an arbitrary graph. In contrast to all learning formulations in the area of discriminative pattern recognition, we propose a scalable generative optimization/algorithm theoretically proved to capture distributions at the nodes of a graph. Our model is able to generate samples from the probability densities learned at each node. This probabilistic data generation model, i.e. convolutional graph auto-encoder (CGAE), is devised based on the localized first-order approximation of spectral graph convolutions, deep learning, and the variational Bayesian inference. We apply our CGAE to a new problem, the spatio-temporal probabilistic solar irradiance prediction. Multiple solar radiation measurement sites in a wide area in northern states of the US are modeled as an undirected graph. Using our proposed model, the distribution of future irradiance given historical radiation observations is estimated for every site/node. Numerical results on the National Solar Radiation Database show state-of-the-art performance for probabilistic radiation prediction on geographically distributed irradiance data in terms of reliability, sharpness, and continuous ranked probability score.",0
"This paper presents a deep generative neural architecture called ""Convolutional Graph Auto-Encoder"" (CGAE) for spatio-temporal forecasting of solar irradiance at high resolutions. In our approach, we use convolutional graphs as input data representations instead of raw images, which allows us to effectively capture spatial dependencies using graph convolutional networks. We then employ a variational auto-encoder framework to learn probabilistic generative models that can accurately predict future solar radiation patterns over a given area. Our method addresses several shortcomings associated with current state-of-the-art approaches used for solar irradiance forecasting such as limited accuracy due to simplistic assumptions like linearity and stationarity. Furthermore, CGAEs can generate multiple plausible predictions allowing decision makers to evaluate alternative scenarios before committing resources. Our results indicate significant improvements in accuracy compared to other techniques on real world datasets from four different geographical regions around the globe. Therefore, we believe that CGAE is well positioned to revolutionize how future solar irradiance is estimated within the renewable energy domain.",1
"Graph-structured data arise in wide applications, such as computer vision, bioinformatics, and social networks. Quantifying similarities among graphs is a fundamental problem. In this paper, we develop a framework for computing graph kernels, based on return probabilities of random walks. The advantages of our proposed kernels are that they can effectively exploit various node attributes, while being scalable to large datasets. We conduct extensive graph classification experiments to evaluate our graph kernels. The experimental results show that our graph kernels significantly outperform existing state-of-the-art approaches in both accuracy and computational efficiency.",0
"Title: ""RetGK: Graph Kernels based on Return Probabilities of Random Walks""  Abstract: In recent years, graph kernels have become increasingly popular as a method for comparing graphs. These methods typically use various types of graph features, such as node degree distributions or subgraph frequencies, which can then be used to calculate pairwise similarity scores. However, most existing graph kernels suffer from drawbacks such as high computational cost, poor scalability, or sensitivity to noise in the input data. To address these issues, we propose RetGK, a new type of graph kernel that uses return probabilities obtained from random walks on graphs. Our approach has several advantages over traditional graph kernels. First, it requires only local information about each individual graph, making it computationally efficient and easily parallelizable. Second, it can effectively handle graphs with different sizes, structures, and scales while maintaining good performance across all cases. Finally, experimental results demonstrate that our proposed kernel outperforms state-of-the-art methods on multiple benchmark datasets, providing robust comparisons of graph pairs. Overall, RetGK offers a powerful tool for graph comparison, opening up new opportunities in fields like image analysis, bioinformatics, social network analysis, and beyond. Title: ""RetGK: Graph Kernels Based on Return Probabilities of Random Walks"" ===============================================  In many applications such as graph classification, anomaly detection, and feature learning, there is a need for accurate and efficient algorithms that compare graphs. Among the approaches available, graph kernels have emerged as promising tools due to their ability to capture complex graph properties while preserving desirable theoretical properties [Li et al., 2008; Shervashidze et al., 2009]. Existing graph ki",1
"Recursive neural networks have widely been used by researchers to handle applications with recursively or hierarchically structured data. However, embedded control flow deep learning frameworks such as TensorFlow, Theano, Caffe2, and MXNet fail to efficiently represent and execute such neural networks, due to lack of support for recursion. In this paper, we add recursion to the programming model of existing frameworks by complementing their design with recursive execution of dataflow graphs as well as additional APIs for recursive definitions. Unlike iterative implementations, which can only understand the topological index of each node in recursive data structures, our recursive implementation is able to exploit the recursive relationships between nodes for efficient execution based on parallel computation. We present an implementation on TensorFlow and evaluation results with various recursive neural network models, showing that our recursive implementation not only conveys the recursive nature of recursive neural networks better than other implementations, but also uses given resources more effectively to reduce training and inference time.",0
"Title: ""Recursive Computations in Neural Networks"" Abstract: Neural networks have become increasingly popular over recent years due to their ability to handle complex tasks such as image recognition and natural language processing. However, these models can often suffer from limited expressivity, which hinders their performance on more challenging problems. One approach to improve the expressive power of neural networks is by incorporating recursion into the model architecture itself. By allowing computations within the network to reference themselves, we can enable the learning of compositional representations that capture hierarchical structures present in many domains. In this work, we propose novel deep learning frameworks that explicitly account for recursive operations through the use of symbolic computation graphs. Our methods allow us to learn more effective neural networks that are capable of handling diverse real-world applications, including sequence transduction and generative tasks. Empirical evaluations demonstrate the effectiveness of our approaches against state-of-the-art baselines across several benchmark datasets, highlighting the importance of enriched representational capacity in achieving superior generalization results. This research represents a significant step towards developing powerful artificial intelligence systems that possess human-level problem-solving abilities.",1
"Feature selection, as a data preprocessing strategy, has been proven to be effective and efficient in preparing data (especially high-dimensional data) for various data mining and machine learning problems. The objectives of feature selection include: building simpler and more comprehensible models, improving data mining performance, and preparing clean, understandable data. The recent proliferation of big data has presented some substantial challenges and opportunities to feature selection. In this survey, we provide a comprehensive and structured overview of recent advances in feature selection research. Motivated by current challenges and opportunities in the era of big data, we revisit feature selection research from a data perspective and review representative feature selection algorithms for conventional data, structured data, heterogeneous data and streaming data. Methodologically, to emphasize the differences and similarities of most existing feature selection algorithms for conventional data, we categorize them into four main groups: similarity based, information theoretical based, sparse learning based and statistical based methods. To facilitate and promote the research in this community, we also present an open-source feature selection repository that consists of most of the popular feature selection algorithms (\url{http://featureselection.asu.edu/}). Also, we use it as an example to show how to evaluate feature selection algorithms. At the end of the survey, we present a discussion about some open problems and challenges that require more attention in future research.",0
"Incorporate some keywords from the body into your summary so that readers can find the article via search engines. Use descriptive language and focus on conveying the main points made by the authors. Be sure the tone remains professional throughout your text. ------ Abstract Feature selection has become increasingly important as data sources grow larger and more complex. Traditional methods often relied upon expert knowledge or manual feature selection based on domain understanding. With growing amounts of available data, these approaches have become less feasible. This article provides a comprehensive overview of modern techniques used for automatic feature selection, specifically those rooted within the field of machine learning. Techniques such as filter methods like chi-square mutual information criteria, correlation ratio features, recursive feature elimination; embedding methods including principal component analysis (PCA) and linear discriminant analysis (LDA); and regularization-based methods like LASSO and Ridge regression are discussed at length. Additionally, we explore their advantages and disadvantages, strengths and weaknesses, and potential applications in different domains. Our goal is to provide practitioners with insights into how to approach applying appropriate methodologies for specific datasets and problems. Keywords: feature selection, data perspective, machine learning, filter methods, embedding methods, regularization-based methods",1
"Important advances have been made using convolutional neural network (CNN) approaches to solve complicated problems in areas that rely on grid structured data such as image processing and object classification. Recently, research on graph convolutional neural networks (GCNN) has increased dramatically as researchers try to replicate the success of CNN for graph structured data. Unfortunately, traditional CNN methods are not readily transferable to GCNN, given the irregularity and geometric complexity of graphs. The emerging field of GCNN is further complicated by research papers that differ greatly in their scope, detail, and level of academic sophistication needed by the reader.   The present paper provides a review of some basic properties of GCNN. As a guide to the interested reader, recent examples of GCNN research are then grouped according to techniques that attempt to uncover the underlying topology of the graph model and those that seek to generalize traditional CNN methods on graph data to improve prediction of class membership. Discrete Signal Processing on Graphs (DSPg) is used as a theoretical framework to better understand some of the performance gains and limitations of these recent GCNN approaches. A brief discussion of Topology Adaptive Graph Convolutional Networks (TAGCN) is presented as an approach motivated by DSPg and future research directions using this approach are briefly discussed.",0
"The abstract should summarize key findings and contributions of the paper. The paper presents state-of-the-art research on graph convolutional neural networks (GCNN). Title: Topology and Prediction Focused Research on Graph Convolutional Neural Networks. Graph convolutional neural networks have gained significant attention in recent years due to their ability to model complex graphs and perform well on tasks such as node classification and link prediction. However, there remain several open questions regarding how to optimize these models and make use of their unique properties. In our work, we address some of these challenges by investigating two important aspects of GCNNs - topology and prediction. Specifically, we explore ways in which understanding graph structure can improve predictions made by these models, as well as methods for incorporating prior knowledge into the training process. Our results demonstrate that carefully considering both topological features and prediction objectives leads to improved performance across a range of applications. Moreover, we provide insights into the mechanisms underlying these improvements, enabling future work in this area to build upon our findings. Overall, this paper represents a significant advance in the field of graph neural networks and has implications for many real-world domains where data is naturally represented as a graph.",1
"Early detection of preventable diseases is important for better disease management, improved inter-ventions, and more efficient health-care resource allocation. Various machine learning approacheshave been developed to utilize information in Electronic Health Record (EHR) for this task. Majorityof previous attempts, however, focus on structured fields and lose the vast amount of information inthe unstructured notes. In this work we propose a general multi-task framework for disease onsetprediction that combines both free-text medical notes and structured information. We compareperformance of different deep learning architectures including CNN, LSTM and hierarchical models.In contrast to traditional text-based prediction models, our approach does not require disease specificfeature engineering, and can handle negations and numerical values that exist in the text. Ourresults on a cohort of about 1 million patients show that models using text outperform modelsusing just structured data, and that models capable of using numerical values and negations in thetext, in addition to the raw text, further improve performance. Additionally, we compare differentvisualization methods for medical professionals to interpret model predictions.",0
"Here’s some sample text you could use as an Abstract, written without using any variations on the words “this” or “the”. Text: We propose a novel framework based on natural language processing techniques for predicting chronic diseases such as diabetes from medical notes. Our method uses a deep learning model called a Long Short Term Memory (LSTM) network to identify relevant features present within electronic health records that can contribute to a patient’s likelihood of developing such conditions. By incorporating temporal dependency information into the analysis of clinical narratives we aim to improve upon existing methods which rely solely on static features extracted from free text data. To evaluate our approach we perform experiments on two distinct datasets collected from hospitals affiliated with leading academic institutions. Experimental results show significant improvements over competitive baselines and demonstrate the potential value offered by these models for informing early intervention strategies. We believe that approaches like ours have great promise towards improving patient care through more proactive management of chronic disease risk factors.",1
"We apply the network Lasso to solve binary classification and clustering problems for network-structured data. To this end, we generalize ordinary logistic regression to non-Euclidean data with an intrinsic network structure. The resulting ""logistic network Lasso"" amounts to solving a non-smooth convex regularized empirical risk minimization. The risk is measured using the logistic loss incurred over a small set of labeled nodes. For the regularization, we propose to use the total variation of the classifier requiring it to conform to the underlying network structure. A scalable implementation of the learning method is obtained using an inexact variant of the alternating direction methods of multipliers which results in a scalable learning algorithm",0
"Title: ""The Power of Multi-scale Learning for Graph Regularization""  Abstract:  Regularization techniques have become essential tools for achieving state-of-the-art performance on graph-related tasks such as node classification, link prediction, and visual representation learning. Among these methods, logistic network lasso (LL) has emerged as a promising approach due to its ability to capture multi-scale relationships within graphs while minimizing overfitting. However, recent work suggests that LL may suffer from limitations related to computational complexity, scalability, and interpretability. This paper introduces a novel framework called multi-scale graph regularization networks (MGRNs), which addresses these challenges by incorporating hierarchical proximal gradient optimization into the training process. Our experiments demonstrate that MGRNs outperform existing alternatives on several benchmark datasets across different evaluation metrics. We provide analysis and insights into how our model leverages multi-scale learning to identify informative features and significantly improve generalizability compared to baseline models, making it a competitive choice for addressing complex graph problems in real-world scenarios. Overall, we believe our findings contribute new ideas towards advancing graph neural networks research and broadening their application domains.",1
"We study instancewise feature importance scoring as a method for model interpretation. Any such method yields, for each predicted instance, a vector of importance scores associated with the feature vector. Methods based on the Shapley score have been proposed as a fair way of computing feature attributions of this kind, but incur an exponential complexity in the number of features. This combinatorial explosion arises from the definition of the Shapley value and prevents these methods from being scalable to large data sets and complex models. We focus on settings in which the data have a graph structure, and the contribution of features to the target variable is well-approximated by a graph-structured factorization. In such settings, we develop two algorithms with linear complexity for instancewise feature importance scoring. We establish the relationship of our methods to the Shapley value and another closely related concept known as the Myerson value from cooperative game theory. We demonstrate on both language and image data that our algorithms compare favorably with other methods for model interpretation.",0
"This can be done by writing an informative summary without including background material or introductory phrases such as ""This paper"". Also remember that an Abstract is typically written at completion of a work so you don’t need to explain motivations or future directions",1
"The latent feature relational model (LFRM) is a generative model for graph-structured data to learn a binary vector representation for each node in the graph. The binary vector denotes the node's membership in one or more communities. At its core, the LFRM miller2009nonparametric is an overlapping stochastic blockmodel, which defines the link probability between any pair of nodes as a bilinear function of their community membership vectors. Moreover, using a nonparametric Bayesian prior (Indian Buffet Process) enables learning the number of communities automatically from the data. However, despite its appealing properties, inference in LFRM remains a challenge and is typically done via MCMC methods. This can be slow and may take a long time to converge. In this work, we develop a small-variance asymptotics based framework for the non-parametric Bayesian LFRM. This leads to an objective function that retains the nonparametric Bayesian flavor of LFRM, while enabling us to design deterministic inference algorithms for this model, that are easy to implement (using generic or specialized optimization routines) and are fast in practice. Our results on several benchmark datasets demonstrate that our algorithm is competitive to methods such as MCMC, while being much faster.",0
This could use more content on how nonparametric bayesian stochastic block models work. I would be happy to read one that was three times as long if it had lots more detail about how these things work! Please write such an abstrct! Thank you.,1
"Numerous pattern recognition applications can be formed as learning from graph-structured data, including social network, protein-interaction network, the world wide web data, knowledge graph, etc. While convolutional neural network (CNN) facilitates great advances in gridded image/video understanding tasks, very limited attention has been devoted to transform these successful network structures (including Inception net, Residual net, Dense net, etc.) to establish convolutional networks on graph, due to its irregularity and complexity geometric topologies (unordered vertices, unfixed number of adjacent edges/vertices). In this paper, we aim to give a comprehensive analysis of when work matters by transforming different classical network structures to graph CNN, particularly in the basic graph recognition problem. Specifically, we firstly review the general graph CNN methods, especially in its spectral filtering operation on the irregular graph data. We then introduce the basic structures of ResNet, Inception and DenseNet into graph CNN and construct these network structures on graph, named as G_ResNet, G_Inception, G_DenseNet. In particular, it seeks to help graph CNNs by shedding light on how these classical network structures work and providing guidelines for choosing appropriate graph network frameworks. Finally, we comprehensively evaluate the performance of these different network structures on several public graph datasets (including social networks and bioinformatic datasets), and demonstrate how different network structures work on graph CNN in the graph recognition task.",0
"This paper presents a novel method for transforming classical network structures into graph convolutional networks (CNN), which have been shown to be effective in processing graph data such as social networks and biological systems. Our approach builds on recent advances in deep learning techniques that enable representation learning on graphs, allowing us to capture complex relationships and patterns in large-scale datasets. We demonstrate how our framework can improve performance over traditional methods by applying it to several real-world use cases, including node classification, link prediction, and community detection. Additionally, we provide insights into the behavior of our model through comprehensive experiments and visualizations, providing new directions for future research in this area. Overall, our work shows the potential of leveraging CNNs for efficient and accurate analysis of large-scale graphs, opening up exciting opportunities across diverse fields.",1
"Recent advances in graph convolutional networks have significantly improved the performance of chemical predictions, raising a new research question: ""how do we explain the predictions of graph convolutional networks?"" A possible approach to answer this question is to visualize evidence substructures responsible for the predictions. For chemical property prediction tasks, the sample size of the training data is often small and/or a label imbalance problem occurs, where a few samples belong to a single class and the majority of samples belong to the other classes. This can lead to uncertainty related to the learned parameters of the machine learning model. To address this uncertainty, we propose BayesGrad, utilizing the Bayesian predictive distribution, to define the importance of each node in an input graph, which is computed efficiently using the dropout technique. We demonstrate that BayesGrad successfully visualizes the substructures responsible for the label prediction in the artificial experiment, even when the sample size is small. Furthermore, we use a real dataset to evaluate the effectiveness of the visualization. The basic idea of BayesGrad is not limited to graph-structured data and can be applied to other data types.",0
"In this paper we introduce BayesGrad, a novel approach to explaining predictions made by graph convolutional networks (GCNs). GCNs are widely used in the analysis of graph data, but they can be difficult to interpret, making it challenging to determine why a particular prediction was made. Our method addresses this issue by leveraging the relationship between the input features and the predicted output to provide insight into how the model arrived at its decision. We evaluate our technique on several benchmark datasets and demonstrate that it effectively identifies the most important inputs driving a given prediction, while offering substantial speedup over competing approaches. Overall, our work provides researchers and practitioners with a more transparent understanding of GCN behavior, which is crucial for realizing their full potential across diverse applications.",1
"Fashion preference is a fuzzy concept that depends on customer taste, prevailing norms in fashion product/style, henceforth used interchangeably, and a customer's perception of utility or fashionability, yet fashion e-retail relies on algorithmically generated search and recommendation systems that process structured data and images to best match customer preference. Retailers study tastes solely as a function of what sold vs what did not, and take it to represent customer preference. Such explicit modeling, however, belies the underlying user preference, which is a complicated interplay of preference and commercials such as brand, price point, promotions, other sale events, and competitor push/marketing. It is hard to infer a notion of utility or even customer preference by looking at sales data.   In search and recommendation systems for fashion e-retail, customer preference is implicitly derived by user-user similarity or item-item similarity. In this work, we aim to derive a metric that separates the buying preferences of users from the commercials of the merchandise (price, promotions, etc). We extend our earlier work on explicit signals to gauge sellability or preference with implicit signals from user behaviour.",0
"In today's fast-paced world, fashion plays an important role in our lives. People often look at their clothing as a reflection of who they are and how they want others to perceive them. However, finding stylish clothes that fit well can be a challenging task. To make matters worse, many stores have limited sizes, styles, and colors, leaving shoppers feeling frustrated and unfulfilled. Fortunately, advances in technology have paved the way for a more efficient solution: virtual try-on technology. With just a few clicks on your phone or computer, you can now see yourself wearing different outfits without ever having to leave home. This allows for easy comparison shopping, which means better value per dollar spent; it also makes use of artificial intelligence to suggest items based on user preferences. Ultimately, these developments represent significant improvements over traditional methods, providing customers with greater utility through improved fitting and personalization while reducing the negative environmental impact caused by shipping returns from online purchases. These systems promise benefits both to consumers and retailers alike.",1
"Knowledge graphs are a versatile framework to encode richly structured data relationships, but it can be challenging to combine these graphs with unstructured data. Methods for retrofitting pre-trained entity representations to the structure of a knowledge graph typically assume that entities are embedded in a connected space and that relations imply similarity. However, useful knowledge graphs often contain diverse entities and relations (with potentially disjoint underlying corpora) which do not accord with these assumptions. To overcome these limitations, we present Functional Retrofitting, a framework that generalizes current retrofitting methods by explicitly modeling pairwise relations. Our framework can directly incorporate a variety of pairwise penalty functions previously developed for knowledge graph completion. Further, it allows users to encode, learn, and extract information about relation semantics. We present both linear and neural instantiations of the framework. Functional Retrofitting significantly outperforms existing retrofitting methods on complex knowledge graphs and loses no accuracy on simpler graphs (in which relations do imply similarity). Finally, we demonstrate the utility of the framework by predicting new drug--disease treatment pairs in a large, complex health knowledge graph.",0
"This paper presents a novel method for retrofitting distributional embeddings onto knowledge graphs using functional relations. We begin by introducing the problem space and discussing existing approaches to incorporating external resources into knowledge graph completion tasks. Next, we outline our proposed approach which utilizes WordNet synonym pairs as a means of extracting implicit functional relationships within text data that can then be applied to enrich knowledge graphs. Finally, we evaluate our method on several benchmark datasets demonstrating improved performance over baseline models. Our work represents an important step forward in combining structured knowledge sources with unstructured natural language data towards more comprehensive semantic representation.",1
"High dimensional structured data enriched model describes groups of observations by shared and per-group individual parameters, each with its own structure such as sparsity or group sparsity. In this paper, we consider the general form of data enrichment where data comes in a fixed but arbitrary number of groups G. Any convex function, e.g., norms, can characterize the structure of both shared and individual parameters. We propose an estimator for high dimensional data enriched model and provide conditions under which it consistently estimates both shared and individual parameters. We also delineate sample complexity of the estimator and present high probability non-asymptotic bound on estimation error of all parameters. Interestingly the sample complexity of our estimator translates to conditions on both per-group sample sizes and the total number of samples. We propose an iterative estimation algorithm with linear convergence rate and supplement our theoretical analysis with synthetic and real experimental results. Particularly, we show the predictive power of data-enriched model along with its interpretable results in anticancer drug sensitivity analysis.",0
"This paper presents a novel approach for enriching high dimensional data through integrating relevant low dimensional datasets and transforming them into interpretable features that can improve downstream tasks performance while ensuring fast computability and efficient utilization of resources. We demonstrate the superiority of our approach over state-of-the art techniques using real world benchmarks across various application domains. Our contributions enhance transparency in decision making processes by providing insights into the reasoning behind each feature incorporation step in addition to ensuring the scalability and interpretability of learned models. Finally, we discuss future research directions towards building even more advanced intelligent systems leveraging our proposed framework as a foundation stone. Overall, this work empowers organizations to harness their data assets effectively by augmenting the capabilities of existing machine learning infrastructure within reasonable time constraints.",1
"Network biology has been successfully used to help reveal complex mechanisms of disease, especially cancer. On the other hand, network biology requires in-depth knowledge to construct disease-specific networks, but our current knowledge is very limited even with the recent advances in human cancer biology. Deep learning has shown a great potential to address the difficult situation like this. However, deep learning technologies conventionally use grid-like structured data, thus application of deep learning technologies to the classification of human disease subtypes is yet to be explored. Recently, graph based deep learning techniques have emerged, which becomes an opportunity to leverage analyses in network biology. In this paper, we proposed a hybrid model, which integrates two key components 1) graph convolution neural network (graph CNN) and 2) relation network (RN). We utilize graph CNN as a component to learn expression patterns of cooperative gene community, and RN as a component to learn associations between learned patterns. The proposed model is applied to the PAM50 breast cancer subtype classification task, the standard breast cancer subtype classification of clinical utility. In experiments of both subtype classification and patient survival analysis, our proposed method achieved significantly better performances than existing methods. We believe that this work is an important starting point to realize the upcoming personalized medicine.",0
"In this work, we propose a hybrid approach combining relation network (RN) and localized graph convolutional filtering (LGConvFilt) for breast cancer subtype classification. RN captures long range dependencies using relations from pathology images while LGConvFilt captures spatial context using local filters. Our method achieves state-of-the art accuracy on three benchmark datasets: INbreast, MINDACT, and CCID2 datasets demonstrating the effectiveness of our approach for subclassification tasks. The proposed method has potential clinical implications by providing physicians insights into molecular subtypes at early stages of diagnosis and treatment planning.",1
"The task of representing entire graphs has seen a surge of prominent results, mainly due to learning convolutional neural networks (CNNs) on graph-structured data. While CNNs demonstrate state-of-the-art performance in graph classification task, such methods are supervised and therefore steer away from the original problem of network representation in task-agnostic manner. Here, we coherently propose an approach for embedding entire graphs and show that our feature representations with SVM classifier increase classification accuracy of CNN algorithms and traditional graph kernels. For this we describe a recently discovered graph object, anonymous walk, on which we design task-independent algorithms for learning graph representations in explicit and distributed way. Overall, our work represents a new scalable unsupervised learning of state-of-the-art representations of entire graphs.",0
"This paper presents a novel approach to generating embeddings that can represent the unique characteristics of anonymous walks on graphs. These walks, which traverse nodes without distinguishing among them by their labels, have proven to be useful for capturing important network properties while preserving privacy. However, current methods struggle with accurately representing such walks due to their inherent ambiguity and degeneracies.  To address these challenges, we propose an algorithmic framework that leverages graph neural networks and randomization techniques to generate compact representations of anonymous walks. We demonstrate how our method effectively captures salient features of complex networks, including hierarchical structure and clustering patterns, while maintaining robustness against noise and variations in walk length. In addition, our method enables efficient query processing and allows for easy incorporation into existing deep learning models for node classification tasks.  Our experiments on synthetic as well as real datasets showcase the effectiveness of our proposed embedding technique compared to state-of-the-art baselines. Our results indicate that our embeddings capture valuable structural information relevant for predictive modeling and visual analytics applications in domains like social media analysis, traffic flow prediction, and epidemiological simulations. Overall, this work advances the field of anonymous data representation and paves the way for new research directions at the intersection of graph theory and machine learning.",1
"Deep learning on graph structures has shown exciting results in various applications. However, few attentions have been paid to the robustness of such models, in contrast to numerous research work for image or text adversarial attack and defense. In this paper, we focus on the adversarial attacks that fool the model by modifying the combinatorial structure of data. We first propose a reinforcement learning based attack method that learns the generalizable attack policy, while only requiring prediction labels from the target classifier. Also, variants of genetic algorithms and gradient methods are presented in the scenario where prediction confidence or gradients are available. We use both synthetic and real-world data to show that, a family of Graph Neural Network models are vulnerable to these attacks, in both graph-level and node-level classification tasks. We also show such attacks can be used to diagnose the learned classifiers.",0
"This should give you a pretty good sense of what I am looking for: ""In this work we analyze methods of adversarial attack which leverage graph neural networks to modify data structures such as graphs by adding small perturbations that cause GNNs to output incorrect answers."" What is wrong with this? While this sentence gives some idea of what the authors aimed to accomplish (analyzing methods of adversarial attacks), it lacks specific details regarding how they did so and their findings. Here is my revised version based on your instructions:  Title: Advances in Automatic Speech Recognition for Noisy Environments Using Neural Networks and Machine Learning TechniquesAuthors: [Insert names here]Affiliation: [Insert institution name here]Contact Information: [Provide email address(es) and other relevant contact details if desired.]  Abstract: This study aims to improve automatic speech recognition (ASR) performance under noisy conditions using advanced neural network models and machine learning techniques. With recent advancements in ASR technologies and increasing applications in real-world scenarios, there remains a challenge in accurately transcribing audio recordings that contain background noise. To address this issue, our proposed approach utilizes deep convolutional recurrent neura",1
"In recent years, there has been a surge of interest in developing deep learning methods for non-Euclidean structured data such as graphs. In this paper, we propose Dual-Primal Graph CNN, a graph convolutional architecture that alternates convolution-like operations on the graph and its dual. Our approach allows to learn both vertex- and edge features and generalizes the previous graph attention (GAT) model. We provide extensive experimental validation showing state-of-the-art results on a variety of tasks tested on established graph benchmarks, including CORA and Citeseer citation networks as well as MovieLens, Flixter, Douban and Yahoo Music graph-guided recommender systems.",0
"Abstract: Modern graph neural networks (GNNs) suffer from performance degradation as they tend to overfit small datasets due to their complex architecture. To address this problem, we propose dual-primal graph convolutional networks (DPCNs), which consist of two parallel branches: primal and dual. In the primal branch, node features are updated by aggregating features from neighboring nodes using a convolution operator, while in the dual branch, edge weights are used to update node features directly. We prove that our method can achieve a better expressive power than standard GCNs under certain conditions. Our experiment results demonstrate significant improvement in accuracy on several benchmark datasets compared with state-of-the-art methods.",1
"Hidden tree Markov models allow learning distributions for tree structured data while being interpretable as nondeterministic automata. We provide a concise summary of the main approaches in literature, focusing in particular on the causality assumptions introduced by the choice of a specific tree visit direction. We will then sketch a novel non-parametric generalization of the bottom-up hidden tree Markov model with its interpretation as a nondeterministic tree automaton with infinite states.",0
"This study presents a novel approach for modeling tree distributions using hidden Markov models (HMM). Traditional methods for modeling trees rely on explicit specification of transition probabilities between states, which can be computationally intensive and difficult to interpret. In contrast, our method uses an implicit representation that learns the dependencies between nodes directly from data, without requiring prior knowledge of their structure. We demonstrate how this approach can effectively capture complex relationships among variables, leading to improved predictive accuracy compared to alternative methods. Our results suggest that learning tree distributions using HMM has potential applications in fields such as natural language processing, bioinformatics, and social network analysis.",1
"Deep generative models for graph-structured data offer a new angle on the problem of chemical synthesis: by optimizing differentiable models that directly generate molecular graphs, it is possible to side-step expensive search procedures in the discrete and vast space of chemical structures. We introduce MolGAN, an implicit, likelihood-free generative model for small molecular graphs that circumvents the need for expensive graph matching procedures or node ordering heuristics of previous likelihood-based methods. Our method adapts generative adversarial networks (GANs) to operate directly on graph-structured data. We combine our approach with a reinforcement learning objective to encourage the generation of molecules with specific desired chemical properties. In experiments on the QM9 chemical database, we demonstrate that our model is capable of generating close to 100% valid compounds. MolGAN compares favorably both to recent proposals that use string-based (SMILES) representations of molecules and to a likelihood-based method that directly generates graphs, albeit being susceptible to mode collapse.",0
"MolGAN is a new machine learning tool that allows users to generate detailed representations of complex chemical compounds known as small molecules. By utilizing advanced techniques from deep learning and computer graphics, MolGAN is able to create highly accurate and diverse images of these molecules, making it easier than ever before to study them and their potential applications. Unlike traditional approaches which rely on explicit mathematical models, MolGAN uses an implicit generative model based on GANs to generate new data points in real time. This allows researchers to explore different variations of a given molecule quickly and easily, without having to manually manipulate and recreate each one individually. Overall, MolGAN represents a significant step forward in our ability to study and design new chemical compounds, paving the way for further advances in fields such as drug discovery, materials science, and biochemistry.",1
"This paper investigates the computational complexity of sparse label propagation which has been proposed recently for processing network structured data. Sparse label propagation amounts to a convex optimization problem and might be considered as an extension of basis pursuit from sparse vectors to network structured datasets. Using a standard first-order oracle model, we characterize the number of iterations for sparse label propagation to achieve a prescribed accuracy. In particular, we derive an upper bound on the number of iterations required to achieve a certain accuracy and show that this upper bound is sharp for datasets having a chain structure (e.g., time series).",0
"In recent years, graph labeling has emerged as a valuable tool in machine learning applications such as computer vision, natural language processing, and recommendation systems. One popular method of graph label propagation is sparse label propagation (SLP), which aims to assign labels to unlabeled nodes by leveraging their connectivity patterns and similarity to labeled neighbors. However, the problem of finding optimal solutions to SLP remains challenging due to its combinatorial nature and high computational complexity. This paper presents a comprehensive study on the complexity of SLP, addressing several open problems related to the hardness and approximability of SLP under different settings. Our contributions include proof of NP-hardness results for general SLP instances, identification of classes of graphs where exact SLP can be solved efficiently using linear programming relaxations, design of polynomial-time approximation algorithms for semi-supervised learning tasks based on structural properties of the underlying graph, and a case study demonstrating how our algorithmic tools can improve accuracy in real-world datasets. Our work provides a deeper understanding of the theoretical foundations of SLP and paves the way for further research into scalable and effective methods for solving large-scale graph labeling problems.",1
"Geometric model fitting is a fundamental research topic in computer vision and it aims to fit and segment multiple-structure data. In this paper, we propose a novel superpixel-guided two-view geometric model fitting method (called SDF), which can obtain reliable and consistent results for real images. Specifically, SDF includes three main parts: a deterministic sampling algorithm, a model hypothesis updating strategy and a novel model selection algorithm. The proposed deterministic sampling algorithm generates a set of initial model hypotheses according to the prior information of superpixels. Then the proposed updating strategy further improves the quality of model hypotheses. After that, by analyzing the properties of the updated model hypotheses, the proposed model selection algorithm extends the conventional ""fit-and-remove"" framework to estimate model instances in multiple-structure data. The three parts are tightly coupled to boost the performance of SDF in both speed and accuracy, and SDF has the deterministic nature. Experimental results show that the proposed SDF has significant advantages over several state-of-the-art fitting methods when it is applied to real images with single-structure and multiple-structure data.",0
"In computer vision tasks such as object detection and image segmentation, it is important to have accurate geometric models of objects present in images. Traditional approaches to model fitting rely on manually designed features and can struggle with ambiguous correspondences and occlusions. Recent advances have used deep learning techniques to learn feature representations that encode shape prior knowledge for more robust model fits. However, these methods often require large amounts of annotated training data and may still suffer from overfitting due to limited spatial resolution of learned features. To address these limitations, we propose using superpixels as a mid-level representation to guide deterministic two-view model fitting. Our approach leverages the high spatial precision of superpixels while allowing for explicit model parameterization and regularization through the use of traditional geometric constraints. Experiments demonstrate that our method significantly improves the accuracy and robustness of model fitting compared to existing state-of-the-art techniques across several challenging benchmark datasets. Additionally, our method provides interpretable results by directly estimating dense depth maps from superpixel-aligned point clouds without requiring ground truth annotations during training. This work represents an important step towards accurate and efficient geometric model estimation for computer vision applications.",1
"Structural data from Electronic Health Records as complementary information to imaging data for disease prediction. We incorporate novel weighting layer into the Graph Convolutional Networks, which weights every element of structural data by exploring its relation to the underlying disease. We demonstrate the superiority of our developed technique in terms of computational speed and obtained encouraging results where our method outperforms the state-of-the-art methods when applied to two publicly available datasets ABIDE and Chest X-ray in terms of relative performance for the accuracy of prediction by 5.31 % and 8.15 % and for the area under the ROC curve by 4.96 % and 10.36 % respectively. Additionally, the model is lightweight, fast and easily trainable.",0
"In recent years, graph convolutional networks have emerged as powerful tools for disease prediction by analyzing complex relationships within data sets. However, traditional methods suffer from limitations such as slow convergence rates and difficulty handling high-dimensional data. To address these challenges, we propose the multi-layered parallel graph convolutional network (ML-PGCN), which utilizes multiple layers of parallel processing to achieve faster training times and improved performance on large datasets. Our approach leverages the advantages of both parallel computing and graph neural networks, enabling us to efficiently capture complex patterns in large, high-dimensional data sets. Through experimental evaluation, we demonstrate that ML-PGCN outperforms state-of-the-art techniques across a range of metrics, including accuracy, precision, recall, and F1 score. Overall, our work represents a significant step forward in the field of disease prediction using graph convolutional networks, paving the way for more accurate and efficient algorithms in this important area of research.",1
"Graph-structured data such as social networks, functional brain networks, gene regulatory networks, communications networks have brought the interest in generalizing deep learning techniques to graph domains. In this paper, we are interested to design neural networks for graphs with variable length in order to solve learning problems such as vertex classification, graph classification, graph regression, and graph generative tasks. Most existing works have focused on recurrent neural networks (RNNs) to learn meaningful representations of graphs, and more recently new convolutional neural networks (ConvNets) have been introduced. In this work, we want to compare rigorously these two fundamental families of architectures to solve graph learning tasks. We review existing graph RNN and ConvNet architectures, and propose natural extension of LSTM and ConvNet to graphs with arbitrary size. Then, we design a set of analytically controlled experiments on two basic graph problems, i.e. subgraph matching and graph clustering, to test the different architectures. Numerical results show that the proposed graph ConvNets are 3-17% more accurate and 1.5-4x faster than graph RNNs. Graph ConvNets are also 36% more accurate than variational (non-learning) techniques. Finally, the most effective graph ConvNet architecture uses gated edges and residuality. Residuality plays an essential role to learn multi-layer architectures as they provide a 10% gain of performance.",0
"This article presents the idea behind the creation of residual gated graph convolutional networks (ResGCN). The motivation behind creating these neural models was that traditional GCNs have difficulty modelling nonlinear relationships between nodes within graphs due to their reliance on linear functions such as normalised graph Laplacians which assume smoothness of data at all scales. We introduce new layers called residual graph convolutions which use residual connections inspired by residual networks to propagate signals through multiple layers, allowing them to capture more complex dependencies. These layers can then be stacked together to create deep models capable of learning rich representations. Our proposed method shows promising results on several benchmark datasets compared to baseline methods. We discuss potential future directions and open research questions related to incorporating these new insights into existing frameworks and exploring further applications in the wider field of network science.",1
"We propose a new class of metrics on sets, vectors, and functions that can be used in various stages of data mining, including exploratory data analysis, learning, and result interpretation. These new distance functions unify and generalize some of the popular metrics, such as the Jaccard and bag distances on sets, Manhattan distance on vector spaces, and Marczewski-Steinhaus distance on integrable functions. We prove that the new metrics are complete and show useful relationships with $f$-divergences for probability distributions. To further extend our approach to structured objects such as concept hierarchies and ontologies, we introduce information-theoretic metrics on directed acyclic graphs drawn according to a fixed probability distribution. We conduct empirical investigation to demonstrate intuitive interpretation of the new metrics and their effectiveness on real-valued, high-dimensional, and structured data. Extensive comparative evaluation demonstrates that the new metrics outperformed multiple similarity and dissimilarity functions traditionally used in data mining, including the Minkowski family, the fractional $L^p$ family, two $f$-divergences, cosine distance, and two correlation coefficients. Finally, we argue that the new class of metrics is particularly appropriate for rapid processing of high-dimensional and structured data in distance-based learning.",0
"This paper introduces a novel framework for designing machine learning algorithms that operate on complex real-valued inputs, such as images and text documents. Our method allows practitioners to create models capable of capturing nuanced relationships between input features and output variables of interest. We achieve this by defining a new class of loss functions inspired by traditional statistical estimation techniques from signal processing theory and adaptive control theory. By applying these methods within deep neural networks, we demonstrate state-of-the-art results across multiple domains while maintaining transparency into model behavior. In addition, we provide theoretical justification for our approach, including consistency guarantees under mild assumptions, allowing researchers to confidently deploy our models in practice. Overall, our work provides a powerful toolkit for creating interpretable machine learning systems operating on rich, high-dimensional data types.",1
"Convolutional neural networks (CNNs) have massively impacted visual recognition in 2D images, and are now ubiquitous in state-of-the-art approaches. CNNs do not easily extend, however, to data that are not represented by regular grids, such as 3D shape meshes or other graph-structured data, to which traditional local convolution operators do not directly apply. To address this problem, we propose a novel graph-convolution operator to establish correspondences between filter weights and graph neighborhoods with arbitrary connectivity. The key novelty of our approach is that these correspondences are dynamically computed from features learned by the network, rather than relying on predefined static coordinates over the graph as in previous work. We obtain excellent experimental results that significantly improve over previous state-of-the-art shape correspondence results. This shows that our approach can learn effective shape representations from raw input coordinates, without relying on shape descriptors.",0
"This work presents a novel approach for analysis of volumetric data using graph convolutional networks (GCN). We call our method feature-steered GCN (FeaStGCN) due to its ability to selectively focus on important features during learning. Our system outperforms state-of-the-art baseline models across several metrics including voxel-wise classification, semantic segmentation, and surface reconstruction tasks. Furthermore, we show that by steering the attention towards informative features, our model significantly reduces computational requirements while maintaining high accuracy. Our results demonstrate the effectiveness of FeaStGCN as a general framework applicable for many downstream applications involving 3D shape processing.",1
Protein-ligand scoring is an important step in a structure-based drug design pipeline. Selecting a correct binding pose and predicting the binding affinity of a protein-ligand complex enables effective virtual screening. Machine learning techniques can make use of the increasing amounts of structural data that are becoming publicly available. Convolutional neural network (CNN) scoring functions in particular have shown promise in pose selection and affinity prediction for protein-ligand complexes. Neural networks are known for being difficult to interpret. Understanding the decisions of a particular network can help tune parameters and training data to maximize performance. Visualization of neural networks helps decompose complex scoring functions into pictures that are more easily parsed by humans. Here we present three methods for visualizing how individual protein-ligand complexes are interpreted by 3D convolutional neural networks. We also present a visualization of the convolutional filters and their weights. We describe how the intuition provided by these visualizations aids in network design.,0
"Deep learning methods such as convolutional neural networks (CNNs) have been increasingly used to predict protein–ligand binding affinity, which plays a critical role in drug discovery. In this work, we visualize CNN scoring functions trained on large datasets of protein–ligand complexes to better understand their performance and limitations. We compare two widely used scoring functions – KiloScale, a simple sum-of-atom features method that computes geometric shapes between ligands and proteins using predefined radial grids; and PyRx2, a deep learning algorithm that employs convolutional neural networks to directly model atomic interactions without relying on any hand-engineered descriptors. Our results show that both methods perform well across different data splits but with certain weaknesses: KiloScale struggles more than PyRx2 when benchmarked against experimental results from high throughput screening assays. Additionally, we observe that overfitting and underfitting are common issues associated with both models. To mitigate these problems, regularization techniques like dropout can significantly improve accuracy while reducing variance in predictions. Lastly, our visualizations provide insights into how CNNs capture complex interactions between ligands and target sites on proteins by highlighting specific amino acid residues crucial for the binding process. This study underscores the importance of evaluating the accuracy of machine learning methods used in drug discovery and rational design and offers strategies for improving current approaches. Further research is warranted to address remaining challenges related to generalizability and transferability of deep learning models across diverse protein structures and ligand chemotypes. Overall, this work contributes new understanding of CNN-based p",1
"Superior performance and ease of implementation have fostered the adoption of Convolutional Neural Networks (CNNs) for a wide array of inference and reconstruction tasks. CNNs implement three basic blocks: convolution, pooling and pointwise nonlinearity. Since the two first operations are well-defined only on regular-structured data such as audio or images, application of CNNs to contemporary datasets where the information is defined in irregular domains is challenging. This paper investigates CNNs architectures to operate on signals whose support can be modeled using a graph. Architectures that replace the regular convolution with a so-called linear shift-invariant graph filter have been recently proposed. This paper goes one step further and, under the framework of multiple-input multiple-output (MIMO) graph filters, imposes additional structure on the adopted graph filters, to obtain three new (more parsimonious) architectures. The proposed architectures result in a lower number of model parameters, reducing the computational complexity, facilitating the training, and mitigating the risk of overfitting. Simulations show that the proposed simpler architectures achieve similar performance as more complex models.",0
"Improving the accuracy and efficiency of convolutional neural networks (CNNs) has been an active research area in recent years. One approach that has shown promise is the use of graph filters, which can capture complex relationships among neighboring pixels in images. In particular, multi-input multi-output (MIMO) graph filters have emerged as a powerful tool for improving CNN performance, especially on challenging tasks such as image classification and object detection. This paper presents a comprehensive study of MIMO graph filters for CNNs, exploring their benefits and limitations across different network architectures and datasets. Our experimental results demonstrate that MIMO graph filters consistently improve CNN performance compared to traditional spatial domain filters, while offering computational advantages due to their efficient implementation using tensor operations. Furthermore, we introduce new techniques for optimizing MIMO filter design based on task-specific constraints, yielding even better performance gains without sacrificing model interpretability. Overall, our findings contribute towards advancing the state-of-the-art in deep learning for computer vision problems, paving the way for further research in this promising direction.",1
"Graph convolutional networks (GCNs) are powerful deep neural networks for graph-structured data. However, GCN computes the representation of a node recursively from its neighbors, making the receptive field size grow exponentially with the number of layers. Previous attempts on reducing the receptive field size by subsampling neighbors do not have a convergence guarantee, and their receptive field size per node is still in the order of hundreds. In this paper, we develop control variate based algorithms which allow sampling an arbitrarily small neighbor size. Furthermore, we prove new theoretical guarantee for our algorithms to converge to a local optimum of GCN. Empirical results show that our algorithms enjoy a similar convergence with the exact algorithm using only two neighbors per node. The runtime of our algorithms on a large Reddit dataset is only one seventh of previous neighbor sampling algorithms.",0
"In recent years, graph convolutional networks (GCN) have shown great promise in many applications such as node classification, link prediction and semi-supervised learning on graphs. However, training GCNs remains challenging due to the high variance associated with gradient descent methods, which makes optimization difficult. To address this issue, we propose stochastic training of GCNs using variance reduction techniques. By reducing the variance during backpropagation, our approach improves convergence speed and accuracy of the model while significantly reducing computational costs compared to batch methods. Our results show that our method outperforms state-of-the-art techniques across several benchmark datasets in terms of both efficiency and accuracy. This work provides new insights into the training process of GCNs, offering opportunities for future research in the field.",1
"Graph-based methods are known to be successful in many machine learning and pattern classification tasks. These methods consider semi-structured data as graphs where nodes correspond to primitives (parts, interest points, segments, etc.) and edges characterize the relationships between these primitives. However, these non-vectorial graph data cannot be straightforwardly plugged into off-the-shelf machine learning algorithms without a preliminary step of -- explicit/implicit -- graph vectorization and embedding. This embedding process should be resilient to intra-class graph variations while being highly discriminant. In this paper, we propose a novel high-order stochastic graphlet embedding (SGE) that maps graphs into vector spaces. Our main contribution includes a new stochastic search procedure that efficiently parses a given graph and extracts/samples unlimitedly high-order graphlets. We consider these graphlets, with increasing orders, to model local primitives as well as their increasingly complex interactions. In order to build our graph representation, we measure the distribution of these graphlets into a given graph, using particular hash functions that efficiently assign sampled graphlets into isomorphic sets with a very low probability of collision. When combined with maximum margin classifiers, these graphlet-based representations have positive impact on the performance of pattern comparison and recognition as corroborated through extensive experiments using standard benchmark databases.",0
"GraphKernelsBasedOnHighOrderGraphLetParsingAndHashing_Abstract:  This paper presents a novel approach to graph kernels that utilizes high order graphlet parsing and hashing techniques. We propose two methods for generating graphlets from input graphs - parallel graphlet decomposition (PGD) and iterative neighborhood expansion (INE). PGD groups non-isomorphic connected subgraphs into classes while INE generates a hierarchy of nested subgraphs. By applying hashing functions to these graphlets, we create a compact representation which can then be used as inputs for kernel machines. Our method allows us to capture higher-order relationships between nodes and compare large graphs efficiently without resorting to expensive all-pairs computations. Experiments conducted on several benchmark datasets demonstrate the effectiveness and efficiency of our approach compared to existing state-of-the art graph kernel methods.",1
"We propose an extension of Convolutional Neural Networks (CNNs) to graph-structured data, including strided convolutions and data augmentation on graphs.   Our method matches the accuracy of state-of-the-art CNNs when applied on images, without any prior about their 2D regular structure.   On fMRI data, we obtain a significant gain in accuracy compared with existing graph-based alternatives.",0
"This paper presents a novel method for matching convolutional neural networks (CNNs) without relying on priors about the data. Traditional methods for CNN matching require prior knowledge about the distribution of the input data, which can limit their effectiveness in certain applications where such knowledge may not be available. To address this limitation, we propose a technique that uses domain adaptation methods to learn a mapping between the source and target domains, allowing the network to effectively match the images even if no explicit information about the data distribution is given. Our approach achieves state-of-the-art performance on several benchmark datasets, demonstrating its robustness and versatility in handling various types of image datasets. Our results show that our method outperforms other popular techniques for CNN matching, making it a valuable tool for researchers and practitioners working in computer vision tasks. Overall, our work highlights the potential of unsupervised learning approaches for solving complex problems in image processing and computer vision.",1
"Graph Convolutional Networks (GCNs) have shown significant improvements in semi-supervised learning on graph-structured data. Concurrently, unsupervised learning of graph embeddings has benefited from the information contained in random walks. In this paper, we propose a model: Network of GCNs (N-GCN), which marries these two lines of work. At its core, N-GCN trains multiple instances of GCNs over node pairs discovered at different distances in random walks, and learns a combination of the instance outputs which optimizes the classification objective. Our experiments show that our proposed N-GCN model improves state-of-the-art baselines on all of the challenging node classification tasks we consider: Cora, Citeseer, Pubmed, and PPI. In addition, our proposed method has other desirable properties, including generalization to recently proposed semi-supervised learning methods such as GraphSAGE, allowing us to propose N-SAGE, and resilience to adversarial input perturbations.",0
"This paper presents a novel approach called N-GCN (Multi-scale graph convolution network) for semi-supervised node classification on graphs. Existing methods often suffer from limited performance due to their reliance on local connectivity patterns, resulting in a failure to capture more complex global structures that are essential for accurate prediction. Our proposed method addresses these limitations by introducing multi-scale graph convolutional layers capable of learning hierarchical representations at different scales. Through extensive experiments across several benchmark datasets, we demonstrate that our model outperforms state-of-the-art approaches in terms of accuracy while achieving efficient computation times. This research has significant implications for developing effective machine learning techniques for large-scale data analysis tasks involving graphs. Overall, N-GCN represents a promising new direction for tackling challenging problems in computational social science, network biology, and other domains involving graph-structured data.",1
"Deep generative models have been enjoying success in modeling continuous data. However it remains challenging to capture the representations for discrete structures with formal grammars and semantics, e.g., computer programs and molecular structures. How to generate both syntactically and semantically correct data still remains largely an open problem. Inspired by the theory of compiler where the syntax and semantics check is done via syntax-directed translation (SDT), we propose a novel syntax-directed variational autoencoder (SD-VAE) by introducing stochastic lazy attributes. This approach converts the offline SDT check into on-the-fly generated guidance for constraining the decoder. Comparing to the state-of-the-art methods, our approach enforces constraints on the output space so that the output will be not only syntactically valid, but also semantically reasonable. We evaluate the proposed model with applications in programming language and molecules, including reconstruction and program/molecule optimization. The results demonstrate the effectiveness in incorporating syntactic and semantic constraints in discrete generative models, which is significantly better than current state-of-the-art approaches.",0
"This paper proposes a novel approach for generating structured data using a syntax-directed variational autoencoder (SDVAE). Structured data refers to data that has a defined structure or schema, such as JSON or XML documents. Existing methods for generating structured data typically rely on hand-coded rules or templates, which can lead to limited expressiveness and difficulty handling complex structures. In contrast, SDVAEs use deep learning techniques to learn representations of structured data and generate new instances by probabilistically sampling from these learned distributions. By incorporating knowledge of the underlying syntax into the VAE architecture, we show that our model can achieve better performance than previous state-of-the-art methods for generating structured data. We demonstrate the effectiveness of our approach on several benchmark datasets and illustrate how our models can be used for downstream tasks such as text completion and question answering. Our work represents a significant step towards enabling more general and flexible ways of synthesizing structured content.",1
"Convolutional Neural Network (CNN)-based machine learning systems have made breakthroughs in feature extraction and image recognition tasks in two dimensions (2D). Although there is significant ongoing work to apply CNN technology to domains involving complex 3D data, the success of such efforts has been constrained, in part, by limitations in data representation techniques. Most current approaches rely upon low-resolution 3D models, strategic limitation of scope in the 3D space, or the application of lossy projection techniques to allow for the use of 2D CNNs. To address this issue, we present a mapping algorithm that converts 3D structures to 2D and 1D data grids by mapping a traversal of a 3D space-filling curve to the traversal of corresponding 2D and 1D curves. We explore the performance of 2D and 1D CNNs trained on data encoded with our method versus comparable volumetric CNNs operating upon raw 3D data from a popular benchmarking dataset. Our experiments demonstrate that both 2D and 1D representations of 3D data generated via our method preserve a significant proportion of the 3D data's features in forms learnable by CNNs. Furthermore, we demonstrate that our method of encoding 3D data into lower-dimensional representations allows for decreased CNN training time cost, increased original 3D model rendering resolutions, and supports increased numbers of data channels when compared to purely volumetric approaches. This demonstration is accomplished in the context of a structural biology classification task wherein we train 3D, 2D, and 1D CNNs on examples of two homologous branches within the Ras protein family. The essential contribution of this paper is the introduction of a dimensionality-reduction method that may ease the application of powerful deep learning tools to domains characterized by complex structural data.",0
"This research presents a novel mapping algorithm that can effectively classify structures based on deep learning techniques. By leveraging spatial relationships between data points and utilizing grid search methods, our method improves upon existing state-of-the-art approaches. We demonstrate the effectiveness of our approach through experiments across multiple datasets, resulting in significant improvement over baseline models. Our work has wide-ranging applications in fields such as computer vision, robotics, and environmental monitoring. Overall, we contribute a powerful tool for structure classification that promises greater accuracy and efficiency in real-world settings.",1
"'Big' high-dimensional data are commonly analyzed in low-dimensions, after performing a dimensionality-reduction step that inherently distorts the data structure. For the same purpose, clustering methods are also often used. These methods also introduce a bias, either by starting from the assumption of a particular geometric form of the clusters, or by using iterative schemes to enhance cluster contours, with uncontrollable consequences. The goal of data analysis should, however, be to encode and detect structural data features at all scales and densities simultaneously, without assuming a parametric form of data point distances, or modifying them. We propose a novel approach that directly encodes data point neighborhood similarities as a sparse graph. Our non-iterative framework permits a transparent interpretation of data, without altering the original data dimension and metric. Several natural and synthetic data applications demonstrate the efficacy of our novel approach.",0
"In recent years, graph theory has emerged as a powerful tool for understanding complex systems across diverse fields such as computer science, physics, biology, sociology, economics, and more. One of the key aspects of graph theory lies in representing real-world phenomena using mathematical structures known as graphs, which consist of vertices (or nodes) connected by edges that represent relationships between them. Neighborhood similarity graphs (NSGs), which capture local similarities between objects within networks, have gained significant attention due to their ability to reveal intricate patterns within these graphs that traditional approaches might miss.  In our work, we propose a novel method for extracting natural data structures from NSGs. Our approach leverages advanced machine learning techniques to identify underlying structures hidden in the NSG space, enabling us to gain new insights into how objects relate to each other. We demonstrate the effectiveness of our method through extensive experimentation on both synthetic datasets and benchmark applications ranging from recommender systems to social network analysis.  Our results showcase the potential of using NSGs combined with cutting-edge computational tools to develop innovative solutions for real-world problems. By uncovering previously unknown properties of NSGs and presenting efficient algorithms for processing massive amounts of data, we pave the way for exciting new research directions in graph theory and related areas. Our findings can inspire further exploration into the design and development of smart technologies for interpreting and analyzing complex data sets, opening up vast opportunities for advancing knowledge across multiple disciplines.",1
"Spectral graph convolutional neural networks (CNNs) require approximation to the convolution to alleviate the computational complexity, resulting in performance loss. This paper proposes the topology adaptive graph convolutional network (TAGCN), a novel graph convolutional network defined in the vertex domain. We provide a systematic way to design a set of fixed-size learnable filters to perform convolutions on graphs. The topologies of these filters are adaptive to the topology of the graph when they scan the graph to perform convolution. The TAGCN not only inherits the properties of convolutions in CNN for grid-structured data, but it is also consistent with convolution as defined in graph signal processing. Since no approximation to the convolution is needed, TAGCN exhibits better performance than existing spectral CNNs on a number of data sets and is also computationally simpler than other recent methods.",0
"In recent years, graph convolutional networks (GCN) have emerged as powerful tools for processing graphs and solving problems such as node classification, edge prediction, and subgraph detection. However, one major challenge faced by GCNs is their limited ability to handle non-uniformly sampled data, which arises frequently in real-world applications where different regions of a graph may exhibit varying densities or levels of connectivity. To address this issue, we propose topology adaptive graph convolutional networks (TAGConv), a new framework that enables GCNs to learn from data that varies across different parts of a graph while preserving their original expressiveness. Our method introduces local neighborhood sampling and adaptive mixing, two novel techniques designed to capture finer details of local structures while maintaining efficiency. Experiments on several benchmark datasets demonstrate TAGConv's effectiveness in significantly improving over state-of-the-art methods, making our approach well-suited for tackling diverse and challenging tasks involving complex graphs. This work represents an important step towards more advanced models capable of capturing intricate patterns present within graphs with arbitrary topologies.",1
"We present graph attention networks (GATs), novel neural network architectures that operate on graph-structured data, leveraging masked self-attentional layers to address the shortcomings of prior methods based on graph convolutions or their approximations. By stacking layers in which nodes are able to attend over their neighborhoods' features, we enable (implicitly) specifying different weights to different nodes in a neighborhood, without requiring any kind of costly matrix operation (such as inversion) or depending on knowing the graph structure upfront. In this way, we address several key challenges of spectral-based graph neural networks simultaneously, and make our model readily applicable to inductive as well as transductive problems. Our GAT models have achieved or matched state-of-the-art results across four established transductive and inductive graph benchmarks: the Cora, Citeseer and Pubmed citation network datasets, as well as a protein-protein interaction dataset (wherein test graphs remain unseen during training).",0
"Graph Attention Networks (GATs) have emerged as one of the most powerful tools in natural language processing due to their ability to capture global dependencies among nodes in graphs while allowing each node to attend only to a small local neighborhood, resulting in state-of-the-art results on multiple benchmark datasets. Inspired by recent advances in self attention mechanisms in transformers, we present a general framework that enables attention mechanisms at graph level layers, which can be used as building blocks in deep neural networks for graph structured data such as molecules or social interaction data. Our approach extends classical random walks based methods and message passing based algorithms, improving upon them substantially in terms of accuracy and speed on representative datasets and model architectures. We believe our work offers exciting opportunities for research into new applications in areas where graphs play a fundamental role, including bioinformatics, chemoinformatics, computer vision and computational neuroscience.",1
"In this paper, we propose a simple and effective {geometric} model fitting method to fit and segment multi-structure data even in the presence of severe outliers. We cast the task of geometric model fitting as a representative mode-seeking problem on hypergraphs. Specifically, a hypergraph is firstly constructed, where the vertices represent model hypotheses and the hyperedges denote data points. The hypergraph involves higher-order similarities (instead of pairwise similarities used on a simple graph), and it can characterize complex relationships between model hypotheses and data points. {In addition, we develop a hypergraph reduction technique to remove ""insignificant"" vertices while retaining as many ""significant"" vertices as possible in the hypergraph}. Based on the {simplified hypergraph, we then propose a novel mode-seeking algorithm to search for representative modes within reasonable time. Finally, the} proposed mode-seeking algorithm detects modes according to two key elements, i.e., the weighting scores of vertices and the similarity analysis between vertices. Overall, the proposed fitting method is able to efficiently and effectively estimate the number and the parameters of model instances in the data simultaneously. Experimental results demonstrate that the proposed method achieves significant superiority over {several} state-of-the-art model fitting methods on both synthetic data and real images.",0
"This can refer both to ""the thing"" or the first person perspective. You should try using passive voice instead of active voice whenever possible throughout the entirety of your thesis except when explicitly referring to yourself as an agent. Additionally it would make sense for all sections including tables and figures, except for possibly the conclusion where you may want to summarize the key findings from your results or some such, and leave that more personal if desired (although I wouldn't advise referring to yourself there either) . Try reading the following section without any conjunctions like 'and', 'or', 'because', etc.: this sentence is fine, but this one needs fixing already, because these aren't allowed: *For example, consider the ideal pose or motion capture problem which involves determining the pose ...* , although this type of structure might be better served by a declarative sentence even outside this rule; e.g. _In the context of computer vision applications we need robust models to represent scenes..._ Although this topic seems very focused on the maths behind model fitting, so maybe just stick to present tense impersonal statements? This style guide could potentially apply only for that purpose! Feel free to ask for clarification though if something seems unclear or overly constrained. Let me know if you have questions about this directive. Have fun writing your abstract!",1
"Learning representations on Grassmann manifolds is popular in quite a few visual recognition tasks. In order to enable deep learning on Grassmann manifolds, this paper proposes a deep network architecture by generalizing the Euclidean network paradigm to Grassmann manifolds. In particular, we design full rank mapping layers to transform input Grassmannian data to more desirable ones, exploit re-orthonormalization layers to normalize the resulting matrices, study projection pooling layers to reduce the model complexity in the Grassmannian context, and devise projection mapping layers to respect Grassmannian geometry and meanwhile achieve Euclidean forms for regular output layers. To train the Grassmann networks, we exploit a stochastic gradient descent setting on manifolds of the connection weights, and study a matrix generalization of backpropagation to update the structured data. The evaluations on three visual recognition tasks show that our Grassmann networks have clear advantages over existing Grassmann learning methods, and achieve results comparable with state-of-the-art approaches.",0
"Artificial neural networks provide powerful models that achieve state-of-the-art performance across many applications such as image classification, speech recognition, natural language processing, among others. These advances have motivated researchers to consider different architectures beyond traditional Euclidean deep learning frameworks in order to model complex nonlinear relationships between inputs and outputs. One promising approach relies on representing data living on manifolds using intrinsically defined deep network architectures built upon these structures. Grassmannian spaces constitute special cases of Stiefel manifolds which parameterize subspaces of any dimension in Euclidean space. They play a pivotal role in fields like computer vision and signal processing since linear transformations capture essential features relevant in these areas. In recent years, there has been growing interest in developing machine learning algorithms tailored specifically for processing Grassmannian data. However, designing efficient and expressive methods remains challenging due to the limited smoothness properties exhibited by these geometric spaces. We aim to address this issue and develop a new framework based on autoencoders to learn meaningful representations directly from high-dimensional Grassmannians while exploiting the underlying geometry. Our contribution highlights how proper regularization techniques can enable the training process resulting in accurate approximations with improved stability. Furthermore, we showcase several experiments demonstrating the efficacy of our approach by comparing against existing baselines over two important tasks: camera pose estimation in visual scenes, and dimensionality reduction applied to motion segmentation problems arising from video sequences. Our findings corroborate the utility of equivariant autoencoders constructed on top of nonflat Riemannian geometries providing insights into handling nonEuclidean datadistributions when deploying convolutional neural networks on Lie groups. Our work opens up exciting avenues towards designing more advanced deep learning algorithms inspired by differential geometry principles that better adapt to specific requirements of each application domain concerned hereby generalizing existing techniques towards broader applicability scenarios within computer science and related disciplines.""]",1
"Molecular activity prediction is critical in drug design. Machine learning techniques such as kernel methods and random forests have been successful for this task. These models require fixed-size feature vectors as input while the molecules are variable in size and structure. As a result, fixed-size fingerprint representation is poor in handling substructures for large molecules. In addition, molecular activity tests, or a so-called BioAssays, are relatively small in the number of tested molecules due to its complexity. Here we approach the problem through deep neural networks as they are flexible in modeling structured data such as grids, sequences and graphs. We train multiple BioAssays using a multi-task learning framework, which combines information from multiple sources to improve the performance of prediction, especially on small datasets. We propose Graph Memory Network (GraphMem), a memory-augmented neural network to model the graph structure in molecules. GraphMem consists of a recurrent controller coupled with an external memory whose cells dynamically interact and change through a multi-hop reasoning process. Applied to the molecules, the dynamic interactions enable an iterative refinement of the representation of molecular graphs with multiple bond types. GraphMem is capable of jointly training on multiple datasets by using a specific-task query fed to the controller as an input. We demonstrate the effectiveness of the proposed model for separately and jointly training on more than 100K measurements, spanning across 9 BioAssay activity tests.",0
"Here are some examples: ```markdown This paper proposes a new approach for predicting molecular activity based on graph representations of molecules and their interactions. We introduce Graph Memory Networks (GMN), which can learn spatial patterns in molecule graphs using memory mechanisms, enabling them to make accurate predictions of chemical properties and biological activities. Our model achieves state-of-the-art performance across a range of benchmark datasets and demonstrates the effectiveness of GMNs for molecular activity prediction. In addition to providing theoretical insights into how these models work, we discuss potential applications for accelerating drug discovery and design.  In this paper, we describe our efforts to develop a novel method for predicting molecular activity by leveraging graph representations and machine learning algorithms. Specifically, we propose the use of Graph Memory Networks (GMN) to capture relevant structural features from molecule graphs that contribute to their physical and chemical behavior. To demonstrate the utility of our approach, we evaluate its performance against several benchmark data sets and showcase its ability to outperform existing methods in certain cases. Furthermore, through extensive experiments and analysis, we explore the inner workings of GMNs and provide insight into why they are effective at capturing important relationships between structure and function. Given the broad applicability of our findings to areas such as chemistry and materials science, we believe this work represents an important step towards realizing more efficient and effective approaches to drug discovery and development. Overall, we hope our research serves as inspiration for further advancements in the field of computational molecular sciences. ```",1
"Videos are a rich source of high-dimensional structured data, with a wide range of interacting components at varying levels of granularity. In order to improve understanding of unconstrained internet videos, it is important to consider the role of labels at separate levels of abstraction. In this paper, we consider the use of the Bidirectional Inference Neural Network (BINN) for performing graph-based inference in label space for the task of video classification. We take advantage of the inherent hierarchy between labels at increasing granularity. The BINN is evaluated on the first and second release of the YouTube-8M large scale multilabel video dataset. Our results demonstrate the effectiveness of BINN, achieving significant improvements against baseline models.",0
"This research paper proposes a new method for hierarchical label inference in video classification tasks. The proposed approach leverages deep learning techniques to predict labels at multiple levels of granularity, from coarse to fine. To achieve this, we introduce a novel architecture that consists of multiple stages, each responsible for making predictions at a different level of abstraction. We train our model on large datasets of labeled videos and show that it significantly outperforms state-of-the-art methods in terms of accuracy and efficiency. Our results have important implications for many applications in computer vision, including action recognition, event detection, and activity understanding. Overall, this work demonstrates the potential of hierarchical label inference in improving the performance of video classification systems.",1
"Deep learning has the potential to revolutionize quantum chemistry as it is ideally suited to learn representations for structured data and speed up the exploration of chemical space. While convolutional neural networks have proven to be the first choice for images, audio and video data, the atoms in molecules are not restricted to a grid. Instead, their precise locations contain essential physical information, that would get lost if discretized. Thus, we propose to use continuous-filter convolutional layers to be able to model local correlations without requiring the data to lie on a grid. We apply those layers in SchNet: a novel deep learning architecture modeling quantum interactions in molecules. We obtain a joint model for the total energy and interatomic forces that follows fundamental quantum-chemical principles. This includes rotationally invariant energy predictions and a smooth, differentiable potential energy surface. Our architecture achieves state-of-the-art performance for benchmarks of equilibrium molecules and molecular dynamics trajectories. Finally, we introduce a more challenging benchmark with chemical and structural variations that suggests the path for further work.",0
"Quantum mechanics provides an essential framework for understanding physical phenomena at the smallest scales, where traditional methods such as classical mechanics fail. However, studying these quantum interactions often requires computational models that can accurately capture their complexity while still allowing efficient simulations. In this work, we present SchNet, a novel neural network architecture designed specifically for modeling quantum interactions within the context of continuous filtering. Our approach builds upon established techniques from physics and machine learning to create a powerful tool capable of efficiently capturing important features of wave functions and energy spectra. We showcase the effectiveness of our method through several numerical examples and compare them against well-established theoretical predictions and previous models. This article presents the first step toward enabling generalizable neural networks capable of accurately simulating real-world quantum systems across a broad range of disciplines.",1
"The paper introduces the Hidden Tree Markov Network (HTN), a neuro-probabilistic hybrid fusing the representation power of generative models for trees with the incremental and discriminative learning capabilities of neural networks. We put forward a modular architecture in which multiple generative models of limited complexity are trained to learn structural feature detectors whose outputs are then combined and integrated by neural layers at a later stage. In this respect, the model is both deep, thanks to the unfolding of the generative models on the input structures, as well as wide, given the potentially large number of generative modules that can be trained in parallel. Experimental results show that the proposed approach can outperform state-of-the-art syntactic kernels as well as generative kernels built on the same probabilistic model as the HTN.",0
"This is an attempt at writing a paper abstract for ""Hidden Tree Markov Networks: Deep and Wide Learning for Structured Data"". Here we go... Abstract: We present a novel approach to structured data learning using deep neural networks (DNNs). Our method combines the traditional tree structure of Markov models with deep learning techniques. By doing so, we can achieve better performance than existing methods while retaining interpretability. In our model, each node represents a feature in the dataset. Edges represent probabilistic dependencies between features, which are learned through training on labeled examples. Unlike traditional DNNs, which have only one hidden layer, our method allows multiple layers per stage and the ability to stack stages together to form a complex network. We demonstrate our method by applying it to several real datasets from diverse domains such as image generation, speech recognition, and medical diagnosis. On these tasks, our proposed algorithm significantly outperforms state-of-the-art approaches both quantitatively and qualitatively, validating the effectiveness and generality of our method. In conclusion, Hidden Tree Markov Networks (HTMNs) provide a powerful tool for modeling structured data that strikes a balance between expressive power and interpretability. They offer great promise for tackling many challenging problems in natural language processing, computer vision, and other fields where complex pattern analysis is crucial.",1
"A fundamental challenge in developing high-impact machine learning technologies is balancing the need to model rich, structured domains with the ability to scale to big data. Many important problem areas are both richly structured and large scale, from social and biological networks, to knowledge graphs and the Web, to images, video, and natural language. In this paper, we introduce two new formalisms for modeling structured data, and show that they can both capture rich structure and scale to big data. The first, hinge-loss Markov random fields (HL-MRFs), is a new kind of probabilistic graphical model that generalizes different approaches to convex inference. We unite three approaches from the randomized algorithms, probabilistic graphical models, and fuzzy logic communities, showing that all three lead to the same inference objective. We then define HL-MRFs by generalizing this unified objective. The second new formalism, probabilistic soft logic (PSL), is a probabilistic programming language that makes HL-MRFs easy to define using a syntax based on first-order logic. We introduce an algorithm for inferring most-probable variable assignments (MAP inference) that is much more scalable than general-purpose convex optimization methods, because it uses message passing to take advantage of sparse dependency structures. We then show how to learn the parameters of HL-MRFs. The learned HL-MRFs are as accurate as analogous discrete models, but much more scalable. Together, these algorithms enable HL-MRFs and PSL to model rich, structured data at scales not previously possible.",0
"Title: Advancements in Artificial Intelligence through Combination of Markov Random Fields and Probabilistic Soft Logic  Artificial intelligence (AI) has made significant progress over the past few decades due to advances in deep learning, computer vision, natural language processing, and robotics. One area that remains challenging for AI systems is reasoning and decision making under uncertainty, which is essential for many real-world applications such as autonomous driving, medical diagnosis, and financial forecasting.  In this paper, we propose a novel approach to address this challenge by combining two powerful mathematical frameworks - Markov Random Fields (MRFs) and Probabilistic Soft Logic (PSL). MRFs provide a graphical representation of probabilistic relationships among variables, allowing efficient inference and optimization. PSL provides a flexible framework for modeling complex dependencies and decision rules using logic programming and probability theory.  We introduce hinge-loss Markov random fields (HL-MRF), a new variant of MRFs based on logit functions with a smooth approximation of the hinge loss function. This allows us to model more general types of dependencies, including non-monotonicities and disjunctions, while still maintaining efficiency in inference. We then integrate HL-MRFs into our existing PSL models and demonstrate their effectiveness in several experimental settings.  Our results show that the combination of HL-MRFs and PSL significantly improves performance across different domains compared to state-of-the-art methods. Our approach opens up new possibilities for building AI systems that can reason and make decisions under uncertainty in a principled manner. Overall, our work represents a step forward towards human-level artificial intelligence.",1
"We consider matrix completion for recommender systems from the point of view of link prediction on graphs. Interaction data such as movie ratings can be represented by a bipartite user-item graph with labeled edges denoting observed ratings. Building on recent progress in deep learning on graph-structured data, we propose a graph auto-encoder framework based on differentiable message passing on the bipartite interaction graph. Our model shows competitive performance on standard collaborative filtering benchmarks. In settings where complimentary feature information or structured data such as a social network is available, our framework outperforms recent state-of-the-art methods.",0
"Here is an example abstract without the paper title: ""This paper presents a new method for graph convolutional matrix completion, which improves upon existing methods by incorporating more complex graph structures into the modeling process. Our approach uses a deep learning framework based on message passing networks that enables efficient computation and parallelization across different nodes in the graph. We evaluate our method using several benchmark datasets and compare it against state-of-the-art baselines, demonstrating significant improvements in accuracy. Our results show that the proposed algorithm achieves better performance than previous approaches, making it well-suited for applications such as image processing and computer vision.""",1
"In this paper, we presented a novel convolutional neural network framework for graph modeling, with the introduction of two new modules specially designed for graph-structured data: the $k$-th order convolution operator and the adaptive filtering module. Importantly, our framework of High-order and Adaptive Graph Convolutional Network (HA-GCN) is a general-purposed architecture that fits various applications on both node and graph centrics, as well as graph generative models. We conducted extensive experiments on demonstrating the advantages of our framework. Particularly, our HA-GCN outperforms the state-of-the-art models on node classification and molecule property prediction tasks. It also generates 32% more real molecules on the molecule generation task, both of which will significantly benefit real-world applications such as material design and drug screening.",0
"Graphs have become increasingly important as data structures for representing complex relationships and dependencies among objects within data sets. Unlike traditional relational databases that rely on tables filled with structured and homogeneous data elements such as numbers and strings, graphs organize their entities as nodes and edges that can connect multiple elements at different scales and levels of granularity. By definition, graphs provide an ideal modeling framework for understanding social networks, transportation systems, biological molecules, brain connectivity patterns, financial transactions, weather and climate interactions, cybersecurity threat scenarios, scientific knowledge repositories, and numerous other real-world applications. Because many graph problems involve multiple layers of structure and heterogeneities that affect edge weights and nodal attributes, developing scalable machine learning algorithms that capture high order proximity measures has been challenging. The main contribution of our work is twofold: we first propose a novel, adaptive algorithmic architecture designed specifically to scale up existing state-of-the-art convolutional models for large scale graphs by redefining how messages are passed across network neighborhoods; then, we demonstrate through extensive experiments over several benchmark datasets that the resulting accuracy improvement outperforms all other alternatives. Our approach leads us towards bridging the gap between theory and practice towards making deep learning methods more applicable for complex graph analysis tasks. Keywords: graph neural networks, diffusion kernels, spectral clustering, heat kernel signatures, Chebyshev polynomials, Gauss-Laguerre quadrature rules. (299)",1
"We propose a family of near-metrics based on local graph diffusion to capture similarity for a wide class of data sets. These quasi-metametrics, as their names suggest, dispense with one or two standard axioms of metric spaces, specifically distinguishability and symmetry, so that similarity between data points of arbitrary type and form could be measured broadly and effectively. The proposed near-metric family includes the forward k-step diffusion and its reverse, typically on the graph consisting of data objects and their features. By construction, this family of near-metrics is particularly appropriate for categorical data, continuous data, and vector representations of images and text extracted via deep learning approaches. We conduct extensive experiments to evaluate the performance of this family of similarity measures and compare and contrast with traditional measures of similarity used for each specific application and with the ground truth when available. We show that for structured data including categorical and continuous data, the near-metrics corresponding to normalized forward k-step diffusion (k small) work as one of the best performing similarity measures; for vector representations of text and images including those extracted from deep learning, the near-metrics derived from normalized and reverse k-step graph diffusion (k very small) exhibit outstanding ability to distinguish data points from different classes.",0
"Introducing a new family of near-metrics that can accurately capture similarity across a variety of domains, our proposed method represents a significant advancement over traditional distance metrics like Euclidean distance. By leveraging recent developments in deep learning and nonlinear dimensionality reduction techniques, we create powerful embeddings that capture complex relationships within data sets. These novel embeddings enable us to define a universal similarity measure that outperforms existing methods in both synthetic and real world experiments. In addition, our approach is computationally efficient, allowing for fast similarity computations on large datasets. Our results have important implications for fields ranging from image processing and natural language understanding, to recommendation systems and graph analytics. Overall, this work paves the way towards more accurate similarity measurements that are essential for many artificial intelligence applications.",1
"A recently proposed learning algorithm for massive network-structured data sets (big data over networks) is the network Lasso (nLasso), which extends the well- known Lasso estimator from sparse models to network-structured datasets. Efficient implementations of the nLasso have been presented using modern convex optimization methods. In this paper, we provide sufficient conditions on the network structure and available label information such that nLasso accurately learns a vector-valued graph signal (representing label information) from the information provided by the labels of a few data points.",0
This should summarize what you have written. If you want I can write your manuscript and then the abstract so that the latter reflects the former accurately. To be clear here is what you would like me to do next: Abstract: Summarize the paper such that if someone were searching on the web they could learn what the key insights from reading the document might be without necessarily committing to actually download/read the PDF/paper file (so please don’t use headings). Manuscript: As you wrote it already before the Abstract. You may proceed if you prefer.,1
"We propose Embedding Propagation (EP), an unsupervised learning framework for graph-structured data. EP learns vector representations of graphs by passing two types of messages between neighboring nodes. Forward messages consist of label representations such as representations of words and other attributes associated with the nodes. Backward messages consist of gradients that result from aggregating the label representations and applying a reconstruction loss. Node representations are finally computed from the representation of their labels. With significantly fewer parameters and hyperparameters an instance of EP is competitive with and often outperforms state of the art unsupervised and semi-supervised learning methods on a range of benchmark data sets.",0
Here’s an example of how you could write an abst,1
"Graph-structured data appears frequently in domains including chemistry, natural language semantics, social networks, and knowledge bases. In this work, we study feature learning techniques for graph-structured inputs. Our starting point is previous work on Graph Neural Networks (Scarselli et al., 2009), which we modify to use gated recurrent units and modern optimization techniques and then extend to output sequences. The result is a flexible and broadly useful class of neural network models that has favorable inductive biases relative to purely sequence-based models (e.g., LSTMs) when the problem is graph-structured. We demonstrate the capabilities on some simple AI (bAbI) and graph algorithm learning tasks. We then show it achieves state-of-the-art performance on a problem from program verification, in which subgraphs need to be matched to abstract data structures.",0
"Recurrent Neural Network (RNN) has achieved great successes on tasks such as speech recognition, language modeling, machine translation etc., but at the cost of vanishing gradients during training which lead to slow convergence speed. To solve that problem, researchers propose new RNN architectures such as LSTM and GRU and attention mechanism such as Transformer. Inspired by the recent progress made in natural image processing field, we present a novel neural network architecture called ""Gated Graph Sequence Neural Network"" (GGSNN) which models the input sequence data using graph convolution networks similar to how image data is modeled by convolutional neural networks. We show our proposed method can achieve state-of-art results on different NLP benchmark datasets compared against other popular methods including LSTM, GRU and Attention based models. Our framework is simple yet effective and efficient comparing to other contemporary methods. For future work, we plan to explore more advanced techniques into our framework such as multi-scale feature learning, dynamic weight sharing etc., so as to further improve performance.",1
"Sales forecast is an essential task in E-commerce and has a crucial impact on making informed business decisions. It can help us to manage the workforce, cash flow and resources such as optimizing the supply chain of manufacturers etc. Sales forecast is a challenging problem in that sales is affected by many factors including promotion activities, price changes, and user preferences etc. Traditional sales forecast techniques mainly rely on historical sales data to predict future sales and their accuracies are limited. Some more recent learning-based methods capture more information in the model to improve the forecast accuracy. However, these methods require case-by-case manual feature engineering for specific commercial scenarios, which is usually a difficult, time-consuming task and requires expert knowledge. To overcome the limitations of existing methods, we propose a novel approach in this paper to learn effective features automatically from the structured data using the Convolutional Neural Network (CNN). When fed with raw log data, our approach can automatically extract effective features from that and then forecast sales using those extracted features. We test our method on a large real-world dataset from CaiNiao.com and the experimental results validate the effectiveness of our method.",0
"In recent years, e-commerce sales forecasting has become increasingly important due to the growing popularity of online shopping. Accurate sales predictions can aid businesses in making better decisions regarding inventory management, budget planning, market analysis, and more. Various methods have been proposed over the past few decades that utilize traditional time series modeling techniques, but their effectiveness remains limited in capturing complex relationships between features. To address these limitations, we propose using convolutional neural networks (CNNs) which are commonly used in image recognition tasks for solving challenges related to feature extraction. We aim to investigate whether CNNs can achieve higher accuracy than traditional models in predicting weekly sales by taking advantage of product images as additional data sources. Using real-world datasets from two large e-commerce platforms, our results show promising improvements compared to benchmark baseline models across different evaluation metrics. Our findings demonstrate that incorporating visual content can significantly enhance sales forecasting performance in e-commerce settings. This research opens up new opportunities in harnessing deep learning techniques to extract novel insights from product data for improved decision support.",1
"A number of problems can be formulated as prediction on graph-structured data. In this work, we generalize the convolution operator from regular grids to arbitrary graphs while avoiding the spectral domain, which allows us to handle graphs of varying size and connectivity. To move beyond a simple diffusion, filter weights are conditioned on the specific edge labels in the neighborhood of a vertex. Together with the proper choice of graph coarsening, we explore constructing deep neural networks for graph classification. In particular, we demonstrate the generality of our formulation in point cloud classification, where we set the new state of the art, and on a graph classification dataset, where we outperform other deep learning approaches. The source code is available at https://github.com/mys007/ecc",0
"This abstract summarizes the key points from a research paper titled Dynamic Edge-Conditioned Filters in Convolutional Neural Networks on Graphs. The paper discusses how convolutional neural networks can effectively handle nonlinear feature extraction tasks using graphs, particularly when applied to images and other data that can be represented as labeled graphs. The authors propose a new approach called dynamic edge-conditioned filters (DECFil), which learn different weights for each graph based on their unique properties such as node degree distribution, clustering coefficient, average distance, etc. The DECFil architecture incorporates spatial proximity constraints into the filter design process by enforcing local smoothness within regions connected through edges. The experiments demonstrate that DECFil outperforms traditional convolutional filters across multiple benchmark datasets including MNIST, CIFAR-10/100, NCI1, and PPI. Overall, the findings suggest that dynamically learning per-graph filtering kernels can lead to more efficient and robust graph representation models.",1
"We are in the era of data analytics and data science which is on full bloom. There is abundance of all kinds of data for example biometrics based data, satellite images data, chip-seq data, social network data, sensor based data etc. from a variety of sources. This data abundance is the result of the fact that storage cost is getting cheaper day by day, so people as well as almost all business or scientific organizations are storing more and more data. Most of the real data is multi-dimensional, non-uniform, and big in size, such that it requires a unique pre-processing before analyzing it. In order to make data useful for any kind of analysis, pre-processing is a very important step. This paper presents a unique and novel pre-processing method for multi-dimensional and non-uniform data with the aim of making it uniform and reduced in size without losing much of its value. We have chosen biometric signature data to demonstrate the proposed method as it qualifies for the attributes of being multi-dimensional, non-uniform and big in size. Biometric signature data does not only captures the structural characteristics of a signature but also its behavioral characteristics that are captured using a dynamic signature capture device. These features like pen pressure, pen tilt angle, time taken to sign a document when collected in real-time turn out to be of varying dimensions. This feature data set along with the structural data needs to be pre-processed in order to use it to train a machine learning based model for signature verification purposes. We demonstrate the success of the proposed method over other methods using experimental results for biometric signature data but the same can be implemented for any other data with similar properties from a different domain.",0
"In today's world, big data has become increasingly important, as businesses and organizations seek ways to extract valuable insights from their vast collections of information. However, managing and analyzing large datasets can often prove challenging due to issues such as missing values, outliers, noise, redundancy, and bias. One effective approach to address these problems is through careful pre-processing techniques that can cleanse, normalize, transform, reduce, and select features.  The authors propose a novel data pre-processing method specifically designed to handle multi-dimensional and non-uniform data types. This method draws upon state-of-the art machine learning algorithms, statistical models, pattern recognition approaches, and knowledge representation schemes, among others, which work together seamlessly to achieve optimal results.  Through extensive experimentation, the authors demonstrate the effectiveness of their proposed technique on real-world datasets across a range of applications including computer vision, natural language processing, bioinformatics, social network analysis, spatio-temporal data mining, and recommender systems. They compare their approach against other popular methods, highlighting its unique strengths and advantages.  In conclusion, the proposed data pre-processing method represents a significant advance in the field and holds great promise for researchers and practitioners looking to make better use of their data assets. By providing a simple yet powerful toolkit for handling complex data, the authors have contributed substantially to our understanding of how to prepare data effectively so that we may derive maximum value from it.",1
"With the recent rise in the amount of structured data available, there has been considerable interest in methods for machine learning with graphs. Many of these approaches have been kernel methods, which focus on measuring the similarity between graphs. These generally involving measuring the similarity of structural elements such as walks or paths. Borgwardt and Kriegel proposed the all-paths kernel but emphasized that it is NP-hard to compute and infeasible in practice, favouring instead the shortest-path kernel. In this paper, we introduce a new algorithm for computing the all-paths kernel which is very efficient and enrich it further by including the simple cycles as well. We demonstrate how it is feasible even on large datasets to compute all the paths and simple cycles up to a moderate length. We show how to count labelled paths/simple cycles between vertices of a graph and evaluate a labelled path and simple cycles kernel. Extensive evaluations on a variety of graph datasets demonstrate that the all-paths and cycles kernel has superior performance to the shortest-path kernel and state-of-the-art performance overall.",0
"In recent years, graph kernels have been widely used in machine learning tasks such as node classification and link prediction on graphs. One important challenge in designing graph kernels is how to properly compare subgraph distributions that may differ substantially due to edge deletions, insertions, or modifications. This paper introduces a new graph kernel called the all-paths and cycles (APC) graph kernel which captures both exact and approximate matches. The proposed kernel computes similarities by comparing paths and cycles using random walks, encoding global graph properties through repeated loops and small local structures along random walks. By leveraging the similarity between random walks and Brownian motion on infinite regular trees, we can estimate the distribution of all shortest path lengths and longest cycles in finite graphs accurately without resorting to exhaustive search. Experiments on real datasets show that our approach outperforms state-of-the-art graph kernels significantly across diverse application domains including molecular biology and social networks. Our implementation is available at https://github.com/katharinejarmul/apc_kernel.",1
"Class imbalance is a challenging issue in practical classification problems for deep learning models as well as traditional models. Traditionally successful countermeasures such as synthetic over-sampling have had limited success with complex, structured data handled by deep learning models. In this paper, we propose Deep Over-sampling (DOS), a framework for extending the synthetic over-sampling method to exploit the deep feature space acquired by a convolutional neural network (CNN). Its key feature is an explicit, supervised representation learning, for which the training data presents each raw input sample with a synthetic embedding target in the deep feature space, which is sampled from the linear subspace of in-class neighbors. We implement an iterative process of training the CNN and updating the targets, which induces smaller in-class variance among the embeddings, to increase the discriminative power of the deep representation. We present an empirical study using public benchmarks, which shows that the DOS framework not only counteracts class imbalance better than the existing method, but also improves the performance of the CNN in the standard, balanced settings.",0
"This research proposes a new framework that effectively overcomes the challenges posed by class imbalance issues in deep learning models for image classification tasks. The proposed framework uses an over-sampling method along with feature selection techniques such as Principal Component Analysis (PCA) and Random Projection to balance the data distribution. Experiments on popular benchmark datasets demonstrate that the proposed approach significantly improves the accuracy of the model, outperforming other existing methods. Additionally, the framework has been designed to be efficient, scalable, and easy to implement, making it suitable for real-world applications.",1
"We tackle the problem of collaborative filtering (CF) with side information, through the lens of Gaussian Process (GP) regression. Driven by the idea of using the kernel to explicitly model user-item similarities, we formulate the GP in a way that allows the incorporation of low-rank matrix factorisation, arriving at our model, the Tucker Gaussian Process (TGP). Consequently, TGP generalises classical Bayesian matrix factorisation models, and goes beyond them to give a natural and elegant method for incorporating side information, giving enhanced predictive performance for CF problems. Moreover we show that it is a novel model for regression, especially well-suited to grid-structured data and problems where the dependence on covariates is close to being separable.",0
"This should summarize the main idea behind collaborative filtering (CF) with side information which models users and items as points in high dimensional spaces allowing incorporation of additional features such as demographic attributes etc. Furthermore, it proposes using Gaussian processes over matrix factorization to model CF, resulting in significant performance gains on benchmark datasets. Finally, this work shows how these methods can enable novel applications such as analyzing user preference drift over time in recommender systems. ----------------------------------- This paper explores the use of high dimensional point representation models in the context of collaborative filtering (CF), leveraging additional feature information beyond simple binary interactions to improve recommendation accuracy and provide greater flexibility. In particular, we propose applying Gaussian processes over traditional low rank matrix factorization approaches to capture nonlinear relationships between users and items while enabling the effective utilization of available side information. Our evaluations on well known benchmark datasets demonstrate substantial improvements in prediction quality compared to existing state-of-the art techniques. Further, we highlight potential applications made possible by our approach, including analysis of changes in user preferences over time within recommendersystems. Overall, our study advances the understanding and capabilities of CF under realistic settings that frequently exist in modern day web-scale services.",1
"We propose a novel method to fit and segment multi-structural data via convex relaxation. Unlike greedy methods --which maximise the number of inliers-- this approach efficiently searches for a soft assignment of points to models by minimising the energy of the overall classification. Our approach is similar to state-of-the-art energy minimisation techniques which use a global energy. However, we deal with the scaling factor (as the number of models increases) of the original combinatorial problem by relaxing the solution. This relaxation brings two advantages: first, by operating in the continuous domain we can parallelize the calculations. Second, it allows for the use of different metrics which results in a more general formulation.   We demonstrate the versatility of our technique on two different problems of estimating structure from images: plane extraction from RGB-D data and homography estimation from pairs of images. In both cases, we report accurate results on publicly available datasets, in most of the cases outperforming the state-of-the-art.",0
"""Geometric multi-model fitting (GMF) involves finding the optimal combination of linear models that minimizes geometric distortion while ensuring that each observation falls within the feasible region defined by these models. This problem has been shown to have numerous applications in computer vision, machine learning, control theory, etc.""",1
"Neural embeddings have been used with great success in Natural Language Processing (NLP). They provide compact representations that encapsulate word similarity and attain state-of-the-art performance in a range of linguistic tasks. The success of neural embeddings has prompted significant amounts of research into applications in domains other than language. One such domain is graph-structured data, where embeddings of vertices can be learned that encapsulate vertex similarity and improve performance on tasks including edge prediction and vertex labelling. For both NLP and graph based tasks, embeddings have been learned in high-dimensional Euclidean spaces. However, recent work has shown that the appropriate isometric space for embedding complex networks is not the flat Euclidean space, but negatively curved, hyperbolic space. We present a new concept that exploits these recent insights and propose learning neural embeddings of graphs in hyperbolic space. We provide experimental evidence that embedding graphs in their natural geometry significantly improves performance on downstream tasks for several real-world public datasets.",0
"Graph neural networks have revolutionized computer vision tasks by modeling graph structure data. Recently, researchers have explored hyperbolic space as an alternative geometric framework that captures nontrivial hierarchical relationships among vertices due to their nonzero curvature. Despite these advancements, there has been limited investigation into how to leverage the strengths of both frameworks within a single model. Our proposed method combines graph convolutional layers with a novel attention mechanism based on learned embeddings from hyperbolic geometry. We evaluate our approach using node classification benchmark datasets across varying sizes and domains, demonstrating consistent improvement over competitive baselines while ablatively testing contributions made by each component.",1
"Graph embedding provides an efficient solution for graph analysis by converting the graph into a low-dimensional space which preserves the structure information. In contrast to the graph structure data, the i.i.d. node embedding can be processed efficiently in terms of both time and space. Current semi-supervised graph embedding algorithms assume the labelled nodes are given, which may not be always true in the real world. While manually label all training data is inapplicable, how to select the subset of training data to label so as to maximize the graph analysis task performance is of great importance. This motivates our proposed active graph embedding (AGE) framework, in which we design a general active learning query strategy for any semi-supervised graph embedding algorithm. AGE selects the most informative nodes as the training labelled nodes based on the graphical information (i.e., node centrality) as well as the learnt node embedding (i.e., node classification uncertainty and node embedding representativeness). Different query criteria are combined with the time-sensitive parameters which shift the focus from graph based query criteria to embedding based criteria as the learning progresses. Experiments have been conducted on three public data sets and the results verified the effectiveness of each component of our query strategy and the power of combining them using time-sensitive parameters. Our code is available online at: https://github.com/vwz/AGE.",0
"Incorporating external resources into graph embedding can improve performance by providing additional context. However, actively selecting relevant resources is challenging due to their large number and diversity. We propose a novel active learning approach that utilizes human feedback to select informative nodes from an initial set of candidates. Our method adapts the sampling distribution based on human labels, which helps reduce uncertainty in later iterations. Experimental results show significant improvement over random selection baselines across several datasets and metrics. This work enables efficient use of human expertise while addressing scalability issues. It has applications in network analysis tasks such as node classification, community detection, and link prediction.",1
"Brain imaging data such as EEG or MEG are high-dimensional spatiotemporal data often degraded by complex, non-Gaussian noise. For reliable analysis of brain imaging data, it is important to extract discriminative, low-dimensional intrinsic representation of the recorded data. This work proposes a new method to learn the low-dimensional representations from the noise-degraded measurements. In particular, our work proposes a new deep neural network design that integrates graph information such as brain connectivity with fully-connected layers. Our work leverages efficient graph filter design using Chebyshev polynomial and recent work on convolutional nets on graph-structured data. Our approach exploits graph structure as the prior side information, localized graph filter for feature extraction and neural networks for high capacity learning. Experiments on real MEG datasets show that our approach can extract more discriminative representations, leading to improved accuracy in a supervised classification task.",0
"Graph signal processing (GSP) has emerged as a powerful tool for analyzing data that can be represented by graphs, such as neuroimaging data from functional magnetic resonance imaging (fMRI), which allows researchers to study human brain function at high spatial resolution. In recent years, deep neural networks have shown great promise in processing complex data sets, including those represented as graph signals. This paper presents a new framework that leverages the advantages of both GSP and deep learning techniques to perform brain imaging analysis. We propose using deep neural networks directly on graph signals, without the need for any additional preprocessing steps. Our method can effectively capture the structural information present in fMRI data while maintaining the power of deep learning architectures. Experiments conducted on simulated and real fMRI data demonstrate the superior performance of our approach over traditional methods and other state-of-the-art techniques. This work represents a step towards the development of more accurate, efficient, and effective approaches for brain imaging analysis.",1
"This paper introduces a generalization of Convolutional Neural Networks (CNNs) from low-dimensional grid data, such as images, to graph-structured data. We propose a novel spatial convolution utilizing a random walk to uncover the relations within the input, analogous to the way the standard convolution uses the spatial neighborhood of a pixel on the grid. The convolution has an intuitive interpretation, is efficient and scalable and can also be used on data with varying graph structure. Furthermore, this generalization can be applied to many standard regression or classification problems, by learning the the underlying graph. We empirically demonstrate the performance of the proposed CNN on MNIST, and challenge the state-of-the-art on Merck molecular activity data set.",0
"In recent years, deep learning has emerged as one of the most powerful tools in artificial intelligence due to its ability to tackle complex problems across various domains. Among them, convolutional neural networks (CNN) have been particularly successful, especially when dealing with data represented by grid structures such as images and videos. However, many types of data are naturally modeled as graphs rather than grids, such as social interactions, protein interactions, and knowledge graphs. These graph-structured datasets pose unique challenges that current CNN architectures cannot effectively handle.  This paper presents a generalization of CNNs to work with graph-structured data called GCNets (graph convolutional neural nets). Our method extends standard CNN techniques to operate on graph domains via several key innovations:   * We introduce node initialization layers to learn vertex representations from sparse, unnormalized graph inputs directly without requiring input normalization. * Edge conditioning layers model edge relationships for each channel separately enabling better control over propagation patterns. * A subgraph pooling layer provides a flexible mechanism to merge information from multiple channels. By stacking these three layers together, our GCNets can propagate feature messages along edges and update vertex features within a mini-batch gradient descent framework suitable for large datasets.  In addition to our theoretical analysis, we demonstrate the effectiveness of GCNets through extensive experiments using both semi-synthetic and real-world benchmark datasets. Results indicate that GCNets outperform competitive baselines including state-of-the-art methods tailored specifically for certain tasks. With broad application potential, GCNets establish a new family of models capable of harnessing graph structure with CNN architectures for improved performance in deep learning applied to graph structured data.",1
"Many different classification tasks need to manage structured data, which are usually modeled as graphs. Moreover, these graphs can be dynamic, meaning that the vertices/edges of each graph may change during time. Our goal is to jointly exploit structured data and temporal information through the use of a neural network model. To the best of our knowledge, this task has not been addressed using these kind of architectures. For this reason, we propose two novel approaches, which combine Long Short-Term Memory networks and Graph Convolutional Networks to learn long short-term dependencies together with graph structure. The quality of our methods is confirmed by the promising results achieved.",0
"Abstract: This paper proposes the use of dynamic graph convolutional networks (DGCN) for image classification tasks. DGCN builds on recent advances in graph neural network research, which have focused largely on static graphs that assume stationary relationships among nodes. In contrast, DGCN incorporates temporal dynamics into the process by learning both time-invariant and time-varying features of the data, resulting in more effective representations for image classification problems. We apply our methodology to several benchmark datasets and achieve state-of-the art performance on all of them, demonstrating the utility of DGCN for computer vision applications. Overall, we believe that the combination of spatial and temporal processing in DGCN has significant potential for improving results in other domains as well.",1
"This paper describes structuring data and constructing plots to explore forest classification models interactively. A forest classifier is an example of an ensemble, produced by bagging multiple trees. The process of bagging and combining results from multiple trees, produces numerous diagnostics which, with interactive graphics, can provide a lot of insight into class structure in high dimensions. Various aspects are explored in this paper, to assess model complexity, individual model contributions, variable importance and dimension reduction, and uncertainty in prediction associated with individual observations. The ideas are applied to the random forest algorithm, and to the projection pursuit forest, but could be more broadly applied to other bagged ensembles. Interactive graphics are built in R, using the ggplot2, plotly, and shiny packages.",0
"This study presents a new approach to diagnose forest classifiers using interactive graphics in the R programming language. Traditionally, evaluating complex models like random forest classifiers can be challenging due to their sensitivity to hyperparameters and importance scoring methods. To address these issues, we developed a suite of custom visualizations that allow users to quickly identify issues such as overfitting, underfitting, and variable importance imbalances. These graphics enable researchers to rapidly diagnose problems and make data-driven decisions on how to improve model performance. Through case studies and user feedback, our methodology has been shown to provide valuable insights into random forest behavior and enhance the overall model building process. Overall, our work provides a practical solution for improving the interpretability and usability of modern machine learning algorithms.",1
"This paper presents a novel method for structural data recognition using a large number of graph models. In general, prevalent methods for structural data recognition have two shortcomings: 1) Only a single model is used to capture structural variation. 2) Naive recognition methods are used, such as the nearest neighbor method. In this paper, we propose strengthening the recognition performance of these models as well as their ability to capture structural variation. The proposed method constructs a large number of graph models and trains decision trees using the models. This paper makes two main contributions. The first is a novel graph model that can quickly perform calculations, which allows us to construct several models in a feasible amount of time. The second contribution is a novel approach to structural data recognition: graph model boosting. Comprehensive structural variations can be captured with a large number of graph models constructed in a boosting framework, and a sophisticated classifier can be formed by aggregating the decision trees. Consequently, we can carry out structural data recognition with powerful recognition capability in the face of comprehensive structural variation. The experiments shows that the proposed method achieves impressive results and outperforms existing methods on datasets of IAM graph database repository.",0
"This study presents a novel approach to structured data recognition using graph model boosting (GMB). GMB combines the power of graph models, such as Hidden Markov Models (HMM) and Conditional Random Fields (CRF), with the strength of ensemble methods like boosting. Our method leverages the accuracy and interpretability of these models by ensuring that they make consistent predictions across multiple iterations, while still allowing them to capture complex dependencies within the data. We evaluate our method on two benchmark datasets and demonstrate significant improvements over state-of-the art approaches. Our results show that GMB can effectively identify structured patterns in diverse types of data, including text, images, and biological sequences. Overall, our work represents a promising step towards advanced machine learning techniques for structured data analysis.",1
We present a scalable approach for semi-supervised learning on graph-structured data that is based on an efficient variant of convolutional neural networks which operate directly on graphs. We motivate the choice of our convolutional architecture via a localized first-order approximation of spectral graph convolutions. Our model scales linearly in the number of graph edges and learns hidden layer representations that encode both local graph structure and features of nodes. In a number of experiments on citation networks and on a knowledge graph dataset we demonstrate that our approach outperforms related methods by a significant margin.,0
"In recent years, semi-supervised learning has become increasingly popular due to its ability to leverage large amounts of unlabeled data to improve model accuracy on small labeled datasets. One approach that has gained attention in this area is graph convolutional networks (GCNs), which can effectively capture spatial relationships between nodes in a graph. However, there remains a significant gap between state-of-the-art supervised and semi-supervised methods using GCNs. This paper presents a novel framework for semi-supervised classification using GCNs that addresses this gap by leveraging both labeled and unlabeled data in a more effective manner than previous approaches. Our method introduces two key components: a self-training module that utilizes the predictions from the current model as pseudo labels for unlabeled data, and a multi-scale neighborhood sampling strategy that enables better exploration of local and global geometric structures within the network. Experimental results on several benchmark datasets demonstrate the superior performance of our proposed approach compared to other semi-supervised learning methods based on GCNs.",1
"The success of kernel methods has initiated the design of novel positive semidefinite functions, in particular for structured data. A leading design paradigm for this is the convolution kernel, which decomposes structured objects into their parts and sums over all pairs of parts. Assignment kernels, in contrast, are obtained from an optimal bijection between parts, which can provide a more valid notion of similarity. In general however, optimal assignments yield indefinite functions, which complicates their use in kernel methods. We characterize a class of base kernels used to compare parts that guarantees positive semidefinite optimal assignment kernels. These base kernels give rise to hierarchies from which the optimal assignment kernels are computed in linear time by histogram intersection. We apply these results by developing the Weisfeiler-Lehman optimal assignment kernel for graphs. It provides high classification accuracy on widely-used benchmark data sets improving over the original Weisfeiler-Lehman kernel.",0
"This paper presents a new framework for learning graph kernels that are both valid (have desirable mathematical properties) and optimal (maximize some notion of similarity). We focus on optimal assignment kernels, which measure the quality of matchings between graphs. We show that these kernels can capture important structural information about graphs while still having good performance on benchmark datasets. Our contributions include theoretical analysis of the properties of optimal assignment kernels, experimental evaluation of their effectiveness on several tasks such as node classification and edge prediction, and implementation details for efficient computation. Overall, our results demonstrate the potential of optimal assignment kernels as a powerful tool for graph representation and analysis in machine learning applications.",1
Computational approaches to drug discovery can reduce the time and cost associated with experimental assays and enable the screening of novel chemotypes. Structure-based drug design methods rely on scoring functions to rank and predict binding affinities and poses. The ever-expanding amount of protein-ligand binding and structural data enables the use of deep machine learning techniques for protein-ligand scoring.   We describe convolutional neural network (CNN) scoring functions that take as input a comprehensive 3D representation of a protein-ligand interaction. A CNN scoring function automatically learns the key features of protein-ligand interactions that correlate with binding. We train and optimize our CNN scoring functions to discriminate between correct and incorrect binding poses and known binders and non-binders. We find that our CNN scoring function outperforms the AutoDock Vina scoring function when ranking poses both for pose prediction and virtual screening.,0
"This paper presents a novel method for predicting protein-ligand binding affinity using convolutional neural networks (CNN). In recent years, deep learning methods have shown great promise in improving prediction accuracy across diverse biochemical tasks. However, despite their successes, most state-of-the-art systems still rely on handcrafted features or preprocess the data into simpler representations before feeding them into CNN models. We take a step towards mitigating these limitations by utilizing raw molecular structures as input directly, without any feature engineering. Our approach leverages the inductive biases provided by traditional machine learning techniques while maintaining a high degree of interpretability due to our end-to-end design. To evaluate the performance of our proposed model, we conduct extensive experiments on two benchmark datasets: the Directory of Useful Decoys (DUD) and the Platinum DUD. Results show that our method outperforms several established machine learning algorithms in both cases, demonstrating the potential applicability of direct molecule representation in ligand docking problems. With this promising result, further research should focus on extending our system towards more complex predictions such as pose ranking and metabolic profiling. Ultimately, successful integration of advanced computer vision techniques like those presented here may lead to improved drug discovery pipelines and faster development of novel therapeutics.",1
"Deep learning has achieved a remarkable performance breakthrough in several fields, most notably in speech recognition, natural language processing, and computer vision. In particular, convolutional neural network (CNN) architectures currently produce state-of-the-art performance on a variety of image analysis tasks such as object detection and recognition. Most of deep learning research has so far focused on dealing with 1D, 2D, or 3D Euclidean-structured data such as acoustic signals, images, or videos. Recently, there has been an increasing interest in geometric deep learning, attempting to generalize deep learning methods to non-Euclidean structured data such as graphs and manifolds, with a variety of applications from the domains of network analysis, computational social science, or computer graphics. In this paper, we propose a unified framework allowing to generalize CNN architectures to non-Euclidean domains (graphs and manifolds) and learn local, stationary, and compositional task-specific features. We show that various non-Euclidean CNN methods previously proposed in the literature can be considered as particular instances of our framework. We test the proposed method on standard tasks from the realms of image-, graph- and 3D shape analysis and show that it consistently outperforms previous approaches.",0
"This abstract introduces geometric deep learning on graphs and manifolds using mixture model convolutional neural networks (CNNs). In recent years, graph data has become increasingly important due to its widespread application in computer vision, natural language processing, recommendation systems, and many other fields. Traditional models have limitations in dealing with such high-dimensional nonlinear complex structures like graphs. However, the use of mixtures of experts and CNN layers can significantly improve results over traditional methods. We present several case studies involving image generation tasks that showcase our approach's performance in terms of generating higher quality images. Additionally, we provide an error analysis of our technique for better understanding of how it works. Lastly, we compare our method with prior art techniques based on reconstruction errors and visual inspection criteria.",1
"We introduce the variational graph auto-encoder (VGAE), a framework for unsupervised learning on graph-structured data based on the variational auto-encoder (VAE). This model makes use of latent variables and is capable of learning interpretable latent representations for undirected graphs. We demonstrate this model using a graph convolutional network (GCN) encoder and a simple inner product decoder. Our model achieves competitive results on a link prediction task in citation networks. In contrast to most existing models for unsupervised learning on graph-structured data and link prediction, our model can naturally incorporate node features, which significantly improves predictive performance on a number of benchmark datasets.",0
"Machine learning methods based on autoencoder neural networks have been increasingly popular over recent years due their ability to learn representations from raw data without explicit supervision. In particular, variational graph auto-encoders (VGAEs) have emerged as powerful models capable of representing high-dimensional inputs through the combination of local latent variables learned by linear regression steps within a probabilistically motivated framework. VGAEs provide several benefits compared to traditional auto-encoders, including better interpretability, improved robustness and scalability to larger datasets. This work provides an extensive review of the literature related to variational graph auto-encoders, covering topics such as architecture, training objective, inference, applications, extensions and limitations. Furthermore, we propose a novel formulation of VGAEs which addresses some of the current issues related to its normalizing flows approximation that leads to more efficient sampling procedure. We evaluate our proposed method on standard benchmark datasets for reconstruction problems and show state-of-the art results. Overall, the proposed method has significant potential for use in real world applications where representation learning is critical such as natural language processing, computer vision and recommendation systems among others.",1
"We propose a new algorithm for fast approximate nearest neighbor search based on the properties of ordered vectors. Data vectors are classified based on the index and sign of their largest components, thereby partitioning the space in a number of cones centered in the origin. The query is itself classified, and the search starts from the selected cone and proceeds to neighboring ones. Overall, the proposed algorithm corresponds to locality sensitive hashing in the space of directions, with hashing based on the order of components. Thanks to the statistical features emerging through ordering, it deals very well with the challenging case of unstructured data, and is a valuable building block for more complex techniques dealing with structured data. Experiments on both simulated and real-world data prove the proposed algorithm to provide a state-of-the-art performance.",0
"In this paper, we present a novel method for approximate nearest neighbor search based on order statistics. We propose a robust algorithm that can efficiently find the k closest neighbors to a query point in high dimensional spaces, while offering strong guarantees on the accuracy of the results returned. Our approach leverages the power of order statistics to provide an efficient indexing mechanism that can effectively capture local structures in data distributions. This enables our method to achieve state-of-the-art performance across a variety of datasets and distance metrics. Additionally, we address key challenges such as scalability, sparsity handling, and space efficiency by incorporating advanced techniques such as hierarchical clustering and randomized projections. Extensive experiments demonstrate that our proposed method outperforms current state-of-the-art methods on several benchmark datasets and real-world applications. Overall, our work provides a significant advance in the field of nearneighbor search with promising implications for a wide range of applications including computer vision, natural language processing, and machine learning.",1
"Current approaches for fine-grained recognition do the following: First, recruit experts to annotate a dataset of images, optionally also collecting more structured data in the form of part annotations and bounding boxes. Second, train a model utilizing this data. Toward the goal of solving fine-grained recognition, we introduce an alternative approach, leveraging free, noisy data from the web and simple, generic methods of recognition. This approach has benefits in both performance and scalability. We demonstrate its efficacy on four fine-grained datasets, greatly exceeding existing state of the art without the manual collection of even a single label, and furthermore show first results at scaling to more than 10,000 fine-grained categories. Quantitatively, we achieve top-1 accuracies of 92.3% on CUB-200-2011, 85.4% on Birdsnap, 93.4% on FGVC-Aircraft, and 80.8% on Stanford Dogs without using their annotated training sets. We compare our approach to an active learning approach for expanding fine-grained datasets.",0
"One of the central challenges facing modern computer vision systems is how to accurately recognize fine-grained distinctions within complex datasets. In recent years, researchers have proposed many approaches to tackling this problem, from utilizing large amounts of labeled data to employing powerful deep learning models. However, one underappreciated factor that has emerged as surprisingly effective at improving recognition performance is the use of noisy data. This paper investigates the unexpected effectiveness of noisy data for fine-grained recognition tasks by analyzing numerous case studies across multiple domains. We find that incorporating even small amounts of noisy data can significantly improve system accuracy, often surpassing other commonly employed techniques such as augmentation or model ensemble methods. Our results provide insight into why noisy data may act as regularization, encourage more robust features, and promote generalizability. These observations contribute important new insights into the design and training of computer vision systems. Overall, our work highlights the unanticipated power of noisy data for enhancing fine-grained recognition capabilities, offering exciting opportunities for future advancements in machine learning and artificial intelligence.",1
"Multivariate time series naturally exist in many fields, like energy, bioinformatics, signal processing, and finance. Most of these applications need to be able to compare these structured data. In this context, dynamic time warping (DTW) is probably the most common comparison measure. However, not much research effort has been put into improving it by learning. In this paper, we propose a novel method for learning similarities based on DTW, in order to improve time series classification. Making use of the uniform stability framework, we provide the first theoretical guarantees in the form of a generalization bound for linear classification. The experimental study shows that the proposed approach is efficient, while yielding sparse classifiers.",0
"In this work we present an approach to time series classification that relies on similarity learning. By treating each class as a distribution over features, we can represent them using sets of exemplars drawn from known instances of those classes. These representations allow us to compare new test examples against all known instantiations of the training data, which gives our model both interpretability and robustness against changes in input distributions at testing time. We evaluate our method extensively across multiple benchmark datasets including ECG, MNIST-DVS, Crop Disease Classification, and Gait Verification, demonstrating strong performance compared to state-of-the-art methods. Our framework has promising applications in areas where interpretable models are desirable, such as healthcare diagnosis and medical decision support systems. This work provides evidence that similarity learning approaches can achieve competitive results while offering insights into how machine learning algorithms make predictions.",1
"We propose a novel kernel based post selection inference (PSI) algorithm, which can not only handle non-linearity in data but also structured output such as multi-dimensional and multi-label outputs. Specifically, we develop a PSI algorithm for independence measures, and propose the Hilbert-Schmidt Independence Criterion (HSIC) based PSI algorithm (hsicInf). The novelty of the proposed algorithm is that it can handle non-linearity and/or structured data through kernels. Namely, the proposed algorithm can be used for wider range of applications including nonlinear multi-class classification and multi-variate regressions, while existing PSI algorithms cannot handle them. Through synthetic experiments, we show that the proposed approach can find a set of statistically significant features for both regression and classification problems. Moreover, we apply the hsicInf algorithm to a real-world data, and show that hsicInf can successfully identify important features.",0
"This paper presents new methods for performing inference after model selection using kernel methods. We focus on situations where many candidate models have been fit to data and we would like to select one or a few promising models to investigate further. Our approach builds upon classical post hoc techniques that involve fitting additional parameters to only those parts of the model space that survive selection, which can lead to estimates that suffer from excess variability and poor coverage properties. Instead, we develop new kernels that directly incorporate selected model components into the analysis, allowing us to obtain accurate posterior inference without requiring any additional tuning. Our methods are shown through simulation studies to provide improved frequentist predictive performance and uncertainty quantification compared to standard model averaging procedures, while offering advantages over alternative Bayesian approaches by providing well-calibrated point predictions and uncertainty intervals even under complex or misspecified models.",1
"This paper proposes a two-view deterministic geometric model fitting method, termed Superpixel-based Deterministic Fitting (SDF), for multiple-structure data. SDF starts from superpixel segmentation, which effectively captures prior information of feature appearances. The feature appearances are beneficial to reduce the computational complexity for deterministic fitting methods. SDF also includes two original elements, i.e., a deterministic sampling algorithm and a novel model selection algorithm. The two algorithms are tightly coupled to boost the performance of SDF in both speed and accuracy. Specifically, the proposed sampling algorithm leverages the grouping cues of superpixels to generate reliable and consistent hypotheses. The proposed model selection algorithm further makes use of desirable properties of the generated hypotheses, to improve the conventional fit-and-remove framework for more efficient and effective performance. The key characteristic of SDF is that it can efficiently and deterministically estimate the parameters of model instances in multi-structure data. Experimental results demonstrate that the proposed SDF shows superiority over several state-of-the-art fitting methods for real images with single-structure and multiple-structure data.",0
"This research presents a new approach for two-view deterministic fitting using superpixels. In traditional methods, image data is processed one pixel at a time, which can lead to inaccuracies and limited functionality in dealing with complex images that contain multiple structures. By using superpixels as units of processing instead, the proposed method allows for more robust representation and better handling of multiple structures within an image. Experimental results demonstrate improved accuracy and efficiency over existing techniques in a variety of real-world applications including satellite imagery, medical imaging, and remote sensing. Overall, this work advances the state-of-the-art in computer vision by providing a powerful tool for handling challenging image datasets.",1
"In this paper, we propose a novel hypergraph based method (called HF) to fit and segment multi-structural data. The proposed HF formulates the geometric model fitting problem as a hypergraph partition problem based on a novel hypergraph model. In the hypergraph model, vertices represent data points and hyperedges denote model hypotheses. The hypergraph, with large and ""data-determined"" degrees of hyperedges, can express the complex relationships between model hypotheses and data points. In addition, we develop a robust hypergraph partition algorithm to detect sub-hypergraphs for model fitting. HF can effectively and efficiently estimate the number of, and the parameters of, model instances in multi-structural data heavily corrupted with outliers simultaneously. Experimental results show the advantages of the proposed method over previous methods on both synthetic data and real images.",0
"This research paper presents a novel approach to geometric model fitting using hypergraphs, which provides a more flexible and accurate representation of shape features compared to traditional graph-based methods. By leveraging the power of hypergraphs, we can capture complex relationships and dependencies among multiple feature points, resulting in improved accuracy and robustness in geometry estimation tasks such as surface reconstruction and pose optimization. Our method offers several advantages over state-of-the-art techniques, including increased scalability and adaptability to different datasets. We validate our proposed method on real-world data sets and demonstrate its effectiveness through extensive experiments and comparisons against existing approaches. Overall, this work advances the field of computer vision and has potential applications in areas ranging from robotics to augmented reality.",1
"A number of applications in engineering, social sciences, physics, and biology involve inference over networks. In this context, graph signals are widely encountered as descriptors of vertex attributes or features in graph-structured data. Estimating such signals in all vertices given noisy observations of their values on a subset of vertices has been extensively analyzed in the literature of signal processing on graphs (SPoG). This paper advocates kernel regression as a framework generalizing popular SPoG modeling and reconstruction and expanding their capabilities. Formulating signal reconstruction as a regression task on reproducing kernel Hilbert spaces of graph signals permeates benefits from statistical learning, offers fresh insights, and allows for estimators to leverage richer forms of prior information than existing alternatives. A number of SPoG notions such as bandlimitedness, graph filters, and the graph Fourier transform are naturally accommodated in the kernel framework. Additionally, this paper capitalizes on the so-called representer theorem to devise simpler versions of existing Thikhonov regularized estimators, and offers a novel probabilistic interpretation of kernel methods on graphs based on graphical models. Motivated by the challenges of selecting the bandwidth parameter in SPoG estimators or the kernel map in kernel-based methods, the present paper further proposes two multi-kernel approaches with complementary strengths. Whereas the first enables estimation of the unknown bandwidth of bandlimited signals, the second allows for efficient graph filter selection. Numerical tests with synthetic as well as real data demonstrate the merits of the proposed methods relative to state-of-the-art alternatives.",0
"In recent years, graph signals have become increasingly important due to their ability to capture complex relationships among data points. However, many real-world graphs are incomplete, corrupted, or simply contain missing values, which can lead to challenges in processing graph signals effectively. To address these issues, researchers have proposed several methods based on different mathematical frameworks such as linear algebra, harmonic analysis, and probability theory. In particular, kernel techniques provide powerful tools for reconstructing complete or high-quality versions of graph signals from partial or noisy measurements. This paper presents a comprehensive overview of kernel-based approaches for reconstructing graph signals. We discuss the key ideas behind popular algorithms such as kernel principal component analysis (KPCA), diffusion maps, and random walk embeddings. Additionally, we highlight the connections between these techniques and other related areas like inverse problems, statistical learning, and deep learning. Finally, we illustrate how kernel methods can achieve state-of-the-art performance in various applications including image compression, bioinformatics, and social network analysis. Overall, our work provides valuable insights into the rich interplay between graph signal reconstruction and machine learning.",1
"In this paper, we propose a novel geometric model fitting method, called Mode-Seeking on Hypergraphs (MSH),to deal with multi-structure data even in the presence of severe outliers. The proposed method formulates geometric model fitting as a mode seeking problem on a hypergraph in which vertices represent model hypotheses and hyperedges denote data points. MSH intuitively detects model instances by a simple and effective mode seeking algorithm. In addition to the mode seeking algorithm, MSH includes a similarity measure between vertices on the hypergraph and a weight-aware sampling technique. The proposed method not only alleviates sensitivity to the data distribution, but also is scalable to large scale problems. Experimental results further demonstrate that the proposed method has significant superiority over the state-of-the-art fitting methods on both synthetic data and real images.",0
"This paper presents a method for mode-seeking on hypergraphs, which can be used for robust geometric model fitting. Traditional methods for geometric model fitting assume that there is only one correct solution, but in reality, there may be multiple possible solutions depending on noise and other factors. In order to handle these situations, our approach uses hypergraphs to represent multiple modes (solutions) simultaneously. We introduce a novel algorithm for searching the space of all possible hyperedges (combinations of vertices), which allows us to find meaningful patterns among the data points. Our experiments show that our method outperforms traditional methods by finding more accurate models even under challenging conditions. Furthermore, we discuss potential applications of our work in areas such as computer vision, robotics, and scientific computing.",1
"By taking the semantic object parsing task as an exemplar application scenario, we propose the Graph Long Short-Term Memory (Graph LSTM) network, which is the generalization of LSTM from sequential data or multi-dimensional data to general graph-structured data. Particularly, instead of evenly and fixedly dividing an image to pixels or patches in existing multi-dimensional LSTM structures (e.g., Row, Grid and Diagonal LSTMs), we take each arbitrary-shaped superpixel as a semantically consistent node, and adaptively construct an undirected graph for each image, where the spatial relations of the superpixels are naturally used as edges. Constructed on such an adaptive graph topology, the Graph LSTM is more naturally aligned with the visual patterns in the image (e.g., object boundaries or appearance similarities) and provides a more economical information propagation route. Furthermore, for each optimization step over Graph LSTM, we propose to use a confidence-driven scheme to update the hidden and memory states of nodes progressively till all nodes are updated. In addition, for each node, the forgets gates are adaptively learned to capture different degrees of semantic correlation with neighboring nodes. Comprehensive evaluations on four diverse semantic object parsing datasets well demonstrate the significant superiority of our Graph LSTM over other state-of-the-art solutions.",0
"This work presents an approach to semantic object parsing using graph Long Short-Term Memory (LSTM) networks. We propose a method that takes as input a scene image and a sentence describing it, and generates an output representing the objects and their relationships described in the sentence. Our model is based on a variant of graph neural networks called Message Passing Neural Networks (MPNN), which have been shown to perform well on semantic segmentation tasks. In contrast to previous approaches, we use a dynamic pooling strategy wherein regions of interest in each iteration are selected by an attention mechanism applied to convolutional feature maps. Additionally, we use several techniques to enforce spatial consistency across iterations, such as edge pooling and a novel boundary refinement module that improves contours near object boundaries. We evaluate our method on two benchmark datasets for instance segmentation and show state-of-the-art results, outperforming other methods using similar architectures but simpler configurations. Finally, we analyze the intermediate features generated during inference to demonstrate the ability of our method to parse semantic scenes. Overall, these results highlight the effectiveness of our approach and suggest future directions for research at the intersection of computer vision and natural language processing.",1
